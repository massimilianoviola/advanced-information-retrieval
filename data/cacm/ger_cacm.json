{"DOCID": "1", "TEXT": "Vorläufiger Bericht - Internationale algebraische Sprache"}
{"DOCID": "2", "TEXT": "Wurzelziehen durch wiederholte Subtraktionen für digitale Computer"}
{"DOCID": "3", "TEXT": "Technikabteilung für Matrixprogrammschemata"}
{"DOCID": "4", "TEXT": "Glossar der Computertechnik und Programmierterminologie"}
{"DOCID": "5", "TEXT": "Zwei Quadratwurzel-Approximationen"}
{"DOCID": "6", "TEXT": "Die Verwendung von Computern in Inspektionsverfahren"}
{"DOCID": "7", "TEXT": "Glossar der Computertechnik und Programmierterminologie"}
{"DOCID": "8", "TEXT": "Zur Äquivalenz und Transformation von Programmschemata"}
{"DOCID": "9", "TEXT": "Vorschlag für ein UNCOL"}
{"DOCID": "10", "TEXT": "Glossar der Computertechnik und Programmierterminologie"}
{"DOCID": "11", "TEXT": "Das Problem der Programmierung der Kommunikation mit wechselnden Maschinen Ein Lösungsvorschlag – Teil 2"}
{"DOCID": "12", "TEXT": "Fehlerschätzung in Runge-Kutta-Verfahren"}
{"DOCID": "13", "TEXT": "Glossar der Computertechnik und Programmierterminologie"}
{"DOCID": "14", "TEXT": "Das Problem der Programmierung der Kommunikation mit wechselnden Maschinen Ein Lösungsvorschlag (Teil 1)"}
{"DOCID": "15", "TEXT": "Rekursive Kurvenanpassungstechnik"}
{"DOCID": "16", "TEXT": "Sekantenmodifikation des Newton-Verfahrens"}
{"DOCID": "17", "TEXT": "Zur Programmierung arithmetischer Operationen"}
{"DOCID": "18", "TEXT": "Einfache automatische Codiersysteme"}
{"DOCID": "19", "TEXT": "Glossar der Computertechnik und Programmierterminologie"}
{"DOCID": "20", "TEXT": "Beschleunigung der Konvergenz iterativer Prozesse: Es wird eine Technik diskutiert, die, wenn sie auf ein iteratives Verfahren zur Lösung einer Gleichung angewendet wird, die Konvergenzrate beschleunigt, wenn die Iteration konvergiert, und eine Konvergenz induziert, wenn die Iteration divergiert. Ein anschauliches Beispiel wird gegeben."}
{"DOCID": "21", "TEXT": "Algebraische Formulierung von Flussdiagrammen"}
{"DOCID": "22", "TEXT": "Abteilung für ungewöhnliche Anwendungen - Automatische Implementierung von Computerlogik"}
{"DOCID": "23", "TEXT": "Binär- und Wahrheitsfunktionsoperationen auf einem Dezimalcomputer mit einem Extraktionsbefehl"}
{"DOCID": "24", "TEXT": "Eine verbesserte Dezimalredundanzprüfung"}
{"DOCID": "25", "TEXT": "Universelle Programmiersysteme"}
{"DOCID": "26", "TEXT": "Eine Subroutinenmethode zur Berechnung von Logarithmen"}
{"DOCID": "27", "TEXT": "Hinweis zu empirischen Grenzen für die Generierung von Bessel-Funktionen"}
{"DOCID": "28", "TEXT": "Anfrage nach Methoden oder Programmen"}
{"DOCID": "29", "TEXT": "Notwendigkeit eines Algorithmus"}
{"DOCID": "30", "TEXT": "Algorithmus zur Analyse logischer Aussagen zur Erstellung einer Wahrheitsfunktionstabelle"}
{"DOCID": "31", "TEXT": "IBM 704 Code-Nundrums"}
{"DOCID": "32", "TEXT": "Tabellen variabler Breite mit binärer Suchfunktion"}
{"DOCID": "33", "TEXT": "Ein programmierter Binärzähler für den IBM-Rechner Typ 650"}
{"DOCID": "34", "TEXT": "Tabellen für die automatische Berechnung"}
{"DOCID": "35", "TEXT": "Eine maschinelle Methode zur Quadratwurzelberechnung"}
{"DOCID": "36", "TEXT": "Ein Queue Network Simulator für IBM 650 und Burroughs 220"}
{"DOCID": "37", "TEXT": "Auswirkungen von Computerentwicklungen"}
{"DOCID": "38", "TEXT": "Eine vorgeschlagene Interpretation in ALGOL"}
{"DOCID": "39", "TEXT": "Das Sekantenverfahren für simultane nichtlineare Gleichungen: Es wird ein Verfahren zur simultanen Lösung eines Systems nicht notwendigerweise linearer Gleichungen, eine Verallgemeinerung des Sekantenverfahrens für eine einzelne Funktion einer Variablen, angegeben."}
{"DOCID": "40", "TEXT": "Finger oder Fäuste? (Die Wahl der Dezimal- oder Binärdarstellung): Das binäre Zahlensystem bietet viele Vorteile gegenüber einer Dezimaldarstellung für einen Hochleistungs-Allzweckcomputer. Die größere Einfachheit einer binären Recheneinheit und die größere Kompaktheit von Binärzahlen tragen beide direkt zur Rechengeschwindigkeit bei. Weniger offensichtlich und vielleicht wichtiger ist die Art und Weise, wie binäre Adressierung und Befehlsformate die Gesamtleistung steigern können. Binäre Adressen sind auch für bestimmte leistungsstarke Operationen wesentlich, die mit dezimalen Befehlsformaten nicht praktikabel sind. Andererseits sind Dezimalzahlen für die Kommunikation zwischen Mensch und Computer unerlässlich. Bei Anwendungen, die die Verarbeitung einer großen Menge von inhärent dezimalen Eingabe- und Ausgabedaten erfordern, kann die Zeit für die Dezimal-Binär-Umwandlung, die von einem rein binären Computer benötigt wird, erheblich sein. Ein langsamerer Dezimaladdierer kann weniger Zeit benötigen als ein schneller binärer Addierer, der eine Addition und zwei Umwandlungen durchführt. Eine sorgfältige Überprüfung der Bedeutung der dezimalen und binären Adressierung und sowohl der binären als auch der dezimalen Datenarithmetik, ergänzt durch effiziente Konvertierungsanweisungen."}
{"DOCID": "41", "TEXT": "Einige Anmerkungen zur Computerforschung in Osteuropa"}
{"DOCID": "42", "TEXT": "Eine neue Methode zur Berechnung von Quadratwurzeln ohne Division"}
{"DOCID": "43", "TEXT": "Eine Technik zur Handhabung von Makrobefehlen"}
{"DOCID": "44", "TEXT": "RUNCIBLE-Algebraische Übersetzung auf einem begrenzten Computer"}
{"DOCID": "45", "TEXT": "Flussgliederung – ein Ersatz für Flussdiagramme"}
{"DOCID": "46", "TEXT": "Multiprogramming STRETCH: Machbarkeitsüberlegungen: Die Tendenz zu zunehmender Parallelität bei Computern wird festgestellt. Die Ausnutzung dieser Parallelität führt zu einer Reihe neuer Probleme im Maschinendesign und in Programmiersystemen. Es werden Mindestanforderungen für die erfolgreiche gleichzeitige Ausführung mehrerer unabhängiger Problemprogramme diskutiert. Diese Anforderungen werden im STRETCH-System durch eine sorgfältig ausgewogene Kombination aus eingebauter und programmierter Logik erfüllt. Es werden Techniken beschrieben, die die Last der programmierten Logik eher auf Systemprogramme (Überwachungsprogramm und Compiler) als auf Problemprogramme legen."}
{"DOCID": "47", "TEXT": "Russischer Besuch bei US-Computern"}
{"DOCID": "48", "TEXT": "Schieberegistercode für Indizierungsanwendungen: In dieser Mitteilung wird die Verwendung eines Schieberegistercodes mit n = 10 zum Anrufen von 64 drahtlosen Telemetriestationen in einer festen zyklischen Reihenfolge beschrieben. Es wird ein hohes Maß an Redundanz verwendet, wodurch ein Einzelfehler-Korrekturcode (\"Minimum-Distance-Three\"-Code) mit 64 10-Bit-Codewörtern als Stationsidentifikationscode verwendet werden kann. Das Einbetten in den Schieberegistercode mit der Periode 1023 erlaubt es, den Code ohne Interpunktion zu verwenden, wobei jeder der Telemetriestationsempfänger einfach empfangene Einsen und Nullen in ein Schieberegister einträgt. Jedes Mal, wenn die gegebene Codekombination auftritt, die die bestimmte Station identifiziert (mit Ausnahme von dummen Fehlerkombinationen mit sehr geringer Wahrscheinlichkeit), wurde sie gerufen. Die Mitteilung beschreibt die Eigenschaften und Anwendung des Codes ausführlich und die Entdeckung des speziellen Beispiels, das auf URAL, dem von der Sowjetunion gebauten Trommelcomputer, der dem indischen statistischen Institut von der United Nations Technical Aid Administration (UNTAA) gespendet wurde, verwendet werden soll."}
{"DOCID": "49", "TEXT": "Wissenschaftliche und geschäftliche Anwendungen (Oracle Curve Plotter)"}
{"DOCID": "50", "TEXT": "Statistische Programme für den IBM 650-Teil II"}
{"DOCID": "51", "TEXT": "Zur Konstruktion von Mikroflussdiagrammen"}
{"DOCID": "52", "TEXT": "Eine effiziente Methode zur Erzeugung gleichmäßig verteilter Punkte auf der Oberfläche einer n-dimensionalen Kugel (Korrigendum)"}
{"DOCID": "53", "TEXT": "Empfehlungen des SHARE ALGOL Komitees"}
{"DOCID": "54", "TEXT": "SALE, eine einfache algebraische Sprache für Ingenieure"}
{"DOCID": "55", "TEXT": "Ein algebraischer Übersetzer"}
{"DOCID": "56", "TEXT": "Vorgeschlagene Symbole für Standardflussdiagramme"}
{"DOCID": "57", "TEXT": "J.E.I.D.A. und sein Rechenzentrum"}
{"DOCID": "58", "TEXT": "LEM-1, Small Size General Purpose Digital Computer Using Magnetic (Ferrite) Elements: Das Papier untersucht einige der Fragen der Entwicklung und Konstruktion eines Allzweck-Digitalcomputers, der kontaktlose magnetische (Ferrit) und kapazitive \"DEZU\" (kapazitiver Langzeitspeicher) verwendet ) Elemente, entwickelt am Labor für elektrische Modellierung VINITYI AN SSSR, unter der Leitung von Professor L.I. Gutenmacher."}
{"DOCID": "59", "TEXT": "Erhebung über Fortschritte und Tendenzen der Entwicklung und Nutzung der automatischen Datenverarbeitung in den Betriebs- und Steuerungssystemen der Bundesregierung, Stand Dezember 1957-III"}
{"DOCID": "60", "TEXT": "Die Alpha-Vektor-Transformation eines Systems linearer Nebenbedingungen"}
{"DOCID": "61", "TEXT": "IBM 709 Bandmatrix-Compiler"}
{"DOCID": "62", "TEXT": "Mehrdimensionale Polynomkurvenanpassung nach der Methode der kleinsten Quadrate"}
{"DOCID": "63", "TEXT": "Oktaldiagramme der binären Konzeption und ihre Anwendbarkeit auf die Computerdesignlogik: Dieses Papier datiert die Entstehung der binären Konzeption vor etwa 5000 Jahren und Oktaldiagramme vor etwa 4800 Jahren, wie sie von den alten Chinesen abgeleitet wurden. Es analysiert die Anwendbarkeit binärer Trinitäten der Oktaldiagramme auf die Designlogik moderner Elektronik-Digital-Computer."}
{"DOCID": "64", "TEXT": "Bemerkungen zu ALGOL und Symbolmanipulation"}
{"DOCID": "65", "TEXT": "Bericht des ALGOL-Unterausschusses - Erweiterungen"}
{"DOCID": "66", "TEXT": "Ein Vorschlag für einen verallgemeinerten Kartencode für 256 Zeichen"}
{"DOCID": "67", "TEXT": "Mitteleuropäische Computer"}
{"DOCID": "68", "TEXT": "Die Rolle der Universität in Computern, Datenverarbeitung und verwandten Bereichen: Es wurde eine Studie über Universitätsprogramme in den Vereinigten Staaten in den Bereichen Computer, Datenverarbeitung, Betriebsforschung und anderen eng verwandten Bereichen durchgeführt. Untersucht wurden Universitätspolitik, Organisation, Verwaltung, Fakultäten, Studierende, Forschung, Curricula, Ausstattung und Finanzierung. Es wird ein integriertes Universitätsprogramm empfohlen, das die Überzeugung widerspiegelt, dass sich viele gegenwärtige Aktivitäten im Zusammenhang mit Computern zu Disziplinen entwickeln werden und als solche die legitime Domäne des Universitätswissenschaftlers sind. Angaben zu einer empfohlenen Graduiertenschule \"Informatik\" werden gemacht."}
{"DOCID": "69", "TEXT": "Statistische Programme für den IBM 650 – Teil I: Es wird eine Sammlung von kurzen Beschreibungen von statistischen Programmen gegeben, die derzeit in Universitätsrechenzentren mit IBM 650 verwendet werden."}
{"DOCID": "70", "TEXT": "Konstruktion eines Satzes von Testmatrizen: Dieses Papier entwickelt die Gleichungen und Eigenschaften eines Satzes von Testmatrizen, die bei der Bestimmung der Genauigkeit von Routinen zum Auffinden der Inversen, Determinanten und/oder Eigenwerte einer Matrix nützlich sind."}
{"DOCID": "71", "TEXT": "Vorschlag für ein realisierbares Programmiersystem: Dieses Dokument schlägt den Entwurf einer Programmiereinrichtung vor (die selbst einen digitalen Computer und ein Programm umfasst), die die Erstellung von Echtzeitprogrammen im großen Maßstab unterstützen wird. Diese Einrichtung soll in der Lage sein, Programme für eine Vielzahl von Maschinen mit ähnlichen Eigenschaften wie der Computer der Einrichtung vorzubereiten. Eine der Grundannahmen ist, dass genügend Speicher mit wahlfreiem Zugriff verfügbar sein wird, um die Notwendigkeit zu vermeiden, ein konstruiertes Programm auf andere als eine triviale Weise zu segmentieren. Obwohl diese Annahme etwas unrealistisch ist, soll sie eine Gelegenheit bieten, sich auf die anderen Aspekte der Programmkonstruktion zu konzentrieren. Das Programmiersystem sollte die Entdeckung so vieler Fehler wie möglich in Quellprogrammanweisungen betonen, bevor es versucht, ein Objektprogramm zu konstruieren. Zu den empfohlenen Computereigenschaften gehören ein Programmunterbrechungsschema, ein großer Zeichensatz und eine indirekte Adressierung."}
{"DOCID": "72", "TEXT": "Ein Bildungsprogramm in Computing"}
{"DOCID": "73", "TEXT": "Ein Echtzeit-Datenassimilator"}
{"DOCID": "74", "TEXT": "Ein Hochgeschwindigkeits-Sortierverfahren"}
{"DOCID": "75", "TEXT": "Parameterschätzung für einfache nichtlineare Modelle"}
{"DOCID": "76", "TEXT": "Binäre Umwandlung eines Dezimalbruchs mit fester Dezimalgenauigkeit"}
{"DOCID": "77", "TEXT": "Über GAT und die Konstruktion von Übersetzern"}
{"DOCID": "78", "TEXT": "Bemerkungen zur praktischen Lösung von Merkmalswertproblemen: Diese Arbeit befasst sich mit der praktischen Lösung von Merkmalswertproblemen für eine gewöhnliche Differentialgleichung. Es ist sofort ersichtlich, dass sequentielle Computer, seien sie digital oder analog, eher Anfangswertprobleme als Grenzwertprobleme lösen, und dass ein mathematisches Verfahren gefunden werden muss, um die Unzulänglichkeit der Maschine zu kompensieren. (Das Kompensieren von Maschinenunvollkommenheiten ist natürlich die normale Tätigkeit des numerischen Analytikers.) Eine Reihe anderer Artikel haben spezielle Geräte auf spezielle Probleme angewendet. Der Zweck dieser Notiz besteht darin, einen mathematischen Rahmen oder ein Modell für diese praktischen Verfahren zu erstellen und somit bei der Verwendung und Erweiterung der Ideen in anderen speziellen Problemen zu helfen."}
{"DOCID": "79", "TEXT": "Programmierung für eine Maschine mit einem erweiterten Adressberechnungsmechanismus"}
{"DOCID": "80", "TEXT": "Eine Technik zur Berechnung kritischer Drehzahlen flexibler Wellen auf einem automatischen Computer"}
{"DOCID": "81", "TEXT": "NORC-Hochgeschwindigkeitsdrucker"}
{"DOCID": "82", "TEXT": "Umgang mit Identifikatoren als interne Symbole in Sprachprozessoren: Es wird untersucht, wie computerorientierte Symbole programmiererorientierte Symbole in Sprachprozessoren ersetzen, und es wird ein praktikables Verfahren dafür vorgestellt."}
{"DOCID": "83", "TEXT": "Ein Besuch in Rechenzentren in der Sowjetunion"}
{"DOCID": "84", "TEXT": "Übersicht über Fortschritte und Tendenzen der Entwicklung und Nutzung der automatischen Datenverarbeitung in Unternehmens- und Managementsteuerungssystemen der Bundesregierung, Stand Dezember 1957-II (Teil 2 siehe CA590406)"}
{"DOCID": "85", "TEXT": "Fehleranalyse in der Gleitkommaarithmetik"}
{"DOCID": "86", "TEXT": "Erhebung über Fortschritte und Tendenzen der Entwicklung und Nutzung der automatischen Datenverarbeitung in den Unternehmens- und Managementsteuerungssystemen der Bundesregierung, Stand Dezember 1957"}
{"DOCID": "87", "TEXT": "Eine Anmerkung zu einer Methode zum gleichmäßigen Erzeugen von Punkten auf N-dimensionalen Kugeln"}
{"DOCID": "88", "TEXT": "Eine effiziente Methode zur Erzeugung gleichmäßig verteilter Punkte auf der Oberfläche einer n-dimensionalen Kugel"}
{"DOCID": "89", "TEXT": "Eine Routine zum Finden der Lösung simultaner linearer Gleichungen mit Polynomkoeffizienten"}
{"DOCID": "90", "TEXT": "Binäre Arithmetik für diskret variable Wortlänge in einem seriellen Computer"}
{"DOCID": "91", "TEXT": "Ein mathematisches Verfahren zur Maschinenteilung"}
{"DOCID": "92", "TEXT": "Eine Checkliste der Intelligenz für Programmiersysteme: Es gibt bemerkenswerte Unterschiede im Grad der Ausgereiftheit verschiedener Programmiersysteme. Eine besondere Manifestation ist der Dschungel von verschiedenen Geräten zur Reproduktion begrenzter menschlicher Entscheidungsprozesse. Hier wird der Versuch unternommen, eine systematische Klassifizierung der verschiedenen Vorrichtungen zu beginnen, um den Computer dazu zu erziehen, die Entscheidungsfunktionen eines oder mehrerer menschlicher Bediener zu übernehmen, sowohl diejenigen, die sich bisher als realisierbar erwiesen haben, als auch solche, die für den Computer höchst wünschenswert sind Zukunft."}
{"DOCID": "93", "TEXT": "Von Formeln zu computerorientierter Sprache: Es wird eine Technik gezeigt, die es einem Computer ermöglicht, einfache algebraische Formeln in einen Computercode mit drei Adressen zu übersetzen."}
{"DOCID": "94", "TEXT": "Ein iteratives Verfahren zum Anpassen der logistischen Kurve: Es wird ein iteratives Verfahren angegeben, um eine logistische Kurve der besten Anpassung der kleinsten Quadrate an einen Satz zweidimensionaler Punkte zu finden."}
{"DOCID": "95", "TEXT": "Eliminierung spezieller Funktionen aus Differentialgleichungen: Ein Satz gewöhnlicher Differentialgleichungen, der mathematische Funktionen enthält, die die Verwendung von Unterprogrammen für die numerische Lösung durch elektronische Computer, Tabellendaten für die numerische Lösung durch Handberechnung oder Funktionsgeneratoren erfordern, wenn analoge Methoden angewendet werden, kann manchmal erweitert werden zu einem äquivalenten Satz von Gleichungen, die die Funktionen nicht enthalten. Dies ist sinnvoll, wenn diese Funktionen hinreichend einfache Differentialgleichungen erfüllen. Zu den Funktionen, die durch dieses Verfahren eliminiert werden können, gehören also die trigonometrischen, inversen trigonometrischen, exponentiellen und viele andere transzendente Funktionen."}
{"DOCID": "96", "TEXT": "Zur Berechnung von Strahlungsintegralen: Es werden der relative Nutzen und die Kosten von vier Möglichkeiten zur Auswertung typischer Strahlungsintegrale mit sphärischen Bessel-Funktionen untersucht. Diese Verfahren sind Tischmaschinenauswertung einer endlichen Reihe, Integration der geeigneten Differentialgleichung durch einen Reeves Electronic Analog Computer und durch einen Litton 40 IBM 704 Computer. Die Ergebnisse sind allgemein auf Gleichungen anwendbar, die von einer Helmholtz- oder Wellengleichung getrennt sind."}
{"DOCID": "97", "TEXT": "Signal Corps Forschung und Entwicklung zur automatischen Programmierung digitaler Computer"}
{"DOCID": "98", "TEXT": "Der Arithmetic Translator-Compiler des IBM FORTRAN Automatic Coding System"}
{"DOCID": "99", "TEXT": "Mögliche Modifikationen der internationalen algebraischen Sprache"}
{"DOCID": "100", "TEXT": "Rekursive Subskriptions-Compiler und Speicher vom Listentyp"}
{"DOCID": "101", "TEXT": "Kernreaktorcodes"}
{"DOCID": "102", "TEXT": "Ein Vergleich von 650 Programmiermethoden"}
{"DOCID": "103", "TEXT": "COPE (Console Operator Proficiency Examination)*: Jedes Jahr werden elektronische Computer anspruchsvoller und die Programme, die sie verarbeiten müssen, werden komplexer. Aus diesem Grund nimmt die Abhängigkeit der Informatiker von den Fähigkeiten und Erfahrungen der Bediener zu. Gleichzeitig wird die Auswahl und Ausbildung qualifizierter Bediener immer schwieriger. Um den Bedarf an einem schnellen, genauen, einheitlichen Bedienertest und einer Schulungshilfe zu decken, haben die Autoren COPE (Console Operator Proficiency Examination) entwickelt, das unten beschrieben wird. Während diese Prüfung speziell für den IBM 705 Model II mit zwei Tape Record Coordinators programmiert ist, könnten ähnliche Programme für andere Computer entwickelt werden."}
{"DOCID": "104", "TEXT": "Digitale Simulation diskreter Strömungssysteme*: Die diskutierten diskreten Strömungssysteme sind durch die Bewegung zufällig ankommender Gegenstände entlang interagierender Kanäle gekennzeichnet. Das Programmieren eines digitalen Computers zum Simulieren solcher Systeme verwendet einige Techniken, die bei anderen Ansätzen für physikalische Probleme nicht üblich sind. Der Hauptteil des Papiers ist eine Diskussion von zwei Simulationsstudien, die einige der beteiligten Programmierprobleme veranschaulichen. Eine davon ist eine umfangreiche Pakethandhabungsanlage, deren Ziel die Optimierung von Parametern wie Lagerkapazitäten und Verarbeitungsgeschwindigkeiten ist. In der anderen werden Flugverkehrsfluss und Kontrollverfahren simuliert, um die Auswirkungen alternativer Kontrollentscheidungen zu vergleichen."}
{"DOCID": "105", "TEXT": "Zwei Methoden zur Wortumkehrung auf dem IBM 709"}
{"DOCID": "106", "TEXT": "Ein Verfahren zum Überlappen und Löschen von Listen: Eine wichtige Eigenschaft des Newell-Shaw-Simon-Schemas zur Computerspeicherung von Listen besteht darin, dass Daten mit mehrfachem Vorkommen nicht an mehr als einer Stelle im Computer gespeichert werden müssen. Das heißt, Listen können \"überlappt\" sein. Leider stellt das Überlappen ein Problem für das nachfolgende Löschen dar. Bei einer Liste, die nicht mehr benötigt wird, ist es erwünscht, nur diejenigen Teile zu löschen, die andere Listen nicht überlappen. Mit LISP verwendet McCarthy eine elegante, aber ineffiziente Lösung des Problems. Die vorliegende Veröffentlichung beschreibt ein allgemeines Verfahren, das ein effizientes Löschen ermöglicht. Das Verfahren verwendet eingestreute Referenzzählungen, um das Ausmaß der Überlappung zu beschreiben."}
{"DOCID": "107", "TEXT": "Arithmetik mit mehrfacher Genauigkeit"}
{"DOCID": "108", "TEXT": "Programmierte Fehlerkorrektur im Projekt Mercury"}
{"DOCID": "109", "TEXT": "Eine Anmerkung zur Annäherung von e^x"}
{"DOCID": "110", "TEXT": "Fibonacci-Suche"}
{"DOCID": "111", "TEXT": "Zur Programmierung der numerischen Lösung von Polynomgleichungen: Es werden numerische Techniken zur Berechnung der Wurzeln von Polynomgleichungen vorgestellt. Durch Anwendung der empfohlenen Skalierungs- und Inversionsregeln können die grundlegenden Iterationstechniken von Bairstow und Newton-Raphson mit großer Zuverlässigkeit angewendet werden. Sowohl ein hohes Maß an Genauigkeit als auch eine schnelle Konvergenz werden realisiert. Numerische Beispiele werden gezeigt, um die Fallstricke zu veranschaulichen und zu zeigen, wie diese durch die Anwendung der empfohlenen Verfahren umgangen werden."}
{"DOCID": "112", "TEXT": "Numerische Lösung der Polynomgleichung (Algorithmus 30)"}
{"DOCID": "113", "TEXT": "Untersuchung der codierten Zeichendarstellung"}
{"DOCID": "114", "TEXT": "Übersicht über Lochkartencodes"}
{"DOCID": "115", "TEXT": "Optimierer: Ihre Struktur"}
{"DOCID": "116", "TEXT": "Der Sumador Chino: Auf einer kürzlichen Autoreise durch Mexiko stieß der Autor auf ein Addiergerät, das als Sumador Chino (chinesische Kreuzotter) bezeichnet wurde. Ein Überblick über die verfügbarere Literatur zur Geschichte der Mathematik und zu Recheninstrumenten hat keinen Hinweis auf ein solches Gerät ergeben. Der Zweck dieser Mitteilung ist es, die Hilfe anderer Mitglieder in Anspruch zu nehmen, um alles ans Licht zu bringen, was über die Entwicklung und den gegenwärtigen Status des Sumador Chino bekannt ist."}
{"DOCID": "117", "TEXT": "Eine Abschätzung der relativen Effizienz zweier interner Sortierverfahren"}
{"DOCID": "118", "TEXT": "Zeichenscannen auf dem IBM 7070"}
{"DOCID": "119", "TEXT": "Hinweis zur Eigenwertberechnung"}
{"DOCID": "120", "TEXT": "Eine einfache Technik zur Codierung von Differentialgleichungen"}
{"DOCID": "121", "TEXT": "Gesamte Berechnungskontrolle und Kennzeichnung"}
{"DOCID": "122", "TEXT": "Kleinste-Quadrate-Anpassung eines Großkreises durch Punkte auf einer Kugel"}
{"DOCID": "123", "TEXT": "Kompilierung für zwei Computer mit NELIAC: NELIAC, ein auf ALGOL basierender Compiler, wurde am U.S. Navy Electronics Laboratory, San Diego, Kalifornien, als \"Bootstrap\"-Compiler für den Remington Rand Univac COUNTESS Computer entwickelt. Dieser Compiler wurde verwendet, um eine Version von sich selbst zu generieren, die als COUNTESS-Programm Maschinencode für den CDC-1604 der Control Data Corporation generierte. Alle drei Versionen von NELIAC akzeptierten im Wesentlichen identische Eingabesprachen."}
{"DOCID": "124", "TEXT": "Ein Algorithmus für das Zuordnungsproblem: Das Zuordnungsproblem wird formuliert und kurz diskutiert. Ein effizienter Algorithmus für seine Lösung wird im ALGOL-Code präsentiert. Basierend auf umfangreichen Experimenten, die auf einem digitalen Computer durchgeführt wurden, wird ein empirischer Zusammenhang zwischen der Lösungszeit und der Größe des Problems angegeben."}
{"DOCID": "125", "TEXT": "Polynomtransformator (Algorithmus 29)"}
{"DOCID": "126", "TEXT": "Anpassung der kleinsten Quadrate durch orthogonale Polynome (Algorithmus 28)"}
{"DOCID": "127", "TEXT": "AUFGABE (Algorithmus 27)"}
{"DOCID": "128", "TEXT": "ROOTFINDER III (Algorithmus 26)"}
{"DOCID": "129", "TEXT": "ROOTFINDER II (Algorithmus 15)"}
{"DOCID": "130", "TEXT": "Reelle Nullstellen einer beliebigen Funktion (Algorithmus 25)"}
{"DOCID": "131", "TEXT": "Lösung tridiagonaler linearer Gleichungen (Algorithmus 24)"}
{"DOCID": "132", "TEXT": "Math Sort (Algorithmus 23)"}
{"DOCID": "133", "TEXT": "Riccati-Bessel-Funktionen erster und zweiter Art (Algorithmus 22)"}
{"DOCID": "134", "TEXT": "Bessel-Funktion für eine Menge ganzzahliger Ordnungen (Algorithmus 21)"}
{"DOCID": "135", "TEXT": "Digitale Computer in Universitäten-IV"}
{"DOCID": "136", "TEXT": "Hinweis zur Zinsberechnung"}
{"DOCID": "137", "TEXT": "Auswerten von Zahlen, die als Zeichenfolgen englischer Wörter ausgedrückt werden"}
{"DOCID": "138", "TEXT": "Einige Gedanken zur Abstimmung verschiedener Zeichensatzvorschläge (Korrigenda)"}
{"DOCID": "139", "TEXT": "Binomialkoeffizienten (Algorithmus 19)"}
{"DOCID": "140", "TEXT": "Crout mit Schwenken (Algorithmus 16)"}
{"DOCID": "141", "TEXT": "Einige Gedanken zur Parallelverarbeitung"}
{"DOCID": "142", "TEXT": "Kommentare zu einer Technik zum Zählen von Einsen"}
{"DOCID": "143", "TEXT": "Eine Liste von Computersystemprogrammen für IBM 650, DATATRON 205 und UNIVAC SS-80"}
{"DOCID": "144", "TEXT": "Machen Sie es nach Zahlen – digitale Kurzschrift: Gegenwärtige Kommunikationssysteme übertragen einzelne Zeichen in Gruppen von codierten Impulsen zwischen einfachen Endgeräten. Da englische Wörter nur einen spärlichen Satz aller möglichen alphabetischen Kombinationen bilden, sind gegenwärtige Verfahren ineffizient, wenn Computersysteme diese Endgeräte ersetzen. Die Verwendung numerischer Darstellungen ganzer Wörter oder gebräuchlicher Phrasen (anstelle von zeichenweisen Darstellungen) erfordert ungefähr ein Drittel der gegenwärtigen Übertragungszeit. Diese Einsparung schlägt sich in den Gesamtkosten nieder. Andere Vorteile ergeben sich aus Code- und Sprachübersetzungsschemata. Es werden Vorkehrungen für die Übertragung von rein numerischen und/oder binären Strömen und für die Einzelzeichenübertragung von Wörtern, die nicht aus dem Wörterbuch stammen, wie z. B. den Namen von Personen oder Orten, getroffen."}
{"DOCID": "145", "TEXT": "Automatische Bewerter für Programmierklassen"}
{"DOCID": "146", "TEXT": "Die Verwendung von Computern im Ingenieurunterricht: Vom 29. bis 30. April hielt das Computerkomitee des College of Engineering der University of Michigan, das als Lenkungsausschuss für das Ford Foundation-Projekt zur Verwendung von Computern in der Ingenieurausbildung fungiert, eine Sonderkonferenz zur Erörterung bestimmter aktueller Themen im Zusammenhang mit dem Ford-Projekt. Dieser Bericht enthält eine komprimierte Transkription der Kernideen der Konferenzteilnehmer zu ausgewählten Themen."}
{"DOCID": "147", "TEXT": "Bericht über eine Konferenz der Universitätsrechenzentrumsdirektoren"}
{"DOCID": "148", "TEXT": "Digitale Computer in Universitäten-III"}
{"DOCID": "149", "TEXT": "Eine Entscheidungsregel für verbesserte Effizienz beim Lösen linearer Programmierprobleme mit dem Simplex-Algorithmus"}
{"DOCID": "150", "TEXT": "Rationale Interpolation durch Kettenbrüche (Algorithmus 18)"}
{"DOCID": "151", "TEXT": "TRDIAG (Algorithmus 17)"}
{"DOCID": "152", "TEXT": "CROUT mit Schwenken (Algorithmus 16)"}
{"DOCID": "153", "TEXT": "Kommentare von einem FORTRAN-Benutzer"}
{"DOCID": "154", "TEXT": "Schnell konvergente Ausdrücke zur Auswertung von e^x"}
{"DOCID": "155", "TEXT": "Versuchen Sie es mit Speicher"}
{"DOCID": "156", "TEXT": "Ein Einführungsproblem in die Symbolmanipulation für den Schüler"}
{"DOCID": "157", "TEXT": "Digitale Computer in Universitäten -II"}
{"DOCID": "158", "TEXT": "ROOTFINDER II (Algorithmus 15)"}
{"DOCID": "159", "TEXT": "ROOTFINDER (Algorithmus 2)"}
{"DOCID": "160", "TEXT": "ROOTFINDER II (Algorithmus 15)"}
{"DOCID": "161", "TEXT": "Wörter systematisch abkürzen (Korrigendum)"}
{"DOCID": "162", "TEXT": "Eine Variantentechnik zum Zählen von Einsen"}
{"DOCID": "163", "TEXT": "Einsen zählen auf dem IBM 7090"}
{"DOCID": "164", "TEXT": "Eine kurze Studie zur Notationseffizienz"}
{"DOCID": "165", "TEXT": "NELIAC-A Dialekt von ALGOL"}
{"DOCID": "166", "TEXT": "Programmierkompatibilität in einer Familie eng verwandter digitaler Computer"}
{"DOCID": "167", "TEXT": "Kombinieren der ALGOL-Anweisungsanalyse mit der Gültigkeitsprüfung"}
{"DOCID": "168", "TEXT": "Multiprogramm Scheduling Teile 3 und 4 Scheduling Algorithmus und externe Beschränkungen"}
{"DOCID": "169", "TEXT": "Das mehrsprachige Terminologieprojekt"}
{"DOCID": "170", "TEXT": "Einige Gedanken zur Abstimmung verschiedener Zeichensatzvorschläge"}
{"DOCID": "171", "TEXT": "Digitale Computer in Universitäten (Teil I)"}
{"DOCID": "172", "TEXT": "Komplexes Exponentialintegral (Algorithmus 13)"}
{"DOCID": "173", "TEXT": "ATLAS ein neues Konzept im Design großer Computer"}
{"DOCID": "174", "TEXT": "Intervallschätzung des Verhältnisses von Zeit in einem Zustand zu Gesamtzeit in einem DoubleExponential-Prozess"}
{"DOCID": "175", "TEXT": "Die Lösung simultaner gewöhnlicher Differentialgleichungen mit einem digitalen Allzweckcomputer"}
{"DOCID": "176", "TEXT": "Symbolmanipulation durch verkettete Listen (Korrigendum)"}
{"DOCID": "177", "TEXT": "Solution of Polynomial Equation by Bairstow Hitchcock Method, A. A. Grau Communications ACM, Februar 1960 (Algorithmus)"}
{"DOCID": "178", "TEXT": "ROOTFINDER (Algorithmus)"}
{"DOCID": "179", "TEXT": "Auswertung des Legendre-Polynoms Pn(X) durch Rekursion (Algorithmus)"}
{"DOCID": "180", "TEXT": "Auswertung des Laguerre-Polynoms Ln(X) durch Rekursion (Algorithmus)"}
{"DOCID": "181", "TEXT": "Auswertung des Hermite-Polynoms Hn(X) durch Rekursion (Algorithmus)"}
{"DOCID": "182", "TEXT": "Auswertung des Tschebyscheff-Polynoms Tn(X) durch Rekursion (Algorithmus)"}
{"DOCID": "183", "TEXT": "Konvertierung zwischen Fließkommadarstellungen"}
{"DOCID": "184", "TEXT": "Eine kurze Methode zur Messung des Fehlers in einer Potenzreihe der kleinsten Quadrate"}
{"DOCID": "185", "TEXT": "Multiprogram Scheduling Teil 1 und 2. Einführung und Theorie*: Um einen schnellen Computer, der Simultanverarbeitungsfähigkeiten besitzt, voll auszunutzen, sollte er weitgehend seine eigene Arbeitslast planen. Die Scheduling-Routine muss extrem schnell ausgeführt werden können, wenn sie sich nicht als selbstzerstörerisch erweisen soll. Der Aufbau eines Ablaufplans beinhaltet die Bestimmung, welche Programme gleichzeitig und welche sequentiell in Bezug aufeinander ausgeführt werden sollen. Es wird ein prägnanter Planungsalgorithmus beschrieben, der dazu neigt, die Zeit zum Ausführen der gesamten anhängigen Arbeitslast (oder einer Teilmenge davon) zu minimieren, abhängig von externen Beschränkungen wie Vorrang, Dringlichkeit usw. Der Algorithmus ist auf eine breite Klasse von Maschinen anwendbar."}
{"DOCID": "186", "TEXT": "Ein Algorithmus, der ALGOL-Zuweisungsanweisungen definiert (Nachtrag)"}
{"DOCID": "187", "TEXT": "Verknüpfungen kompilieren"}
{"DOCID": "188", "TEXT": "Das Institut für Computermathematik der Staatlichen Universität Moskau"}
{"DOCID": "189", "TEXT": "Die Zukunft automatischer digitaler Computer"}
{"DOCID": "190", "TEXT": "Bendix G-20-System"}
{"DOCID": "191", "TEXT": "Wörter systematisch abkürzen"}
{"DOCID": "192", "TEXT": "Eine Technik zum Zählen von Einsen in einem binären Computer"}
{"DOCID": "193", "TEXT": "A Beginnen Sie bei der automatischen Speicherzuweisung"}
{"DOCID": "194", "TEXT": "Divisionslose Berechnung von Quadratwurzeln durch fortgesetztes Quadrieren"}
{"DOCID": "195", "TEXT": "Was ist ein Code?"}
{"DOCID": "196", "TEXT": "Bericht über die algorithmische Sprache ALGOL 60"}
{"DOCID": "197", "TEXT": "Ein imaginäres Zahlensystem"}
{"DOCID": "198", "TEXT": "Ein Hochgeschwindigkeits-Multiplikationsprozess für digitale Computer"}
{"DOCID": "199", "TEXT": "Euklidischer Algorithmus (Algorithmus 7)"}
{"DOCID": "200", "TEXT": "Bessel-Funktion I, asymptotische Entwicklung (Algorithmus 6)"}
{"DOCID": "201", "TEXT": "Bessel-Funktion I, Reihenentwicklung (Algorithmus 5)"}
{"DOCID": "202", "TEXT": "Ein Steuersystem für die logische Blockdiagnose mit Datenladen: Dieses Dokument beschreibt einen Abschnitt eines integrierten Diagnoseüberwachungssystems, das die Überprüfung von Befehlsabschnitten oder Subroutinen überall im Objektprogramm erleichtert. Ein neues Verfahren zum Spezifizieren aller diagnostischen Operationen in einem Format ähnlich einem Computerprogramm macht das System bequem zu verwenden und relativ einfach zu verstehen. Die Veröffentlichung beschreibt auch eine Reihe weiterer neuartiger diagnostischer Merkmale, die in das System aufgenommen werden können."}
{"DOCID": "203", "TEXT": "Dekodierungskombinationen der ersten n ganzen Zahlen, die jeweils k genommen werden"}
{"DOCID": "204", "TEXT": "Beweis von Theoremen durch Mustererkennung I"}
{"DOCID": "205", "TEXT": "Makrobefehlserweiterungen von Compilersprachen: Makrobefehlscompiler, die aus einem kleinen Satz von Funktionen aufgebaut sind, können extrem leistungsfähig gemacht werden. Insbesondere die bedingte Assemblierung, verschachtelte Definitionen und die Notation in Klammern dienen dazu, einen Compiler in die Lage zu versetzen, sehr allgemeine Erweiterungen seiner Grundsprache zu akzeptieren."}
{"DOCID": "206", "TEXT": "Symbolmanipulation in XTRAN"}
{"DOCID": "207", "TEXT": "Syntaktische und semantische Ergänzungen zu ALGOL"}
{"DOCID": "208", "TEXT": "Eine Einführung in die Sprache der Informationsverarbeitung V"}
{"DOCID": "209", "TEXT": "Symbolmanipulation durch verkettete Listen"}
{"DOCID": "210", "TEXT": "Rekursive Funktionen symbolischer Ausdrücke und ihre maschinelle Berechnung, Teil I"}
{"DOCID": "211", "TEXT": "Teilen Sie Standard-Flussdiagrammsymbole"}
{"DOCID": "212", "TEXT": "Halbierungsroutine (Algorithmus 4)"}
{"DOCID": "213", "TEXT": "Numerische Inversion von Laplace-Transformationen"}
{"DOCID": "214", "TEXT": "Ein Algorithmus, der ALGOL-Zuweisungsanweisungen definiert"}
{"DOCID": "215", "TEXT": "Die Ausführungsoperationen – ein vierter Modus der Befehlssequenzierung"}
{"DOCID": "216", "TEXT": "Eine Anmerkung zur Verwendung des Abakus bei der Zahlenumwandlung"}
{"DOCID": "217", "TEXT": "Sowjetische Computertechnologie-1959"}
{"DOCID": "218", "TEXT": "Computervorbereitung einer Gedichtkonkordanz"}
{"DOCID": "219", "TEXT": "Ehe-mit Problemen"}
{"DOCID": "220", "TEXT": "Eine neue Methode zur Berechnung von Quadratwurzeln ohne Division"}
{"DOCID": "221", "TEXT": "Die grundlegende Seite der Bandetikettierung"}
{"DOCID": "222", "TEXT": "Codierungsisomorphismen: Die Codierung von externen Symbolen in recheninterne Symbole kann manchmal so durchgeführt werden, dass relevante Informationseigenschaften erhalten bleiben, aber in einer Form, die viel einfacher zu handhaben ist. Ein Fallbeispiel wird vorgestellt."}
{"DOCID": "223", "TEXT": "Selbstverschlüsselung: Programmierung"}
{"DOCID": "224", "TEXT": "Sequentielle Formelübersetzung: Die Syntax einer algorithmischen Sprache wie ALGOL wird praktischerweise als eine Folge von Zuständen beschrieben, die durch ein Element namens Keller angezeigt werden. Übergänge werden durch zulässige Zustandssymbolpaare gesteuert, die durch eine Übergangsmatrix dargestellt werden können. Diese Beschreibung der Syntax liefert gleichzeitig eine äußerst einfache Regel, um Anweisungen in der algorithmischen Sprache in Maschinenprogramme zu übersetzen. Eine sequentielle Behandlung ist jedoch bei bestimmten Optimierungsverfahren wie der rekursiven Adressberechnung nicht praktikabel."}
{"DOCID": "225", "TEXT": "Eine Technik zur Handhabung von Makrobefehlen (Korrigendum)"}
{"DOCID": "226", "TEXT": "Lösung der Polynomgleichung nach Bairstow-Hitchcock-Methode (Algorithmus 3)"}
{"DOCID": "227", "TEXT": "ROOTFINDER (Algorithmus 2)"}
{"DOCID": "228", "TEXT": "QUADI (Algorithmus 1)"}
{"DOCID": "229", "TEXT": "Ein Terminologievorschlag"}
{"DOCID": "230", "TEXT": "Ein Vorschlag für die Kompatibilität von Zeichencodes"}
{"DOCID": "231", "TEXT": "Ein Vorschlag für eine Reihe von Veröffentlichungsstandards zur Verwendung durch die ACM"}
{"DOCID": "232", "TEXT": "Ein Hochgeschwindigkeits-Sortierverfahren"}
{"DOCID": "233", "TEXT": "Abstracts-Zusätzliche Kernreaktorcodes"}
{"DOCID": "234", "TEXT": "Ein SAP-ähnliches Montageprogramm für den IBM 650"}
{"DOCID": "235", "TEXT": "Zwei Denkstücke"}
{"DOCID": "236", "TEXT": "Sowjetische Kybernetik und Computer: Dieser Artikel enthält Beobachtungen zur sowjetischen Forschung und Technologie in Kybernetik und Informatik, die der Autor während eines Besuchs in der Sowjetunion als Delegierter des IFAC-Kongresses über automatische Steuerung machte, der im Sommer 1960 in Moskau stattfand."}
{"DOCID": "237", "TEXT": "Computerproduktion von Peek-A-Boo-Blättern"}
{"DOCID": "238", "TEXT": "Simulation und Analyse biochemischer Systeme"}
{"DOCID": "239", "TEXT": "Ineffizienz der Verwendung von Booleschen Funktionen für Informationsabrufsysteme"}
{"DOCID": "240", "TEXT": "Verarbeitung von Magnetbanddateien mit variablen Blöcken"}
{"DOCID": "241", "TEXT": "Maschinelle Berechnung der Momente einer Wahrscheinlichkeitsverteilung: Es wird ein Verfahren zur Berechnung der Momente einer Wahrscheinlichkeitsverteilung auf einer Maschine vorgestellt, das wenig mehr als n Additionen und n Verweise auf den Speicher für jeden Moment erfordert, anstatt mindestens n Multiplikationen. 2n Additionen und 2n Verweise auf den Speicher, die von der einfachsten Methode benötigt werden (wobei n die Anzahl der Einträge in der Wahrscheinlichkeitsverteilung ist). Das Verfahren ist direkt anwendbar, wenn eine tabellarische Verteilung existiert, wie wenn sie durch wiederholte Faltung berechnet wurde; aber in diesem Fall spart es sowohl Zeit als auch Genauigkeit."}
{"DOCID": "242", "TEXT": "Anmerkungen zur Prüfung von geometrisch gewichteten Prüfziffern: Diese Anmerkung beschreibt ein Verfahren zur Verwendung von geometrischen Gewichtungsmodul 11-Prüfziffern auf einem Computer, der weder Multiplikation noch Division hat. Außerdem wurde versucht, einige Beschränkungen dieses Systems aufzuzeigen."}
{"DOCID": "243", "TEXT": "N-dimensionale Codes zum Erkennen und Korrigieren mehrerer Fehler: Das Papier stellt eine neue Familie von Codes zum Erkennen und Korrigieren mehrerer Fehler in einer binär codierten Nachricht vor. Die Nachricht selbst ist (konzeptionell) in einem mehrdimensionalen rechteckigen Array angeordnet. Die Prozesse der Codierung und Fehlererkennung basieren auf Paritätsauswertungen entlang vorgeschriebener Abmessungen des Arrays. Die Wirksamkeit der Codes wird durch Einführen eines \"Systemprüfbits\" erhöht, das im wesentlichen eine Paritätsprüfung der anderen Paritätsbits ist. In dieser Arbeit werden nur dreidimensionale Codes mit Paritätsauswertungen entlang der Horizontalen, der Vertikalen und einer Hauptdiagonalen diskutiert. Die Codefamilie ist jedoch nicht auf drei Dimensionen beschränkt, wie die Diskussion von Minnick und Ashenhurst über einen ähnlichen mehrdimensionalen Einzelbit-Auswahlplan zeigt, der für einen anderen Zweck verwendet wird [6]. Ein vierdimensionaler Code, der drei Fehler korrigiert und vier Fehler erkennt, wurde entwickelt; die Erweiterung auf höherdimensionale Codes mit größerer Korrekturleistung ist einfach."}
{"DOCID": "244", "TEXT": "Unvollständige elliptische Integrale (Algorithmus 73)"}
{"DOCID": "245", "TEXT": "Ein Satz assoziierter Legendre-Polynome zweiter Art (Algorithmus 62)"}
{"DOCID": "246", "TEXT": "Kleinste-Quadrate-Anpassung durch orthogonale Polynome (Algorithmus 28)"}
{"DOCID": "247", "TEXT": "Unvollständige elliptische Integrale (Algorithmus 73)"}
{"DOCID": "248", "TEXT": "Was ist proprietär in der mathematischen Programmierung? - Impressionen einer Podiumsdiskussion: Eine Podiumsdiskussion zum Thema \"Was ist proprietär in der mathematischen Programmierung?\" wurde vom Special Interest Committee on Mathematical Programming der ACM während einer Diskussionshalle am 7. September beim 16. Nationalen ACM-Treffen in Los Angeles gesponsert. Diese Notiz besteht ausschließlich aus den Eindrücken, die der Moderator des Panels gesammelt hat, und repräsentiert nicht unbedingt die Position eines der Panelisten oder anderer Diskussionsteilnehmer."}
{"DOCID": "249", "TEXT": "Spezifikationssprachen für mechanische Sprachen und ihre Prozessoren*-A Baker's Dozen"}
{"DOCID": "250", "TEXT": "Eine technische Anwendung von Logikstrukturtabellen"}
{"DOCID": "251", "TEXT": "Design ballistischer Nocken: Dieses Dokument stellt ein digitales Computerprogramm für die schnelle Berechnung von Herstellungsdaten vor, die für das Design von Vorseriennocken wesentlich sind, die in ballistischen Computern von Panzer-Feuerleitsystemen verwendet werden. Das erzeugte Nockenprofil führt den Überhöhungswinkel ein, der von der Panzerhauptbewaffnung für einen bestimmten Munitionstyp benötigt wird."}
{"DOCID": "252", "TEXT": "Programmierung eines Duplex-Computersystems: Dieses Dokument beschreibt ein Verfahren zur Duplex-Computerprogrammierung, das mit zwei Computern in einem militärischen Verteidigungssystem verwendet wurde. Das Verfahren kombiniert spezielle Programme mit einem grundlegenden Datenverarbeitungsprogrammpaket. Der Duplexbetrieb verleiht dem System eine größere Zuverlässigkeit. Nachdem das erforderliche Integrationsniveau erreicht ist, führen beide Computer eine ähnliche Verarbeitung an denselben Eingaben durch und überprüfen kontinuierlich die Zwischen- und Endergebnisse."}
{"DOCID": "253", "TEXT": "Über ein Programm für Ray-Chaudhuris Algorithmus für eine minimale Abdeckung eines abstrakten Komplexes"}
{"DOCID": "254", "TEXT": "SMALGOL-61: Vor und während der Western Joint Computer Conference 1961 hatten mehrere Personen in den Joint Users Groups Interesse an der Definition einer \"Smalgol\"-Sprache bekundet. Dies soll eine ALGOL-Sprache zur Verwendung mit Compilern auf relativ kleinen Computern sein. Es entstand ein vorläufiger Bericht. Auf der ACM-Nationalkonferenz vier Monate später einigte sich ein Unterausschuss nach Prüfung mehrerer Gegenvorschläge auf eine endgültige Fassung. Die Empfehlungen des Unterausschusses für eine Standarduntermenge von ALGOL 60 zur Verwendung auf kleinen Computern werden hier vorgestellt."}
{"DOCID": "255", "TEXT": "Augmentation (Algorithmus 68)"}
{"DOCID": "256", "TEXT": "Ein Satz von Testmatrizen (Algorithmus 52)"}
{"DOCID": "257", "TEXT": "Invertieren (Algorithmus 42)"}
{"DOCID": "258", "TEXT": "Kompositionsgenerator (Algorithmus 72)"}
{"DOCID": "259", "TEXT": "Permutation (Algorithmus 71)"}
{"DOCID": "260", "TEXT": "Interpolation durch Aitken (Algorithmus 70)"}
{"DOCID": "261", "TEXT": "Bandaufteilung"}
{"DOCID": "262", "TEXT": "KARTE"}
{"DOCID": "263", "TEXT": "Bibliotheksladen mit Auswahl alternativer Routinen"}
{"DOCID": "264", "TEXT": "Ein verallgemeinerter Mehrphasen-Merge-Algorithmus"}
{"DOCID": "265", "TEXT": "Subroutinen auf niedriger Ebene zur Verwendung in Fortran: Dieses Dokument beschreibt einige Subroutinen, die in symbolischen Sprachen codiert sind und zur Verwendung in Fortran-codierten Programmen verwendet werden, um mit \"spezieller Arithmetik\" (z. B. Multipräzisionsarithmetik), Symbolmanipulation, Bitmanipulation und erweitertem Zeichen umzugehen set input-output und visuelle anzeige."}
{"DOCID": "266", "TEXT": "Anpassen von Kugeln nach der Methode der kleinsten Quadrate"}
{"DOCID": "267", "TEXT": "Einige Vorschläge zur Verbesserung der Effizienz von ALGOL 60"}
{"DOCID": "268", "TEXT": "Stochastische Auswertung einer statischen Speicherallokation"}
{"DOCID": "269", "TEXT": "Kernzuteilung basierend auf Wahrscheinlichkeit"}
{"DOCID": "270", "TEXT": "Techniken für Speicherzuweisungsalgorithmen"}
{"DOCID": "271", "TEXT": "Ein halbautomatisches Speicherzuweisungssystem zur Ladezeit"}
{"DOCID": "272", "TEXT": "Ein Speicherzuweisungsschema für ALGOL 60: Ein Speicherzuweisungsschema für eine Maschine mit einem Kernspeicher mit 2048 Befehlen und einer Magnettrommel wird beschrieben. Die Verwendung der Trommel zum Speichern von Programmblöcken und/oder Daten muss vom Programmierer durch Hilfsinformationen im ALGOL-Programm gesteuert werden. Die Verwaltungsroutinen, die die Speicherung zur Laufzeit steuern, werden vollständig beschrieben. Ein ausführliches Beispiel wird gegeben."}
{"DOCID": "273", "TEXT": "Erfahrung in der automatischen Speicherzuweisung"}
{"DOCID": "274", "TEXT": "Dynamische Speicherzuweisung im Atlas-Computer, einschließlich automatischer Nutzung eines Backing Stores"}
{"DOCID": "275", "TEXT": "Dynamische Speicherzuweisung für ein Informationsabrufsystem"}
{"DOCID": "276", "TEXT": "Programmorganisation und Aufzeichnungen für die dynamische Speicherzuweisung: Das in diesem Dokument präsentierte Material ist Teil des Entwurfsplans des Kernzuweisungsabschnitts des ASCII-MATIC-Programmiersystems. Das Projekt ASCII-MATIC befasst sich mit der Anwendung von Computertechniken auf die Aktivitäten bestimmter militärischer Geheimdienstoperationen des Hauptquartiers der US-Armee."}
{"DOCID": "277", "TEXT": "Probleme der Speicherzuweisung in einem Multiprozessor-Mehrprogrammsystem"}
{"DOCID": "278", "TEXT": "Eine allgemeine Formulierung der Speicherzuweisung: Es wird versucht, einen allgemeinen Computerspeicherzuweisungsprozess zu formulieren. Einem gegebenen Computer M ist ein fiktiver Computer M' zugeordnet, der im Wesentlichen identisch mit M ist, außer in Bezug auf den Besitz eines unbegrenzten Primärspeichers. Abbildungen des gesamten Speichersatzes (intern und extern) von M in den Satz direkter Adressen von M' werden eingeführt. Eine Programmsequenz P für M' wird als M-zulässig (bezogen auf einen bestimmten Ausführungszeitraum) bezeichnet, wenn es eine Abbildung gibt, unter der P und seine effektiven Datenreferenzen alle in dem direkten Adresssatz von M liegen. Speicherzuordnung wird als a betrachtet Prozess, für ein beliebiges M'-Programm eine Folge von Abbildungen, eine Entkopplung des Programms in M-zulässige Unterprogramme und einen verbindenden Satz von Zwischenspielen zu erstellen. Ein Existenzbeweis im Sinne eines vollständig interpretierenden M-Programms wie angegeben. Einige Spezialfälle werden diskutiert. Es werden verschiedene Beschränkungen der Allgemeingültigkeit von M'-Programmen betrachtet, unter denen eine praktischere Realisierung von Zuordnungsprozessen handhabbar wird."}
{"DOCID": "279", "TEXT": "Der Fall für die dynamische Speicherzuweisung"}
{"DOCID": "280", "TEXT": "Ein vorgeplanter Ansatz für einen Compiler zur Speicherzuweisung"}
{"DOCID": "281", "TEXT": "Ein Hex auf e^x setzen: Neuere Anmerkungen zur ungefähren natürlichen Antilogie haben keine indirekten Formulierungen zur Beschreibung von e^x berücksichtigt. In dieser Notiz produzieren wir eine besondere Familie von sehr schnellen, hochpräzisen und äußerst praktischen exponentiellen Bewertungsformeln, die von einer solchen Formulierung abgeleitet sind."}
{"DOCID": "282", "TEXT": "Optimale Bandschreibverfahren: Betrachten Sie ein Magnetbandsystem mit einer Leseprüfung nach dem Schreiben. Wenn beim Schreiben eines Datensatzes ein Fehler auftritt, kann eine programmierte Fehlerroutine entweder einen Teil oder den gesamten Bereich auf dem Band umgehen oder versuchen, den Datensatz in demselben Bereich neu zu schreiben. Diese Arbeit bewertet diese beiden Verfahren anhand des zu erwartenden Rechenzeitverlustes und entwickelt eine Entscheidungsregel zur Auswahl des optimalen Verfahrens. Die Regel hängt entscheidend davon ab, wie oft das zu beschreibende Band in der Zukunft verwendet wird. In dem Fall, in dem das optimale Verfahren darin besteht, einen Bereich zu umgehen, ist eine zweite Entscheidung – die Größe des zu umgehenden Bereichs – erforderlich. Es wird eine Formel entwickelt, um den optimalen zu umgehenden Bereich für jedes Verfahren zu bestimmen."}
{"DOCID": "283", "TEXT": "Umkehrung einer komplexen Matrix"}
{"DOCID": "284", "TEXT": "Manipulation algebraischer Ausdrücke: Ein Algorithmus zur algebraischen Manipulation von Ausdrücken der Form SUM{CiPi, i=1,...,n}; wurde in Verbindung mit der Entwicklung von Programmen für systemanalytische Probleme entwickelt. Dieser Algorithmus ermöglicht es uns, Gesamtsystem-Übertragungsfunktionen aus algebraisch beschriebenen Blockdiagrammen eines beliebigen linearen kontinuierlichen Mehrschleifen-Rückkopplungssystems abzuleiten. Die maschinelle Darstellung des abgeleiteten Ausdrucks liegt aufgrund des Algorithmus in einer Form vor, die die Aufgabe des Kompilierens vereinfacht. Der Algorithmus wurde für einen bestimmten Zweck in Verbindung mit Systemanalysestudien entwickelt. Seine Anwendung als mathematisches Gerät geht jedoch weit über die Grenzen des ursprünglichen Problems hinaus."}
{"DOCID": "285", "TEXT": "Lösung tridiagonaler Matrizen"}
{"DOCID": "286", "TEXT": "Eine iterative Methode zur Inversion von Potenzreihen"}
{"DOCID": "287", "TEXT": "Die verallgemeinerte Technik für wichtige Ereignisse"}
{"DOCID": "288", "TEXT": "Ein syntaktisches Diagramm von ALGOL 60"}
{"DOCID": "289", "TEXT": "Scheduling kritischer Pfade (Algorithmus 40)"}
{"DOCID": "290", "TEXT": "Kettenverfolgung (Algorithmus 69)"}
{"DOCID": "291", "TEXT": "Verwendung von MOBOL bei der Vorbereitung von Abrufprogrammen"}
{"DOCID": "292", "TEXT": "Eine Sprache zum Abrufen von Informationen für Rechtsstudien"}
{"DOCID": "293", "TEXT": "Das Labor für angewandte Mathematik des David W. Taylor Model Basin"}
{"DOCID": "294", "TEXT": "Ein imaginäres Zahlensystem"}
{"DOCID": "295", "TEXT": "Rationale Näherungen für die Fehlerfunktion und für ähnliche Funktionen"}
{"DOCID": "296", "TEXT": "Eine Anmerkung zur Arithmetik mit mehrfacher Genauigkeit"}
{"DOCID": "297", "TEXT": "Eine Anmerkung zur Anpassung von Großkreisen durch kleinste Quadrate"}
{"DOCID": "298", "TEXT": "Ein 48-Bit-Pseudozufallszahlengenerator: Ein neuer 48-Bit-Pseudozufallszahlengenerator, der für mehrere Computer geeignet ist, wurde statistisch auf Zufälligkeit getestet, um seine Eignung für die Verwendung in Monte-Carlo-Programmen zu bestimmen. Frequenztests, Verteilungen bestimmter Momente niedriger Ordnung, Läufe nach oben und unten sowie Läufe über und unter dem Mittelwert wurden auf eine halbe Million generierter Zahlen angewendet, die innerhalb des Intervalls (0,1) lagen, und auf drei Sätze von ganzen Zahlen, die aus den angegebenen erhalten wurden Bits innerhalb der generierten Zahlen. Diese Tests bestätigten die Zufälligkeit aller Zahlen mit Ausnahme des Satzes ganzer Zahlen, die von den niederwertigsten Bits stammen."}
{"DOCID": "299", "TEXT": "Ein verallgemeinerter Mehrphasen-Merge-Algorithmus"}
{"DOCID": "300", "TEXT": "COBOL: Ein Beispielproblem: Ein vereinfachtes Warenkontrollproblem wurde ausgewählt, um Benutzern und potenziellen Benutzern von Computersystemen COBOL vorzustellen. Ein mythisches Kaufhaus, \"E. Language Bros., Inc.\", programmiert in der COBOL-Sprache einen der vielen Läufe auf seinem Computer."}
{"DOCID": "301", "TEXT": "Ein Satz von Testmatrizen (Algorithmus 52)"}
{"DOCID": "302", "TEXT": "Augmentation (Algorithmus 68)"}
{"DOCID": "303", "TEXT": "Einige grundlegende Terminologie im Zusammenhang mit mechanischen Sprachen und ihren Prozessoren: Die Vorschläge in diesem Dokument sind Teil der Terminologie, die bei der Arbeit für das Office of Computer Research and Education der University of Pennsylvania verwendet wird. Die Arbeit wird gemeinsam von der National Science Foundation und dem Air Force Office of Scientific Research unterstützt."}
{"DOCID": "304", "TEXT": "N-te Wurzeln einer komplexen Zahl (Algorithmus 53)"}
{"DOCID": "305", "TEXT": "CRAM (Algorithmus 67)"}
{"DOCID": "306", "TEXT": "INVRS (Algorithmus 66)"}
{"DOCID": "307", "TEXT": "FINDEN (Algorithmus 65)"}
{"DOCID": "308", "TEXT": "QUICKSORT (Algorithmus 64)"}
{"DOCID": "309", "TEXT": "PARTITION (Algorithmus 63)"}
{"DOCID": "310", "TEXT": "Ein Satz assoziierter Legendre-Polynome zweiter Art (Algorithmus 62)"}
{"DOCID": "311", "TEXT": "Prozeduren für Bereichsarithmetik (Algorithmus 61)"}
{"DOCID": "312", "TEXT": "Ein weiterer Hinweis zur Annäherung von e^x"}
{"DOCID": "313", "TEXT": "Eine iterative Methode zur Inversion von Potenzreihen"}
{"DOCID": "314", "TEXT": "Eine divisionslose Methode zur Umwandlung ganzer Zahlen"}
{"DOCID": "315", "TEXT": "Lösung tridiagonaler Matrizen"}
{"DOCID": "316", "TEXT": "Ein Algorithmus für Äquivalenzerklärungen"}
{"DOCID": "317", "TEXT": "Zur Approximation von Kurven durch Liniensegmente mit dynamischer Programmierung"}
{"DOCID": "318", "TEXT": "Schussstabilität von Kampffahrzeugen (aktive Aufhängung)"}
{"DOCID": "319", "TEXT": "Über eine Klasse von Iterationsformeln und einige historische Anmerkungen: Die Klasse von Iterationsformeln, die durch rationale Approximationen der \"Euler-Formel\" erhältlich sind, wird mit den entsprechenden Fehlerabschätzungen abgeleitet. Einigen historischen Anmerkungen zu iterativen Verfahren folgt eine Herleitung der Euler-Formel mit der zugehörigen Fehlerschätzung in einer neuen Notation, die die Fehlerschätzung vereinfacht und Verallgemeinerungen nahelegt. Der letzte Abschnitt betrachtet die Pade-Annäherungen an das \"Euler-Polynom\" und zeigt, wie eine Reihe bekannter Formeln aus diesem einheitlichen Ansatz abgeleitet werden können. Es gibt eine kurze Diskussion über die \"beste\" Formel."}
{"DOCID": "320", "TEXT": "Logik-Strukturtabellen: Logiktabellen sind eine hervorragende Möglichkeit, die in Prozeduren, Operationen, Systemen und Schaltungen erforderliche Logik zu entwickeln und auszudrücken. Anhand einiger einfacher Beispiele wird ein Regelwerk zum Schreiben und Verwenden von Logiktabellen erklärt. Dann wird die logische Struktur eines Verkaufsautomaten angegeben, in der zwei Logiktabellen verwendet werden. Logiktabellen sind von Natur aus zweidimensional, was es uns ermöglicht, sowohl die sequentiellen als auch die parallelen Aspekte der Logik vollständig auszudrücken und zu berücksichtigen. Sie können direkt in ein Computerprogramm kompiliert werden und beseitigen so die Notwendigkeit von Flussdiagrammen und manueller Codierung."}
{"DOCID": "321", "TEXT": "ALGOL 60 Vertraulich: Der ALGOL 60-Bericht* scheint beim ersten Anblick eine sehr komplexe Sprache zu beschreiben, die schwer zu erlernen sein wird. Die \"metalinguistischen Formeln\" dienen zwar vortrefflich dazu, eine Sprache genau zu spezifizieren, sind aber für einen Anfänger sicherlich nicht sehr lesbar. Die Erfahrung hat jedoch gezeigt, dass es nach der Erklärung des Berichts tatsächlich einfach ist, ALGOL zu lernen und Algorithmen darin zu schreiben. Die Sprache ist so allgemein und mächtig, dass sie eine enorme Klasse von Problemen bewältigen kann. Es ist nicht schwer, die Teile von ALGOL zu lernen, die in anderen Compilersprachen vorhanden sind: wie man Zuweisungen schreibt und zu und für Anweisungen geht usw. Tatsächlich wurden viele der unnötigen Einschränkungen, die von anderen Compilersprachen auferlegt wurden, endlich aufgehoben. Aber ALGOL lässt auch viele nicht offensichtliche Dinge zu, wie wir später sehen werden, und hierin liegt ein Problem: ALGOL scheint zu allgemein geworden zu sein. Es wurden so viele Einschränkungen aufgehoben, dass viele technische Details auftauchen, die schwer zu erlernen und richtig zu verwenden sind. In diesem Artikel werden einige der obskureren Merkmale der Sprache betrachtet und ihre Nützlichkeit diskutiert. Die Anmerkungen basieren auf den Interpretationen der Autoren des ALGOL 60-Berichts."}
{"DOCID": "322", "TEXT": "Operational Compatibility of Systems-CONVENTIONS: Das General Standards Committee der SHARE-Organisation hat angesichts der wachsenden Zahl verfügbarer Programmiersysteme erhebliche Anstrengungen dem Problem des effizienten Betriebs eines Computers gewidmet. Jedes dieser Programmiersysteme wurde so codiert, dass es einen festen Satz von Hardwarekomponenten verwendet, ohne die Tatsache zu erkennen, dass andere möglicherweise ein Speichermedium belegen, das von dem ersten benötigt wird. Diese Inkompatibilitäten werden derzeit behoben, indem der Computer für jedes System nach Bedarf manuell eingerichtet wird. Der folgende Satz von Konventionen wird in Betracht gezogen, um die Einrichtungszeit des Computers zu minimieren. Sie sind von so weitreichendem Interesse, dass wir der Meinung sind, dass andere Computerbenutzer sich ihrer bewusst sein sollten. -George F. Ryckman, Vorsitzender"}
{"DOCID": "323", "TEXT": "Der Stand der digitalen Computertechnologie in Europa"}
{"DOCID": "324", "TEXT": "Romberg-Integration (Algorithmus 60)"}
{"DOCID": "325", "TEXT": "Numerische Lösung der Polynomgleichung (Algorithmus 30)"}
{"DOCID": "326", "TEXT": "MATHSORT (Algorithmus 23)"}
{"DOCID": "327", "TEXT": "Nullstellen eines reellen Polynoms durch resultierende Prozedur (Algorithmus 59)"}
{"DOCID": "328", "TEXT": "Matrixinversion (ALgorithm 58)"}
{"DOCID": "329", "TEXT": "Umfrage und Empfehlungen zur automatischen Abstraktion und Indizierung: In Vorbereitung auf die weit verbreitete Verwendung automatischer Scanner, die Dokumente lesen und deren Inhalt zur Analyse an andere Maschinen übertragen, stellt dieser Bericht ein neues Konzept der automatischen Analyse vor: den Relativfrequenzansatz zur Messung der Signifikanz von Wörtern, Wortgruppen und Sätzen. Der Relative-Häufigkeit-Ansatz wird ausführlich diskutiert, ebenso wie seine Anwendung auf Probleme der automatischen Indizierung und automatischen Abstraktion. Der Bericht enthält eine Zusammenfassung der automatischen Analysestudien, die zum Zeitpunkt der Erstellung dieses Berichts veröffentlicht wurden. Schlussfolgerungen weisen auf anspruchsvollere mathematische und linguistische Techniken zur Lösung von Problemen der automatischen Analyse hin."}
{"DOCID": "330", "TEXT": "Eine Methode zur Bewertung der Fläche der Normalfunktion"}
{"DOCID": "331", "TEXT": "Sukzessive Approximationen und Computerspeicherprobleme in gewöhnlichen Differentialgleichungen"}
{"DOCID": "332", "TEXT": "An Indirect Chaining Method for Addressing on Secondary Keys: Verfahren zur Eingabe von Dateien mit wahlfreiem Zugriff auf der Grundlage eines Schlüssels werden kurz überblickt. Das weit verbreitete Verkettungsverfahren, das auf einer pseudozufälligen Schlüsseltransformation basiert, wird genauer betrachtet. Anschließend wird eine effiziente Verallgemeinerung des Verkettungsverfahrens vorgestellt, die eine Wiederherstellung auf zusätzlichen Schlüsseln ermöglicht."}
{"DOCID": "333", "TEXT": "Entwurf eines verbesserten* Übertragungs-/Datenverarbeitungscodes"}
{"DOCID": "334", "TEXT": "Division und Quadratwurzel im viertelimaginären Zahlensystem"}
{"DOCID": "335", "TEXT": "Einige numerische Experimente unter Verwendung der Newton-Methode für nichtlineare parabolische und elliptische Randwertprobleme: Unter Verwendung einer Verallgemeinerung der Newton-Methode, einer nichtlinearen parabolischen Gleichung der Form U(t)-U(xx)=g(U) und einer nichtlinearen elliptischen Gleichung U( xx)+U(yy)=exp(U) werden numerisch gelöst. Ein Vergleich dieser Ergebnisse mit Ergebnissen, die unter Verwendung des Picard-Iterationsverfahrens erhalten wurden, zeigt, dass das Quisi-Linearisierungsverfahren in vielen Fällen erhebliche Vorteile sowohl hinsichtlich der Zeit als auch der Genauigkeit bietet."}
{"DOCID": "336", "TEXT": "Eine praktische Technik zur Bestimmung des optimalen Entspannungsfaktors der Methode der sukzessiven Überentspannung"}
{"DOCID": "337", "TEXT": "Weitere Übersicht über Lochkartencodes"}
{"DOCID": "338", "TEXT": "GROUT II (Algorithmus 43)"}
{"DOCID": "339", "TEXT": "Reelles Exponentialintegral (Algorithmus 20)"}
{"DOCID": "340", "TEXT": "Legendre-Polynom (Algorithmus 13)"}
{"DOCID": "341", "TEXT": "Tschebyscheff-Polynom (Algorithmus 10)"}
{"DOCID": "342", "TEXT": "Lösung der Polynomgleichung von Barstow-Hitchcock (Algorithmus 3)"}
{"DOCID": "343", "TEXT": "Über häufig auftretende Fehler in ALGOL 60-Programmen (Algorithmus 25)"}
{"DOCID": "344", "TEXT": "Ber- oder Bei-Funktion (Algorithmus 57)"}
{"DOCID": "345", "TEXT": "Vollständiges elliptisches Integral zweiter Art (Algorithmus 56)"}
{"DOCID": "346", "TEXT": "Vollständiges elliptisches Integral erster Art (Algorithmus 55)"}
{"DOCID": "347", "TEXT": "Gamma-Funktion für Bereich 1 bis 2 (Algorithmus 54)"}
{"DOCID": "348", "TEXT": "N-te Wurzeln einer komplexen Zahl (Algorithmus 53)"}
{"DOCID": "349", "TEXT": "Eine Reihe von Testmatrizen"}
{"DOCID": "350", "TEXT": "Inverse einer Matrix anpassen, wenn ein Element gestört ist (Algorithmus 51)"}
{"DOCID": "351", "TEXT": "Umkehrung eines endlichen Segments der Hilbert-Matrix (Algorithmus 50)"}
{"DOCID": "352", "TEXT": "Sphärische Neumantenfunktion (Algorithmus 49)"}
{"DOCID": "353", "TEXT": "Logarithmus einer komplexen Zahl (Algorithmus 48)"}
{"DOCID": "354", "TEXT": "Zugehörige Legendre-Funktionen erster Art für reelle oder imaginäre Argumente (Algorithmus 47)"}
{"DOCID": "355", "TEXT": "Exponential einer komplexen Zahl (Algorithmus 46)"}
{"DOCID": "356", "TEXT": "INTERESSE (Algorithmus 45)"}
{"DOCID": "357", "TEXT": "Rekursiv berechnete Bessel-Funktionen (Algorithmus 44)"}
{"DOCID": "358", "TEXT": "Crout mit Pivot II (Algorithmus 43)"}
{"DOCID": "359", "TEXT": "INVERT (Algorithmus 42)"}
{"DOCID": "360", "TEXT": "Auswertung der Determinante (Algorithmus 41)"}
{"DOCID": "361", "TEXT": "Programmierte Fehlerkorrektur auf einem Dezimalrechner"}
{"DOCID": "362", "TEXT": "Tabellen-Look-At-Techniken"}
{"DOCID": "363", "TEXT": "Über die Annäherung transzendenter Zahlen durch Kettenbrüche"}
{"DOCID": "364", "TEXT": "Über die Kompilierung von Subscript-Variablen"}
{"DOCID": "365", "TEXT": "Bessel-Funktionen integraler Ordnung und komplexes Argument"}
{"DOCID": "366", "TEXT": "Eigenwerte einer symmetrischen 3 x 3 Matrix"}
{"DOCID": "367", "TEXT": "Topologische Ordnung einer Liste von zufällig nummerierten Elementen eines Netzwerks: Es wird ein Netzwerk von gerichteten Liniensegmenten angenommen, das frei von kreisförmigen Elementen ist. Die Linien werden durch ihre Endknoten identifiziert und es wird angenommen, dass die Knoten durch ein nicht-topologisches System nummeriert sind. Wenn eine Liste dieser Zeilen in numerischer Reihenfolge gegeben ist, kann eine einfache Technik verwendet werden, um mit hoher Geschwindigkeit eine Liste in topologischer Reihenfolge zu erstellen."}
{"DOCID": "368", "TEXT": "Reelle Nullstellen einer beliebigen Funktion (Algorithmus 25)"}
{"DOCID": "369", "TEXT": "Crout mit Schwenken (Algorithmus 16)"}
{"DOCID": "370", "TEXT": "Halbierungsroutine (Algorithmus 4)"}
{"DOCID": "371", "TEXT": "Bemerkungen zu den Algorithmen 2 und 3, Algorithmus 15 und Algorithmen 25 und 26"}
{"DOCID": "372", "TEXT": "Scheduling kritischer Pfade (Algorithmus 40)"}
{"DOCID": "373", "TEXT": "Korrelationskoeffizienten mit Matrixmultiplikation (Algorithmus 39)"}
{"DOCID": "374", "TEXT": "Teleskop2 (Algorithmus 38)"}
{"DOCID": "375", "TEXT": "Teleskop1 (Algorithmus 37)"}
{"DOCID": "376", "TEXT": "Tschebycheff (Algorithmus 36)"}
{"DOCID": "377", "TEXT": "SIEB (Algorithmus 35)"}
{"DOCID": "378", "TEXT": "Eine verallgemeinerte Technik zur Symbolmanipulation und numerischen Berechnung"}
{"DOCID": "379", "TEXT": "Bitweise Operationen"}
{"DOCID": "380", "TEXT": "Vergleich von iterativen Methoden zur Berechnung von n-ten Wurzeln: Drei iterative Methoden zur Berechnung von n-ten Wurzeln (einschließlich einer vom Autor vorgeschlagenen) werden auf zwei Arten verglichen: (1) Theoretische Konvergenzschätzungen werden angegeben. (2) Ein neuer Makrocompiler, der die Maschinenlaufzeit schätzt, wird verwendet, um die Laufzeit der drei Methoden für eine Vielzahl von Eingabedaten zu vergleichen."}
{"DOCID": "381", "TEXT": "Eine alternative Form des \"UNCOL-Diagramms\""}
{"DOCID": "382", "TEXT": "Statistische Programme an der University of North Carolina"}
{"DOCID": "383", "TEXT": "Über das Finden von Mindestrouten in einem Netzwerk mit Abbiegestrafen"}
{"DOCID": "384", "TEXT": "Gamma-Funktion (Algorithmus 34)"}
{"DOCID": "385", "TEXT": "FAKTORIELL (Algorithmus 33)"}
{"DOCID": "386", "TEXT": "MULTINT (Algorithmus 32)"}
{"DOCID": "387", "TEXT": "Gamma-Funktion (Algorithmus 31)"}
{"DOCID": "388", "TEXT": "Lösung von Polynomgleichungen nach der Bairstow-Hitchcock-Methode (Algorithmus 3)"}
{"DOCID": "389", "TEXT": "Reelles Exponentialintegral (Algorithmus 20)"}
{"DOCID": "390", "TEXT": "Komplexes Exponentialintegral (Algorithmus 13)"}
{"DOCID": "391", "TEXT": "Das BKS-System für den Philco-2000"}
{"DOCID": "392", "TEXT": "Kommentar zu A Paper on Parallel Processing"}
{"DOCID": "393", "TEXT": "Zwei Subroutinen zur Symbolmanipulation mit einem algebraischen Compiler"}
{"DOCID": "394", "TEXT": "Mehrfachprogrammierung Datenverarbeitung"}
{"DOCID": "395", "TEXT": "Division mit mehrfacher Genauigkeit"}
{"DOCID": "396", "TEXT": "Automatisierung des Debuggens von Programmen: Automatisches Debuggen kann die Vorlaufzeit zwischen der Codierung und der effektiven Verwendung eines komplexen Programms erheblich verkürzen. Es erzwingt auch die Analyse von Debugging-Kriterien, was zu nachweislich genauen Programmen führt. Der Programmierer spezifiziert das zu debuggende Programm, Speicherbereiche, den Satz von Eingangsdaten, die maximale Wiederholung von Schleifen und Prüfpunktinformationen für jeden Datensatz. Das ausführende Debugging-Programm führt das zu debuggende Programm aus, führt Prüffunktionen aus und erstellt eine Ablaufverfolgungsaufzeichnung seiner eigenen späteren Analyse und Lokalisierung von Fehlern. Anwendungen sind ziemlich flexibel, und das System kann alleine oder in Verbindung mit anderen Debugging-Techniken verwendet werden."}
{"DOCID": "397", "TEXT": "Ein Kartenformat für Referenzdateien in der Informationsverarbeitung: Dieses Papier schlägt ein Kartenformat vor, das für eine Vielzahl von Referenzdateien in der Informationsverarbeitung geeignet ist. Eine 80-Spalten-IBM-Karte ist in zwei Felder unterteilt – Referenzmaterialfeld (Spalten 1–67) und Identifikationsfeld (Spalten 68–80). Das Format für das Referenzmaterial ist flexibel, während das Format für die Identifizierung starr ist. Das Referenzmaterial umfasst grundsätzlich einen Index, Titel, Quelle, Klasse, Zusammenfassung und Querverweis für jeden Eintrag. Die Identifizierung umfasst im Wesentlichen Codes für eine Matrix von Deskriptoren, eine Eintragsnummer und die Art, das Hauptinteresse und die Quelle der Referenz. Die Identifizierung bietet auch eine Auswahl, um Material für persönliche sowie allgemeine Dateien zu identifizieren. Da dieses Kartenformat ausreicht, um das normalerweise mit Handbüchern, Artikeln, Programmierbegriffen, Hardwarebegriffen, Geräten, Maschinensystemen, Abkürzungen usw. verbundene Material zu identifizieren, eignet es sich als Standard für Handschlagkarten in der Informationsverarbeitung."}
{"DOCID": "398", "TEXT": "Das SLANG-System"}
{"DOCID": "399", "TEXT": "Kompilierungstechniken für boolesche Ausdrücke und bedingte Anweisungen in ALGOL 60"}
{"DOCID": "400", "TEXT": "Kommentare zur Implementierung rekursiver Prozeduren und Blöcke in ALGOL 60"}
{"DOCID": "401", "TEXT": "Zuweisung von Speicher für Arrays in ALGOL 60"}
{"DOCID": "402", "TEXT": "Dynamische Deklarationen"}
{"DOCID": "403", "TEXT": "Thunks -- Eine Methode zum Kompilieren von Prozeduranweisungen mit einigen Kommentaren zu Prozeduranweisungen"}
{"DOCID": "404", "TEXT": "Ein syntaktischer Compiler für ALGOL 60"}
{"DOCID": "405", "TEXT": "Ein Algorithmus zum Codieren effizienter arithmetischer Operationen: Die meisten existierenden Formelübersetzungsschemata ergeben eine ineffiziente Codierung. Es wird ein Verfahren beschrieben, das die Anzahl der Speicher- und Abrufoperationen reduziert, konstante Teilausdrücke während der Kompilierung auswertet und viele äquivalente Teilausdrücke erkennt."}
{"DOCID": "406", "TEXT": "Die Verwendung von Threaded-Listen beim Aufbau eines kombinierten ALGOL- und maschinenähnlichen Assembly-Prozessors"}
{"DOCID": "407", "TEXT": "MADCAP: Ein wissenschaftlicher Compiler für eine Lehrbuchsprache für angezeigte Formeln"}
{"DOCID": "408", "TEXT": "Die interne Organisation des MAD Translator"}
{"DOCID": "409", "TEXT": "CL-1, An Environment for a Compiler: Ein flexibles, umfangreiches Programmiersystem zur Erleichterung der Lösung von Informationsverarbeitungsproblemen und zur Bereitstellung einer Kommunikation zwischen Programmen und/oder Programmierern wurde auf dem Computer IBM 709/7090 entwickelt und realisiert. Das System basiert auf einem Master-File-Konzept und verfügt über Vorkehrungen zum Akzeptieren, Speichern und Abrufen sowohl von Beschreibungen als auch von Instanzen großer und komplexer Datensätze sowie von Algorithmen, die auf diesen Datensätzen definiert sind. Sowohl Daten als auch Algorithmen können in einer Familie von Befehls- und Beschreibungssprachen ausgedrückt werden. Das Konzept unterschiedlicher Datenbeschreibungen und der Inhalt und die Verwendung solcher Beschreibungen werden ausführlich diskutiert."}
{"DOCID": "410", "TEXT": "Der CLIP-Übersetzer"}
{"DOCID": "411", "TEXT": "Verwendung von Magnetband zur Datenspeicherung im ORACLE-ALGOL-Übersetzer"}
{"DOCID": "412", "TEXT": "Rekursive Prozesse und ALGOL-Übersetzung"}
{"DOCID": "413", "TEXT": "Ein einfacher Compiler für arithmetische Ausdrücke"}
{"DOCID": "414", "TEXT": "Datenverarbeitungssystem IBM 1440 mit fünf neuen Einheiten: Das Datenverarbeitungssystem IBM 1440, das kürzlich von der International Business Machines Corporation angekündigt wurde, verfügt nicht nur über das Plattenspeicherlaufwerk 1311 mit austauschbaren Plattenpaketen, sondern über vier weitere neu entwickelte Einheiten."}
{"DOCID": "415", "TEXT": "Die Nutzung digitaler Computer in Westdeutschland"}
{"DOCID": "416", "TEXT": "Mehrfachschießmethode für Zweipunkt-Grenzwertprobleme"}
{"DOCID": "417", "TEXT": "Rechtliche Implikationen der Computernutzung: Dieses Dokument zeigt eine Vielzahl von Möglichkeiten auf, wie Computersysteme, die in Wirtschaft und Industrie verwendet werden, in rechtliche Verstrickungen verwickelt sein können, und legt nahe, dass Computerspezialisten die Verantwortung haben, Unterstützung bei der Verhinderung oder Minimierung dieser Verstrickungen während der Planungsphase anzufordern. Es werden Techniken vorgeschlagen, um die rechtliche Klärung mit der geringsten Belastung für die neue Technologie effektiv zu gestalten und allgemein ein günstiges rechtliches Klima dafür zu schaffen. Computerspezialisten werden auch auf potenzielle Gelegenheiten aufmerksam gemacht, Anwälten die technischen Aspekte von Computersystemen zu interpretieren, die in Rechtssituationen involviert sind."}
{"DOCID": "418", "TEXT": "ZUFÄLLIG (Algorithmus 133)"}
{"DOCID": "419", "TEXT": "Magisches Quadrat (Algorithmus 118)"}
{"DOCID": "420", "TEXT": "PERM (Algorithmus 115)"}
{"DOCID": "421", "TEXT": "Position des Punktes relativ zum Polygon (Algorithmus 112)"}
{"DOCID": "422", "TEXT": "KOMBINATION (Algorithmus 94)"}
{"DOCID": "423", "TEXT": "Matrixinversion (Algorithmus 58)"}
{"DOCID": "424", "TEXT": "Gamma-Funktion (Algorithmus 31)"}
{"DOCID": "425", "TEXT": "Vollständiges elliptisches Integral (Algorithmus 149)"}
{"DOCID": "426", "TEXT": "Begriff des magischen Quadrats (Algorithmus 148)"}
{"DOCID": "427", "TEXT": "PSIF (Algorithmus 147)"}
{"DOCID": "428", "TEXT": "Mehrfache Integration (Algorithmus 146)"}
{"DOCID": "429", "TEXT": "Adaptive nimerische Integration nach der Simpson-Regel (Algorithmus 145)"}
{"DOCID": "430", "TEXT": "BAUMORT2 (Algorithmus 144)"}
{"DOCID": "431", "TEXT": "BAUMORT1 (Algorithmus 143)"}
{"DOCID": "432", "TEXT": "Dreiecksregression (Algorithmus 142)"}
{"DOCID": "433", "TEXT": "Arrays mit fester Weltlänge in Computern mit variabler Wortlänge"}
{"DOCID": "434", "TEXT": "Zeichenmanipulation in 1620 Fortran II"}
{"DOCID": "435", "TEXT": "Eine Entscheidungsmatrix als Grundlage für eine einfache Dateneingaberoutine: Derzeit wird viel Zeit und Mühe auf die Entwicklung größerer und besserer Compilersprachen, Multiprogramm-Ausführungssysteme usw. verwendet, da die Implementierung neuer Methoden und Verfahren erfolgt nicht augenblicklich, sondern durch einen evolutionären Prozess erfolgt, sollten wir uns auch mit dem Problem der Pflege, Verbesserung und Integration neuer Ideen in bestehende Systeme befassen. An diesem etwas vernachlässigten Bereich interessiert sich der Autor. Es wird ein Verfahren vorgestellt, das eine Entscheidungsmatrix verwendet, um ein Standardsystemprogrammierproblem zu handhaben, nämlich das Bereitstellen einer Dateneingaberoutine."}
{"DOCID": "436", "TEXT": "Auswertung von Polynomen per Computer"}
{"DOCID": "437", "TEXT": "Kompilieren von Matrixoperationen"}
{"DOCID": "438", "TEXT": "Mechanische Pragmatik: Eine Zeitbewegungsstudie eines mechanischen Miniatur-Sprachsystems"}
{"DOCID": "439", "TEXT": "Online-Digitalcomputer zur Messung eines neurologischen Kontrollsystems"}
{"DOCID": "440", "TEXT": "Datensatzverknüpfung: Besondere Schwierigkeiten treten bei der Entwicklung zuverlässiger Systeme zum Suchen und Aktualisieren großer Dokumentendateien auf, die hauptsächlich auf der Grundlage von Namen und anderen persönlichen Angaben identifiziert werden müssen. Das zugrunde liegende Problem besteht darin, Identifizierungsinformationen, die einzeln unzuverlässig sind, aber insgesamt eine beträchtliche Unterscheidungskraft haben können, nahezu maximal zu nutzen. In einer methodischen Studie zur Verknüpfung von Vital- und Gesundheitsakten zu Familiengruppierungen für demografische Forschungszwecke wurden allgemein auf Namensfindungssysteme anwendbare Regeln entwickelt. Diese Regeln werden beschrieben, und es wird diskutiert, wie die Informationsnutzung für den Abgleich optimiert werden kann."}
{"DOCID": "441", "TEXT": "Topologische Sortierung großer Netzwerke: Die topologische Sortierung ist ein Verfahren, das für viele Probleme bei der Analyse von Netzwerken erforderlich ist. Ein Beispiel für ein solches Problem ist PERT. Die vorliegende Arbeit stellt ein sehr allgemeines Verfahren zum Erhalten einer topologischen Ordnung vor. Es erlaubt die Behandlung größerer Netze als mit den derzeitigen Verfahren gehandhabt werden können, und erreicht dies mit größerer Effizienz. Obwohl das Verfahren an jede Maschine angepasst werden kann, wird es in Bezug auf die 7090 diskutiert. Ein PERT-Netzwerk von 30.000 Aktivitäten kann in weniger als einer Stunde Maschinenzeit bestellt werden. Die Methode wurde als Nebenprodukt von Verfahren entwickelt, die von Westinghouse, Baltimore, benötigt wurden. Es wurde nicht programmiert und es gibt derzeit keine Pläne, es zu implementieren. In Bezug auf die beschriebenen Techniken werden Westinghouses gegenwärtige und erwartete Bedürfnisse vollständig durch das derzeit verwendete Lockheed-Programm gedeckt."}
{"DOCID": "442", "TEXT": "Crout mit Ausgleich und Iteration (Algorithmus 135)"}
{"DOCID": "443", "TEXT": "Komplexe Zahl zu einer reellen Potenz (Algorithmus 106)"}
{"DOCID": "444", "TEXT": "Auswertung des Jacobi-Symbols (Algorithmus 99)"}
{"DOCID": "445", "TEXT": "KOMBINATION (Algorithmus 94)"}
{"DOCID": "446", "TEXT": "Simpsons Integration (Algorithmus 84)"}
{"DOCID": "447", "TEXT": "Bescheinigung über die Berechnung von Ostern"}
{"DOCID": "448", "TEXT": "Pfadmatrix (Algorithmus 141)"}
{"DOCID": "449", "TEXT": "Matrixinversion (Algorithmus 140)"}
{"DOCID": "450", "TEXT": "Lösung der Diophantischen Gleichung (Algorithmus 139)"}
{"DOCID": "451", "TEXT": "Verschachtelung von for Statement II (Algorithmus 138)"}
{"DOCID": "452", "TEXT": "Verschachtelung von for Statement I (Algorithmus 137)"}
{"DOCID": "453", "TEXT": "Vergrößerung einer Gruppe (Algorithmus 136)"}
{"DOCID": "454", "TEXT": "Crout mit Ausgleich und Iteration (Algorithmus 135)"}
{"DOCID": "455", "TEXT": "Potenzierung von Reihen (Algorithmus 134)"}
{"DOCID": "456", "TEXT": "ZUFÄLLIG (Algorithmus 133)"}
{"DOCID": "457", "TEXT": "Quantenmechanische Integrale über alle Integrale vom Slater-Typ"}
{"DOCID": "458", "TEXT": "Koeffizientenbestimmung (Algorithmus 131)"}
{"DOCID": "459", "TEXT": "PERMUTE (Algorithmus 130)"}
{"DOCID": "460", "TEXT": "MINIFUN (Algorithmus 129)"}
{"DOCID": "461", "TEXT": "Kodierung medizinischer Anamnesedaten für die Computeranalyse"}
{"DOCID": "462", "TEXT": "Techniken der Computermustererkennung: Elektrokardiographische Diagnose: Die Verwendung von programmierten digitalen Computern als allgemeine Musterklassifikations- und Erkennungsgeräte ist eine Phase des aktuellen lebhaften Interesses an künstlicher Intelligenz. Es ist wichtig, eine Klasse von Signalen zu wählen, die gegenwärtig zum Zweck der Mustererkennung von geschulten Personen einem hohen Maß an visueller Inspektion unterzogen wird. Auf diese Weise können Vergleiche zwischen maschineller und menschlicher Leistung erhalten werden. Als zusätzliche Motivation dient auch ein praktisches Ergebnis. Klinische Elektrokardiogramme bilden eine solche Klasse von Signalen. Die Herangehensweise an das hier dargestellte Problem konzentriert sich auf die Verwendung mehrerer adaptiver angepasster Filter, die normalisierte Signale klassifizieren. Der vorliegende Bericht gibt einige Hintergründe für die Anwendung dieser Methode wieder."}
{"DOCID": "463", "TEXT": "Zur Mehrdeutigkeit in Phrasenstruktursprachen"}
{"DOCID": "464", "TEXT": "Syntaktische Analyse durch einen digitalen Computer: Dieses Dokument liefert einen Bericht über die Schattensprache, die verwendet wird, um die Syntax zu beschreiben, und über eine entsprechende Unterroutine, die es einem Computer ermöglicht, eine syntaktische Analyse durchzuführen. Die Eingabe in dieses Unterprogramm besteht aus einer zu analysierenden Zeichenkette und einer Beschreibung der zu verwendenden Syntax. Die Syntax wird in der Shadow-Sprache ausgedrückt. Die Ausgabe besteht aus einer Ablaufverfolgungstabelle, die die Ergebnisse der syntaktischen Analyse in tabellarischer Form ausdrückt. Mehrere Versionen des Unterprogramms und einiger zugehöriger Programme sind nun seit über drei Jahren im Einsatz. Die vorliegende Darstellung der Sprache und der Subroutine enthält eine Zusammenfassung von Material, das zuvor in unveröffentlichten Berichten beschrieben wurde, sowie einige zusätzliche Diskussionen der Arbeit in Bezug auf allgemeinere Fragen zu problemorientierten Sprachen und Zeichenkettentransformationen."}
{"DOCID": "465", "TEXT": "PERM (Algorithmus 115)"}
{"DOCID": "466", "TEXT": "Allgemeine Ordnungsarithmetik (Algorithmus 93)"}
{"DOCID": "467", "TEXT": "Permutationsgenerator (Algorithmus 87)"}
{"DOCID": "468", "TEXT": "Unvollständige elliptische Integrale (Algorithmus 73)"}
{"DOCID": "469", "TEXT": "Scheduling kritischer Pfade (Algorithmus 40)"}
{"DOCID": "470", "TEXT": "Summation von Fourier-Reihen (Algorithmus 128)"}
{"DOCID": "471", "TEXT": "ORTHO (Algorithmus 127)"}
{"DOCID": "472", "TEXT": "Gauß-Methode (Algorithmus 126)"}
{"DOCID": "473", "TEXT": "WEIGHTCOEFF (Algorithmus 125)"}
{"DOCID": "474", "TEXT": "Eingabedatenorganisation in Fortran"}
{"DOCID": "475", "TEXT": "Eine Testmatrix für Inversionsverfahren"}
{"DOCID": "476", "TEXT": "Weitere Bemerkungen zum Abtasten einer Banddatei-II"}
{"DOCID": "477", "TEXT": "Weitere Bemerkungen zum Abtasten einer Banddatei-I"}
{"DOCID": "478", "TEXT": "Implementieren eines Stacks"}
{"DOCID": "479", "TEXT": "A Dispersion Pass Algorithm for the Polyphase Merge: Dieses Dokument stellt eine neue Art der Dispergierung von Zeichenketten für eine Polyphase-Mischung vor. Wenn die Anzahl der dispergierten Fäden zwischen zwei Ebenen liegt, die für die Polyphase-Mischung akzeptabel sind, wird eine wirtschaftlichere Technik zum Erreichen der nächsten Ebene für die Polyphase-Mischung gezeigt und bewiesen."}
{"DOCID": "480", "TEXT": "Schnelle Berechnung elliptischer Jacobi-Funktionen (Korrigendum)"}
{"DOCID": "481", "TEXT": "Ein eintägiger Blick auf die Datenverarbeitung"}
{"DOCID": "482", "TEXT": "TALL-A Listenprozessor für den Philco 200 Computer"}
{"DOCID": "483", "TEXT": "Über die Nichtexistenz einer Phrasenstrukturgrammatik für ALGOL 60: ALGOL 60 ist teilweise durch formale Mechanismen der Phrasenstrukturgrammatik, teilweise durch informell festgelegte Einschränkungen definiert. Es wird gezeigt, dass keine formalen Mechanismen der verwendeten Art ausreichen, um ALGOL 60 zu definieren."}
{"DOCID": "484", "TEXT": "Hankel-Funktion (Algorithmus 124)"}
{"DOCID": "485", "TEXT": "Reale Fehlerfunktion, ERF(x) (Algorithmus 123)"}
{"DOCID": "486", "TEXT": "Tridiagonale Matrix (Algorithmus 122)"}
{"DOCID": "487", "TEXT": "NORMDEV (Algorithmus 121)"}
{"DOCID": "488", "TEXT": "Eine Heuristik für das Umblättern von Seiten in einem Computer mit mehreren Programmen"}
{"DOCID": "489", "TEXT": "Aktueller Stand von IPL-V für den Philco 2000 Computer (Juni 1962)"}
{"DOCID": "490", "TEXT": "Programmierte Methoden für die grafische Ausgabe von Druckern"}
{"DOCID": "491", "TEXT": "Verwendung von Multiprogramming beim Entwurf eines kostengünstigen Digitalcomputers"}
{"DOCID": "492", "TEXT": "Analyse eines Dateiadressierungsverfahrens: Dieses Papier stellt ein neues Dateiadressierungsverfahren vor, das auf der Berechnung einer Adresse aus der Identifikation eines Datensatzes basiert. Für große Umlauffeilen scheint es vorteilhafter zu sein als herkömmliche Feilen. Die Wahrscheinlichkeitsverteilung der Verschiebung von Datensätzen von ihrer berechneten Adresse, die um eins kleiner ist als die Anzahl der zum Adressieren eines Datensatzes erforderlichen Sonden, wird auf der Grundlage eines Markov-Kettenmodells berechnet. Für den nicht an Mathematik interessierten Leser sollten die Einleitung und die Zusammenfassung ausreichend sein."}
{"DOCID": "493", "TEXT": "Die Eigenschaftsklassifizierungsmethode für Dateidesign und -verarbeitung"}
{"DOCID": "494", "TEXT": "Ein endlicher sequentiell kompakter Prozess für die Adjungierten von Matrizen über beliebigen Integralbereichen"}
{"DOCID": "495", "TEXT": "Ein Verfahren zur Invertierung großer symmetrischer Matrizen: Bei der Methode der kleinsten Quadrate zur gleichzeitigen Anpassung mehrerer Parameter sind die Koeffizienten der Normalgleichungen die Elemente einer symmetrischen positiv-definiten Matrix. Um die Normalgleichungen zu lösen und die Präzisionsmaße der resultierenden Parameter auszuwerten, ist eine Inversion dieser Koeffizientenmatrix erforderlich. Viele verfügbare Verfahren zur Matrixinversion nutzen die Symmetrie nicht aus. Wenn also für einen Hochgeschwindigkeitscomputer programmiert wird, müssen alle n^2 Elemente gespeichert und bearbeitet werden, während nur (n + 1)/2 davon unabhängig sind. Um es einem Computer mit gegebener Speicherkapazität zu ermöglichen, eine größere Matrix zu handhaben, wurde das folgende Verfahren zum Invertieren einer symmetrischen Matrix entwickelt."}
{"DOCID": "496", "TEXT": "Eine Reihe von Matrizen zum Testen von Computerprogrammen"}
{"DOCID": "497", "TEXT": "Weitere Bemerkungen zur Liniensegment-Kurvenanpassung unter Verwendung dynamischer Programmierung: In einer kürzlich erschienenen Veröffentlichung zeigte Bellman, wie dynamische Programmierung verwendet werden könnte, um die Lösung für ein zuvor von Stone betrachtetes Problem zu bestimmen. Das Problem umfasst die Bestimmung, gegeben N, der N Unterteilungspunkte eines gegebenen Intervalls (a, B) und der entsprechenden Liniensegmente, die die beste Anpassung der kleinsten Quadrate an eine Funktion g(x) in dem Intervall ergeben. Bellman beschränkte sich in erster Linie auf die analytische Ableitung, schlug jedoch kurz vor, wie die Lösung der für jeden einzelnen Unterteilungspunkt u(i) abgeleiteten Gleichung auf eine diskrete Suche reduziert werden könnte. In diesem Artikel wird das Berechnungsverfahren ausführlicher betrachtet, und die Ähnlichkeiten mit einigen von Stones Gleichungen werden aufgezeigt. Es wird ferner gezeigt, dass eine Gleichung für u(i) ohne Minimierung gefunden werden kann. Außerdem wird gezeigt, wie das Bellman-Verfahren auf das Kurvenanpassungsproblem angewendet werden kann, wenn die zusätzlichen Einschränkungen hinzugefügt werden, dass die Enden der Liniensegmente auf der Kurve liegen müssen."}
{"DOCID": "498", "TEXT": "Magisches Quadrat (Algorithmus 117 & 118)"}
{"DOCID": "499", "TEXT": "Permutationsgenerator (Algorithmus 87)"}
{"DOCID": "500", "TEXT": "PERMUTE (Algorithmus 86)"}
{"DOCID": "501", "TEXT": "JACOBI (Algorithmus 85)"}
{"DOCID": "502", "TEXT": "Simpsons Integration (Algorithmus 84)"}
{"DOCID": "503", "TEXT": "Rationale Wurzeln von Polynomen mit ganzzahligen Koeffizienten (Algorithmus 78)"}
{"DOCID": "504", "TEXT": "FAKTOREN (Algorithmus 75)"}
{"DOCID": "505", "TEXT": "Kompositionsgenerator (Algorithmus 72)"}
{"DOCID": "506", "TEXT": "PERMUTATION (Algorithmus 71)"}
{"DOCID": "507", "TEXT": "Partition, Quicksort, Find (Algorithmus 63, 64, 65)"}
{"DOCID": "508", "TEXT": "Matrixinversion (Algorithmus 58)"}
{"DOCID": "509", "TEXT": "Matrixinversion (Algorithmus 58)"}
{"DOCID": "510", "TEXT": "Ber- oder Bei-Funktion (Algorithmus 57)"}
{"DOCID": "511", "TEXT": "Ein Satz von Testmatrizen (Algorithmus 52)"}
{"DOCID": "512", "TEXT": "Teleskop 1 (Algorithmus 37)"}
{"DOCID": "513", "TEXT": "SIEB (Algorithmus 35)"}
{"DOCID": "514", "TEXT": "Binomialkoeffizienten (Algorithmus 19)"}
{"DOCID": "515", "TEXT": "Rationale Interpolation durch Kettenbrüche (Algorithmus 18)"}
{"DOCID": "516", "TEXT": "Matrixinversion II (Algorithmus 120)"}
{"DOCID": "517", "TEXT": "Auswertung des Pert-Netzwerks (Algorithmus 119)"}
{"DOCID": "518", "TEXT": "Magisches Quadrat (ungerade Ordnung) (Algorithmus 118)"}
{"DOCID": "519", "TEXT": "Magisches Quadrat (gerade Ordnung) (Algorithmus 117)"}
{"DOCID": "520", "TEXT": "Komplexe Division (Algorithmus 116)"}
{"DOCID": "521", "TEXT": "PERM (Algorithmus 115)"}
{"DOCID": "522", "TEXT": "Generierung von Partitionen mit Einschränkungen (Algorithmus 114)"}
{"DOCID": "523", "TEXT": "BAUMSORTIERUNG (Algorithmus 113)"}
{"DOCID": "524", "TEXT": "Position des Punktes relativ zum Polygon (Algorithmus 112)"}
{"DOCID": "525", "TEXT": "Eine Computertechnik zur Handhabung der Varianzanalyse"}
{"DOCID": "526", "TEXT": "Zeichenmanipulation in Fortran"}
{"DOCID": "527", "TEXT": "Die Beschreibungsliste von Konzepten: Ein Konzept ist als eine Klasse von Objekten definiert, deren Mitglieder durch Verarbeitung ihrer Eigenschaften unterschieden werden können. Eigenschaft ist definiert als eine Aufteilung der Menge aller Objekte in disjunkte Klassen. Die formale Definition eines Begriffs ist rekursiver Natur. Ein Konzept wird durch eine Listenstruktur beschrieben. Zwischen der rekursiven Definition eines Konzepts und seiner Beschreibungslistenstruktur wird eine Eins-zu-Eins-Entsprechung hergestellt. Wie die Definition wird auch die Beschreibungslistenstruktur eines Begriffs rekursiv aus elementaren Listenstrukturen aufgebaut. Die so erhaltenen Listenstrukturen werden mit der vom Autor in einer früheren Veröffentlichung diskutierten Beschreibungslistenstruktur verglichen."}
{"DOCID": "528", "TEXT": "FORTRAN für die Geschäftsdatenverarbeitung"}
{"DOCID": "529", "TEXT": "Regression und codierte Muster in der Datenbearbeitung"}
{"DOCID": "530", "TEXT": "Eine Computermethode zur Strahlenbehandlungsplanung"}
{"DOCID": "531", "TEXT": "Personenabgleich durch elektronische Methoden: Die Datensatzverknüpfung bei der Aktualisierung von Dateien wird in vielen Einrichtungen durch die Verwendung einer vorab zugewiesenen Nummer erreicht, wie z. B. einer Gehaltsabrechnungsnummer, Kundennummer oder Sozialversicherungsnummer. In Vital- und Gesundheitsakten wird jedoch im Allgemeinen keine eindeutige Nummer einer Person vorab zugewiesen, um erhaltene Leistungen an das Gesundheitsamt zu melden. Um festzustellen, ob sich verschiedene Arztberichte auf dieselbe Person beziehen, müssen Name und andere Identifikationen verglichen werden. Dies ist ein mühsamer Vorgang, der aufgrund von Namensfehlern, Namensänderungen bei Heirat und anderen Problemen mit verschiedenen Fehlern behaftet ist. Wir sind an der Führung eines psychiatrischen Fallregisters in Maryland interessiert, wo sich viele der Berichte von über hundert psychiatrischen Einrichtungen auf denselben Patienten beziehen. Diese Aufzeichnungen müssen verknüpft werden, um nicht duplizierte Zählungen von betreuten Personen und Längsschnittaufzeichnungen der psychiatrischen Vorgeschichte bereitzustellen. Eine frühere Veröffentlichung [1] beschreibt unsere allgemeinen Verfahren zur Registerpflege durch Verwendung eines digitalen Computers (Honeywell 800). Hier stellen wir unsere ersten Vorgehensweisen für den Personen-Matching-Prozess detaillierter vor, um Kommentare und Vorschläge von Personen zu erhalten, die Erfahrung mit dem Matching haben."}
{"DOCID": "532", "TEXT": "Zur Berechnung rationaler Approximationen stetiger Funktionen"}
{"DOCID": "533", "TEXT": "Digitale Synthese von korreliertem stationären Rauschen: In dieser Anmerkung schlagen wir ein Verfahren zum Erzeugen von stationärem Rauschen mit einer vorgeschriebenen Autokovarianzfunktion durch digitale Verfahren vor. Der Bedarf für eine solche Technik entsteht häufig beim Testen der Leistung von Datenverarbeitungs- und Engineering-Systemen, wo Eingaben erforderlich sind, die mit korreliertem Rauschen (bekannter Form) verfälscht sind. Die Technik ist ziemlich einfach und erzeugt streng genommen stationäres Rauschen, das ungefähr mit R(t), der vorgeschriebenen Autokovarianzfunktion (acf), über ein Intervall [–T(0), T(0)] übereinstimmt. Das Verfahren besteht darin, die Spektraldichte durch einen periodischen Prozess mit Spektrallinien zu approximieren und dann das periodische Rauschen mit zufälligen Phasen und geeigneten Amplituden zu synthetisieren. Um die Erörterung der statistischen Eigenschaften des erzeugten Rauschens zu vereinfachen, wird die Technik zunächst in Form einer exakten harmonischen Analyse vorgestellt. In der Praxis wird die im dritten Abschnitt vorgestellte diskrete harmonische Analyse verwendet."}
{"DOCID": "534", "TEXT": "Schnelle Berechnung elliptischer Jacobi-Funktionen"}
{"DOCID": "535", "TEXT": "Dreieckslaufmuster für die Bergab-Methode zum Lösen einer transzendentalen Gleichung"}
{"DOCID": "536", "TEXT": "Nichtlineare Regression und die Lösung simultaner Gleichungen: Hat man eine Menge von Observablen (Z1,...,Zm), die mit bestimmten Parametern (A1,...,An) durch eine Gleichung S(Z1, ...;A1,...)=0, hat man häufig das Problem, eine Menge von Werten der Ai zu bestimmen, die die Summe der Differenzquadrate zwischen beobachteten und berechneten Werten einer ausgezeichneten Observablen, etwa Zm, minimiert. Wenn die Lösung der obigen Gleichung für Zm, Zm=N(Z1,...;A1,...) zu einer Funktion N führt, die in Ai nichtlinear ist, dann kann man sich auf eine Version der Gaußschen Regression [ 1,2] für ein Iterationsschema, das zu einem minimierenden Satz von Werten konvergiert. Es wird hier gezeigt, dass dieselbe Minimierungstechnik für die Lösung gleichzeitiger (nicht notwendigerweise linearer) Gleichungen verwendet werden kann."}
{"DOCID": "537", "TEXT": "Ein Maschinenprogramm zum Theorem-Beweis: Das Programm eines Beweisverfahrens wird im Zusammenhang mit Probeläufen und möglichen Verbesserungen diskutiert."}
{"DOCID": "538", "TEXT": "Quantenmechanische Integrale von Orbitalen vom Slater-Typ (Algorithmus 110)"}
{"DOCID": "539", "TEXT": "Bestimmte exponentielle Integrale B (Algorithmus 109)"}
{"DOCID": "540", "TEXT": "Bestimmte exponentielle Integrale A (Algorithmus 108)"}
{"DOCID": "541", "TEXT": "Simpsons Integration (Algorithmus 84)"}
{"DOCID": "542", "TEXT": "FAKTOREN (Algorithmus 75)"}
{"DOCID": "543", "TEXT": "Interpolation von Aitken (Algorithmus 70)"}
{"DOCID": "544", "TEXT": "Ber- oder Bei-Funktion (Algorithmus 57)"}
{"DOCID": "545", "TEXT": "Inverse einer Matrix anpassen, wenn ein Element gestört ist (Algorithmus 51)"}
{"DOCID": "546", "TEXT": "Logarithmus einer komplexen Zahl (Algorithmus 48)"}
{"DOCID": "547", "TEXT": "Gamma-Funktion (Algorithmus 34)"}
{"DOCID": "548", "TEXT": "Molekular-Orbital-Berechnung molekularer Wechselwirkungen"}
{"DOCID": "549", "TEXT": "Quantenmechanische Integrale von Orbitalen vom Slater-Typ"}
{"DOCID": "550", "TEXT": "Bestimmte exponentielle Integrale B (Algorithmus 109)"}
{"DOCID": "551", "TEXT": "Bestimmte exponentielle Integrale A (Algorithmus 108)"}
{"DOCID": "552", "TEXT": "Gauß-Methode (Algorithmus 107)"}
{"DOCID": "553", "TEXT": "Komplexe Zahl zu einer reellen Potenz (Algorithmus 106)"}
{"DOCID": "554", "TEXT": "Newton Maehly, (Algorithmus 105)"}
{"DOCID": "555", "TEXT": "Reduktion auf Jacobi (Algorithmus 104)"}
{"DOCID": "556", "TEXT": "Zur Übersetzung boolescher Ausdrücke"}
{"DOCID": "557", "TEXT": "Simulation eines Computerzeitmessgeräts"}
{"DOCID": "558", "TEXT": "A Modified Inversion Procedure for Product Form of the Inverse Linear Programming Codes: Dieser Beitrag beschreibt einen neuen Algorithmus zur Auswahl der Pivot-Zeile bei Matrix-Inversion bei Verwendung der Produktform der Inversen. Dieser Algorithmus wurde für lineare Programmiercodes entwickelt; es wäre jedoch wertvoll für die Inversion jeder nicht dichten Matrix. Die in diesem Dokument beschriebenen Verfahren wurden gründlich getestet und sind seit neun Monaten auf dem IBM 7090-Computer von Esso Research and Engineering in Betrieb. Aufgrund dieses Verfahrens wurden erhebliche Computerkosteneinsparungen realisiert."}
{"DOCID": "559", "TEXT": "Lösung von Eigenwertproblemen mit näherungsweise bekannten Eigenvektoren"}
{"DOCID": "560", "TEXT": "Kommunikation zwischen unabhängig übersetzten Blöcken"}
{"DOCID": "561", "TEXT": "Analytische Differenzierung per Computer"}
{"DOCID": "562", "TEXT": "AVINT (Algorithmus 77)"}
{"DOCID": "563", "TEXT": "Sortierverfahren (Algorithmus 76)"}
{"DOCID": "564", "TEXT": "CRAM (Algorithmus 67)"}
{"DOCID": "565", "TEXT": "INVRS (Algorithmus 66)"}
{"DOCID": "566", "TEXT": "Matrixinversion (Algorithmus 58)"}
{"DOCID": "567", "TEXT": "Logarithmus einer komplexen Zahl (Algorithmus 48)"}
{"DOCID": "568", "TEXT": "Exponential einer komplexen Zahl (Algorithmus 46)"}
{"DOCID": "569", "TEXT": "Binomialkoeffizienten (Algorithmus 19)"}
{"DOCID": "570", "TEXT": "Simpsons Regelintegrator (Algorithmus 103)"}
{"DOCID": "571", "TEXT": "Permutation in lexikografischer Reihenfolge (Algorithmus 102)"}
{"DOCID": "572", "TEXT": "Element zur verketteten Liste hinzufügen (Algorithmus 100)"}
{"DOCID": "573", "TEXT": "Element aus verketteter Liste entfernen (Algorithmus 101)"}
{"DOCID": "574", "TEXT": "Auswertung des Jacobi-Symbols (Algorithmus 99)"}
{"DOCID": "575", "TEXT": "Auswertung bestimmter komplexer Linienintegrale (Algorithmus 98)"}
{"DOCID": "576", "TEXT": "Kürzester Weg (Algorithmus 97)"}
{"DOCID": "577", "TEXT": "VORFAHRT (Algorithmus 96)"}
{"DOCID": "578", "TEXT": "Generierung von Partitionen in Part-Count-Form (Algorithmus 95)"}
{"DOCID": "579", "TEXT": "KOMBINATION (Algorithmus 94)"}
{"DOCID": "580", "TEXT": "Allgemeine Ordnungsarithmetik (Algorithmus 93)"}
{"DOCID": "581", "TEXT": "Eine Anmerkung zum Abtasten einer Banddatei"}
{"DOCID": "582", "TEXT": "Ein verlorenes Bit"}
{"DOCID": "583", "TEXT": "Eine Redundanzprüfung für ALGOL-Programme"}
{"DOCID": "584", "TEXT": "Bericht über die algorithmische Sprache FORTRAN II"}
{"DOCID": "585", "TEXT": "Anfängliche Erfahrungen mit einem funktionierenden Multiprogramming-System: Das Lewis Research Center hat während der letzten fünf Jahre verschiedene Formen und Grade der Programmgleichzeitigkeit beim Betrieb seines modifizierten Computers Sperry-Rand Univac Scientific Model 1103 verwendet. Diese Gleichzeitigkeit hat sich von einer anfänglichen Errungenschaft der selbstsuchenden Ein- und Ausgabe zum automatischen Timesharing von unabhängig codierten Problemen entwickelt. Mehrere wichtige Maschinen- und Programmsystemmodifikationen waren notwendig, um diese Entwicklung zu vollenden. Mehrere zusätzliche Modifikationen, obwohl nicht erforderlich, wurden hinzugefügt, um die Codierung und den Betrieb zu erleichtern. Alle Umbauten mussten in einem relativ moderaten Tempo erfolgen, um sicherzustellen, dass die grundlegende Datenreduktionslast des Rechenzentrums termingerecht abgeschlossen wurde. Einige pädagogisch wertvolle Fehler wurden gemacht, und ihre vorgeschlagenen Abhilfemaßnahmen wiesen oft den Weg zu nützlichen zukünftigen Verbesserungen oder betonten einige der Grundprinzipien eines Multiprogramming-Systems. Das folgende Material ist eine Beschreibung der Entwicklung des Programmier- und Hardwaresystems, das sich zum gegenwärtigen Multiprogramming-System am Lewis Research Center entwickelt hat."}
{"DOCID": "586", "TEXT": "Gleichzeitiges Gleichungssystem und Matrixinversionsroutine (Algorithmus 92)"}
{"DOCID": "587", "TEXT": "Romberg-Integration (Algorithmus 60)"}
{"DOCID": "588", "TEXT": "Tschebyscheff-Kurvenanpassung (Algorithmus 91)"}
{"DOCID": "589", "TEXT": "Auswertung des Fresnel-Cosinus-Integrals (Algorithmus 90)"}
{"DOCID": "590", "TEXT": "Auswertung des Fresnel-Sinus-Integrals (Algorithmus 89)"}
{"DOCID": "591", "TEXT": "Auswertung des asymptotischen Ausdrucks für die Fresnel-Sinus- und Cosinus-Integrale (Algorithmus 88)"}
{"DOCID": "592", "TEXT": "COBOL-Batching-Probleme"}
{"DOCID": "593", "TEXT": "Eine Einführung in eine maschinenunabhängige Datenteilung"}
{"DOCID": "594", "TEXT": "Ein erweitertes Eingabe-Ausgabe-System für einen COBOL-Compiler"}
{"DOCID": "595", "TEXT": "Leitfäden zum Unterrichten von COBOL: Der Unterricht von COBOL kann in drei Hauptthemenbereiche unterteilt werden. Sie sind die Syntax von COBOL, die Verwendung einer solchen Syntax bei der Lösung eines bestimmten Problems und Programmierkonzepte. Es ist allgemein anerkannt, dass der Programmierer über gewisse Kenntnisse der Hardware und der Computerlogik verfügen muss. Das Unterrichtsproblem ergibt sich aus der Bestimmung, wie gründlich ein Student die Hardware und Logik für diesen Computer kennen muss, für den er COBOL-Programme schreiben wird. Leider gibt es fast keine historischen Daten zur Programmierkompetenz von Schülern und sie sind bestenfalls schwer zu messen. Wie könnten wir dann an die Lösung dieses Problems herangehen?"}
{"DOCID": "596", "TEXT": "Gleitkomma-Arithmetik in COBOL: In diesem Dokument werden die Grundoperationen der Gleitkomma-Arithmetik untersucht und COBOL-Prozeduren für deren Ausführung zusammen mit der Spezifikation des Arbeitsspeichers angegeben. Die Arbeit schließt mit einem Beispiel, in dem diese Verfahren verwendet werden."}
{"DOCID": "597", "TEXT": "Modulare Datenverarbeitungssysteme, geschrieben in COBOL"}
{"DOCID": "598", "TEXT": "The COBOL Librarian - A Key to Object Program Efficiency: Viele Antworten auf die Frage \"Wie kann ein COBOL-Compiler zur Generierung eines effizienten Objektprogramms gezwungen werden?\" Der Zweck dieses Artikels besteht darin, eine mögliche Antwort vorzustellen: die Erstellung und vollständige Nutzung einer gut aufgebauten COBOL-Bibliothek."}
{"DOCID": "599", "TEXT": "Ein Report Writer für COBOL"}
{"DOCID": "600", "TEXT": "Syntaktische Diagramme von COBOL 61"}
{"DOCID": "601", "TEXT": "Zwischenbericht über das COBOL-Bewertungsprogramm des Bureau of Ships"}
{"DOCID": "602", "TEXT": "COBOL und Kompatibilität"}
{"DOCID": "603", "TEXT": "Grundelemente von COBOL 61"}
{"DOCID": "604", "TEXT": "Warum COBOL?"}
{"DOCID": "605", "TEXT": "Computersimulation des Stadtverkehrs: Bei der Simulation des Verkehrsflusses auf Stadtstraßen hat das National Bureau of Standards Datenverarbeitungstechniken verwendet, um Fahrzeugbewegungen in dem Modell zu tabellieren und bewegte Bilder zu erstellen. Jedem Fahrzeug wird eine digitale Identifikation zugewiesen, die Ein- und Ausfahrtspunkte, Fahrzeugtyp, gewünschte Geschwindigkeit und tatsächliche Geschwindigkeit in Proportionen, die Felddaten simulieren, angibt. Änderungen am Modell können vorgenommen werden, um deren Folgen zu beobachten und die Fähigkeit einer realen Straße zu bestimmen, in Zukunft erwartete Lasten zu tragen."}
{"DOCID": "606", "TEXT": "Ein Verfahren zum Eliminieren von Mehrdeutigkeiten aufgrund von Signalübereinstimmung im digitalen Design"}
{"DOCID": "607", "TEXT": "Die Berechnung von Ostern..."}
{"DOCID": "608", "TEXT": "Permutation (Algorithmus 71)"}
{"DOCID": "609", "TEXT": "Permutation (Algorithmus 71)"}
{"DOCID": "610", "TEXT": "SIEB (Algorithmus 35)"}
{"DOCID": "611", "TEXT": "Permutationsgenerator (Algorithmus 87)"}
{"DOCID": "612", "TEXT": "Permutieren (Algorithmus 86)"}
{"DOCID": "613", "TEXT": "JACOBI (Algorithmus 85)"}
{"DOCID": "614", "TEXT": "Simpsons Integration (Algorithmus 84)"}
{"DOCID": "615", "TEXT": "Adressieren mehrdimensionaler Arrays: Eine nützliche Methode zum Darstellen einer Funktion von n Variablen besteht darin, die Funktion so zu betrachten, dass sie ihre Werte an ausgewählten Punkten im n-dimensionalen Raum annimmt. Obwohl dieses Bild für den Analytiker von Wert ist, müssen die Elemente eines n-dimensionalen Arrays im konventionellen Speicher als lineares Array oder Vektor existieren. Die Mittel zur Durchführung der Transformation eines Satzes von Indizes, die sich auf einem Array-Element im n-Raum befinden, in die Position (Adresse) des Elements in seinem Speichervektor, ist Gegenstand dieses Dokuments. Es wird darauf hingewiesen, dass die Transformation der Indexadresse rechnerisch identisch mit der Umwandlung einer Zahl von einem festen in ein gemischtes Radix-Zahlensystem ist. Es werden mehrere Wege zur Implementierung der Transformation beschrieben."}
{"DOCID": "616", "TEXT": "An Information Algebra – Phase I Bericht – Sprachstrukturgruppe des CODASYL-Entwicklungsausschusses: Dieser Bericht repräsentiert die Ergebnisse der ersten Phase der Arbeit der Sprachstrukturgruppe. Das Ziel dieser Arbeit ist es, auf der Systemebene der Datenverarbeitung zu einer geeigneten Struktur für eine maschinenunabhängige Problemdefinitionssprache zu gelangen. Der Bericht basiert zum größten Teil auf einem mathematischen Modell namens \"An Information Algebra\", das hauptsächlich von R. Bosak entwickelt wurde. Wir hoffen, dass dieser Bericht gelesen wird (a) mit großem Interesse von Entwicklern und Implementierern von Programmiersprachen und all jenen, die an der Entwicklung eines theoretischen Ansatzes zur Datenverarbeitung interessiert sind; (b) mit Interesse und Verständnis von professionellen Programmierern und Systemanalytikern; und (c) mit Anerkennung durch den Geschäftsmann-Analysten-Manager. Die Autoren haben in diesem Bericht keinen erschöpfenden Diskurs versucht. Vielmehr haben sie versucht, den Fachleuten, denen es sehr wichtig ist, eine Arbeitssprache für den Gebrauch des Systemanalytikers bereitzustellen, eine Philosophie vorzustellen. Sie vertrauen darauf, dass die Ideen in diesem Bericht andere dazu anregen werden, in ähnliche Richtungen zu denken. Fragen und Kommentare sind willkommen und können an jedes Mitglied der Language Structure Group gerichtet werden: Robert Bosak, System Development Corporation; Richard F. Clippinger, EDV-Abteilung von Honeywell; Carey Dobbs, Remington Rand Univac-Abteilung; Roy Goldfinger (Vorsitzender), IBM Corporation; Renee B. Jasper, Verwaltungsbüro der Marine; William Keating, Nationale Kasse; George Kendrick, General Electric Company; Jean E. Sammet, IBM Corporation."}
{"DOCID": "617", "TEXT": "POSEIDON: Jeder Computer, der Teil eines Kontrollsystems ist – ob vollständig automatisch oder teilweise menschlich – muss mit der gleichen Geschwindigkeit wie das Kontrollsystem arbeiten. Es muss seine Berechnungen oder Datenverarbeitung schnell genug durchführen, damit die Ergebnisse zu den erforderlichen Zeitpunkten in der Aktion des Steuerungssystems verfügbar sind. Dies wird als Arbeiten in \"Echtzeit\" bezeichnet."}
{"DOCID": "618", "TEXT": "Computer - The Key to Total Systems Control: An Industrial Viewpoint: Mensch-Mensch-Maschine-Prozesse werden in fünf Haupttypen charakterisiert, und die Märkte für jeden Typ werden für 1950 und 1960 gezeigt und für 1970 geschätzt."}
{"DOCID": "619", "TEXT": "Abrufen falsch geschriebener Namen in einem Fluggastdatensystem: Dieses Papier diskutiert das begrenzte Problem der Erkennung und des Abrufs eines gegebenen falsch geschriebenen Namens aus einer Liste von mehreren hundert Namen, wie z. B. dem Reservierungsinventar für einen gegebenen Flug eines großen Düsenflugzeugs. Auf dem Telefile (einem Solid-State-Computer mit Kern und Trommelspeicher mit gespeichertem Programmkern) wurde ein Programm entwickelt und betrieben, das trotz erheblicher Rechtschreibfehler entweder zum Zeitpunkt der ursprünglichen Eingabe oder zum Zeitpunkt des Abrufs die Aufzeichnungen der Passagiere erfolgreich abruft. Das Verfahren beinhaltet eine automatische Bewertungstechnik, die die Namen in komprimierter Form abgleicht. Nur die wenigen Namen, die dem angeforderten Namen am ähnlichsten sind, werden zusammen mit ihren angehängten Telefonnummern für die endgültige manuelle Auswahl des Agenten präsentiert. Das Programm hat erfolgreich Namen isoliert und gefunden, die einer Reihe von ungewöhnlichen (sowie üblichen) Rechtschreibfehlern ausgesetzt waren."}
{"DOCID": "620", "TEXT": "RATFACT (Algorithmus 78)"}
{"DOCID": "621", "TEXT": "Romberg-Integration (Algorithmus 60)"}
{"DOCID": "622", "TEXT": "Optimale Klassifizierung von Objekten (Algorithmus 83)"}
{"DOCID": "623", "TEXT": "Einsparung einer Sequenz 2 (Algorithmus 82)"}
{"DOCID": "624", "TEXT": "Einsparung einer Sequenz 1 (Algorithmus 81)"}
{"DOCID": "625", "TEXT": "Reziproke Gammafunktion des reellen Arguments (Algorithmus 80)"}
{"DOCID": "626", "TEXT": "Eine Methode zur Darstellung, Speicherung und Abfrage von 13 Zufallscodes in einer 4-stelligen Zahl oder 16 Zufallscodes in einer 5-stelligen Zahl"}
{"DOCID": "627", "TEXT": "Verknotete Listenstrukturen"}
{"DOCID": "628", "TEXT": "Über eine Gleitkommazahlendarstellung zur Verwendung mit algorithmischen Sprachen"}
{"DOCID": "629", "TEXT": "Auf einem Wired-In-Binär-zu-Dezimal-Konvertierungsschema"}
{"DOCID": "630", "TEXT": "Eine Bewertung der Autocode-Lesbarkeit: Von den vielen Anforderungen an einen Autocode ist das Anforderungspaar „leicht zu lesen“ und „leicht zu schreiben“ oft nicht kompatibel. Dieses Papier argumentiert, dass Lesbarkeit automatisch im Übersetzungsprozess hinzugefügt werden kann, so dass der Programmierer die größtmögliche Ausdrucksökonomie genießen kann, während für die Verwaltung eine vollständige und gültige COBOL-Version gedruckt wird, um alle Vorteile der Lesbarkeit und Kompatibilität zu bieten."}
{"DOCID": "631", "TEXT": "Automatische Programmiersprachenübersetzung durch syntaktische Analyse*"}
{"DOCID": "632", "TEXT": "Vektorkardiographische Diagnostik mit Hilfe von ALGOL"}
{"DOCID": "633", "TEXT": "Simulation und Analyse biochemischer Systeme (III. Analyse und Mustererkennung)"}
{"DOCID": "634", "TEXT": "Manipulation von Bäumen beim Informationsabruf*"}
{"DOCID": "635", "TEXT": "Eine Anmerkung zum Multiplizieren boolescher Matrizen"}
{"DOCID": "636", "TEXT": "Bandaufteilung in einem iterativen Programm"}
{"DOCID": "637", "TEXT": "Ein NELIAC-generierter 7090-1401-Compiler: NELIAC-Systeme für verschiedene Maschinen wurden unter Verwendung des ursprünglichen NELIAC-Systems generiert, das 1958 am Naval Electronics Laboratory, San Diego, entwickelt wurde. Ein grundlegender \"Bootstrap\" -Prozess wurde verwendet, um alle außer dem ersten zu generieren , d.h. die Systeme wurden in der NELIAC-Sprache beschrieben und von einem bestehenden NELIAC-Compiler generiert. Diese Erfahrung hat gezeigt, dass es keine inhärenten Schwierigkeiten gibt, „Compiler mit Compilern zu bauen“; tatsächlich wies es auf viele Vorteile bei der Verwendung eines POL zum Aufbau von Programmiersystemen hin. Dieser Bericht stellt die Ergebnisse eines im Mai 1961 abgeschlossenen Projekts vor, bei dem das NELIAC-System verwendet wurde, um einen Compiler für den IBM 1401 zu generieren. Der 1401-Compiler, der auf dem 7090 läuft und 1401-Programme erzeugt, wurde in der NELIAC-Sprache und beschrieben generiert mit 7090 NELIAC-System. Die Reduzierung der Programmierzeit und die Verbesserung der Dokumentation des Systems waren sehr signifikant."}
{"DOCID": "638", "TEXT": "SURGE: Eine Neucodierung des COBOL-Warenkontrollalgorithmus"}
{"DOCID": "639", "TEXT": "Differenzausdruckskoeffizienten (Algorithmus 79)"}
{"DOCID": "640", "TEXT": "Rationale Wurzeln von Polynomen mit ganzzahligen Koeffizienten (Algorithmus 78)"}
{"DOCID": "641", "TEXT": "Interpolation, Differentiation und Integration (Algorithmus 77)"}
{"DOCID": "642", "TEXT": "Eine Einführung in ALGOL"}
{"DOCID": "643", "TEXT": "Simulation und Analyse biochemischer Systeme (II. Lösung von Differentialgleichungen)"}
{"DOCID": "644", "TEXT": "A String Language for Symbol Manipulation Based on ALGOL 60: Es wird eine künstliche Computerprogrammiersprache vorgeschlagen, um die Manipulation von Zeichenketten und Symbolen zu beschreiben. Das im ALGOL 60-Bericht eingeführte Konzept von Strings wird erweitert durch Hinzufügen von: (1) der Deklaration von Strings, Teilstrings und String-Arrays mit expliziten Längen; (2) die Fähigkeit, Zeichenfolgen zu verketten und zu verschieben; und (3) die Rangordnung von Symbolen zum Vergleichen von Stichen in Booleschen Beziehungen. Auf eine Einführung oder informelle Beschreibung der Sprache folgen Beispiele, eine Beschreibung von Experimenten mit der Sprache auf einem IBM 704-Computer und eine formale Beschreibung, die zusammen mit dem ALGOL 60-Bericht die vorgeschlagene Zeichenfolgensprache definiert."}
{"DOCID": "645", "TEXT": "INVRS (Algorithmus 66)"}
{"DOCID": "646", "TEXT": "Umkehrung eines endlichen Segments der Hilbert-Matrix (Algorithmus 50)"}
{"DOCID": "647", "TEXT": "Numerische Lösung der Polynomgleichung (Algorithmus 30)"}
{"DOCID": "648", "TEXT": "Sortierverfahren (Algorithmus 76)"}
{"DOCID": "649", "TEXT": "FAKTOREN (Algorithmus 75)"}
{"DOCID": "650", "TEXT": "Kurvenanpassung mit Einschränkungen (Algorithmus 74)"}
{"DOCID": "651", "TEXT": "Ein Überblick über Sprachen und Systeme für den Informationsabruf"}
{"DOCID": "652", "TEXT": "Verwendung der semantischen Struktur in Informationssystemen"}
{"DOCID": "653", "TEXT": "Übersetzung von Abrufanfragen in einer „semiformalen“ englischähnlichen Sprache*"}
{"DOCID": "654", "TEXT": "Sprachprobleme durch stark strukturierte Daten"}
{"DOCID": "655", "TEXT": "COMIT als eine IR-Sprache: Viele der Merkmale, die COMIT zu einer rundum guten Symbolmanipulationssprache machen, machen es auch gut geeignet für verschiedene Arten von Programmen zum Abrufen von Informationen. Hier finden Sie eine allgemeine Diskussion dieser einzigartigen und anderen Programmiersprache und eine Untersuchung einiger ihrer Anwendungen."}
{"DOCID": "656", "TEXT": "Ein Informationssystem mit der Fähigkeit, Intelligenz aus Daten zu extrahieren"}
{"DOCID": "657", "TEXT": "Informationsstrukturen zum Verarbeiten und Abrufen"}
{"DOCID": "658", "TEXT": "Diskussion - Die Vor- und Nachteile einer speziellen IR-Sprache"}
{"DOCID": "659", "TEXT": "Umkehrung der Reihe (Algorithmus 193)"}
{"DOCID": "660", "TEXT": "Weitere Testmatrizen für Determinanten und Inverse (Pracnique)"}
{"DOCID": "661", "TEXT": "Indizierung und die Lambda-Notation: Einige Methoden zur Indizierung sequentiell gespeicherter Elemente von spärlichen mehrdimensionalen Arrays sind in der Schema-A-Notation beschrieben."}
{"DOCID": "662", "TEXT": "Shuttlesortierung (Algorithmus 175)"}
{"DOCID": "663", "TEXT": "Determinante (Algorithmus 159)"}
{"DOCID": "664", "TEXT": "Zuordnung (Algorithmus 27)"}
{"DOCID": "665", "TEXT": "Gauß-Seidel (Algorithmus 220)"}
{"DOCID": "666", "TEXT": "Topologische Ordnung für Pert-Netzwerke (Algorithmus 219)"}
{"DOCID": "667", "TEXT": "Kutta Merson (Algorithmus 218)"}
{"DOCID": "668", "TEXT": "Minimale Mehrkostenkurve (Algorithmus 217)"}
{"DOCID": "669", "TEXT": "Eine Spezifikation von JOVIAL"}
{"DOCID": "670", "TEXT": "Einige rechtliche Implikationen der Verwendung von Computern im Bankgeschäft: Die Einführung von Computern im Bankgeschäft hat eine Vielzahl von rechtlichen Implikationen, die in diesem sehr frühen Stadium sorgfältige Aufmerksamkeit verdienen. Die Branche ist stark staatlich reguliert und unterliegt daher vielen Gesetzen und Vorschriften. Es ist auch von wichtigen, von Gerichten aufgestellten Common-Law-Regeln betroffen. Die rechtlichen Auswirkungen betreffen nicht nur die Mechanisierung selbst, sondern auch das sehr bedeutende, wirtschaftlich attraktive Phänomen der Off-Premise-Verarbeitung. Es ist wichtig, bereits jetzt viele rechtliche Aspekte zu identifizieren und zu berücksichtigen, bevor sich Systeme und Praktiken herauskristallisieren, um die späteren Auswirkungen unerwarteter physischer Komplikationen und Kosten zu vermeiden. Die rechtlichen Aspekte der Computerisierung im Bankgeschäft sind besonders vielfältig. In manchen Staaten stellt sich grundsätzlich die Frage, ob Banken per Gesetz berechtigt sind, direkt oder über Genossenschaften in die neuen Anlagen zu investieren. Anspruchsvoller sind Fragen im Zusammenhang mit externen Auftragsverarbeitern, insbesondere im Hinblick auf die Verpflichtung zur Geheimhaltung von Informationen über die Kunden einer Bank, die Angemessenheit der Vertrauensschadendeckung, den Haftungsumfang bei missbräuchlicher Scheckverweigerung und die Regulierungsanfälligkeit durch Regierungsbehörden. Ebenfalls relevant ist die Angemessenheit der Datenverarbeitung durch Banken für Nichtbanken und insbesondere die kostenlose Erbringung dieser Dienstleistung für Bankeinleger."}
{"DOCID": "671", "TEXT": "TELEFILE – Eine Fallstudie einer Online-Sparkassenanwendung: Die Entwicklung eines Online-Computersystems für eine Sparkasseninstitution wird von den frühen konzeptionellen Anforderungen der Bank bis zur Vollendung des Designs durch The Teleregister Corporation verfolgt. Es werden sowohl Bank- als auch Ausstattungskriterien spezifiziert, die zur Entwicklung des Telefile-Systems der Teleregister Corporation führten. Der Betrieb der Online- und Offline-Programme wird beschrieben und es werden Statistiken zur Zuverlässigkeit und Leistung des Systems angeführt. Der Nutzen für die Bank wird aus Sicht des Bankers diskutiert; ein Hinweis auf zukünftige Trends im Online-Sparkassenbereich wird ebenfalls diskutiert."}
{"DOCID": "672", "TEXT": "Jüngste Entwicklungen, die ADP in der Steuerverwaltung betreffen"}
{"DOCID": "673", "TEXT": "Kontenklassifizierung bei Automatisierenden Banken"}
{"DOCID": "674", "TEXT": "Anwendung von IBM 1620 EDV-Methoden zur Berechnung der Bildungskonstanten komplexer Eisen"}
{"DOCID": "675", "TEXT": "Kodierung klinischer Labordaten für die automatische Speicherung und den automatischen Abruf: Eine Reihe von klinischen Laborkodes wurde entwickelt, um Urinanalysen, Blutchemie und hämatologische Testergebnisse für die automatische Datenverarbeitung zu akzeptieren und zu speichern. Obwohl die Codes als Teil einer computergestützten Krankenhaussimulation erstellt wurden, waren sie in der Lage, die Ergebnisse aller Labortests zu verarbeiten, denen sie begegnet sind. Das einzigartige Merkmal dieser Codes besteht darin, dass sie sowohl konventionell aufgezeichnete qualitative als auch quantitative Testergebnisse akzeptieren können. Folglich müssen klinische Testergebnisse nicht willkürlich geschichtet, standardisiert oder in irgendeiner Weise verändert werden, um kodiert zu werden. Dieses Papier beschreibt, wie die Codes entwickelt wurden, und präsentiert eine Liste der Urinanalysecodes. Fünf Kriterien, die bei der Entwicklung der Codes verwendet wurden, werden skizziert und das Problem der mehrfach synonymen Terminologie diskutiert. Eine Lösung des Problems wird beschrieben. Flexible, computererzeugte zusammengesetzte Laborberichte werden ebenfalls diskutiert, zusammen mit der Reproduktion eines solchen Berichts. Das Papier kommt zu dem Schluss, dass, obwohl viele Probleme ungelöst bleiben, die nächsten zehn Jahre Zeuge der Entstehung eines praktischen automatisierten Informationssystems im Labor sein könnten."}
{"DOCID": "676", "TEXT": "Zur Berechnung eines bestimmten Typs unvollständiger Beta-Funktionen"}
{"DOCID": "677", "TEXT": "Länge der Strings für eine Merge-Sortierung: Es werden detaillierte Statistiken über die Länge der maximal sortierten Strings gegeben, die sich aus der ersten (internen Sortier-)Phase einer Merge-Sortierung auf Bändern ergeben. Es wird gezeigt, dass die durch ein alternierendes Verfahren erzeugten Saiten (d. h. eines, das abwechselnd aufsteigende und absteigende Saiten erzeugt) tendenziell nur drei Viertel so lang sind wie die bei einem Verfahren, das nur aufsteigende Saiten erzeugt, im Gegensatz zu Aussagen, die zuvor in erschienen sind die Literatur. Daher wird eine geringfügige Modifikation des Read-Backward-Polyphase-Merge-Algorithmus vorgeschlagen."}
{"DOCID": "678", "TEXT": "Optimieren der Bitzeit-Computersimulation: Eine Hauptkomponente eines Bitzeit-Computersimulationsprogramms ist der Boolesche Compiler. Der Compiler akzeptiert die Booleschen Funktionen, die die digitalen Schaltungen des simulierten Computers darstellen, und erzeugt entsprechende Sätze von Maschinenbefehlen, die anschließend auf dem \"Host\"-Computer ausgeführt werden. Es werden Techniken diskutiert, um die Ausgereiftheit des Booleschen Compilers zu erhöhen, um die Bitzeit-Computersimulation zu optimieren. Die Techniken sind auf jeden Universalcomputer anwendbar."}
{"DOCID": "679", "TEXT": "Neuere Verbesserungen in MADCAP: MADCAP ist eine Programmiersprache, die Tiefstellungen, Hochstellungen und bestimmte Formen von angezeigten Formeln zulässt. Die grundlegende Implementierung dieser Sprache wurde in einem früheren Artikel beschrieben [MADCAP: Ein wissenschaftlicher Compiler für eine Lehrbuchsprache mit angezeigten Formeln, Comm. ACM 4 (Januar 61), 31-36]. Dieses Papier diskutiert jüngste Verbesserungen in der Sprache in drei Bereichen: komplexe Anzeige, logische Steuerung und Unterprogrammierung. Im Bereich der komplexen Darstellung sind die hervorstechendsten Verbesserungen eine Notation für die Integration und für die Binomialkoeffizienten. Im Bereich der logischen Steuerung ist die wichtigste Neuerung eine Notation für variabel verschachtelte Schleifen. Die Erörterung der Unterprogrammierung konzentriert sich auf MADCAPs Notation für und Verwendung von \"Prozeduren\"."}
{"DOCID": "680", "TEXT": "Ein fehlerkorrigierender Parse-Algorithmus"}
{"DOCID": "681", "TEXT": "Flexible Abkürzung von Wörtern in einer Computersprache"}
{"DOCID": "682", "TEXT": "Rekursive Programmierung in FORTRAN II"}
{"DOCID": "683", "TEXT": "Eine serielle Technik zur Bestimmung minimaler Pfade"}
{"DOCID": "684", "TEXT": "Interpolation, Differentiation und Integration (Algorithmus 77)"}
{"DOCID": "685", "TEXT": "Euler-Summation (Algorithmus 8)"}
{"DOCID": "686", "TEXT": "Glatt (Algorithmus 216)"}
{"DOCID": "687", "TEXT": "Schäfte (Algorithmus 215)"}
{"DOCID": "688", "TEXT": "q-Bessel-Funktionen In(t) (Algorithmus 214)"}
{"DOCID": "689", "TEXT": "Bericht über einen Besuch zur Diskussion gemeinsamer Programmiersprachen in der Tschechoslowakei und Polen, 1963"}
{"DOCID": "690", "TEXT": "USA Teilnahme an einem internationalen Standardglossar zur Informationsverarbeitung"}
{"DOCID": "691", "TEXT": "Eine Beschreibung der APT-Sprache: Die APT-Sprache (Automatically Programmed Tools) für die Programmierung numerischer Steuerungen wird unter Verwendung der metalinguistischen Notation beschrieben, die in dem Bericht ALGOL 60 eingeführt wurde. Beispiele für die Verwendung von APT sind enthalten. Präsentiert werden auch eine historische Zusammenfassung der Entwicklung von APT und eine Aussage über seinen gegenwärtigen Status."}
{"DOCID": "692", "TEXT": "Über die Umkehrung einer Testmatrix"}
{"DOCID": "693", "TEXT": "Eine Erweiterung der Fibonacci-Suche auf mehrere Variablen: Eine Technik, die Fibonacci-Suchkonzepte verwendet, wurde entwickelt, um Optimierungsprobleme zu lösen, die unimodale Funktionen mehrerer Variablen beinhalten. Die Technik hat sich nicht als optimal im Sinne der eindimensionalen Fibonacci-Suche erwiesen. Es ist jedoch für bestimmte Arten von Berechnungen wertvoll."}
{"DOCID": "694", "TEXT": "Ein Vergleich von Platten und Bändern: Die Hauptmerkmale aktueller Magnetplatten und Bandeinheiten werden zusammengefasst und verglichen. Einige Eigenschaften von Diskettendateien werden anhand eines Sortierbeispiels veranschaulicht und mit einem Tapesort verglichen. Es wird die Schlussfolgerung gezogen, dass Plattendateien in einigen wichtigen Anwendungen mit Bändern konkurrenzfähig sind."}
{"DOCID": "695", "TEXT": "Verwendung der Plattendatei auf Stretch: Der Aufsatz beginnt mit einer kurzen Beschreibung des Stretch-Computers (IBM 7030), wobei besonderes Augenmerk auf die Organisation und den Betrieb seiner Eingabe-Ausgabe-Ausrüstung gelegt wird. Physikalische Eigenschaften des Zwei-Platten-Systems (4.194.304 72-Bit-Wörter, 8 usec-pro-Wort-Übertragungsrate usw.) werden notiert. Timing-Einschränkungen aufgrund von Armbewegungen und Plattendrehungen werden diskutiert. Anwendungen der Plattenbenutzung werden getrennt für Problemprogramme und für Systemprogramme wie Compiler und das Überwachungsprogramm diskutiert. Ungefähr 260.000 Wörter Plattenspeicher sind für die Speicherung von Systemprogrammen und der Subroutinenbibliothek reserviert. Problemprogramme werden jedoch derzeit nicht auf der Platte abgelegt. Bestimmte Programmiertechniken werden zum Übertragen von Wörtern zwischen Platten- und Kernspeicher mit minimaler Verzögerung und Unterbrechung der arithmetischen Einheit erörtert. Dumps auf der Festplatte werden sowohl für die Wiederherstellung nach einer Computerfehlfunktion als auch für mathematische oder physikalische Entwicklungen während der Berechnung berücksichtigt. Es werden einige Kommentare bezüglich der Zuverlässigkeit, Ökonomie, Nützlichkeit und Schwächen oder Beschränkungen des Plattensystems gemacht. Es werden mehrere mögliche zukünftige Anwendungen erwähnt, die Plattenkonnotationen zu haben scheinen."}
{"DOCID": "696", "TEXT": "Ein automatisches Datenerfassungs- und Abfragesystem unter Verwendung von Festplattendateien: Die Lockheed Missiles and Space Company hat ein groß angelegtes automatisches Datenerfassungssystem (ADA) installiert, das die Produktionsstätten des Unternehmens in Van Nuys und Sunnyvale, Kalifornien, miteinander verbindet. Das System umfasst über 200 entfernte Eingabestationen, die Betriebsdaten des Unternehmens sammeln und an ein zentrales Datenverarbeitungszentrum übertragen. Zwei RCA 301 EDV-Systeme dienen zur Erfassung und Steuerung des Datenflusses, der an das Rechenzentrum übermittelt wird. Eine RCA 366-Datendiskdatei mit großer Kapazität wird verwendet, um Informationen zu speichern, die erforderlich sind, um aktuelle Informationen als Antwort auf Anfragen bereitzustellen, die von entfernt angeordneten Abfragestationen empfangen werden. Zusätzlich zur Speicherung von Daten auf den Plattendateien zeichnet das System automatisch alle eingehenden und ausgehenden Daten auf Magnetband auf, die als Eingabe für die herkömmlichen Offline-Geschäftsdatenverarbeitungsanwendungen des Unternehmens verwendet werden."}
{"DOCID": "697", "TEXT": "Eine numerische Methode zur Bestimmung von Isodosenkurven im Wanderfeld für die Behandlungsplanung in der Strahlentherapie"}
{"DOCID": "698", "TEXT": "DATA-DIAL: Zwei-Wege-Kommunikation mit Computern von gewöhnlichen Wähltelefonen: Es wird ein Betriebssystem beschrieben, das es Benutzern ermöglicht, einen entfernt angeordneten Computer von gewöhnlichen Wähltelefonen anzurufen. An den Telefonen der Benutzer sind keine spezielle Hardware oder Anschlüsse erforderlich. Die Eingabe in den Computer erfolgt über die Telefonwählscheibe; die Ausgabe vom Computer erfolgt in gesprochener Form. Ergebnisse eines Tests mit Telefonen im Raum Boston werden gemeldet."}
{"DOCID": "699", "TEXT": "Ein Konturkartenprogramm für die Röntgenkristallographie: Ein FORTRAN-Programm wird zur Verwendung mit dem IBM 7090-System und einem X, Y-Plotter zur Erzeugung einer Konturkarte beschrieben. Eine Matrix von Punkten, die in jeder Dimension gleichmäßig beabstandet sind, wird konturiert. Skalierungsfaktoren entlang der Achsen können unterschiedlich sein und die Achsen müssen nicht senkrecht sein."}
{"DOCID": "700", "TEXT": "Hermite-Interpolation (Algorithmus 210)"}
{"DOCID": "701", "TEXT": "Shuttlesortierung (Algorithmus 175)"}
{"DOCID": "702", "TEXT": "Zuweisen (Algorithmus 173)"}
{"DOCID": "703", "TEXT": "Zuweisen (Algorithmus 173)"}
{"DOCID": "704", "TEXT": "Kombinatorik von M Dingen, einzeln genommen, zwei gleichzeitig, bis zu N gleichzeitig (Algorithmus 161)"}
{"DOCID": "705", "TEXT": "Kombinatorik von M Dingen, N gleichzeitig genommen (Algorithmus 160)"}
{"DOCID": "706", "TEXT": "Fourierreihen-Approximation (Algorithmus 157)"}
{"DOCID": "707", "TEXT": "Erf(x) (Algorithmus 123)"}
{"DOCID": "708", "TEXT": "Auswertung der Fresnel-Integrale (Algorithmus 88, 89, 90)"}
{"DOCID": "709", "TEXT": "Zuordnung (Algorithmus 27)"}
{"DOCID": "710", "TEXT": "Fresnel-Integrale (Algorithmus 213)"}
{"DOCID": "711", "TEXT": "Häufigkeitsverteilung (Algorithmus 212)"}
{"DOCID": "712", "TEXT": "Hermite-Interpolation (Algorithmus 211)"}
{"DOCID": "713", "TEXT": "Lagrange-Interpolation (Algorithmus 210)"}
{"DOCID": "714", "TEXT": "Gauß (Algorithmus 209)"}
{"DOCID": "715", "TEXT": "Diskrete Faltung (Algorithmus 208)"}
{"DOCID": "716", "TEXT": "Stringsort (Algorithmus 207)"}
{"DOCID": "717", "TEXT": "Partitionierungsalgorithmen für endliche Mengen: Die Partitionen einer Menge mit n Elementen werden durch bestimmte n-Tupel positiver ganzer Zahlen dargestellt. Es werden Algorithmen beschrieben, die ohne Wiederholungen die n-Tupel erzeugen, die entsprechen: (1) allen Partitionen der gegebenen Menge, (2) allen Partitionen der gegebenen Menge in m oder weniger Mengen (1 <= m <= n), und ( 3) alle Zerlegungen der gegebenen Menge in genau m Mengen (1 <= m <= n)."}
{"DOCID": "718", "TEXT": "Ein Experiment zur automatischen Verifizierung von Programmen: Wie effektiv ersetzt ein Compiler die explizite Verifizierung, und was kostet diese Technik?"}
{"DOCID": "719", "TEXT": "Stapel mit variabler Breite: Zeichenadressierbare Computer mit variablem Feld gestatten die einfache Einrichtung und Handhabung von Stapeln mit variabler Breite. Einzelne Maschinenbefehle können variable Feldelemente nach unten in solche Stapel schieben oder sie aufklappen lassen. Die Verfügbarkeit einer Vielzahl von Feldbegrenzern ermöglicht es der Maschine, mit einem Befehl mehr als ein Element mit variabler Breite nach unten oder oben zu drücken. Da diese Stapeloperationen zur Grundlage von Compiler-Decodierungsalgorithmen gemacht werden können, hat die richtige Verwendung von Maschinen dieser Klasse zum Kompilieren Vorteile gegenüber Maschinen mit Wörtern fester Länge."}
{"DOCID": "720", "TEXT": "Formatfreie Eingabe in FORTRAN"}
{"DOCID": "721", "TEXT": "Bericht über vorgeschlagene amerikanische Standard-Flussdiagrammsymbole für die Informationsverarbeitung: Dieses Papier stellt die wesentlichen Inhalte der vorgeschlagenen amerikanischen Standard-Flussdiagrammsymbole für die Informationsverarbeitung vor. Dies ist der erste vorgeschlagene Standard, der vom Unterkomitee X3.6 für Problembeschreibung und -analyse der American Standards Association (ASA) erstellt wurde."}
{"DOCID": "722", "TEXT": "Darstellung der ALGOL-Symbole durch die ALCOR-Gruppe"}
{"DOCID": "723", "TEXT": "ECMA-Teilmenge von ALGOL 60"}
{"DOCID": "724", "TEXT": "Ein Profil des Programmierers: Zusammenfassung: 549 Mitglieder der ACM nahmen an einer Studie teil, die sich hauptsächlich mit der Einstellung von Programmierern zu ihrer Karriere und ihrem Job befasste. Ein sehr hoher Prozentsatz von Programmierern ist offenbar zufällig ins Berufsleben eingetreten; es hat sich für die meisten als glückliche Wahl erwiesen und sie gehen davon aus, dass sie in den nächsten fünf Jahren in diesem Bereich bleiben werden. Ihre hauptsächliche Arbeitszufriedenheit hängt mit der Art ihrer Arbeit zusammen, und die meisten finden, dass ihre Jobs ein hohes Maß an beruflichem Interesse und gute Arbeitsbedingungen bieten. Die Gehalts- und Aufstiegsaussichten sind jedoch nicht so zufriedenstellend. Mehr als die Hälfte berichtet von einer positiven Einstellung gegenüber Programmierern und Programmierung seitens ihrer Organisationen. Die Fluktuation untereinander wird in erster Linie auf ein schlechtes Management-Gehalt zurückgeführt – bei anderen Programmierern wird das Hauptmotiv für die Fluktuation angesehen. Die Art der angebotenen Arbeit und das Gehalt sind die wichtigsten Determinanten für die Annahme einer neuen Stelle. Programmierer sind weniger mobil als erwartet. Programmierer neigen dazu, ihre Kollegen im Großen und Ganzen in einem positiven Licht zu sehen. Persönlichkeiten scheinen je nach Funktion zu variieren, Systemprogrammierer unterscheiden sich von Anwendungsprogrammierern. Vier Hauptprobleme für das Programmieren in der unmittelbaren Zukunft werden von den Teilnehmern aufgelistet: Sprachen, Personal, verschiedene spezifische Anwendungen und Techniken und Programmieren als Beruf aufbauen."}
{"DOCID": "725", "TEXT": "Computerdemonstration für Gruppenbeteiligung"}
{"DOCID": "726", "TEXT": "Ein allgemeines Programm zur Analyse von quadratischen und rechteckigen Gitterdesigns: Dieses Dokument beschreibt ein Allzweckprogramm, das diese unvollständigen Blockdesigns behandelt, die als quadratische und rechteckige Gitter bekannt sind. Flussdiagramme sind angegeben, so dass das Berechnungsverfahren für jeden digitalen Computer programmiert werden kann."}
{"DOCID": "727", "TEXT": "Zur Näherungslösung von Delta(u)=F(u): Dreidimensionale Dirichlet-Probleme für Delta(u)=F(u), Fu >= 0, werden numerisch durch ein außergewöhnlich schnelles, außergewöhnlich genaues numerisches Verfahren behandelt. Programmierdetails, zahlreiche Beispiele und mathematische Theorie werden geliefert. Die Erweiterung der Methode auf natürliche Weise auf n-dimensionale Probleme wird anhand eines 4-dimensionalen Beispiels angedeutet."}
{"DOCID": "728", "TEXT": "Computergezeichnete Flussdiagramme*: Um dem Bedarf nach verbesserter Dokumentation geschriebener Computerprogramme gerecht zu werden, wird ein einfaches System für effektive Kommunikation vorgestellt, das sich als sehr vielversprechend erwiesen hat. Der Programmierer beschreibt sein Programm in einem einfachen Format, und der Computer erstellt aus dieser Eingabe Flussdiagramme und andere Auflistungen mit Querverweisen. Die Beschreibung kann leicht auf dem neuesten Stand gehalten werden, und die endgültige Ausgabe erklärt das ursprüngliche Programm klar und deutlich. Das System hat sich auch als wertvolle Debugging- und Codierungshilfe erwiesen."}
{"DOCID": "729", "TEXT": "Eine Verallgemeinerung von ALGOL"}
{"DOCID": "730", "TEXT": "MIRFAG: Ein Compiler, der auf einer standardmäßigen mathematischen Notation und einfachem Englisch basiert: Eine Pilotversion des Compilers MIRFAG, die jetzt in Betrieb ist, wird beschrieben. Hauptmerkmale des Systems, das zur Lösung naturwissenschaftlicher Probleme bestimmt ist, ist die Darstellung mathematischer Formeln vollständig in lehrbuchüblicher Notation. Die Verwendung von einfachem Englisch für organisatorische Anweisungen, die automatische Fehlerdiagnose, die den tatsächlichen Ort des Fehlers im unkompilierten Programm anzeigt, und der Versuch, die Fragmentierung der ursprünglichen Problemstellung zu minimieren, die ein normales Merkmal von Programmiersystemen ist."}
{"DOCID": "731", "TEXT": "Symmetrischer Listenprozessor: Es wird ein Listenverarbeitungssystem beschrieben, bei dem jede Listenzelle sowohl eine Vorwärts- als auch eine Rückwärtsverknüpfung sowie ein Datum enthält. Dieses System ist zum Einbetten in höhere Sprachen vorgesehen, die in der Lage sind, in Maschinensprache codierte Funktionen und Subroutinen aufzurufen. Die Darstellung erfolgt in Form von FORTRAN-Programmen, die nur von einem begrenzten Satz von FORTRAN-Programmen abhängig sind, die nur von einem begrenzten Satz von \"primitiven\" Maschinensprachen-Subroutinen abhängen, die ebenfalls definiert sind. Schließlich wird ein Satz von Feld-, insbesondere Zeichen-, Manipulationsprimitiven angegeben, um das System abzurunden."}
{"DOCID": "732", "TEXT": "Monte-Carlo-Inverse (Algorithmus 166)"}
{"DOCID": "733", "TEXT": "Newton-Interpolation mit vorwärts dividierten Differenzen (Algorithmus 169)"}
{"DOCID": "734", "TEXT": "Newton-Interpolation mit rückwärts dividierten Differenzen (Algorithmus 168)"}
{"DOCID": "735", "TEXT": "Berechnung konfluenter geteilter Differenzen (Algorithmus 167)"}
{"DOCID": "736", "TEXT": "Modifizierte Hankel-Funktionen (Algorithmus 163)"}
{"DOCID": "737", "TEXT": "Potenzierung von Reihen (Algorithmus 158)"}
{"DOCID": "738", "TEXT": "Fourierreihen-Approximation (Algorithmus 157)"}
{"DOCID": "739", "TEXT": "MINIFUN (Algorithmus 129)"}
{"DOCID": "740", "TEXT": "INTERESSE (Algorithmus 45)"}
{"DOCID": "741", "TEXT": "Auswertung der Determinante (Algorithmus 41)"}
{"DOCID": "742", "TEXT": "Auswertung der Determinante (Algorithmus 41)"}
{"DOCID": "743", "TEXT": "ARCCOSIN (Algorithmus 206)"}
{"DOCID": "744", "TEXT": "ATIVE (Algorithmus 205)"}
{"DOCID": "745", "TEXT": "STEEP2 (Algorithmus 204)"}
{"DOCID": "746", "TEXT": "STEEP1 (Algorithmus 203)"}
{"DOCID": "747", "TEXT": "Erzeugung von Permutationen in lexikografischer Reihenfolge (Algorithmus 202)"}
{"DOCID": "748", "TEXT": "Ein semi-iterativer Prozess zur Bewertung von Arctangens"}
{"DOCID": "749", "TEXT": "Hinweis zu Stochastischen Matrizen"}
{"DOCID": "750", "TEXT": "Eigenvektoren der PEI-Matrix"}
{"DOCID": "751", "TEXT": "Eine Anmerkung zu einem Satz von Testmatrizen für die Inversion"}
{"DOCID": "752", "TEXT": "Schließen eines Druckbands"}
{"DOCID": "753", "TEXT": "Ein Verfahren zum Konvertieren von Logiktabellenbedingungen in eine effiziente Folge von Testanweisungen"}
{"DOCID": "754", "TEXT": "Ihr indiskreter Monitor"}
{"DOCID": "755", "TEXT": "Eine exponentielle Methode zur numerischen Integration gewöhnlicher Differentialgleichungen: Es wird eine Formel zur numerischen Integration vorbereitet, die einen exponentiellen Term beinhaltet. Diese Formel wird mit zwei Standardintegrationsmethoden verglichen, und es wird gezeigt, dass die Exponentialformel für eine große Klasse von Differentialgleichungen überlegene Stabilitätseigenschaften für große Schrittweiten aufweist. Daher kann diese Formel mit einer großen Schrittgröße verwendet werden, um die Gesamtrechenzeit für eine Lösung erheblich zu verringern, insbesondere bei solchen technischen Problemen, bei denen keine hohe Genauigkeit erforderlich ist."}
{"DOCID": "756", "TEXT": "Ein Computerprogramm zum Bearbeiten der Nachrichten"}
{"DOCID": "757", "TEXT": "Simulation eines Verkehrsnetzes"}
{"DOCID": "758", "TEXT": "Skelettstruktur von PERT- und CPA-Computerprogrammen: Es wird eine Einführung in die innere Mechanik von PERT- und CPA-Computerprogrammen gegeben. Die Hauptkomponenten dieser Programme sowie ihre Zwecke und Wechselbeziehungen werden umrissen."}
{"DOCID": "759", "TEXT": "Kontinuierliche Operationsnotation für Symbolmanipulation und Array-Verarbeitung: Es wird ein kurzer Bericht über ein Notationsmittel gegeben, das bei der formalen Darstellung von Syntaxen, Zeichenfolgenbeziehungen und Zeichenfolgentransformationsverfahren sowie von Rechenverfahren, die mit Arrays von Funktionen vieler Variablen umgehen, sehr nützlich ist . Die Vorrichtung besteht aus der Verwendung bestimmter \"fortgesetzter Operationen\" oder \"kollektiver\" Symbole, die analog zu dem Summensymbol (Sigma) und fortgesetzten Multiplikationssymbol (Pi) der konventionellen Mathematik sind."}
{"DOCID": "760", "TEXT": "Dialekte von FORTRAN"}
{"DOCID": "761", "TEXT": "Eine Anmerkung zum Dangling Else in ALGOL 60: Es werden einige Überarbeitungen von ALGOL 60 vorgeschlagen, die nicht nur bestimmte mehrdeutige Aussagen eliminieren, sondern auch der Sprache etwas Komfort verleihen. Eine Erörterung des Hintergrunds des Problems und eine Beweisskizze, dass die Mehrdeutigkeiten beseitigt wurden, sind enthalten."}
{"DOCID": "762", "TEXT": "Einige Bemerkungen zur Syntax symbolischer Programmiersprachen"}
{"DOCID": "763", "TEXT": "Ein syntaktisch gesteuerter Generator formaler Sprachprozessoren"}
{"DOCID": "764", "TEXT": "Reduktion einer Matrix mit Polynomelementen (Algorithmus 170)"}
{"DOCID": "765", "TEXT": "Orthogonale Polynom-Oberflächenanpassung der kleinsten Quadrate (Algorithmus 164)"}
{"DOCID": "766", "TEXT": "XY-Bewegungsdarstellung (Algorithmus 162)"}
{"DOCID": "767", "TEXT": "Zertifizierung von Algorithmus 161 Kombinatorik von M Dingen, einzeln genommen, zwei gleichzeitig, bis zu N gleichzeitig [M. L. Wolfson und H. V. Wright, Comm. ACM, April 1963]"}
{"DOCID": "768", "TEXT": "Zertifizierung von Algorithmus 160 Combinatorial of M Things N at a Time [M. L. Wolfson und H. V. Wright, Comm. ACM, April 1963]"}
{"DOCID": "769", "TEXT": "Mengenalgebra (Algorithmus 156)"}
{"DOCID": "770", "TEXT": "Kombination in beliebiger Reihenfolge (Algorithmus 155)"}
{"DOCID": "771", "TEXT": "Kombination in lexikografischer Reihenfolge (Algorithmus 154)"}
{"DOCID": "772", "TEXT": "GOMORY (Algorithmus 153)"}
{"DOCID": "773", "TEXT": "Matrixinversion (Algorithmus 140)"}
{"DOCID": "774", "TEXT": "Jacobi (Algorithmus 85)"}
{"DOCID": "775", "TEXT": "Interpolation, Differentiation und Integration (Algorithmus 77)"}
{"DOCID": "776", "TEXT": "Partition, Quicksort und Find (Algorithmus 62, 64 und 65)"}
{"DOCID": "777", "TEXT": "Ein Satz von Testmatrizen (Algorithmus 52)"}
{"DOCID": "778", "TEXT": "Zugehörige Legendre-Funktionen erster Art für reelle oder imaginäre Argumente (Algorithmus 47)"}
{"DOCID": "779", "TEXT": "CROUT II (Algorithmus 43)"}
{"DOCID": "780", "TEXT": "Algorithmus 42 INVERT, Alg.107 Gauss-Methode, Alg.120 Inversion II und gjr"}
{"DOCID": "781", "TEXT": "Teleskop 2 (Algorithmus 38)"}
{"DOCID": "782", "TEXT": "Teleskop 1 (Algorithmus 37)"}
{"DOCID": "783", "TEXT": "Shellsort (Algorithmus 201)"}
{"DOCID": "784", "TEXT": "Normaler Zufall (Algorithmus 200)"}
{"DOCID": "785", "TEXT": "Konvertierungen zwischen Kalenderdatum und julianischer Tageszahl (Algorithmus 199)"}
{"DOCID": "786", "TEXT": "Adaptive Integration und multiple Integration (Algorithmus 198)"}
{"DOCID": "787", "TEXT": "Matrixdivision (Algorithmus 197)"}
{"DOCID": "788", "TEXT": "Müllers Methode zum Finden von Wurzeln einer beliebigen Funktion (Algorithmus 196)"}
{"DOCID": "789", "TEXT": "Bandlösung (Algorithmus 195)"}
{"DOCID": "790", "TEXT": "Zersol (Algorithmus 194)"}
{"DOCID": "791", "TEXT": "Zeichenmanipulation in 7090 Fortran"}
{"DOCID": "792", "TEXT": "Binär-zu-Dezimal-Integer-Konvertierung mit mehrfacher Genauigkeit, die nur Addition und Subtraktion verwendet"}
{"DOCID": "793", "TEXT": "Zugeordnete Listenstrukturen"}
{"DOCID": "794", "TEXT": "A List-Type Storage Technique for Alphameric Information: Es wird ein platz- und zeitsparendes Verfahren zur Speicherung und Manipulation von Zeichenketten beliebiger Länge in einem Computer mit fester Wortlänge vorgeschlagen. Das Verfahren wird in einer Anwendung auf Algol-Typ-Identifikatoren in einer Algol-ähnlichen Blockstruktur veranschaulicht."}
{"DOCID": "795", "TEXT": "Debuggen von Systemen auf Quellsprachenebene"}
{"DOCID": "796", "TEXT": "SABRAG, ein kostengünstiger Time-Sharing-Computer: Der serielle SABRAC-Computer, der in der wissenschaftlichen Abteilung des israelischen Verteidigungsministeriums entwickelt und gebaut wurde, verfügt über eine Magnettrommel mit 5000 Plätzen als Hauptspeicher. Um zu vermeiden, dass auf optimale Programmiertechniken zurückgegriffen werden muss, und um seine Gesamteffizienz zu erhöhen, wurde dem Computer außerdem ein 224-Wörter-Ferritkernspeicher gegeben, aus dem das Programm befolgt wird. Übertragungen zwischen den Hülsen- und Trommelspeichern und zu und von den doppelten Papierband-Eingangs- und -Ausgangskanälen sind alle autonom (gleichzeitig, zeitgeteilt) verfügbar. Multiplikations- und Divisionsaufträge sind ebenfalls autonom, sodass die Maschine bis zu drei Aufträge gleichzeitig ausführen kann. Alle Funktionen sind natürlich verriegelt. Eine Reihe weiterer fortgeschrittener Befehle und Einrichtungen sind ebenfalls enthalten. Insbesondere erlaubt ein \"Execute\"-Befehl einen temporären Sprung für bis zu vier Befehle, und ein zweites Modifikatorregister erlaubt eine doppelte Modifikation im Allgemeinen und eine relative Adressierung von Subroutinen im Besonderen. Somit ist die effektive Gesamtgeschwindigkeit der Maschine viel höher, als es ihre Basisspezifikation erwarten lassen würde, und ihr Design zeigt einen Weg auf, auf dem die Konzepte des Time-Sharing in \"kostengünstige\" Computer eingebaut werden können."}
{"DOCID": "797", "TEXT": "Amerikanischer Standardcode für den Informationsaustausch"}
{"DOCID": "798", "TEXT": "Ein System zum Abrufen von Katalogeinträgen"}
{"DOCID": "799", "TEXT": "Design eines trennbaren Übergangsdiagramm-Compilers*: Es wird ein COBOL-Compiler-Design vorgestellt, das kompakt genug ist, um eine schnelle Kompilierung einer großen Teilmenge von COBOL in einem Durchgang auf einem mittelgroßen Computer zu ermöglichen. Versionen desselben Compilers für kleinere Maschinen benötigen nur zwei Arbeitsbänder plus ein Compiler-Band. Die angegebenen Methoden sind weitgehend auf die Konstruktion von ALGOL-Compilern anwendbar."}
{"DOCID": "800", "TEXT": "Die Unterprogrammsprache Linking Segment und Linking Loader"}
{"DOCID": "801", "TEXT": "Lösung der kleinsten Quadrate mit Einschränkungen (Algorithmus 177)"}
{"DOCID": "802", "TEXT": "SYMINV2 (Algorithmus 150)"}
{"DOCID": "803", "TEXT": "Syminv2 (Algorithmus 150)"}
{"DOCID": "804", "TEXT": "Potenzierung von Reihen (Algorithmen 134)"}
{"DOCID": "805", "TEXT": "Newton Maehly (Algorithmus 105)"}
{"DOCID": "806", "TEXT": "Bemerkung zur Zertifizierung von Matrixinversionsverfahren"}
{"DOCID": "807", "TEXT": "Umkehrung der Reihe (Algorithmus 193)"}
{"DOCID": "808", "TEXT": "Konfluent hypergeometrisch (Algorithmus 192)"}
{"DOCID": "809", "TEXT": "Hypergeometrisch (Algorithmus 191)"}
{"DOCID": "810", "TEXT": "Komplexe Potenz (Algorithmus 190)"}
{"DOCID": "811", "TEXT": "Glättung 2 (Algorithmus 189)"}
{"DOCID": "812", "TEXT": "Glättung 1 (Algorithmus 188)"}
{"DOCID": "813", "TEXT": "Differenzen und Ableitungen (Algorithmus 187)"}
{"DOCID": "814", "TEXT": "Komplexe Arithmetik (Algorithmus 186)"}
{"DOCID": "815", "TEXT": "Normalwahrscheinlichkeit für Kurvenanpassung (Algorithmus 185)"}
{"DOCID": "816", "TEXT": "Erlang-Wahrscheinlichkeit für Kurvenanpassung (Algorithmus 184)"}
{"DOCID": "817", "TEXT": "Nexcom (Algorithmus 152)"}
{"DOCID": "818", "TEXT": "Realisieren von booleschen Verknüpfungen auf dem IBM 1620"}
{"DOCID": "819", "TEXT": "Polynomauswertung überarbeitet"}
{"DOCID": "820", "TEXT": "Überprüfung auf Schleifen in Netzwerken"}
{"DOCID": "821", "TEXT": "Weitere Bemerkungen zum Abtasten einer Banddatei-III"}
{"DOCID": "822", "TEXT": "Echtzeitprogrammierungsspezifikationen: Probleme bei der Implementierung großer Echtzeitanwendungen werden behandelt und Richtlinienvorschläge für Programm- und Dateispezifikationen entwickelt. Die geschilderten Probleme treten auch in der Systemprogrammierung auf."}
{"DOCID": "823", "TEXT": "Eine syntaktische Beschreibung von BC NELLIAC"}
{"DOCID": "824", "TEXT": "DESCRIPTRAN-Automated Descriptive Geometry*: Die beschreibende Geometrie besteht aus Verfahren, die ursprünglich entwickelt wurden, um 3-Raum-Geometrieprobleme durch grafische Konstruktionen und Messungen anstelle von Berechnungen zu lösen. Darüber hinaus vereinheitlicht und vereinfacht es jedoch die Herangehensweise an viele solcher Probleme. Wenn man Subroutinen aufrufen kann, die neue Koordinaten berechnen, die denen entsprechen, die aus den grafischen Konstruktionen erhältlich sind, gibt es den dreifachen Vorteil des Ansatzes der beschreibenden Geometrie, der Genauigkeit der Berechnung und der Geschwindigkeit des digitalen Computers. DESCRIPTRAN macht es möglich, viele Probleme im 3-Raum mit wenigen Anweisungen zu programmieren; es besteht aus 15 Unterprogrammen analog zu den Verfahren der darstellenden Geometrie."}
{"DOCID": "825", "TEXT": "PIP: A Photo-Interpretive Program for the Analysis of Spark-Chamment Data*: Ein funktionierendes Computerprogramm, das fotografisch aufgenommene Daten verarbeitet, wird beschrieben. Die Eingabe für das Programm besteht aus Funkenkammerfotos, auf denen Spuren hochenergetischer Teilchen aufgezeichnet sind. Das Programm scannt, misst und führt die vorläufige Interpretation dieser Fotos automatisch durch. Im Dauerbetrieb wird eine Verarbeitungsrate von 5.000 fotografischen Bildern pro Stunde erreicht."}
{"DOCID": "826", "TEXT": "Bemerkungen zu Fortran-Subroutinen für die Zeitreihenanalyse"}
{"DOCID": "827", "TEXT": "Disk File Sorting: Sortiertechniken unter Verwendung eines IBM 1401 mit einem Speichergerät mit wahlfreiem Zugriff werden evaluiert."}
{"DOCID": "828", "TEXT": "Inkompressible Strömungsnetzberechnungen: Eine allgemeine Methode zur Berechnung von Strömungen und Drücken in Fluidströmungsnetzen wird vorgestellt. Das Verfahren ist auf die Verwendung von Computern anwendbar."}
{"DOCID": "829", "TEXT": "Die externe Sprache KLIPA Für den Computer URAL-2 Digital"}
{"DOCID": "830", "TEXT": "CORC-The Cornell Computing Language"}
{"DOCID": "831", "TEXT": "Echte Fehlerfunktion, ERF (Algorithmus 123)"}
{"DOCID": "832", "TEXT": "Kurvenanpassung mit Einschränkungen (Algorithmus 74)"}
{"DOCID": "833", "TEXT": "Reduktion einer symmetrischen Bandmatrix auf dreifach diagonale Form"}
{"DOCID": "834", "TEXT": "Nichtrekursive adaptive Integration (Algorithmus 182)"}
{"DOCID": "835", "TEXT": "Komplementäre Fehlerfunktion – Großes X (Algorithmus 181)"}
{"DOCID": "836", "TEXT": "Fehlerfunktion-Großes X (Algorithmus 180)"}
{"DOCID": "837", "TEXT": "Unvollständiges Beta-Verhältnis (Algorithmus 179)"}
{"DOCID": "838", "TEXT": "Direktsuche (Algorithmus 178)"}
{"DOCID": "839", "TEXT": "Lösung der kleinsten Quadrate mit Einschränkungen (Algorithmus 177)"}
{"DOCID": "840", "TEXT": "Kleinste-Quadrate-Oberflächenanpassung (Algorithmus 176)"}
{"DOCID": "841", "TEXT": "Shuttlesortierung (Algorithmus 175)"}
{"DOCID": "842", "TEXT": "A-posteriori-Grenzen an einer Nullstelle eines Polynoms (Algorithmus 174)"}
{"DOCID": "843", "TEXT": "Zuweisen (Algorithmus 173)"}
{"DOCID": "844", "TEXT": "1410 Fortran-Bearbeitungsfunktion"}
{"DOCID": "845", "TEXT": "Eine weitere Testmatrix für Determinanten und Inversen"}
{"DOCID": "846", "TEXT": "Selbstumkehrungstabelle"}
{"DOCID": "847", "TEXT": "Ein Penny-Matching-Programm: Die Logik eines für den CSX-1 geschriebenen Penny-Matching-Programms wird beschrieben."}
{"DOCID": "848", "TEXT": "Eine Anmerkung zu Bereichstransformationen für Quadratwurzel und Logarithmus: Es gab den Keim einer Idee in zwei früheren Artikeln [1,2], die anscheinend niemand in fast fünf Jahren aufgegriffen hat. Für bestimmte Funktionen scheint es wünschenswert, das Argument in eine Nahbereichssymmetrie umzuwandeln. 10.1 wird Beispiele dieser Verwendung für die Quadratwurzel- und Logarithmusfunktion sowohl für Binär- als auch für Dezimalmaschinen geben."}
{"DOCID": "849", "TEXT": "Verwendung von Baumstrukturen zur Verarbeitung von Dateien: Bei Datenverarbeitungsproblemen werden häufig Dateien verwendet, die sowohl gesucht als auch geändert werden müssen. Binäre Suchtechniken sind zum Durchsuchen großer Dateien effizient, aber die zugehörige Dateiorganisation lässt sich nicht ohne weiteres an die Dateiänderungen anpassen. Umgekehrt erlaubt eine verkettete Dateizuweisung eine effiziente Änderung, kann aber nicht effizient durchsucht werden. Eine Datei, die in einer baumartigen Struktur organisiert ist, wird diskutiert, und es wird gezeigt, dass eine solche Datei mit Zeiten proportional zu slog(s)N sowohl gesucht als auch geändert werden kann, wobei N die Anzahl von Dateielementen und s ein Parameter von ist der Baum. Es wird auch gezeigt, dass die Optimierung des Werts von s zu einer Suchzeit führt, die nur 25 Prozent langsamer ist als die binäre Suche. Die Baumorganisation verwendet zwei Datenketten und kann als Kompromiss zwischen den Organisationen für die binäre Suche und die verkettete Datei angesehen werden. Die Beziehung der Baumorganisation zur mehrdimensionalen Indexierung und zur Trie-Struktur wird ebenfalls diskutiert."}
{"DOCID": "850", "TEXT": "Umwandlungs-, Rückumwandlungs- und Vergleichstechniken beim Sortieren mit variabler Länge: Es wird die Logik zum Umwandeln hochvariabler Eingabedatensätze in ein Format beschrieben, das von einem Sortierprogramm einfach und effizient verarbeitet werden kann. Die internen Datensatzformate werden in Bezug auf (1) ihre Umwandlung von Eingabeformaten, (2) ihre Rückwandlung in Ausgabeformate und (3) Vergleichstechniken zwischen internen Formaten diskutiert."}
{"DOCID": "851", "TEXT": "Entwurf und Eigenschaften einer Sortierung von Datensätzen mit variabler Länge unter Verwendung neuer Sortiertechniken für Datensätze mit fester Länge: Dieses Dokument beschreibt die Anwendung mehrerer neuer Techniken zum Sortieren von Datensätzen mit fester Länge auf die Probleme der Sortierung von Datensätzen mit variabler Länge. Die Techniken wurden auf einem Computersystem Sylvania 9400 mit 32.000 Speicherworten fester Länge implementiert. Insbesondere sequenzieren die Techniken Datensätze mit variabler Länge und unbegrenzter Größe, erzeugen lange anfängliche Datenketten, führen Datenketten mit der Potenz von T-1 zusammen, wobei T die Anzahl der Arbeitsbänder in einem System ist, und schränken das Volumen nicht ein von Eingabedaten."}
{"DOCID": "852", "TEXT": "Eine Methode zum Vergleich des Zeitbedarfs von Sortierverfahren"}
{"DOCID": "853", "TEXT": "Das COBOL-Sortierverb"}
{"DOCID": "854", "TEXT": "Einige Merkmale des Sortierens in Computersystemen, die Direktzugriffsspeichergeräte verwenden: Die wesentlichen Unterschiede in den Merkmalen von Direktzugriffsspeichern und Bandgeräten schreiben vor, dass Konzepte und Ziele des Computerprogrammdesigns vom Standpunkt des verwendeten externen Dateimediums betrachtet werden. Dies gilt insbesondere beim Sortieren. In einem bandorientierten System besteht das Hauptsortierproblem in der Minimierung der Zusammenführungszeit trotz der begrenzt möglichen Zusammenführungsreihenfolgen. Im Gegensatz dazu fördert das Sortieren in einem auf Direktzugriff ausgerichteten System die Auswahl der optimalen Zusammenführungsreihenfolge aus vielen möglichen Reihenfolgen. Das letztgenannte Problem wird in diesem Dokument diskutiert, zusammen mit Kriterien, die zum Bestimmen der optimalen Zusammenführungsreihenfolge gemäß den verschiedenen Eigenschaften von Speichergeräten mit wahlfreiem Zugriff entwickelt wurden. Aufmerksamkeit wird auch dem Problem der Schlüsselsortierung gegenüber der Datensatzsortierung und dem möglicherweise schwerwiegenden Nachteil der Schlüsselsortierung in einem System mit wahlfreiem Zugriff geschenkt."}
{"DOCID": "855", "TEXT": "Organisation und Struktur von Dataon-Plattendateispeichersystemen für effizientes Sortieren und andere Datenverarbeitungsprogramme: Es wird ein Ansatz zur Organisation und Struktur von Daten auf Bryant-Plattendateispeichersystemen zum Sortieren und Durchführen anderer Datenverarbeitungsfunktionen vorgestellt. Die folgenden Bereiche werden behandelt: Eigenschaften von Bryant Disc File Systemen auf dem Bendix G-20 und RCA 301; zwei vorgeschlagene \"Verkettungs\"-Strukturen für Daten; und Funktionen einer Plattendatei-Ausführungsroutine. Die Konzepte zum Sortieren und Durchführen einer Dateiwartungsverarbeitung unter Verwendung der vorgeschlagenen Struktur und Ausführungsroutine werden diskutiert. Zusätzlich wird gezeigt, dass das Sortieren ohne die Verwendung von Plattenspeicher-Arbeitsbereichen durchgeführt werden kann."}
{"DOCID": "856", "TEXT": "Sortieren mit großem Volumen, wahlfreiem Zugriff, Trommelspeicherung: Ein Ansatz zum Sortieren von Datensätzen wird unter Verwendung von Trommelspeichern mit wahlfreiem Zugriff beschrieben. Das beschriebene Sort-Programm ist als verallgemeinertes, selbsterzeugendes Sortieren ausgelegt, das auf eine Vielzahl von Datensatzanweisungen anwendbar ist. Diese Beschreibung ist in drei Teile gegliedert. Der erste Teil stellt die Betriebsumgebung vor; die zweite definiert die allgemeine Lösung; der dritte Teil beschreibt die interne Sort-Merge-Technik."}
{"DOCID": "857", "TEXT": "Sortieren von nichtredundanten Dateien – Techniken, die im FACT-Compiler verwendet werden: Einige typische Dateistrukturen, darunter einige, die als \"nicht-redundant\" bezeichnet werden, werden untersucht, und die in FACT verwendeten Verfahren zum Sortieren solcher Dateien werden diskutiert."}
{"DOCID": "858", "TEXT": "Ein Banddatei-Zusammenführungsmuster-Generator: Es wird eine Routine präsentiert, die die Folge von Zusammenführungszyklen spezifiziert, um die Zusammenführung von sortierten Banddateien zu bewirken. Die Routine ist darauf ausgelegt, die verstrichene Computerzeit zu minimieren, indem sie die Leistung der Zusammenführungszyklen variiert, um alle verfügbaren Bandlaufwerke zu verwenden, mit ihrer Eigenschaft, einer Einzelspulendatei ein Laufwerk und jeder Mehrfachspulendatei zwei Laufwerke zuzuweisen ."}
{"DOCID": "859", "TEXT": "Computergeplante Sortierungen"}
{"DOCID": "860", "TEXT": "Ein Vergleich zwischen der Polyphasen- und der oszillierenden Sortiertechnik: Ein Vergleich zwischen der oszillierenden und der mehrphasigen Sortiertechnik wird für Computersysteme mit vier bis zehn Bandlaufwerken entwickelt. Die Basis für den Vergleich ist das gesamte Lesen und Schreiben, das für eine unterschiedliche Anzahl von Eingabeketten und Bandlaufwerken für die zwei Techniken erforderlich ist."}
{"DOCID": "861", "TEXT": "Read-Backward-Polyphase-Sortierung: Read-Backward-Polyphase-Sortierung bietet eine effizientere Nutzung der für eine Sortierung verfügbaren Bänder als die meisten anderen Sortiertechniken. Backward Polyphase erzeugt einen kontinuierlichen Zusammenführungsprozess aus n-1 Bändern, wobei n die Gesamtzahl der Bänder ist, die im Sortierprozess verwendet werden. Jede der verfügbaren Vorsortiertechniken kann in Verbindung mit der Polyphase-Mischsortierung verwendet werden, vorausgesetzt, dass die Vorsortierung in der Lage ist, sowohl aufsteigende als auch absteigende Zeichenfolgen zu erzeugen und die Zeichenfolgen auf die verschiedenen Bänder zu verteilen, wie es die Polyphasen-Mischung erfordert."}
{"DOCID": "862", "TEXT": "Zeichenfolgenverteilung für die Polyphase-Sortierung"}
{"DOCID": "863", "TEXT": "Mehrphasensortierung"}
{"DOCID": "864", "TEXT": "Eine empirische Studie zur minimalen Speichersortierung"}
{"DOCID": "865", "TEXT": "Interne und Bandsortierung unter Verwendung der Ersatzauswahltechnik: Eine allgemeine Technik zum Sequenzieren unsortierter Aufzeichnungen wird vorgestellt. Es wird gezeigt, dass die Technik für die erste Stufe eines verallgemeinerten Sortierprogramms (die Bildung von Anfangsketten) sowie für das Sortieren von Datensätzen innerhalb eines Speichers (einer internen Sortierung) anwendbar ist. Es wird gezeigt, dass bei gegebenen N Datensätzen im Speicher Datensätze unter Verwendung von 1+log2 N Tests pro Datensatz sequenziert werden, dass die anfänglichen Zeichenfolgenlängen für zufällig eingegebene Datensätze durchschnittlich 2 N betragen und dass Lesen, Schreiben und Verarbeiten gleichzeitig ausgeführt werden können, wenn der Computer dies zulässt solche Überschneidungen."}
{"DOCID": "866", "TEXT": "Sortieren auf Computern"}
{"DOCID": "867", "TEXT": "Kleinste-Quadrate-Anpassung von Ebenen an Oberflächen unter Verwendung dynamischer Programmierung: Dynamische Programmierung wurde kürzlich von Stone, von Bellman und von Gluss verwendet, um die enge Anpassung von unterbrochenen Liniensegmenten an eine Kurve in einem Intervall unter der Bedingung zu bestimmen, dass die Anzahl der Segmente fest ist . In der vorliegenden Arbeit werden sukzessive Modelle entwickelt, um das Verfahren auf die Anpassung von gebrochenen ebenen Segmenten an Oberflächen z = g (x, y) zu erweitern, die über bestimmte Arten von Unterbereichen des (x, y)-Raums definiert sind. Das erste Modell betrachtet eine rechteckige Fläche mit der Einschränkung, dass die Ebenensegmente über einem Gitter im (x,y)-Raum definiert sind. Anschließend wird gezeigt, wie dieses Modell in einen Algorithmus integriert werden kann, der sukzessive Annäherungen an optimale Anpassungen für jede Art von geschlossenem Bereich liefert. Abschließend werden Anwendungen kurz beschrieben."}
{"DOCID": "868", "TEXT": "Eine vorgeschlagene Methode zur umfassenderen Nutzung von Zeichenfolgen in ALGOL 60"}
{"DOCID": "869", "TEXT": "Begriff des magischen Quadrats (Algorithmus 148)"}
{"DOCID": "870", "TEXT": "Begriff des magischen Quadrats (Algorithmus 148)"}
{"DOCID": "871", "TEXT": "PSIF (Algorithmus 147)"}
{"DOCID": "872", "TEXT": "Adaptive numerische Integration nach der Simpson-Regel (Algorithmus 145)"}
{"DOCID": "873", "TEXT": "Zufällig (Algorithmus 133)"}
{"DOCID": "874", "TEXT": "Tschebyscheff-Kurvenanpassung (Algorithmus 91)"}
{"DOCID": "875", "TEXT": "Unvollständige elliptische Integrale (Algorithmus 73)"}
{"DOCID": "876", "TEXT": "Vollständiges elliptisches Integral (Algorithmus 149)"}
{"DOCID": "877", "TEXT": "Vollständiges elliptisches Integral erster Art (Algorithmus 55)"}
{"DOCID": "878", "TEXT": "Reduktion einer Matrix mit Polynomelementen (Algorithmus 170)"}
{"DOCID": "879", "TEXT": "Newton-Interpolation mit vorwärts dividierten Differenzen (Algorithmus 169)"}
{"DOCID": "880", "TEXT": "Newton-Interpolation mit rückwärts dividierten Differenzen"}
{"DOCID": "881", "TEXT": "Berechnung konfluenter geteilter Differenzen (Algorithmus 167)"}
{"DOCID": "882", "TEXT": "Monte Carlo (Algorithmus 166)"}
{"DOCID": "883", "TEXT": "Vollständige elliptische Integrale (Algorithmus 165)"}
{"DOCID": "884", "TEXT": "Orthogonale Polynom-Oberflächenanpassung der kleinsten Quadrate (Algorithmus 164)"}
{"DOCID": "885", "TEXT": "Modifizierte Hankel-Funktion (Algorithmus 163)"}
{"DOCID": "886", "TEXT": "XY-Bewegungsdarstellung (Algorithmus 162)"}
{"DOCID": "887", "TEXT": "Kombinatorik von M Dingen, einzeln genommen, zwei gleichzeitig, bis zu N gleichzeitig (Algorithmus 161)"}
{"DOCID": "888", "TEXT": "Algorithmus 160 Kombinatorik von M Dingen, N gleichzeitig genommen"}
{"DOCID": "889", "TEXT": "Offizielle Aktionen und Antworten zu ALGOL als Programmiersprache"}
{"DOCID": "890", "TEXT": "Ausgewählte Definitionen: Eine Auswahl der Definitionen, die vom Unterausschuss für Programmierterminologie des ACM-Normenausschusses vorbereitet wurden, wird den ACM-Mitgliedern zur Überprüfung vorgelegt."}
{"DOCID": "891", "TEXT": "Jedermanns Informationsbeschaffungssystem: Das Informationsbeschaffungsproblem, dessen Lösung hier vorgestellt wird, wurde von einer technischen Bibliothek mit begrenztem Budget und Personal gestellt. Die Lösung ist jedoch ziemlich allgemein und auf viele verschiedene Arten von Wiedergewinnungsproblemen anwendbar. Ferner ermöglicht das Lösungsverfahren vielen Gruppen, die zuvor ein Informationsabrufprogramm als teuer und schwierig (vom Programmierstandpunkt) abgetan haben, ihre Position zu überdenken, da die vorliegende Lösung es ermöglicht, ein Informationsabrufprogramm zu installieren in weniger als drei Monaten und mit relativ wenig Equipment."}
{"DOCID": "892", "TEXT": "RECOL-A Abrufbefehlssprache: Es wird ein Abfrageschema zum Abrufen und Manipulieren von Datendateiaufzeichnungen beschrieben. Die Sprache des Abfrageschemas ermöglicht die Auswahl von Dateiaufzeichnungen mit dem Bereich logischer Bedingungsaussagen, das Definieren von Aufzeichnungsklassen, das Zuordnen von Dateiaufzeichnungen, das Editieren der gedruckten Ausgabe und das Zusammenfassen der Ergebnisse der obigen Operationen. Es werden einige Beispiele einer typischen Dateianwendung und die wichtigeren Merkmale einer bestimmten Maschinenimplementierung gegeben."}
{"DOCID": "893", "TEXT": "Signifikanz-Arithmetik auf einem digitalen Computer: Der 7090 an der NYU wurde so modifiziert, dass er einen \"Signifikanz-Modus\" enthält, der die Identifizierung von signifikanten Bits in den Ergebnissen von Gleitkomma-Arithmetikoperationen erleichtern soll. Die Art und Weise, in der Gleitkomma-Arithmetik in diesem Modus gehandhabt wird, wird diskutiert. Es werden mehrere numerische Experimente beschrieben, die diesen Modus verwenden, und es werden Vergleiche mit dem gewöhnlichen \"normalisierten Modus\" angestellt. Beispiele sind die Potenzreihenauswertung, die Lösung linearer Gleichungen, die Determinantenauswertung und die Matrixinversion."}
{"DOCID": "894", "TEXT": "Eine iterative Faktorisierungstechnik für Polynome: Es wird eine iterative Technik gezeigt, mit der Faktoren beliebigen Grades für Polynome in einer Variablen gefunden werden können. Es zeigt sich, dass Konvergenz immer auftritt, wenn ein bestimmter Jacobi-Wert nicht verschwindet und wenn die anfängliche Annäherung an einen Faktor nahe genug an einem tatsächlichen Faktor liegt. Der Prozess ist einfach programmiert, und vorläufige Ergebnisse weisen darauf hin, dass er gut für die Verwendung mit digitalen Computern geeignet ist. Für Faktoren vom Grad zwei ist die Technik ähnlich der von Bairstow, wobei das vorliegende Verfahren etwas einfacher ist."}
{"DOCID": "895", "TEXT": "Eine rechnerische Erweiterung der Variaten-Differenz-Methode: Hier wird eine rechnerische Erweiterung der Variaten-Differenz-Methode vorgestellt, wie sie von G. Tintner [1] entwickelt wurde."}
{"DOCID": "896", "TEXT": "Charakteristische Werte und Vektoren fehlerhafter Matrizen"}
{"DOCID": "897", "TEXT": "Hinweis zum Beweis der Nichtexistenz einer Phrasenstrukturgrammatik für ALGOL 60"}
{"DOCID": "898", "TEXT": "Zufällig (Algorithmus 133)"}
{"DOCID": "899", "TEXT": "Magisches Quadrat (Algorithmus 117 & 118)"}
{"DOCID": "900", "TEXT": "Vorfahr (Algorithmus 79)"}
{"DOCID": "901", "TEXT": "Differenzausdruckskoeffizienten (Algorithmus 79)"}
{"DOCID": "902", "TEXT": "Determinante (Algorithmus 159)"}
{"DOCID": "903", "TEXT": "Potenzierung von Reihen (Algorithmus 134 )"}
{"DOCID": "904", "TEXT": "Fourierreihen-Approximation (Algorithmus 157)"}
{"DOCID": "905", "TEXT": "Mengenalgebra (Algorithmus 156)"}
{"DOCID": "906", "TEXT": "Kombination in beliebiger Reihenfolge (Algorithmus 155)"}
{"DOCID": "907", "TEXT": "Kombination in lexikografischer Reihenfolge (Algorithmus 154)"}
{"DOCID": "908", "TEXT": "Testmatrix für Inversion"}
{"DOCID": "909", "TEXT": "Arithmetische Erklärungen (Korrigendum)"}
{"DOCID": "910", "TEXT": "Selektive Anweisungsfalle für die 7090"}
{"DOCID": "911", "TEXT": "Eine Variante der Dateisuche"}
{"DOCID": "912", "TEXT": "Adressierung eines Arrays Yi in k-Dimensionen von Fortran zur Varianzanalyse"}
{"DOCID": "913", "TEXT": "Neliac"}
{"DOCID": "914", "TEXT": "Jovial und seine Dokumentation"}
{"DOCID": "915", "TEXT": "Dokumentation von IPL-V"}
{"DOCID": "916", "TEXT": "FORTRAN"}
{"DOCID": "917", "TEXT": "COMIT"}
{"DOCID": "918", "TEXT": "COBOL"}
{"DOCID": "919", "TEXT": "Dokumentationsprobleme: ALGOL 60"}
{"DOCID": "920", "TEXT": "Auf dem Weg zu einer besseren Dokumentation von Programmiersprachen"}
{"DOCID": "921", "TEXT": "Unvollständige elliptische Integrale (Algorithmus 73)"}
{"DOCID": "922", "TEXT": "Multint (Algorithmus 32)"}
{"DOCID": "923", "TEXT": "Gomory (Algorithmus 153)"}
{"DOCID": "924", "TEXT": "Nexcom (Algorithmus 152)"}
{"DOCID": "925", "TEXT": "Ort eines Vektors in einer lexikographisch geordneten Liste Algorithmus 151)"}
{"DOCID": "926", "TEXT": "Syminv2 (Algorithmus 150)"}
{"DOCID": "927", "TEXT": "Lineare Programmierung angewendet auf die UV-Absorptionsspektroskopie"}
{"DOCID": "928", "TEXT": "Zeichenmanipulation in FORTRAN"}
{"DOCID": "929", "TEXT": "Glossar Konstruktion"}
{"DOCID": "930", "TEXT": "Dezimal-zu-Binär-Konvertierung von kurzen Feldern"}
{"DOCID": "931", "TEXT": "Systematische Fehleranalyse digitaler Computerprogramme"}
{"DOCID": "932", "TEXT": "Matrixinversion durch Gauß-Jordan-Inversion II (Algorithmus 120)"}
{"DOCID": "933", "TEXT": "Magische Quadrate (Algorithmus 117 & 118)"}
{"DOCID": "934", "TEXT": "Gauß-Methode (Algorithmus 107)"}
{"DOCID": "935", "TEXT": "Berechnung von Primzahlen mittels GPS (Algorithmus)"}
{"DOCID": "936", "TEXT": "Ein Satz von Testmatrizen (Algorithmus 52)"}
{"DOCID": "937", "TEXT": "Umkehrung eines endlichen Segments der Hilbert-Matrix (Algorithmus 50)"}
{"DOCID": "938", "TEXT": "Invertieren (Algorithmus 42)"}
{"DOCID": "939", "TEXT": "Gamma-Funktion (Algorithmus 31)"}
{"DOCID": "940", "TEXT": "Generieren diskreter Zufallsvariablen in einem Computer: Diese Notiz befasst sich mit Einzelheiten darüber, wie man einen Computer anweist, eines aus vielen Dingen mit zugewiesenen Wahrscheinlichkeiten auszuwählen. Das Verfahren verwendet eine einheitliche Variable, um den Computer zu einer Speicherstelle zu leiten; wenn dies durch eine Folge geeignet gewählter bedingter Wahrscheinlichkeiten erfolgt, ergeben sich eine effiziente Nutzung des Speicherplatzes und recht schnelle Programme."}
{"DOCID": "941", "TEXT": "Ein rekursives Programm für das allgemeine n-dimensionale Integral: Es wird ein allgemeines Programm für die n-dimensionale Integration mit variablen Grenzen skizziert. Das Programm ist rekursiv und verwendet die Simpson-Regel in Kombination mit wiederholter Halbierung, um die erforderliche Genauigkeit zu erreichen. Es wurde im Ferranti Mercury Autocode Scheme entwickelt."}
{"DOCID": "942", "TEXT": "FORTRAN-Subroutinen für die Zeitreihenanalyse: Die Autoren waren kürzlich an einer Zeitreihenstudie beteiligt, die ein ziemlich typisches Stück angewandter statistischer Forschung darstellte und umfangreiche Berechnungen mit einer mäßig großen Datenmenge beinhaltete. Wir haben herausgefunden, dass die vielen verschiedenen erforderlichen numerischen Prozesse fast vollständig aus einer kleinen Anzahl grundlegender Operationen aufgebaut werden konnten, und ein Satz von FORTRAN-Subroutinen wurde geschrieben, um diese auszuführen. Der Hauptzweck dieser Anmerkung ist die Beschreibung dieser Subroutinen, aber da die Frage allgemeiner statistischer Programme aktuell ist [1], fügen wir einige allgemeine Bemerkungen hinzu."}
{"DOCID": "943", "TEXT": "In der Problembeschreibung häufig kombinierte Begriffe"}
{"DOCID": "944", "TEXT": "Speicher- und Sucheigenschaften eines baumorganisierten Speichersystems: Ein Speicher mit Listeneigenschaften [1] kann verwendet werden, um numerische, alphabetische oder alphanumerische Bäume zu konstruieren. Solche Bäume haben Eigenschaften zum Speichern und Abrufen von Informationen, die auf Probleme anwendbar sind, die große Datenmengen betreffen, oder auf Probleme, bei denen die Menge, Wortlänge und Verteilung gespeicherter Informationen a priori nicht bekannt ist oder sich während der Verarbeitung schnell ändert. Der Zweck dieser Arbeit ist es, die Speicher- und Sucheigenschaften eines baumorganisierten Speichersystems unter der Annahme zu untersuchen, dass ein Speicher verfügbar ist, der bestimmte Listeneigenschaften besitzt. Von Hauptinteresse ist die Anwendung, bei der eine Symboltabelle, ein Wörterbuch oder eine ähnliche Datei gespeichert und durchsucht werden soll."}
{"DOCID": "945", "TEXT": "Arithmetische Deklarationen: Eine Anwendung auf COBOL"}
{"DOCID": "946", "TEXT": "Vorschläge zu Problemen mit ALGOL 60 (ROME) – Ein Bericht des Unterausschusses der American Standards Association X3.4.2"}
{"DOCID": "947", "TEXT": "Ergänzung zum ALGOL 60 Report"}
{"DOCID": "948", "TEXT": "Hinweis zur Verwendung von Prozeduren"}
{"DOCID": "949", "TEXT": "Ganzzahlige und vorzeichenbehaftete Konstanten in ALGOL: Es werden einige Bemerkungen zu den Beziehungen zwischen Syntax und Semantik in den Programmiersprachen gemacht. Das Ziel ist, darauf hinzuweisen, dass, wenn es stimmt, dass die Grammatik einer kontextfreien Sprache nicht nur als Zeichenkettengenerierungsmittel, sondern auch als Methode zum Ausdrücken einer Bedeutung konzipiert werden sollte, die Grammatik von ALGOL offen ist etwas Kritik."}
{"DOCID": "950", "TEXT": "Parallele Methoden zur Integration gewöhnlicher Differentialgleichungen: Dieser Aufsatz ist der These gewidmet, dass, um den vollen Nutzen für Echtzeitberechnungen hochgradig paralleler Computer zu nutzen, wie sie in naher Zukunft zu erwarten sind, ein Großteil der numerischen Analyse erforderlich sein wird in eine \"parallelere\" Form umzuformulieren. Damit ist gemeint, dass serielle Algorithmen durch Algorithmen ersetzt werden sollen, die aus mehreren Teilaufgaben bestehen, die ohne Kenntnis der Ergebnisse der anderen Teilaufgaben berechnet werden können. Als ein Beispiel wird ein Verfahren zum \"Parallelisieren\" der numerischen Integration einer gewöhnlichen Differentialgleichung vorgeschlagen, wobei der Vorgang bei allen Standardverfahren vollständig seriell ist."}
{"DOCID": "951", "TEXT": "Rationale Tschebyscheff-Approximationen an die Bessel-Funktion Integrale Kis(x): Der zweite Remes-Algorithmus wird verwendet, um die Integrale Kis durch rationale Funktionen zu approximieren. Die zugehörigen Koeffizienten für die Näherungen von Ki1, Ki2, Ki3 sind für unterschiedliche Genauigkeiten angegeben."}
{"DOCID": "952", "TEXT": "Eine weitere Verwendung von FORTRAN II Chaining"}
{"DOCID": "953", "TEXT": "Scannen von Text mit einem 1401"}
{"DOCID": "954", "TEXT": "Ein Hinweis zur Berechnung von Wahrscheinlichkeiten in einer F-Verteilung"}
{"DOCID": "955", "TEXT": "Eine Klasse von Matrizen zum Testen von Inversionsverfahren"}
{"DOCID": "956", "TEXT": "Eine Familie von Testmatrizen"}
{"DOCID": "957", "TEXT": "Verfahren zum teilweisen Wiederbeschreiben von Magnetband"}
{"DOCID": "958", "TEXT": "Ein Fall von zu viel Präzision"}
{"DOCID": "959", "TEXT": "Mark Sense- und Port-A-Punch-Programmiereingänge"}
{"DOCID": "960", "TEXT": "Kurvenanpassung mit Format Fortran"}
{"DOCID": "961", "TEXT": "Begrenzte Bit-Manipulation unter Verwendung von FORTRAN II: Es werden Techniken entwickelt, um Bits nur unter Verwendung von FORTRAN II zu manipulieren. Diese Techniken ermöglichen es, einzelne Bits zu testen, bestimmte Felder zu verschieben und in BCD codierte Zahlen in Binär umzuwandeln."}
{"DOCID": "962", "TEXT": "Quadratwurzel mit doppelter Genauigkeit für den CDC-3600: Im Januar 1960 stellte der verstorbene Hans J. Maehly eine Zusammenfassung von Annäherungen an die elementaren Funktionen für den CDC-1604-Computer fertig. Die von Maehly vorgeschlagenen Annäherungen und Techniken sind gleichermaßen auf den zweiten großen Computer der CDC-Reihe, den 3600, anwendbar. Im Gegensatz zum 1604 verfügt der 3600 jedoch über eine eingebaute Gleitkommaarithmetik mit doppelter Genauigkeit. Die vorliegende Arbeit, die weitgehend von den Erfolgen von Maehly und seinen Mitarbeitern inspiriert ist, betrifft die Erweiterung einer von Maehlys Ideen zu einem Unterprogramm mit doppelter Genauigkeit für den 3600."}
{"DOCID": "963", "TEXT": "Relative Auswirkungen des Zentralprozessors und der Eingabe-Ausgabe-Geschwindigkeiten auf den Durchsatz auf dem großen Computer: In diesem Artikel wird eine Technik zur Bestimmung der relativen Auswirkungen der internen Geschwindigkeit des Computers und der Geschwindigkeit der Eingabe-Ausgabe-Einheiten auf die Gesamtgeschwindigkeit vorgestellt das System. Es werden Gleichungen abgeleitet, die die Bestimmung dieser Effekte aus Hardwarenutzungsmessungen erlauben."}
{"DOCID": "964", "TEXT": "Mechanisierung mühsamer Algebra – die Koeffizienten der theoretischen Chemie: Eine Formeltabelle für bestimmte Integrale mit Legendre-Funktionen wurde mechanisch durch ein Programm konstruiert, das algebraische Operationen durchführte. Die Formeln sind alle rationale algebraische Ausdrücke in einer einzigen Variablen und wurden durch eine Wiederholungsprozedur konstruiert. Sie sind von Interesse in der molekularen Quantenchemie. Triviale Codierungstechniken wurden verwendet, um die entsprechenden Programme in FORTRAN zu schreiben. Die Ergebnisse wurden auf einem Photon S-560-System fotokomponiert, das von Bändern gesteuert wurde, die direkt von der Computerausgabe gestanzt wurden, wodurch manuelle Tastatureingaben, Transkriptionsfehler und Tastaturkorrekturen vermieden wurden."}
{"DOCID": "965", "TEXT": "Größter gemeinsamer Teiler (Algorithmus 237 [A1])"}
{"DOCID": "966", "TEXT": "Auswertung der Determinante (Algorithmus 224 [F3])"}
{"DOCID": "967", "TEXT": "Komplementäre Fehlerfunktion (Algorithmus 181 [S15])"}
{"DOCID": "968", "TEXT": "Radikal-inverse Quasi-Zufallspunktfolge (Algorithmus 247 [G5])"}
{"DOCID": "969", "TEXT": "Graycode (Algorithmus 246 [Z])"}
{"DOCID": "970", "TEXT": "Baumsortierung 3 (Algorithmus [M1])"}
{"DOCID": "971", "TEXT": "Time-Sharing in einem Verkehrssteuerungsprogramm: Das Verkehrssignalsteuerungssystem von Toronto besteht aus einer Vielzahl von logisch unterschiedlichen Computerprogrammen, die alle um Maschinenzeit konkurrieren. Um diese Anforderungen zu erfüllen, wurde ein Time-Sharing-Programm geschrieben, dessen Zweck darin besteht, die verschiedenen Unterprogramme innerhalb des Echtzeitsystems in der Reihenfolge einer vordefinierten Priorität auszuführen. In diesem Papier werden die interessanteren Aspekte des Timesharing-Programms umrissen."}
{"DOCID": "972", "TEXT": "Ein als Finite-State-Automat implementiertes Exekutivsystem: Das von der Air Force verwendete 473L-Befehls- und Steuersystem ermöglicht vielen Bedienern den Zugriff auf große Datendateien durch die Verwendung eines Computers. Die Mensch-Maschine-Schnittstelle wird durch mehrere Kommunikationskonsolen erfüllt, von denen Bediener Abfragen eingeben und Antworten anzeigen können. Eine Datenverbindung ermöglicht entfernten Stationen, Nachrichten, Statusmeldungen und Inventare direkt an den Computer zu senden. Die über die Online-Datenverbindung empfangenen Informationen werden verwendet, um die auf der Platte gespeicherten Datendateien zu aktualisieren. Das 473L-Programmiersystem ist in ein Executive Control Program und fünf Komponenten mit unterschiedlichen Verarbeitungsprioritäten unterteilt. Diese Prioritäten ermöglichen es dem System, am empfindlichsten auf die Konsoleneingaben zu reagieren, und ermöglichen es den Bedienern an allen Konsolen, den zentralen Prozessor zeitlich gemeinsam zu nutzen. Das Executive Control Program sorgt für die geordneten Kontrollübergänge zwischen den Programmiersystemkomponenten. Der Hauptschwerpunkt des Artikels liegt auf der Technik der Verwendung der Definition eines endlichen Automaten zum Organisieren des Exekutivkontrollprogramms."}
{"DOCID": "973", "TEXT": "Schätzung von Herzparametern unter Verwendung von Hautpotentialmessungen: Ein grundlegendes Problem der Vektorkardiographie ist die Schätzung des Zustands des Herzens auf der Grundlage von Hautpotentialmessungen. Ein mathematisches Modell, das ventrikuläre Dipole mit Oberflächenpotentialen in Beziehung setzt, wird skizziert. Dann wird gezeigt, dass das inverse Problem – das der Bestimmung elektrischer Herzparameter auf der Basis von Hautpotentialmessungen – als nichtlineares Mehrpunkt-Randwertproblem angesehen werden kann. Eine durchführbare Lösung unter Verwendung von Quasilinearisierung und Hochgeschwindigkeits-Digitalcomputern wird angegeben."}
{"DOCID": "974", "TEXT": "Eine Technik zum Lesen von lückenlosen Bändern macht Elektrokardiographenanalyse auf dem IBM 7090 möglich: Um Arrhythmien und höherfrequente Komponenten des Elektrokardiogramms zu untersuchen, müssen lange Serien von Patientenherzzyklen untersucht werden, bevor ein gültiger Vergleich verschiedener Herzschläge gemacht werden kann. Es wird eine Technik zur automatischen Analyse langer Herzzyklenserien über einen Digitalcomputer vorgestellt."}
{"DOCID": "975", "TEXT": "Das neue Arbeitsprogramm für das internationale Standardvokabular in Computern und Informationsverarbeitung"}
{"DOCID": "976", "TEXT": "Fresnel-Integrale (Algorithmus 213 [S20])"}
{"DOCID": "977", "TEXT": "Konvertierungen zwischen Kalenderdatum und julianischer Tageszahl (Algorithmus 199 [Z])"}
{"DOCID": "978", "TEXT": "Fresnel-Integrale (Algorithmus 244 [S20])"}
{"DOCID": "979", "TEXT": "Logarithmus einer komplexen Zahl (Algorithmus 243 [B3])"}
{"DOCID": "980", "TEXT": "Arithmetik mit mehrfacher Genauigkeit und die exakte Berechnung der Symbole 3-j, 6-j und 9-j: In diesem Artikel wird ein System von Mehrzweck-Festkommaroutinen mit mehrfacher Genauigkeit und deren Verwendung in Unterroutinen beschrieben, die genau die berechnen quantenmechanische 3-j-, 6-j- und 9-j-Symbole großer Argumente."}
{"DOCID": "981", "TEXT": "Rundungsprobleme in der kaufmännischen Datenverarbeitung: Eine gängige Forderung in der kaufmännischen Datenverarbeitung ist, dass die allgemein verständlich gerundete Summe einer Zahlenmenge gleich der Summe der einzeln gerundeten Zahlen ist. Um dies zu erreichen, werden vier Rundungsverfahren beschrieben. Welches Verfahren geeignet ist, hängt davon ab, ob die zu akkumulierenden Zahlen im Vorzeichen variieren können, ob ihre Summe im Vorzeichen variieren kann und ob die letzte zu summierende Zahl vor ihrer Rundung als solche erkannt werden kann."}
{"DOCID": "982", "TEXT": "Ein induktiver Ansatz zur Sprachübersetzung: Die Möglichkeit der natürlichen Sprachübersetzung mittels fester Operationen an Beispielübersetzungen wird betrachtet. Das Konzept der Satzübersetzung, das die Arbeit motiviert, wird informell vorgestellt, und die Messung der physikalischen Ähnlichkeit in Paaren von Zeichenfolgen wird diskutiert, ein Begriff, der bei dem vorgeschlagenen Übersetzertyp eine zentrale Rolle spielt. Experimentelle Beweise werden zur Unterstützung der Prämisse vorgelegt, auf der diese Konzeption basiert."}
{"DOCID": "983", "TEXT": "Aufwickelspulen für perforiertes 1-Zoll-Band für den Informationsaustausch (vorgeschlagener amerikanischer Standard)"}
{"DOCID": "984", "TEXT": "Bericht über Input-Output-Verfahren für ALGOL 60 (IFIP)"}
{"DOCID": "985", "TEXT": "Bericht über SUBSET ALGOL 60 (IFIP)"}
{"DOCID": "986", "TEXT": "Vorgeschlagene Änderung des vorgeschlagenen amerikanischen Standards zur Spezifikation von Allzweck-Papierkarten für die Informationsverarbeitung"}
{"DOCID": "987", "TEXT": "FORTRAN vs. Basic FORTRAN (Eine Programmiersprache für die Informationsverarbeitung auf automatischen Datenverarbeitungssystemen)"}
{"DOCID": "988", "TEXT": "Geschichte und Zusammenfassung der FORTRAN-Standardisierungsentwicklung für die ASA"}
{"DOCID": "989", "TEXT": "Eine Methode zur Syntaxspezifikation"}
{"DOCID": "990", "TEXT": "Anweisungen vom Constraint-Typ in Programmiersprachen: Es wird vorgeschlagen, Anweisungen in eine Programmiersprache aufzunehmen, die Beziehungen zwischen Variablen implizieren, aber keine expliziten Zuweisungsanweisungen sind. Der Compiler baut eine Newtonsche Iteration auf und verwendet dazu eine Routine zur formalen Differenzierung."}
{"DOCID": "991", "TEXT": "Gamma-Funktion mit Controller-Genauigkeit (Algorithmus 225 [S14])"}
{"DOCID": "992", "TEXT": "Gamma-Funktion (Algorithmus 221 [S14])"}
{"DOCID": "993", "TEXT": "Kutta Merson (Algorithmus 218 [D2])"}
{"DOCID": "994", "TEXT": "Stringsort (Algorithmus 207 [M1])"}
{"DOCID": "995", "TEXT": "Steep1 (Algorithmus 203 [E4])"}
{"DOCID": "996", "TEXT": "Permutationen einer Menge mit Wiederholungen (Algorithmus 242 [G6])"}
{"DOCID": "997", "TEXT": "Patentschutz von Computerprogrammen"}
{"DOCID": "998", "TEXT": "Computerprogramme sind patentierbar"}
{"DOCID": "999", "TEXT": "Gemeinsame Erfindung von Computern"}
{"DOCID": "1000", "TEXT": "Offenlegung von Computerpatenten"}
{"DOCID": "1001", "TEXT": "Copyright-Aspekte der Computernutzung: Dieser Aufsatz beschäftigt sich mit der Frage, was eine Urheberrechtsverletzung an einem Buch oder anderen nicht dramatischen literarischen Werken darstellt, wenn das Werk in einen Computer eingespeist und von diesem indexiert, analysiert, teilweise nachgedruckt oder anderweitig verwertet wird Computer, um eine mit dem Auge lesbare Ausgabe zu erzeugen. Auch die Frage der Urheberfähigkeit von Programmen und der Verletzung von Urheberrechten an Programmen wird diskutiert. Das Papier ist in erster Linie auf eine Diskussion des gegenwärtigen Gesetzes gerichtet. Einige Aspekte des vorgeschlagenen neuen Urheberrechtsgesetzes sind ebenfalls enthalten. Im Hinblick auf die geplante Revision des Urheberrechtsgesetzes werden allgemeine Empfehlungen ausgesprochen."}
{"DOCID": "1002", "TEXT": "Ein schnelles Verfahren zur digitalen Filterung: Da ein Großteil der Computerzeit, die für die Zeitreihenanalyse aufgewendet wird, für Multiplikationen verwendet wird, wurde eine minimale Multiplikationsmethode für die digitale Filterung entwickelt, mit der Erwartung, dass sie online in Echtzeit nützlich wäre Analyse biologischer Daten. Die Filter sind aus einer Folge leicht analysierbarer Komponenten in einer Weise aufgebaut, die eine Kaskadierung erleichtert. Das Repertoire an Frequenzgangkurven umfasst relativ gute Tiefpass- und Bandpassdesigns. Es sind Programme verfügbar, um sowohl die Synthese dieser Filter als auch ihre Anwendung auf Computern zu implementieren, deren Assembler die Definition rekursiver Makros ermöglichen."}
{"DOCID": "1003", "TEXT": "Ein Computeranalyseverfahren für thermische Diffusion in biochemischen Systemen: Bei der thermischen Detektion schneller biochemischer Reaktionen ist es notwendig, die Temperaturdaten für transiente Wärmeleitungsverluste in einem zylindrischen Kalorimeter zu korrigieren. Um die Komplexität zu handhaben, die sich aus unterschiedlichen thermischen Relaxationszeiten konzentrischer Isolierschichten ergibt, wurde ein Computerprogramm entwickelt, das die Temperaturverteilung des Systems als Funktion von Radius und Zeit angibt. Diese Verteilung wird bei jedem Schritt durch ein Unterprogramm korrigiert, das den momentanen chemischen Zustand der Aktion sowie die durch diese Reaktion erzeugte Wärme berechnet. Das Programm basiert auf einer direkten Aussage des Fourier-Gesetzes der Wärmeleitung und der chemischen Geschwindigkeitsgleichung, um ein \"Buchhaltungsgesetz\" bereitzustellen, um die Reaktanten und den Fluss der Wärmepakete so zu verfolgen, dass der Computer die Wärmeverteilung kontinuierlich speichert. Als Computeranalyseverfahren wird hier ein solches angesehen, bei dem die physikalischen Gesetzmäßigkeiten eines Prozesses explizit im Programm verwendet werden. Normalerweise führt dies dazu, dass viele der herkömmlich verwendeten mathematischen Verfahren bestanden werden. Das Programm wurde gegen einige bekannte exakte Lösungen der Wärmegleichung getestet und lieferte identische Ergebnisse und wurde gut mit experimentellen Daten einer bekannten biochemischen Reaktion verglichen. Die Konstruktion von Computerprogrammen auf der Grundlage der direkten Aussage der physikalischen Gesetze ist ein allgemein anwendbares Prinzip, das auf mehrere andere physikalische Phänomene angewendet wurde."}
{"DOCID": "1004", "TEXT": "Arkustangens (Algorithmus [B1])"}
{"DOCID": "1005", "TEXT": "Koordinaten auf einem Ellipsoid (Algorithmus 240 [Z])"}
{"DOCID": "1006", "TEXT": "Eine Speicherzuweisungs- und Referenzstruktur: Es wird ein Verfahren vorgeschlagen und diskutiert, das es ermöglicht, eine subscripted-Variable-Fähigkeit (im FORTRAN-Sinn) zu Assemblersystemen vom AUTOCODER-Typ hinzuzufügen."}
{"DOCID": "1007", "TEXT": "Erweiterung bestehender Compiler durch ausgeklügelte Verwendung von Makros: Es wird eine Beschreibung einer Anwendung präsentiert, in der Makros und Zeichenfolgenverkettung verwendet wurden, um eine neue Einrichtung zu BELFAP hinzuzufügen."}
{"DOCID": "1008", "TEXT": "Planen von Besprechungen mit einem Computer: Es wird die Computerplanung von Papieren beschrieben, wie sie für das Treffen der Federation of American Societies for Experimental Biology (FASEB) von 1960 entwickelt wurde. Das FASEB-Treffen ist das größte wissenschaftliche Treffen, das jedes Jahr in den Vereinigten Staaten stattfindet. Die für FASEB entwickelte Technik kann angewendet werden, um jedes Meeting mit parallelen Sitzungen zu planen."}
{"DOCID": "1009", "TEXT": "Lösung kombinatorischer Probleme unter Verwendung von Erzeugungsfunktionen auf einem Computer mit variablen Feldern: Die Nützlichkeit von Erzeugungsfunktionen bei der Lösung kombinatorischer Probleme wird diskutiert. Einzelne Umsetzungsergebnisse werden vorgestellt und bewertet."}
{"DOCID": "1010", "TEXT": "Eine Mehrbenutzer-Recheneinrichtung für Bildung und Forschung: Heutige Recheneinrichtungen sind in ihrem Wert für die wissenschaftliche Forschung eingeschränkt, da sie nicht in der Lage sind, intensiv mit Benutzern zu interagieren. Die volle Leistungsfähigkeit eines Forschungscomputers sollte an vielen Terminals verfügbar sein, die jedem Benutzer die Möglichkeit geben, beliebige einfache oder komplexe Verfahren zu erstellen, zu korrigieren und auszuführen. Die Implementierung wird für ein kleines Mehrbenutzer-Computersystem beschrieben, das es mehreren Benutzern ermöglicht, unabhängig mit der Maschine zu arbeiten und unter Verwendung einer Schreibmaschinenkommunikation eine zufriedenstellende Antwort zu erhalten."}
{"DOCID": "1011", "TEXT": "Logarithmus einer komplexen Zahl (Algorithmus 48 [B3])"}
{"DOCID": "1012", "TEXT": "Formale Parsing-Systeme: Die automatische syntaktische Analyse ist in letzter Zeit sowohl für die Datenverarbeitung natürlicher Sprache als auch für syntaxgesteuerte Compiler wichtig geworden. Ein formales Analysesystem G = (V,u,T,R) besteht aus zwei endlichen disjunkten Vokabularen, V und T, einer Viele-Viele-Abbildung, u, von V auf T, und einem rekursiven Satz R von Strings in T, der syntaktisch genannt wird Satz Klassen. Jedes Programm zur automatischen syntaktischen Analyse legt ein formales Parsing-System fest. Ein gerichteter Produktionsanalysator (I,T,X,p) ist eine nichtdeterministische Kellerspeichermaschine mit internem Vokabular I, Eingabevokabular T und allen Produktionen von p in der Form: (Z,a) -> aY1 ... Ym wobei Z, Yi Elemente der Menge I und a ein Element der Menge T sind. Jede kontextfreie Sprache kann durch einen gerichteten Produktionsanalysator analysiert werden. Der Kuno-Oettinger Mehrwege-Syntaktanalysator für Englisch ist ein konkretes Beispiel eines gerichteten Produktionsanalysators und eines funktionierenden Parsing-Algorithmus. In diesem Beitrag wird der Zusammenhang zwischen den vom Analysator zugewiesenen Strukturen und denen einer herkömmlichen Phrasenstrukturgrammatik untersucht."}
{"DOCID": "1013", "TEXT": "Abschlussprüfungsplanung: Es wird ein Verfahren zur Planung von Abschlussprüfungen beschrieben, um eine minimale Anzahl von Studentenkonflikten zu ergeben. Die \"Minimierung\" wird durch wiederholtes Auswerten eines nichtlinearen Satzes von Gleichungen erreicht. Eingebettet in den Prozess ist eine zufällige oder Monte-Carlo-Auswahl von Aufgaben. Wie bei solchen heuristischen Techniken ist die Lösung möglicherweise nicht optimal, und es können viele Lösungen gefunden werden, die lokal minimale Ergebnisse liefern. Computerprogramme werden beschrieben und empirische Ergebnisse angegeben."}
{"DOCID": "1014", "TEXT": "Maschinensteuerungen für die Varianzanalyse: Ein Hauptproblem bei der Verwendung der Varianzanalyse ist mit zunehmender Anzahl von Faktoren der exponentielle Anstieg der Anzahl von Wechselwirkungen. Auch wenn der Experimentator möglicherweise nicht an diesen Wechselwirkungen interessiert ist, ist es aufgrund des Problems, Fehlerterme zu erhalten, unmöglich, sie in den meisten experimentellen Designs zu ignorieren. Es liegt daher nahe, den Großteil der Arbeit, die mit der Berechnung der Wechselwirkungen verbunden ist, dem Computer zuzuwenden. Ein Programmgerät, um den Computer dazu zu bringen, dies zu tun, wird beschrieben."}
{"DOCID": "1015", "TEXT": "Near-Minimax-Polynom-Approximationen und Partitionierung von Intervallen: Es wird ein Verfahren zur Near-Minimax-Polynom-Approximation beschrieben. Als Nebenprodukt liefert dieses Verfahren eine Formel für eine Schätzung des maximalen Fehlers, der mit einem gegebenen Näherungsgrad verbunden ist. Unter Verwendung dieser Formel wird ein Partitionierungsalgorithmus zum Teilen eines Grundintervalls in Teilintervalle erhalten, für die Annäherungen gleichen Grades denselben maximalen Fehler ergeben."}
{"DOCID": "1016", "TEXT": "Austauschbare perforierte Band Variable Blockformate für Positionierung und geraden Schnitt (RS-273) und Konturierung und Konturierung/Positionierung (RS-274) Numerisch gesteuerte Werkzeugmaschinen (vorgeschlagene amerikanische Standards)"}
{"DOCID": "1017", "TEXT": "Kommentare zur Bit-Sequenzierung des ASCII bei der Serial-by-Bit-Datenübertragung"}
{"DOCID": "1018", "TEXT": "Gauß (Algorithmus 209 [S15])"}
{"DOCID": "1019", "TEXT": "XY-Bewegungsdarstellung (Algorithmus 162 [J6])"}
{"DOCID": "1020", "TEXT": "Freifeldlesen (Algorithmus 239 [I5])"}
{"DOCID": "1021", "TEXT": "Methode der konjugierten Gradienten (Algorithmus 238 [F4])"}
{"DOCID": "1022", "TEXT": "Größter gemeinsamer Teiler (Algorithmus 237 [A1])"}
{"DOCID": "1023", "TEXT": "Bessel-Funktionen erster Art (Algorithmus 236 [S17])"}
{"DOCID": "1024", "TEXT": "Eine Anmerkung zur Bildung der freien Liste"}
{"DOCID": "1025", "TEXT": "Ein Verfahren zur Syntaxprüfung ALGOL 60: Ein Syntaxprüfer wurde basierend auf der Syntax von ALGOL entworfen, wie im ALGOL 60-Bericht [Mitteilungen der ACM, Mai 1960] beschrieben. Da die Definition der Elemente der Sprache rekursiv ist, schien es am wünschenswertesten, den Syntaxprüfer als einen Satz gegenseitig rekursiver Prozessoren zu entwerfen, die durch Subroutinen miteinander verbunden sind, die bestimmte Buchhaltungsfunktionen ausführen. Aufgrund der rekursiven Natur der Sprache und des Syntaxprüfers erforderte das Problem der Wiederherstellung nach einem Fehler viel Aufmerksamkeit. Es wurde eine Methode entwickelt, die es erlaubt, die meisten Programme trotz Fehler vollständig zu überprüfen."}
{"DOCID": "1026", "TEXT": "Teile-und-Korrektur-Verfahren für die Division mit mehrfacher Genauigkeit: Ein Divisionsproblem wird definiert und eine Notation eingeführt, um es mit dem Problem der Operation mit mehrfacher Genauigkeit in einem digitalen Computer in Beziehung zu setzen. Ein grundlegendes Teile-und-Korrektur-Verfahren für die Division mit mehrfacher Genauigkeit wird formuliert und seine bekannten Eigenschaften werden kurz besprochen. Von besonderem Interesse ist die Tatsache, dass das Verfahren bei jedem Schritt einen Satz von genau drei Schätzungen für das gewünschte Ergebnis erzeugt, von denen eine genau ist."}
{"DOCID": "1027", "TEXT": "Eine alternative Prüfsummenmethode"}
{"DOCID": "1028", "TEXT": "Untersuchung einer neuen analytischen Methode zur numerischen Ableitungsbewertung: Ein kürzlich vorgeschlagener analytischer Ansatz zur numerischen Ableitungsbewertung wird diskutiert. Es wird gezeigt, dass die Technik sowohl genau als auch einfach anzuwenden ist, obwohl bestimmte angezeigte Modifikationen erforderlich sind. Seine Verwendung sollte das Schreiben und Debuggen von Programmen, die Ableitungen hochkomplexer Funktionen erfordern, erheblich erleichtern."}
{"DOCID": "1029", "TEXT": "A Simple Automatic Derivative Evaluation Program: Ein Verfahren zur automatischen Berechnung von totalen/partiellen Ableitungen beliebiger algebraischer Funktionen wird vorgestellt. Die Technik ermöglicht die Berechnung numerischer Werte von Ableitungen, ohne analytische Ausdrücke für die Ableitungen zu entwickeln. Der Schlüssel zu der Methode ist die Zerlegung der gegebenen Funktion durch Einführung von Zwischenvariablen in eine Reihe von elementaren Funktionsschritten. Zur automatischen Auswertung und Differenzierung dieser neuen Variablen steht eine Bibliothek von elementaren Funktionsunterprogrammen zur Verfügung. Der letzte Schritt in diesem Prozess erzeugt die Ableitung der gewünschten Funktion. Das Hauptmerkmal dieses Ansatzes ist seine Einfachheit. Es kann als schnelles Reaktionswerkzeug verwendet werden, wenn die Ableitung analytischer Ableitungen mühsam ist, und auch als Debugging-Werkzeug für Programme, die Ableitungen enthalten."}
{"DOCID": "1030", "TEXT": "Techniken zur Simulation von Computerlogik: Die Simulation eines digitalen Computers ist ein integraler Bestandteil der meisten Computerdesign-Automatisierungssysteme. Die Auswertung der Booleschen Funktionen, die den zu simulierenden Computer charakterisieren, bildet einen wesentlichen Teil eines Simulationssystems. Es werden vier allgemeine Verfahrensklassen zur Auswertung dieser Funktionen definiert. Um die Effizienz eines Simulationssystems stark zu steigern, werden Verfahren zum gleichzeitigen Auswerten vieler Funktionen für einen Satz von Werten der Variablen und zum gleichzeitigen Auswerten einer Funktion für viele Sätze von Werten für die Variablen vorgestellt."}
{"DOCID": "1031", "TEXT": "Ein Hinweis zum Beginn des Newton-Raphson-Verfahrens: Es wird die Bestimmung einer geeigneten Anfangsschätzung für eine Wurzel einer Gleichung f(x) = 0 durch Berechnen der Wurzeln einer Folge verwandter Gleichungen beschrieben."}
{"DOCID": "1032", "TEXT": "Theoretische Überlegungen zu Informationsabrufsystemen: Informationsspeicher- und -abrufsysteme bestehen aus drei Hauptkomponenten: (a) Identifizierung von Informationen und Kennzeichnung für einen effektiven Abruf, (b) Suchstrategie, wie man in die Datei eingibt, um das Scannen von nicht relevantem Material zu umgehen , und (c) Dateiorganisation, um den Zugriff auf Informationen effizient zu gestalten. Zum Identifizieren von Informationen schlägt der Aufsatz vor, dass eine Metasprache (kürzlich in einem Aufsatz von Goffman, Verhoeff und Belzer erörtert) in Verbindung mit einer Objektsprache verwendet wird. Für die Suchstrategie wird ein lineares Modell für eine Bewertungsfunktion der Relevanz entwickelt, das das System für das Auffinden relevanter Dokumente und das Nichtauffinden nicht relevanter Dokumente belohnt und das System für entgangene relevante Dokumente und falsches Ablegen bestraft. Auf die Unzulänglichkeiten eines linearen Modells wird hingewiesen. Zwei Ansätze zur Dateiorganisation werden diskutiert. Die eine ist die Selbstorganisation der Datei basierend auf ihrer Historie und früheren Leistung, und die zweite ist eine selbsterzeugende Teilmenge der Datei mit einer hohen Wahrscheinlichkeit, dass sie relevant ist."}
{"DOCID": "1033", "TEXT": "Experimentelles personalisiertes Array-Übersetzersystem: Ein System, das für die enge Mensch-Maschine-Interaktion in einer Mehrzweck-Problemlösungsumgebung entwickelt wurde, ist experimentell betriebsbereit. Das System verwendet eine Array-orientierte symbolische Quellensprache, die leistungsstarke Anweisungstypen enthält. Dazu gehören numerische, boolesche, relationale und Auswahloperatoren für Operanden, die ganze Arrays sein können. Das System erlaubt auch eine einfache Spezifikation von Test- und Argumentarrays in einzelnen Anweisungen. Das vollständig symbolische Betriebssystem umfasst die Anzeige und Eingabe von Programmen und Daten. Die Ablaufsteuerung wird durch einen Unterbrechungsschalter unterstützt, der es dem Benutzer ermöglicht, während der Ausführung mit dem Programm zu interagieren. Zusätzlich zur normalen Sequenzierung gespeicherter Programme bietet das System Ablaufverfolgungsoptionen und die Möglichkeit, jede Anweisung zur sofortigen Ausführung einzugeben. Die derzeitige Implementierung des Systems erfolgt mit einem interpretierenden Übersetzer auf einem IBM 1620-Computer."}
{"DOCID": "1034", "TEXT": "Autosate: Eine automatisierte Datensystem-Analysetechnik wird beschrieben. Die Technik wurde entwickelt, um einige der Hauptprobleme zu lindern, die derzeitige Analyse-Arbeitslasten, lange Zeitspanne zwischen Projektbeginn und Systembetriebsdatum, das Fehlen expliziter Anweisungen für die Durchführung von Datensystemanalysen und die Verwendung der Ergebnisse und das Fehlen belasten einer Technik zur Kontrolle von Datensystemänderungen während ihrer gesamten Lebensdauer. Die Analyse ist darauf ausgerichtet, Auslastung, Beziehungen und Ablageeigenschaften von Dokumenten im Informationsverbund automatisiert zu ermitteln."}
{"DOCID": "1035", "TEXT": "Eigenschaften der FORTRAN CEP-Sprache: Die FORTRAN CEP-Sprache unterscheidet sich von FORTRAN II hauptsächlich, weil: (1) sie die Vielfalt der Modi für reelle Größen erweitert; (2) es erlaubt geeignete Mischungen in einer Input/Output-Liste oder in einem Ausdruck von Größen, die unter verschiedenen Modi auftreten; (3) es macht es möglich, eine größere Anzahl von Eingabe-/Ausgabegeräten zu adressieren; und (4) es beseitigt die Beschränkungen hinsichtlich der Komplexität der Liste von Größen, die zwischen dem Magnetkernspeicher und der Trommel oder den Magnetbandeinheiten zu übertragen sind."}
{"DOCID": "1036", "TEXT": "Bemerkung zur weiteren Verallgemeinerung von ALGOL"}
{"DOCID": "1037", "TEXT": "Reduktion einer Matrix mit Polynomelementen (Algorithmus 170 [F3])"}
{"DOCID": "1038", "TEXT": "Crout mit Ausgleich und Iteration (Algorithmus 135 [F4])"}
{"DOCID": "1039", "TEXT": "Summation von Fourier-Reihen (Algorithmus 128 [C6])"}
{"DOCID": "1040", "TEXT": "Romberg-Integration (Algorithmus 60 [D1])"}
{"DOCID": "1041", "TEXT": "Zufällige Permutation (Algorithmus 235 [G6])"}
{"DOCID": "1042", "TEXT": "Poisson-Charlier-Polynome (Algorithmus 234 [S23])"}
{"DOCID": "1043", "TEXT": "Talk-Eine High-Level-Quellsprachen-Debugging-Technik mit Echtzeit-Datenextraktion: TALK, was „Take A Look“ bedeutet, ist eine Debugging-Technik, die beim Debuggen komplexer Echtzeit-Programmiersysteme wesentlich hilft, indem das Benutzerprogramm an gewünschten Punkten unterbrochen wird, um zuvor zu extrahieren angegebenen Daten. Die extrahierten Daten werden später bearbeitet, wobei die zugehörigen Daten mit ihrer übergeordneten Quellsprachenidentifikation aufgelistet werden."}
{"DOCID": "1044", "TEXT": "Ein automatischer Lader für Subroutinen-Verschachtelungen: Es wird ein Verfahren zum automatischen Laden von Bibliotheks-Subroutinen beschrieben, das so angepasst werden kann, dass es in Verbindung mit jedem herkömmlichen Zwei-Durchgangs-Assembler arbeitet. Das Verfahren ist speziell darauf ausgelegt, mit einer verschachtelten Bibliotheksstruktur fertig zu werden."}
{"DOCID": "1045", "TEXT": "Programmierung der Varianzanalyse durch Sequenzen von Operatoren und isomorphe Abbildungen: Ein spezieller Operatorkalkül, der 1956 von Hartley zusammen mit einem neuen Abbildungsschema entwickelt wurde, hat sich als effizient bei der Programmierung der Varianzanalyse für Multifaktor-Experimente erwiesen. Der Operatorkalkül und das Abbildungsschema werden detailliert beschrieben."}
{"DOCID": "1046", "TEXT": "A Compiler-Building System Developed by Brooker and Morris: In einer Reihe von Artikeln, die in den letzten zwei Jahren veröffentlicht wurden, haben R. A. Brooker und D. Morris (zusammen mit J. S. Rohl in ihrem jüngsten Artikel) ein sehr interessantes Programmiersystem vorgestellt, das sie entwickelt haben für den Ferranti-Atlas-Computer. Das vorliegende Papier beschreibt einige der Hauptmerkmale ihres Systems. Es erweitert einige Punkte, die die ursprünglichen Autoren kurz behandelt haben, und behandelt nur sehr leicht einige Themen, denen sie beträchtlichen Raum widmen. Der Zweck dieses Papiers stellt lediglich Erläuterungen dar. Abgesehen von einigen sehr kleinen Details und einigen Kommentaren weicht es nicht absichtlich von dem in den aufgeführten Referenzen veröffentlichten Material ab oder ergänzt es."}
{"DOCID": "1047", "TEXT": "Generierung von Testmatrizen durch Ähnlichkeitstransformationen: Es wird ein Verfahren zum Erhalten von Testmatrizen mit einer vorgeschriebenen Verteilung von charakteristischen Wurzeln angegeben. Das Verfahren besteht darin, durch besonders einfache Ähnlichkeitstransformationen aus kanonischen Formen vollständige Matrizen zu erzeugen. Die erzeugten Matrizen haben auch bekannte charakteristische Vektoren, Inverse und Determinanten."}
{"DOCID": "1048", "TEXT": "Annäherungslösung axialsymmetrischer Probleme: Eine Vielzahl physikalischer Probleme in so unterschiedlichen Bereichen wie der elektrostatischen Feldtheorie, der Wärme- und idealen Flüssigkeitsströmung und der Spannungskonzentrationstheorie reduzieren sich unter der Annahme der Achsensymmetrie auf die Untersuchung einer elliptischen partiellen Differentialgleichung. Probleme vom Dirichlet-Typ, die mit dieser Gleichung verbunden sind, werden an Regionen untersucht, deren Grenzen einen nicht entarteten Teil der x-Achse umfassen, und es werden äußerst genaue numerische Verfahren für Annäherungslösungen angegeben."}
{"DOCID": "1049", "TEXT": "Numerische Lösung nichtlinearer Zweipunkt-Randwertprobleme durch Finite-Differenzen-Methoden: Die Lösung nichtlinearer Zweipunkt-Randwertprobleme ist oft eine äußerst schwierige Aufgabe. Abgesehen von Fragen der Realität und Eindeutigkeit gibt es für dieses Problem kein etabliertes numerisches Verfahren. Derzeit sind Schießtechniken die einfachste Methode, um diese Probleme anzugehen. Wenn diese fehlschlagen, kann oft die schwierigere Methode der finiten Differenzen verwendet werden, um eine Lösung zu erhalten. Dieses Papier gibt Beispiele und diskutiert die Finite-Differenzen-Methode für nichtlineare Zweipunkt-Randwertprobleme."}
{"DOCID": "1050", "TEXT": "Eine Aufschlüsselungstechnik für Teile unter Verwendung von Listenstrukturen: Eine Aufschlüsselung von Teilen mit Listenstruktur wird vorgeschlagen und diskutiert. Implementierungsfakten werden unter Verwendung dieser Techniken auf dem Betriebsprogramm dargestellt."}
{"DOCID": "1051", "TEXT": "Listenelemente mit mehreren Wörtern: Das Listenkonzept, wie es ursprünglich von Newell, Simon und Shaw vorgeschlagen wurde, spezifizierte einzelne Computerwörter als Elemente einer Liste. Dieser Bericht beschreibt die Verwendung von zwei oder mehr aufeinanderfolgenden Wörtern als ein Element. Eine solche Verwendung führt zu einer beträchtlichen Einsparung sowohl des zum Halten einer gegebenen Datenmenge erforderlichen Platzes als auch der Ausführungszeit, die zum Durchführen eines gegebenen Prozesses an den Daten erforderlich ist. Nach einer kurzen Beschreibung von Standardlistenstrukturen mit Einzelwortelementen werden die Mehrwortelemente eingeführt. Dann werden Elemente mit variabler Länge zusammen mit den entsprechenden Platznutzungsproblemen beschrieben. Schließlich werden mehrere Beispiele gegeben, um die Verwendung von Mehrwortlisten zu veranschaulichen. Dieses Papier versucht, verschiedene neuere Arbeiten zusammenzustellen, die einige dieser Konzepte auf unterschiedliche Weise angewendet haben, und aufzuzeigen, wie sie sich auf die allgemeineren Probleme beziehen."}
{"DOCID": "1052", "TEXT": "Reduzierung von Rundungsfehlern durch Programmierung: Bei der Akkumulation einer Summe, wie z. B. bei einer numerischen Integration mit einer großen Anzahl von Intervallen, wird die Summe selbst viel größer als die einzelnen Summanden. Dies kann eine ungenauere Summe ergeben, wenn die Anzahl der Intervalle erhöht wird. Separate Variablen können als Akkumulatoren eingerichtet werden, um Teilsummen innerhalb verschiedener unterschiedlicher Intervalle zu halten. Somit werden die umfangreichen aufeinanderfolgenden Kürzungen eliminiert."}
{"DOCID": "1053", "TEXT": "Entwurf und Implementierung einer Mehrzweck-Eingaberoutine: Eine Mehrzweck-Eingaberoutine wird diskutiert und für FORTRAN befürwortet. Die Philosophie solcher Programme wird untersucht und veranschaulicht."}
{"DOCID": "1054", "TEXT": "Gauss-Seidel (Algorithmus 220 )"}
{"DOCID": "1055", "TEXT": "q-Bessel-Funktionen In(t) (Algorithmus 214)"}
{"DOCID": "1056", "TEXT": "Shellsort (Algorithmus 201)"}
{"DOCID": "1057", "TEXT": "Scheduling kritischer Pfade (Algorithmus 40)"}
{"DOCID": "1058", "TEXT": "Simpson-Regel für multiple Integration (Algorithmus 233)"}
{"DOCID": "1059", "TEXT": "Heapsort (Algorithmus 232)"}
{"DOCID": "1060", "TEXT": "Matrixinversion (Algorithmus 231)"}
{"DOCID": "1061", "TEXT": "Matrixpermutation (Algorithmus 230)"}
{"DOCID": "1062", "TEXT": "Symbolmanipulation in FORTRAN-SASP I Subroutinen: Es wird eine Reihe von Subroutinen zur Verwendung in FORTRAN beschrieben, deren Zweck darin besteht, Ausgabezeichenfolgen aus (i) Eingabezeichenfolgen zu synthetisieren, die von der zuvor berichteten SHADOW-Unterroutine zur allgemeinen syntaktischen Analyse analysiert wurden, und/oder ( ii) beliebig geformte gepackte BCD-Strings. Unterroutinen vom Funktionstyp sind für Zwischenoperationen enthalten, die an den Zeichenfolgen durchgeführt werden, die in einer abgekürzten internen Darstellung gespeichert sind. Die automatische Art und Weise, in der eine interne Darstellung für jede neu erzeugte Teilkette sequentiell in einem Block eines gemeinsamen Speichers gespeichert wird, und die Art und Weise, in der ein Speicherblock zu diesem Zweck dynamisch zugewiesen wird, werden diskutiert."}
{"DOCID": "1063", "TEXT": "Perforiertes 1-Zoll-Papierband für den Informationsaustausch (vorgeschlagener amerikanischer Standard)"}
{"DOCID": "1064", "TEXT": "Perforierter Bandcode für den Informationsaustausch (vorgeschlagener amerikanischer Standard)"}
{"DOCID": "1065", "TEXT": "Bitsequenzierung des American Standard Code for Information Interchange (ASCII) bei der Serial-by-Bit-Datenübertragung (vorgeschlagener amerikanischer Standard)"}
{"DOCID": "1066", "TEXT": "Zunehmende Anwendungen linearer Programmierung: Die Verwendung linearer Programmiermodelle hat in den letzten Jahren so stark zugenommen, dass das gesamte Konzept zum Organisieren eines Computercodes eine radikale Änderung erfahren hat. Es reicht nicht mehr aus, einen mathematischen Algorithmus (also das Simplex-Verfahren) auf einen Computercode zu reduzieren. Ein fortgeschrittener Code muss mit einer solchen Vielzahl von Situationen fertig werden, dass die jeweiligen Computerunterprogramme in einem integrierten System organisiert werden müssen. Der Schwerpunkt dieses Dokuments liegt auf den zugrunde liegenden Prinzipien, auf denen zukünftige lineare Programmiersysteme basieren müssen. Diese Gesichtspunkte werden durch die neuen Anforderungen beeinflusst, die Anwendungen in der Erdölindustrie an solche Systeme stellen. Einige der Komponenten eines solchen Systems sind: Übersetzung der Problemstellung in Form von Grunddaten in Koeffizienten der linearen Programmiermatrix, Datenübertragung zur direkten Eingabe in den Computer, Datendatei im Rechenzentrum, Datenverarbeitung und -aufbereitung vor der Lösung des Simplex-Algorithmus, einen effizienten und zuverlässigen Code zum Lösen des oben erwähnten Algorithmus und flexible Mittel zum Zusammenfassen der Ergebnisse."}
{"DOCID": "1067", "TEXT": "Bilderzeugung mit einem Standard-Zeilendrucker: Es wird ein Verfahren zur Erzeugung von Grautonbildern auf einem Zeilendrucker unter Ausnutzung der unterschiedlichen Schwärzegrade von Standard-Druckzeichen beschrieben. Es wurden Graustufen mit 17, 32 und 64 Stufen entwickelt. Gescannte Bilder von Blutzellen werden verwendet, um die Technik zu zeigen."}
{"DOCID": "1068", "TEXT": "Ein FORTRAN II Ladezeit-Sparer"}
{"DOCID": "1069", "TEXT": "Eine Methode zum Vergleich der internen Betriebsgeschwindigkeiten von Computern"}
{"DOCID": "1070", "TEXT": "Expand, ein System zur Replikation von Eingabekarten"}
{"DOCID": "1071", "TEXT": "Abrechnung der Computernutzung für allgemeine Time-Sharing-Systeme: Die aktuelle Entwicklung allgemeiner Time-Sharing-Systeme erfordert eine Überarbeitung der Abrechnungsverfahren für die Computernutzung. Da Benutzer von Timesharing-Systemen gleichzeitig arbeiten, ist es notwendig, genauer zu sein, was die Menge an Computerzeit und Speicherplatz betrifft, die ein Benutzer tatsächlich verwendet. Die verschiedenen Kostenfaktoren, die für die Abrechnung der Computernutzung in generalisierten Time-Sharing-Systemen berücksichtigt werden sollten, werden diskutiert."}
{"DOCID": "1072", "TEXT": "Ein verbesserter Äquivalenzalgorithmus: Ein Algorithmus zum Zuweisen von Speicher auf der Grundlage von ÄQUIVALENZ-, DIMENSION- und GEMEINSAME-Deklarationen wird vorgestellt. Der Algorithmus basiert auf einer Baumstruktur und hat die Rechenzeit gegenüber einem zuvor veröffentlichten Algorithmus um 40 Prozent reduziert, indem alle Äquivalenzklassen mit einem Scan der ÄQUIVALENZ-Deklarationen identifiziert werden. Das Verfahren ist auf jedes Problem anwendbar, bei dem es notwendig ist, Äquivalenzklassen zu identifizieren, wenn die Elementpaare gegeben sind, die die Äquivalenzbeziehung definieren."}
{"DOCID": "1073", "TEXT": "Ein schnelles Verfahren zum Erzeugen exponentieller Zufallsvariablen: Ein sehr schnelles Verfahren zum Erzeugen exponentieller Zufallsvariablen in einem digitalen Computer wird skizziert."}
{"DOCID": "1074", "TEXT": "Schäfte (Algorithmus 215)"}
{"DOCID": "1075", "TEXT": "Shuttlesort (Algorithmus 175)"}
{"DOCID": "1076", "TEXT": "Mehrfache Integration (Algorithmus 146)"}
{"DOCID": "1077", "TEXT": "Chebyshev-Kurvenanpassung (Algorithmus 91)"}
{"DOCID": "1078", "TEXT": "Elementarfunktionen durch Kettenbrüche (Algorithmus 229)"}
{"DOCID": "1079", "TEXT": "Q-Bessel-Funktionen (Algorithmus 228)"}
{"DOCID": "1080", "TEXT": "Tschebyscheff-Polynomkoeffizienten (Algorithmus 227)"}
{"DOCID": "1081", "TEXT": "Normalverteilungsfunktion (Algorithmus 226)"}
{"DOCID": "1082", "TEXT": "Gamma-Funktion mit kontrollierter Genauigkeit (Algorithmus 225)"}
{"DOCID": "1083", "TEXT": "Ein Experiment in einem benutzerorientierten Computersystem: Eine Version eines Software-Hardware-Systems zum Zwecke der Erleichterung der Programmierung und Analyse wohlformulierter Probleme wird beschrieben. Ein modifizierter Flexowriter wird verwendet, um computerakzeptable Eingaben zu erzeugen, wenn Gleichungen oder berechenbare Anforderungen auf ziemlich dieselbe Weise eingegeben werden, wie sie in herkömmlichen mathematischen Texten erscheinen würden. Die Tipp- und Sprachregeln sind recht flexibel und uneingeschränkt. Während der Compiler-Teil effizient ist, hat das System als Ganzes viel breitere Aspekte als Werkzeug für das Studium von Problemlösungs- und selbstlernenden Systemen."}
{"DOCID": "1084", "TEXT": "Zum Deklarieren willkürlich codierter Alphabete: Die Unfähigkeit vorhandener Programmiersprachen, Zeichenketten aus mehr als einem oder zwei Alphabeten zu handhaben, wird erwähnt, und es wird ein Schema zum Deklarieren zusätzlicher Alphabete vorgeschlagen. Das Schema sieht Folgendes vor: Viele-zu-Eins-Codierungen, Rechts- oder Linksausrichtung, Vergleichen von Sequenzen, die sich von numerischen Sequenzen unterscheiden, Variationen in der Zeichengröße (Anzahl von Bits) von Alphabet zu Alphabet und beliebige Zeichendarstellung in der Ausgangssprache."}
{"DOCID": "1085", "TEXT": "Spezifikation für Allzweck-Papierkarten für die Informationsverarbeitung (vorgeschlagener amerikanischer Standard)"}
{"DOCID": "1086", "TEXT": "Ein Vorschlag für Input-Output-Konventionen in ALGOL 60-A Report of the Subcommittee on ALGOL of the ACM Programming Language Committee"}
{"DOCID": "1087", "TEXT": "Probleme bei der automatischen Abstraktion: Eine Vielzahl von Problemen bezüglich des Entwurfs und des Betriebs eines automatischen Abstraktionssystems werden diskutiert. Der Zweck besteht darin, einen allgemeinen Überblick über mehrere Hauptproblembereiche zu geben. Es wird kein Versuch unternommen, Details zu diskutieren oder Präferenzen unter alternativen Lösungen aufzuzeigen."}
{"DOCID": "1088", "TEXT": "Menüplanung per Computer: Es wurde ein Computercode entwickelt, der Menüs plant, indem er minimale Kostenkombinationen von Menüelementen findet, so dass die täglichen diätetischen, gastronomischen und Produktionsanforderungen für eine Folge von Tagen erfüllt werden können. Es wird ein schneller, spezieller ganzzahliger Programmieralgorithmus beschrieben, der die theoretische Lösung des Problems annähert. Bei Bedarf kann jedes Menü online geändert und anschließend nachoptimiert werden. Bis zu 30 Prozent Einsparung bei den Lebensmittelkosten sind möglich. Ein FORTRAN-Programm für den IBM 1410 ist auf Anfrage erhältlich. Der Implementierung des Systems muss eine erhebliche Menge an Datenverarbeitung vorausgehen."}
{"DOCID": "1089", "TEXT": "Planung eines Rechenzentrums"}
{"DOCID": "1090", "TEXT": "Unvollständige Betafunktionsverhältnisse (Algorithmus 222)"}
{"DOCID": "1091", "TEXT": "Hypergeometrisch und konfluent hypergeometrisch (Algorithmus 191 & 192)"}
{"DOCID": "1092", "TEXT": "Nichtrekursive adaptive Integration (Algorithmus 182)"}
{"DOCID": "1093", "TEXT": "Auswertung der Determinante (Algorithmus 224)"}
{"DOCID": "1094", "TEXT": "Prime Twins (Algorithmus 223)"}
{"DOCID": "1095", "TEXT": "Dezimaltabellen von binär codierten Tabellen"}
{"DOCID": "1096", "TEXT": "Zur Vermeidung von Matrixumkehrungen zwischen 7090 FORTRAN II und 7090 FORTRAN IV"}
{"DOCID": "1097", "TEXT": "An Algorithm for Converting Integers from Base A to Base B: Ein wenig bekannter, einfacher Algorithmus zur Integer-Konvertierung zwischen Zahlensystemen wird vorgestellt und bewiesen."}
{"DOCID": "1098", "TEXT": "Ein Vergleich von Computersprachen zur Listenverarbeitung (einschließlich eines detaillierten Vergleichs von COMIT, IPL-V, LISP 1.5 und SLIP): Es wird ein detaillierter Vergleich von COMIT, IPL-V, LISP 1.5 und SLIP präsentiert – vier bekannte Computerprogramme Sprachen, die unter ihnen alle Hauptmerkmale bestehender Listenverarbeitungssprachen aufweisen. Wichtige Gemeinsamkeiten von Listenverarbeitungssprachen werden besprochen: Formen von Datenstrukturen, die manipuliert werden, Notwendigkeit dynamischer Speicherzuweisung, Verwendung von Kellerspeichern und Verwendung rekursiver Operationen. Die Hauptunterschiede zwischen den vier betrachteten Sprachen werden detailliert beschrieben: Darstellungen von Daten, sowohl durch den Programmierer als auch innerhalb der Maschine; Methoden zur Speicherzuweisung; Programmierformalismen und spezielle Verfahren verfügbar, einschließlich arithmetischer Einrichtungen; und Benutzerfreundlichkeit in Bezug auf Verfügbarkeit, Dokumentation, Lernhilfen und Debugging-Möglichkeiten. Ein grober Vergleich zeigt, dass alle besprochenen Sprachen ungefähr gleich schnell sind. Schließlich geben die Autoren einige Heuristiken an, um bei der Auswahl einer dieser Sprachen zur Verwendung in bestimmten Problemanwendungen zu helfen, und kommen zu dem Schluss, dass keine der betrachteten Sprachen in allen möglichen Listenverarbeitungsanwendungen deutlich überlegen ist."}
{"DOCID": "1099", "TEXT": "Professionelle Computerarbeit für Blinde: Entwicklungen in der Computertechnologie haben neue berufliche Möglichkeiten für intelligente Blinde eröffnet. Da es nur wenige oder gar keine Berufe gibt, an denen Blinde ohne schwerwiegende Nachteile teilnehmen können, sind die Möglichkeiten, die ihnen geboten werden, durch Computernutzung Zugang zu verschiedenen Berufen zu erhalten, einschließlich des Programmierens, wichtig für die zukünftige Rehabilitationsplanung. Unmittelbar interessant ist auch die Tatsache, dass sich Blinde besonders für Programmierarbeiten eignen können. Aufgrund des intensiven Trainings und der ständigen Erfahrung mit der Lokalisierung von Objekten in der unsichtbaren Umgebung und auch aufgrund des hervorragend trainierten Gedächtnisses bringt der Blinde Programmierfähigkeiten in die Arbeit ein, die sich der Sehende kaum aneignen musste. Diese Qualifikationen sollten zu weniger Debugging-Problemen führen und den Blind zu einer wertvollen Ergänzung für jede Systemgruppe machen. Bevor aus Blinden ein ernsthafter Profi werden konnte, mussten eine Reihe von Hilfsmitteln und Techniken entwickelt werden, die zwischen Maschine und Programmierer vermitteln können. Dieses Papier beschreibt die Techniken und Hilfsmittel, die von den Mitarbeitern des Medical Computing Center des University of Cincinnati College of Medicine entwickelt wurden."}
{"DOCID": "1100", "TEXT": "Stand der Lehrpläne für Informatik an Hochschulen und Universitäten"}
{"DOCID": "1101", "TEXT": "Der Platz des logischen Designs und der Switching-Theorie im Computer-Lehrplan"}
{"DOCID": "1102", "TEXT": "Mechanische Sprachen: Eine Kursspezifikation"}
{"DOCID": "1103", "TEXT": "Logik für die Informatik"}
{"DOCID": "1104", "TEXT": "Ein Undergraduate Curriculum in Numerical Analysis"}
{"DOCID": "1105", "TEXT": "Zur Einführung digitaler Computer"}
{"DOCID": "1106", "TEXT": "Programmierung digitaler Computer"}
{"DOCID": "1107", "TEXT": "Computer und Bildung"}
{"DOCID": "1108", "TEXT": "Digital Data Processor for Tracking the Partly Illuminated Moon*: Eine Studie über Mondverfolgungstechniken und die Herstellung eines Steckbretts zur Bewertung der Machbarkeit der besten ausgewählten Technik wurde durchgeführt, um ein Verfolgungssystem zur Beobachtung der Sichtlinie zur Mitte eines Teils zu definieren beleuchteter Mond. Der Datenverarbeitungsteil des Systems wird im Detail dargestellt und dann im Allgemeinen der Betrieb der Trackerkopfanordnung zum Datenauslesen, der Betrieb des gesamten Systems und die Auswirkung von Überlegungen zur Datenverarbeitung auf die Konstruktion des Trackersystems beschrieben. Das System besteht im Wesentlichen aus einem optischen Sensor, einem Digitalcomputer und einem Tracker-Antriebsmechanismus. Die drei in Kaskade geschalteten Systemeinheiten bilden den Regelkreis. Für diese Anwendung wurde ein optisches Teleskop mit einem radialen mechanischen Abtastmechanismus verwendet, das die Messdaten der Mondsichtlinie ausliest. Diese Informationen werden sequentiell in einen digitalen Spezialcomputer eingelesen, der die Messungen extrahiert und die Fehlersignale berechnet, die den Tracker in die geeignete Lage treiben."}
{"DOCID": "1109", "TEXT": "Umrechnung einer Potenz in eine Reihe von Tschebyscheff-Polynomen*: Auch langsam konvergierende Potenzreihen lassen sich als Reihen in Tschebyscheff-Polynome umformen, wenn bei der Auswertung der Koeffizienten geeignete Folgetransformationen verwendet werden. Das Verfahren wird durch die Berechnung der Koeffizienten für die Entwicklung des Logarithmus und des Dilogarithmus veranschaulicht."}
{"DOCID": "1110", "TEXT": "Ein Fourierreihenverfahren zur numerischen Lösung einer Klasse parabolischer partieller Differentialgleichungen*: Es wird ein Fourierreihenverfahren beschrieben, das, wenn es auf eine bestimmte Klasse parabolischer partieller Differentialgleichungen angewendet wird, das Problem auf ein System gewöhnlicher Differentialgleichungen reduziert. Es wird eine Anwendung angegeben, für die das Verfahren einen erheblichen Vorteil gegenüber herkömmlichen Finite-Differenzen-Verfahren zeigt."}
{"DOCID": "1111", "TEXT": "Eine Klasse iterativer Techniken zur Faktorisierung von Polynomen*: Eine Iterationsmethode wird in Bezug auf eine Funktion mit etwas willkürlichem Charakter entwickelt. Für die Konvergenz des Prozesses sind hinreichende Bedingungen gegeben, die für Polynome in einer Variablen Faktoren beliebigen Grades ergeben. Als Spezialfälle treten sowohl das Verfahren von Lin als auch das Verfahren von Newton auf."}
{"DOCID": "1112", "TEXT": "Eine Technik zur Computererkennung und -korrektur von Rechtschreibfehlern*: Die beschriebene Methode geht davon aus, dass ein Wort, das in einem Wörterbuch nicht zu finden ist, höchstens einen Fehler aufweist, der ein falscher, fehlender oder zusätzlicher Buchstabe oder eine einzelne Transposition sein kann. Das nicht identifizierte Eingabewort wird erneut mit dem Wörterbuch verglichen, wobei jedes Mal geprüft wird, ob die Wörter übereinstimmen – unter der Annahme, dass einer dieser Fehler aufgetreten ist. Bei einem Testlauf mit verstümmeltem Text wurden über 95 Prozent dieser Fehlertypen korrekt identifiziert."}
{"DOCID": "1113", "TEXT": "Computererstellte Perspektivenfilme als wissenschaftliches und kommunikatives Werkzeug*: Die grundlegende Transformation, die für eine perspektivische Zeichnung erforderlich ist, lässt sich leicht programmieren. Diese Tatsache und das Aufkommen von Hochgeschwindigkeits-Mikrofilmdruckern wie dem General Dynamics Electronics S-C 4020 ermöglichen perspektivische Filme als direkte Ausgabe von einem Computer. Die Programmierung eines solchen Films wird kurz beschrieben, um die Winkelbewegungen eines Satelliten zu untersuchen, der ein Lageregelungssystem enthält. Im Film stellt ein dominoförmiger Kasten den Satelliten dar und eine Kugel mit Breiten- und Längenkreisen die Erde. Die Kosten betrugen ungefähr drei bis acht Minuten IBM 7090-Zeit pro Minute Film."}
{"DOCID": "1114", "TEXT": "Generieren einer kanonischen Präfixcodierung*: Computerprogramme zum Generieren einer erschöpfenden Präfixcodierung mit minimaler Redundanz werden beschrieben. Ein Programm erzeugt einen Huffman-Frequenzbaum, ein anderes bestimmt die Strukturfunktionen einer Codierung und ein drittes Programm ordnet Codes zu."}
{"DOCID": "1115", "TEXT": "Randomisierte binäre Suche mit Baumstruktur: Es wird ein effizienteres Verfahren zur Verwendung von Baumstrukturen vorgeschlagen, das sowohl Plus- als auch Minuszweige im Suchpfad verwendet. Sehr signifikante Gewinne ergeben sich, wenn der Suchschlüssel alphabetische Zeichen enthält."}
{"DOCID": "1116", "TEXT": "Tests an einem Computerverfahren zum Erstellen von Stundenplänen*: Ein zuvor vorgeschlagenes Computerverfahren zum Erstellen von Stundenplänen, basierend auf einer Iteration mit Booleschen Matrizen, wird beschrieben. In begrenzten Tests hat das Verfahren bei jedem Versuch erfolgreich Zeitpläne erstellt. Es werden Referenzen gegeben, die das Fahrplanproblem mit Sätzen über Matrizen von Nullen und Einsen und mit Sätzen über zweigeteilte Graphen in Beziehung setzen. Es werden einige Probleme bei der Anwendung der Methode zur Erstellung von Zeitplänen in realen Situationen erwähnt."}
{"DOCID": "1117", "TEXT": "Mehrphasen-Sortierung mit überlappendem Zurückspulen*: Es wird eine Variation der Mehrphasen-Zusammenführungs-Sortierungstechnik beschrieben, die es ermöglicht, dass jeweils ein Band zurückgespult wird, während die Zusammenführung auf den verbleibenden Bändern fortgesetzt wird. Das Ergebnis ist die Überlappung eines großen Teils der Rückspulzeit. Die Technik sollte immer dann in Betracht gezogen werden, wenn eine Sortierung geschrieben wird, um auf fünf oder mehr Bändern zu arbeiten, die nicht rückwärts gelesen werden können. Die Einsparungen des Überlappungsverfahrens scheinen mit zunehmender Anzahl verfügbarer Bänder zuzunehmen."}
{"DOCID": "1118", "TEXT": "FORTRAN-Subroutinen zur Reduzierung von Zeitreihendaten*"}
{"DOCID": "1119", "TEXT": "Ein offener Brief an X3.4.3 (FORTRAN Standards – American Association)"}
{"DOCID": "1120", "TEXT": "„ALCOR-Gruppendarstellungen von ALGOL-Symbolen“, Comm. ACM 6 (1963), 597-599. (Korrigenda)"}
{"DOCID": "1121", "TEXT": "Kommentare zu \"A Continued Operation Notation\"*: Diese Anmerkung soll mehrere Punkte in einem kürzlich erschienenen Papier klären und korrigieren, in dem einige Notationen für die Symbolmanipulation von M.P. Barnett [Komm. ACM 6 (August 1963)]."}
{"DOCID": "1122", "TEXT": "Eine Anmerkung zu einigen Compileralgorithmen: Zwei Compilergeneratoren für arithmetische Ausdrücke werden diskutiert: einer, der derzeit in einem experimentellen Compiler verwendet wird, und eine Verbesserung, die von K. Speierman von Burroughs vorgeschlagen wurde."}
{"DOCID": "1123", "TEXT": "Gauß (Algorithmus 209)"}
{"DOCID": "1124", "TEXT": "Matrixdivision (Algorithmus 197)"}
{"DOCID": "1125", "TEXT": "Syminv2 (Algorithmus 150)"}
{"DOCID": "1126", "TEXT": "ERF (Algorithmus 123)"}
{"DOCID": "1127", "TEXT": "Tridiagonale Matrix (Algorithmus 122)"}
{"DOCID": "1128", "TEXT": "Auswertung der Determinante (Algorithmus 41)"}
{"DOCID": "1129", "TEXT": "Unvollständige Betafunktionsverhältnisse (Algorithmus 222)"}
{"DOCID": "1130", "TEXT": "Gamma-Funktion (Althm 221)"}
{"DOCID": "1131", "TEXT": "Über Kontext und Mehrdeutigkeit beim Parsing*"}
{"DOCID": "1132", "TEXT": "Eine Erweiterung von ALGOL zum Manipulieren von Formeln*"}
{"DOCID": "1133", "TEXT": "Ein Programmierpaket für einige allgemeine Rechenarten*"}
{"DOCID": "1134", "TEXT": "Einige Auswirkungen des 6600-Computers auf Sprachstrukturen*: Das Problem des Kompilierens effizienter 6600-Codes veranlasste die Entwicklung einer Zwischensprache, die die Struktur der Maschine widerspiegelt, die leichter zu manipulieren ist, um die Objektprogrammeffizienz zu verbessern. Das Thema dieser Arbeit ist die Zwischensprache und Methoden zu ihrer Manipulation. Zusammenstellungen einer Reihe von arithmetischen Anweisungen werden diskutiert. Es wird davon ausgegangen, dass alle Funktionen und Exponentiale aus diesen Aussagen entfernt und durch einfache Variablen ersetzt wurden. Der Einfachheit halber wird die Behandlung von Indizes ignoriert. Eine vereinfachte 6600-Struktur wird dargestellt, um das Kompilierverfahren zu veranschaulichen. Zur Vereinfachung werden mehrere Annahmen getroffen, obwohl es Fälle gibt, in denen die Annahmen in der tatsächlichen Maschine verletzt werden."}
{"DOCID": "1135", "TEXT": "Eine allgemeine geschäftsorientierte Sprache basierend auf Entscheidungsausdrücken*: Die Struktur einer Programmiersprache für digitale Computer, die eine breite Klasse von Geschäfts- und Dateiverarbeitungsanwendungen abdeckt, wird vorgestellt. Eine solche Struktur, die auf dem Identifizieren und Integrieren der allen Prozessen einer solchen Klasse gemeinsamen Aspekte in einen Compiler basiert, erlaubt das Schreiben extrem kompakter Programme, selbst für vergleichsweise komplexe Anwendungen, in Form von Tabellen von Steuerausdrücken, die nur Informationen ausdrücken, die für die spezielle Anwendung charakteristisch sind . Darüber hinaus können lokale Änderungen eines Prozesses (z. B. Änderungen, die nur eine der beteiligten Ausgabedateien betreffen) durch lokale Änderungen im Programm (z. B. Änderung nur eines Eintrags der Tabellen) bewirkt werden. Diese Struktur ermöglicht auch eine kostengünstige Erstellung von Compilern mit Ladegeschwindigkeit, die die Quellprogramme in effiziente Maschinencodes übersetzen. Der hier gewählte Ansatz weicht von konventionellen Konstruktionsphilosophien für mechanische Sprachen ab. Es betont die strukturelle Analyse der Klasse von Prozessen, die in den Sprachen dargestellt werden sollen, im Gegensatz zur Betonung formaler (d. h. inhaltsunabhängiger) syntaktischer Definitionen. Es stützt sich ausschließlich auf die nicht prozedurale Darstellung des Prozesses als Mengen (Tabellen) von Beziehungen zwischen Daten und Ergebnissen (es gibt keine Steueranweisungen wie GO TO usw.), anstatt Prozedurbeschreibungen zu verwenden (die Eins-zu-Eins-Übersetzungen von Flussdiagrammen sind). ). Hier wird ein unveränderliches Verfahrensmuster als charakteristisch für die Klasse aller Stapelverarbeitungen identifiziert. Diese neue Philosophie hat das Potenzial, bekannte Mängel anderer geschäftsorientierter Sprachen zu überwinden, und erfüllt vollständig die Anforderungen, die CODASYL an solche Sprachen stellt, einschließlich Maschinenunabhängigkeit."}
{"DOCID": "1136", "TEXT": "Anfänge einer Theorie des Umgangs mit Informationen*"}
{"DOCID": "1137", "TEXT": "Eine Formatsprache*"}
{"DOCID": "1138", "TEXT": "Formalismus in Programmiersprachen*"}
{"DOCID": "1139", "TEXT": "FORTRAN IV als Syntaxsprache*"}
{"DOCID": "1140", "TEXT": "„Strukturelle Zusammenhänge“ in formaler Sprache*"}
{"DOCID": "1141", "TEXT": "Kontextbegrenzte syntaktische Analyse"}
{"DOCID": "1142", "TEXT": "Eine Erweiterung von ALGOL-ähnlichen Sprachen"}
{"DOCID": "1143", "TEXT": "Analyse von Zerfallstypdaten*: Es wurde eine vergleichende Studie mit einer Vielzahl von numerischen Techniken zum Anpassen von experimentellen Daten des Zerfallstyps an Formen durchgeführt, die die Summen von Exponentialen beinhalten. Statistische Fehler der angepassten Parameter werden ebenfalls berechnet. Diese Methoden wurden auf künstlich erzeugte Datensätze sowie auf die Ergebnisse von Experimenten mit radioaktiven Tracern an Menschen und Tieren angewendet. Die Ergebnisse zeigen, dass die Werte der angepassten Parameter sehr empfindlich auf Variationen im Anpassungsverfahren reagieren. Daher große Sorgfalt, sehr empfindlich gegenüber Schwankungen im Anpassungsverfahren. Daher muss bei der Identifizierung solcher Werte mit physikalischen Konstanten große Sorgfalt walten. Obwohl die Werte von Funktionen, die von diesen angepassten Parametern abgeleitet werden, die definitiv physikalischen Entitäten zugeordnet werden können, im Allgemeinen unter Variationen in den Anpassungstechniken stabiler sind, können Fehlergrenzen so groß sein, dass selbst ihnen kein großes Vertrauen entgegengebracht werden kann. Es erscheint daher am besten, eine einheitliche Technik sowohl für die Durchführung der Experimente als auch für die Analyse der Daten zu wählen und dann nur relative Ergebnisse zwischen einem Subjekt und dem nächsten als signifikant zu betrachten."}
{"DOCID": "1144", "TEXT": "Digitale Computerbestimmung der Alphaquellenaktivität: Es wird eine Technik zur Bestimmung der Aktivität und Homogenität einer Alphaquelle beschrieben. Es wird angenommen, dass die Technik, die einen digitalen Computer verwendet, viele Verwendungen und Anwendungen auf dem Gebiet der Kernphysik hat. Die Technik beinhaltet die Computermanipulation des digitalen Bildes der nuklearen Quelle. Experimentelle Einzelheiten werden angegeben."}
{"DOCID": "1145", "TEXT": "GIT-A Heuristisches Programm zum Testen von Paaren gerichteter Liniendiagramme auf Isomorphie*: Bei einem gegebenen Paar gerichteter Liniendiagramme ist das Problem, festzustellen, ob sie isomorph sind oder nicht, eines, für das keine effiziente algorithmische Lösung bekannt ist. Da ein einfacher Aufzählungsalgorithmus 40 Jahre Laufzeit auf einem sehr schnellen Computer benötigen könnte, um zwei Graphen mit 15 Knoten zu vergleichen, scheint ein ausgefeilterer Ansatz erforderlich zu sein. Die Situation ist ähnlich derjenigen, die in Bereichen wie Spielen und Theorembeweisen vorherrscht, wo praktische Algorithmen unbekannt sind (für die interessanten Fälle), wo aber verschiedene praktische, wenn auch nur teilweise erfolgreiche Techniken verfügbar sind. Git-Graph Isomorphism Tester – enthält eine Vielzahl von Prozessen, die versuchen, die Suche nach einem Isomorphismus einzugrenzen oder zu zeigen, dass keiner existiert. Für eine Lösung verlässt man sich nicht ausschließlich auf ein Schema, und das Programm ist darauf ausgelegt, übermäßige Berechnungen entlang fruchtloser Linien zu vermeiden. GIT wurde in der COMIT-Sprache geschrieben und erfolgreich auf dem IBM 7090 getestet."}
{"DOCID": "1146", "TEXT": "Eine effiziente zusammengesetzte Formel für mehrdimensionale Quadratur: Eine (2s+1)-Punkt-Quadraturformel zweiten Grades zur Integration über ein s-dimensionales Hyperrechteck wird vorgestellt. Alle bis auf einen der Punkte liegen auf der Oberfläche, wobei Gewichte mit entgegengesetztem Vorzeichen an Punkten auf gegenüberliegenden Flächen befestigt sind. Wenn ein großes Volumen in kongruente rechteckige Unterteilungen unterteilt wird, ist nur ein Punkt in jeder inneren Unterteilung erforderlich, um eine Genauigkeit zweiten Grades zu erreichen."}
{"DOCID": "1147", "TEXT": "Zur numerischen Lösung von Randwertproblemen linearer gewöhnlicher Differentialgleichungen*: Zur Lösung von Randwertproblemen linearer gewöhnlicher Differentialgleichungen wird ein numerisches Verfahren vorgestellt. Das beschriebene Verfahren ist nicht iterativ und verwendet irgendein einstufiges numerisches Integrationsschema, um das Problem von einem der Grenzwerte auf einen der Anfangswerte zu reduzieren. Es werden Kommentare zu einigen numerischen Ergebnissen der Anwendung der Methode auf ein bestimmtes Problem gemacht. Außerdem wird eine Erweiterung des beschriebenen Algorithmus auf allgemeinere Probleme diskutiert."}
{"DOCID": "1148", "TEXT": "Ein Beispiel für Arithmetik mit \"signifikanten Stellen\"*: Es wird gezeigt, dass verschiedene Verfahren zur Handhabung des Summierungsprozesses für die geometrische Reihe Ergebnisse liefern, die sehr unterschiedliche Signifikanzen anzeigen, wenn sie in einer Maschine ausgeführt werden, die Arithmetik mit \"signifikanten Stellen\" enthält."}
{"DOCID": "1149", "TEXT": "GARGOYLE , eine Sprache zum Schreiben von Compilern*"}
{"DOCID": "1150", "TEXT": "Ein Fortran-Post-Mortem-Verfahren"}
{"DOCID": "1151", "TEXT": "Eine Anmerkung zur Multiplikation boolescher Matrizen II"}
{"DOCID": "1152", "TEXT": "Fließkomma-Arithmetik mit 84-Bit-Zahlen: Es wird eine klassische und unkomplizierte Technik vorgestellt, die nicht auf die Größe oder Art der verwendeten Zahlendarstellung oder Arithmetik mit mehrfacher Genauigkeit beschränkt ist."}
{"DOCID": "1153", "TEXT": "Ein schnelles Verfahren zum Generieren normalverteilter Zufallsvariablen*: Eine Technik zum Generieren normalverteilter Zufallszahlen wird beschrieben. Es ist schneller als die derzeit allgemein verwendeten und ist sowohl auf Binär- als auch auf Dezimalcomputer leicht anwendbar."}
{"DOCID": "1154", "TEXT": "Automaten mit mehreren Bändern und unendlichen Zuständen -- Ein Überblick: Ein Überblick über Maschinen, die leistungsfähiger als endliche Automaten und weniger leistungsstark als allgemeine Turing-Maschinen sind, wird vorgestellt. Es wird davon ausgegangen, dass die Maschinen in dieser Kategorie genauso eng mit digitalen Computern verwandt sind wie entweder die endlichen Automaten oder die uneingeschränkten Turing-Maschinen. Zwischenmaschinen können erstellt werden, indem ein unendlicher Speicher an eine endliche Maschine angefügt wird und dann eines oder alle der folgenden ausgeführt werden: (1) die Art und Weise einschränken, in der auf den unbegrenzten Teil des Speichers zugegriffen werden kann, (2) gebunden die Anzahl der Schritte, die für eine Berechnung durch eine zunehmende rekursive Funktion der Länge der Eingabe zulässig sind, (3) die Gesamtmenge des verfügbaren Speichers auf die gleiche Weise einschränken. Beispiele aus allen drei Klassen und ihre Eigenschaften werden diskutiert."}
{"DOCID": "1155", "TEXT": "Experimente mit einem deduktiven Frage-Antwort-Programm: Als Untersuchung zur künstlichen Intelligenz wurden Computerexperimente zur deduktiven Frage-Antwort mit einem LISP-Programm namens DEDUCOM, einem Akronym für DEDUctive COMmunicator, durchgeführt. Bei 68 Fakten beantwortete DEDUCOM 10 Fragen, die anhand der Fakten beantwortet werden konnten. Ein Fakt teilt DEDUCOM entweder eine bestimmte Information oder eine Methode zur Beantwortung einer allgemeinen Art von Frage mit. Einige Schlussfolgerungen aus dem Artikel sind: (1) DEDUCOM kann eine Vielzahl von Fragen beantworten. (2) Ein Mensch kann die deduktive Kraft von DEDUCOM erhöhen, indem er ihm mehr Fakten mitteilt. (3) DEDUCOM kann sehr einfache Programme schreiben (man hofft, dass diese Fähigkeit der Vorläufer der Fähigkeit zur Selbstprogrammierung ist, was eine Möglichkeit des Lernens ist). (4) Das Suchverfahren von DEDUCOM hat derzeit zwei große Mängel: Einige Fragen, die anhand der gegebenen Fakten beantwortet werden können, können nicht beantwortet werden, und einige andere beantwortbare Fragen können nur beantwortet werden, wenn die relevanten Fakten in der \"richtigen\" Reihenfolge angegeben werden. (6) Gegenwärtig hat die Methode von DEDUCOM, logische Ableitungen im Prädikatenkalkül zu machen, zwei schlimme Mängel: einige Tatsachen müssen in logisch äquivalente geändert werden, bevor sie an DEDUCOM gegeben werden, und einige redundante Tatsachen müssen an DEDUCOM gegeben werden."}
{"DOCID": "1156", "TEXT": "Hankel-Funktion (Algorithmus 124 [S17])"}
{"DOCID": "1157", "TEXT": "Verfahren für die Normalverteilungsfunktionen (Algorithmus 272 [S15])"}
{"DOCID": "1158", "TEXT": "Programmstrukturen für parallele Verarbeitung: Konstrukte zum Organisieren und Explizieren von parallelen Programmsegmenten werden als Erweiterungen von ALGOL 60 diskutiert. Die Konstrukte dienen als Metabefehle und werden durch Geräte mit Multiverarbeitungsfähigkeit motiviert."}
{"DOCID": "1159", "TEXT": "Machine Independence: Its Technology and Economics: Es wird ein Überblick über Techniken zum Übertragen von Programmen und insbesondere Compilern von einem Computer auf einen anderen angeboten. Von den untersuchten Methoden wird die \"Bootstrap\"-Technik für eine ausführliche Diskussion herausgegriffen, wobei der Schwerpunkt auf ihrer Ökonomie liegt. Die Überlegungen, die für die Anwendbarkeit des Bootstrappings im konkreten Fall ausschlaggebend sind, werden diskutiert und versucht, diese angemessen qualitativ zu gewichten. Schließlich werden Gründe für die Annahme angeführt, dass das Problem der Maschinenunabhängigkeit durch aktuelle Trends im Computerdesign erheblich verringert wird und dass eher dieser Prozess der Konvergenz im Hardwaredesign als irgendwelche vorhersehbaren Softwareentwicklungen zu seiner zufriedenstellenden Lösung führen werden."}
{"DOCID": "1160", "TEXT": "CAT: A 7090-3600 Computergestützte Übersetzung: Ein halbautomatisches Übersetzungssystem wurde implementiert, das 7090 FAP-Sprachprogramme in 3600 Assemblersprache umwandelt. Die Eingabe in das System ist ein FAP-Programmdeck, das speziell für die Übersetzung durch den Benutzer vorbereitet wurde. Die Ausgabe besteht aus dem übersetzten COMPASS-Sprachprogramm zusammen mit einer umfassenden Diagnoseliste, die der Benutzer analysieren muss, um fragwürdige Bereiche der Übersetzung zu überprüfen. Der Übersetzungsprozessor besteht aus drei unterschiedlichen Phasen: einer Zusammenstellung des FAP-Programms, einer umfassenden Analyse des zusammengestellten Codes unter besonderer Berücksichtigung der Aktionen von Befehlen auf andere Befehle und auf Daten und schließlich dem Ausgabedurchlauf, der das COMPASS-Programm im erzeugt Form von Makrobefehlen."}
{"DOCID": "1161", "TEXT": "1401-Kompatibilitätsfunktion auf dem IBM System/360 Modell 30: Die \"zweite Generation\" von speicherprogrammierbaren Computern, zu der die IBM 1400-Serie gehörte, brachte EDV erstmals in großem Umfang auf den Massenmarkt. Im Laufe dieser Ära führten schnelle technologische Veränderungen zu einer raschen Veralterung von Datenverarbeitungsgeräten. Programme, die für ein bestimmtes System geschrieben wurden, erforderten eine langwierige Konvertierung, da inkompatible neue Maschinen zum Einsatz kamen. Das IBM System/360 wurde speziell für das Konvertierungsproblem entwickelt. Eine der beim Modell 30 verfügbaren Konvertierungshilfen ist die 1401-Kompatibilitätsfunktion. Dieses Merkmal ermöglicht in Verbindung mit anderen Hilfsmitteln einen reibungslosen und kostengünstigen Übergang zur optimalen Nutzung des neuen Systems."}
{"DOCID": "1162", "TEXT": "Eine Assemblersprache zum Neuprogrammieren: Eine vollständige Neuprogrammierung von Compilersprachenprogrammen ist selten erforderlich. Es sind Programme in Assemblersprache, die die größten Schwierigkeiten bereiten. Assemblersprachen bieten im Allgemeinen eine Eins-zu-Eins-Übersetzung von einer symbolischen in eine numerische Version eines Programms, d. h. von einer Assemblersprache in eine Maschinensprache. Die hier vorgestellte Metasprache kann verwendet werden, um die Abbildung einer beliebigen Sprache, die einer kanonischen Listenform entspricht, in einen beliebigen Strom von Bits zu spezifizieren. Dieser Bitstrom kann als ein Maschinensprachenprogramm, ein Zeichenstrom oder was auch immer der Benutzer sonst noch wünscht behandelt werden. Somit kann diese Metasprache verwendet werden, um von einer Assemblersprache in eine andere oder von der Assemblersprache für eine Maschine in die Maschinensprache einer anderen abzubilden."}
{"DOCID": "1163", "TEXT": "Philco/IBM-Übersetzung auf problemorientierter, symbolischer und binärer Ebene: Ein Übersetzungssystem wurde entwickelt, um den größten Teil des Aufwands zu eliminieren, der früher erforderlich war, um Codes der Philco-2000-Serie für den IBM 7094-Betrieb neu zu programmieren. Die Erfahrung mit diesem System ist begrenzt, aber äußerst erfolgreich und fördert die Anwendung der Techniken auf andere Quell- und Objektsprachen."}
{"DOCID": "1164", "TEXT": "Emulation großer Systeme: Das Konvertierungsproblem und eine neue Technik namens Emulation werden diskutiert. Die Technik der Emulation wird entwickelt und umfasst Abschnitte sowohl auf der zentralen Verarbeitungseinheit (CPU) als auch auf der Eingabe/Ausgabe-Einheit (E/A). Auf diese allgemeine Behandlung folgen drei Abschnitte, die detaillierter die Implementierung von Kompatibilitätsmerkmalen unter Verwendung der Emulationstechniken für die Systeme IBM 7074, 7080 und 7090 auf IBM System/360 beschreiben."}
{"DOCID": "1165", "TEXT": "Der Spectra 70/45 Emulator für den RCA 301: Das RCA 301 Emulator System wird mit dem Spectra 70/45 als Umprogrammierhilfe mitgeliefert. Es ermöglicht, dass ein RCA 301-Objektprogramm auf dem Spectra 70/45 ausgeführt wird, ohne dass Änderungen im RCA 301-Objektcode erforderlich sind. Die Ausführungsraten sind erheblich besser als bei herkömmlichen Simulationen. Der Emulator bietet eine Erhöhung der Durchsatzkapazität für den 301-Benutzer auf dem Spectra 70/45. Der Emulator verwendet sowohl Hardware-Mikroprogrammroutinen als auch Softwareroutinen, um seine Funktion zu erfüllen."}
{"DOCID": "1166", "TEXT": "Eine Verwendung von Makros bei der Übersetzung der symbolischen Assemblersprache von einem Computer in einen anderen: Eine Reihe von Makrooperationen wurde vorbereitet, um die Übersetzung von symbolischen Assemblersprachenprogrammen von IBM 7090 in Maschinensprachenprogramme von IBM 7040 zu unterstützen. Dieser Satz, der am Anfang des 7090-Symboldecks eingefügt ist, behandelt inkompatible Befehlsmnemoniken als Makrobefehle, um äquivalente 7040-Befehlssätze zu erzeugen. Inkompatible Befehle werden in grundlegende Operationsklassen kategorisiert, die durch ein einziges grundlegendes Skelett ausgedrückt werden können. Es sind mehrere Ebenen von Makroaufrufen erforderlich, um Argumente für jede einzelne Anweisung an das Grundskelett zu liefern. Eine Modifikation zur Ausführungszeit der Adresse oder des Tags eines inkompatiblen Befehls erfordert die Einbeziehung eines Adress-Tag-Äquivalents. E/A wird durch Generieren von Aufrufen an E/A-Simulationssubroutinen gehandhabt."}
{"DOCID": "1167", "TEXT": "Über die Übersetzung von Maschinensprachenprogrammen: Die automatische Übersetzung von Maschinensprachenprogrammen wird mit dem Aufkommen neuer Großrechner zu einem höchst erstrebenswerten Ziel. Es werden die Fallstricke analysiert, die eine vollständig automatische Übersetzung erschweren, und es wird gezeigt, dass diese vor allem semantischer Natur sind. Es wird ein halbautomatisches Verfahren zur Lösung semantischer Probleme vorgeschlagen."}
{"DOCID": "1168", "TEXT": "Across Machine Lines in COBOL: Die Produktion eines großen, in COBOL geschriebenen Dateiwartungs- und Abrufprogrammsystems wird beschrieben. Die COBOL-Sprache wurde speziell verwendet, um den Betrieb des Systems auf drei IBM-Computern zu ermöglichen."}
{"DOCID": "1169", "TEXT": "Ein Algorithmus zum Minimieren von Backboard-Verdrahtungsfunktionen: Ein teilweise erschöpfender Algorithmus wird zum Lösen des folgenden Problems vorgestellt, das sich aus dem automatischen Layout eines Computers ergibt. Bei einem gegebenen geordneten Satz E1, E2, ..., EN von N Computerkomponenten wird für jede Permutation der Elemente E1, E2, ..., EN ein Wert einer ganzzahligen Funktion F angehängt. Der Algorithmus findet ein lokales Minimum von F durch Auswerten der Menge {Delta F} der Inkremente, die einer bestimmten Menge von Austauschvorgängen von zwei Elementen entsprechen. Dann wird der Austausch durchgeführt, der dem kleinsten negativen Inkrement von {Delta F} entspricht. Der Prozess wird iteriert und gestoppt, wenn die Menge der Inkremente eine positive oder leere Menge ist, was bewiesenermaßen einem Minimum entspricht. Das Verfahren ähnelt der Downhill-Methode zum Finden des Minimums einer reellen Funktion F(P) und kann auf andere Platzierungsprobleme angewendet werden. Experimentelle Ergebnisse werden mit Rückwänden präsentiert, die aus vielen Elementen und unterschiedlichen Anfangsplatzierungen bestehen."}
{"DOCID": "1170", "TEXT": "Analysieren der englischen Syntax mit einem Pattern-Learning-Parser: Ein auf Mustererkennung und Lernlogik basierendes Abhängigkeitsanalysesystem wurde entwickelt, um aus der Erfahrung mit analysiertem Text auf Wortklassen und syntaktische Kombinationsregeln zu schließen. Die zum Bilden von Wortklassen verwendeten Merkmale sind die Tiefe im Abhängigkeitsbaum jedes Wortes, die Richtung seines Gouverneurs und die gleichen Merkmale für jeden seiner unmittelbaren Nachbarn. Syntaktische Kombinationsregeln zeigen die Beziehung eines Wortes zu seinem Gouverneur im Tiefenmuster des Satzes. Das System wurde an 400 elementaren englischen Grundsätzen getestet, darunter 300, die zuvor von Knowlton in einem anderen Lernparser aller 400 Sätze verwendet wurden. Nach Erfahrung mit 300 Sätzen war es in der Lage, mit 77-prozentiger Genauigkeit auf die nächsten 100 zu verallgemeinern. In kumulativen Lernversuchen nach den ersten 200 Sätzen hatte es eine durchschnittliche Wahrscheinlichkeit von 0,9, jeden neuen Satz, auf den es stieß, genau zu analysieren. Es wurde der Schluss gezogen, dass das System zum Erlernen des Parsens des Großteils des Grundenglischen geeignet ist, dass jedoch eine weitere Entwicklung erforderlich ist, bevor Schlussfolgerungen über seine Anwendung auf gewöhnliches Englisch gespeichert werden können. Das System ist betriebsbereit und auf dem Time-Shared-Computing-System von ARPA/SDC verfügbar."}
{"DOCID": "1171", "TEXT": "Ein Vergleich des Primal-Simplex- und des Primal-Dual-Algorithmus für die lineare Programmierung: Ein statistischer Vergleich des Primal-Dual- und des häufiger verwendeten Primal-Simplex-Algorithmus zur Lösung von Problemen der linearen Programmierung wurde unter der Annahme durchgeführt, dass mit einem vollständigen künstlichen Algorithmus begonnen wird Basis. Unter diesen Bedingungen zeigt die Primal-Dual-Methode eine statistisch signifikante Überlegenheit bei zufällig generierten Problemen. Über eine Regressionsanalyse wurde auch festgestellt, dass die relevanten Parameter bei der Bestimmung des Unterschieds in der Anzahl der Iterationen zwischen den Algorithmen nicht nur die Anzahl der Beschränkungen und die Anzahl der Variablen sind, sondern auch das Verhältnis der letzteren zur ersteren."}
{"DOCID": "1172", "TEXT": "Umwandlung von Entscheidungstabellen mit begrenztem Eintrag in Computerprogramme: Entscheidungstabellen sind nützlich, um einen Satz komplexer Entscheidungsregeln auf der Grundlage gegebener Sätze von Bedingungen zu beschreiben. Algorithmen, die die Tabellen effizient in Computerprogramme umwandeln können, werden die Nützlichkeit von Entscheidungstabellen für Computerbenutzer erweitern. Zwei solcher Algorithmen, basierend auf der Arbeit von M. S. Montalbano, werden hier beschrieben und erweitert, um Bindestriche und ELSE-Entscheidungsregeln zu handhaben. Der erste Algorithmus minimiert den für das resultierende Programm benötigten Computerspeicherplatz, der zweite minimiert die Computerlaufzeit. Beide lokalisieren während des Konvertierungsprozesses eventuelle Widersprüche oder Redundanzen zwischen den Regeln in einer Tabelle."}
{"DOCID": "1173", "TEXT": "Die Leistung eines Systems zur automatischen Segmentierung von Programmen innerhalb eines ALGOL-Compilers (GIER ALGOL): Der GIER ALGOL-Compiler verwendet ein automatisches System zur Abwicklung der Übertragungen von Programmsegmenten vom Trommelspeicher zum Kernspeicher zur Programmausführungszeit. Die Logik dieses Systems wird beschrieben. Die Leistung des Systems wird hauptsächlich auf der Grundlage von Ausführungszeiten in Bezug auf zwei spezifische Programme diskutiert. Diese Diskussion endet mit einer Bewertung der potenziellen Vorteile verschiedener Möglichkeiten zur Verbesserung des Systems."}
{"DOCID": "1174", "TEXT": "Inverse Permutation (Algorithmus 250 [G6])"}
{"DOCID": "1175", "TEXT": "Quickersort (Algorithmus 271 [M1])"}
{"DOCID": "1176", "TEXT": "Finden von Eigenvektoren durch Gaußsche Eliminierung (Algorithmus 270 [F2])"}
{"DOCID": "1177", "TEXT": "Determinantenauswertung (Algorithmus 269 [F3])"}
{"DOCID": "1178", "TEXT": "ALGOL 60 Reference Language Editor (Algorithmus 268 [R2])"}
{"DOCID": "1179", "TEXT": "PUFFT – The Purdue University Fast FORTRAN Translator: Es wird ein kernresidentes Compile-and-Go-System beschrieben, das für den IBM 7090/7094-Computer entwickelt wurde. In etwas mehr als der Hälfte des Kernspeichers von 32 KB bietet PUFFT einen Monitor für die Auftragssequenzierung, einen Übersetzer für die vollständige FORTRAN IV-Sprache, die FORTRAN-Subroutinenbibliothek, ein Eingabe-Ausgabe-System zur Verwendung zur Kompilierzeit und zur Ausführungszeit und eine ziemlich aufwändige Routine zum Schreiben von Diagnosenachrichten. Stapel von kleinen und mittelgroßen FORTRAN IV-Quellsprachenprogrammen werden mit sehr hohen Geschwindigkeiten verarbeitet. Die Sprachkompatibilität wurde aufrechterhalten, so dass Programme im PUFFT-System debuggt und dann in dem vom Hersteller gelieferten IBJOB-IBFTC-System neu kompiliert und ausgeführt werden können."}
{"DOCID": "1180", "TEXT": "AXLE: Eine axiomatische Sprache für String-Transformationen: AXLE ist eine Sprache, die für die Datenmanipulation entwickelt wurde. Daten, die in linearer Form in einem Arbeitsbereich angeordnet sind, werden gemäß einer Tabelle von Axiomen transformiert, die als Imperative bezeichnet werden. Eine Transformation besteht aus einer Übereinstimmungsprozedur, die entscheidet, wo ein Imperativ anwendbar ist, und einer Ersetzungsprozedur, die diesen Teil des Arbeitsbereichs modifiziert. Imperative werden in Übereinstimmung mit Definitionen symbolischer Begriffe angewendet, die systematisch in einer Behauptungstabelle dargestellt werden. Der Definitionsprozess umfasst den Spezialfall rekursiver Behauptungen. Mehrere vollständige Imperativprogramme werden gegeben, um einige Anwendungen der Sprache zu zeigen."}
{"DOCID": "1181", "TEXT": "Ein einfaches Datenübertragungssystem unter Verwendung des Bürotelefons: Es hat sich ein Verfahren zum direkten Übertragen von Daten eines Typs, der aus vielen Laborsituationen stammt, zu einem zentralen Computer entwickelt. Das Verfahren erfordert fast keine spezialisierte Ausrüstung und verwendet irgendein gewöhnliches Telefon auf einer \"Anruf\"-Basis. Gegenwärtige Anwendungen umfassen Herzleistungsberechnungen, Radioaktivitäts-Tracerstudien und neurophysiologische Zeitsequenzstudien von Nervenimpulsen."}
{"DOCID": "1182", "TEXT": "Kontextkorrelate der Synonymie: Es wurde eine experimentelle Bestätigung für die Hypothese erhalten, dass der Anteil von Wörtern, die den Kontexten von Wort A und den Kontexten von Wort B gemeinsam sind, eine Funktion des Grades ist, in dem A und B eine ähnliche Bedeutung haben. Die Formen der Funktionen weisen jedoch darauf hin, dass die Kontextähnlichkeit als Kriterium nur für die Erkennung von Wortpaaren mit sehr ähnlicher Bedeutung zuverlässig ist."}
{"DOCID": "1183", "TEXT": "Eine Anmerkung zur Verwendung eines digitalen Computers für mühsame Algebra und Programmierung: Ein spezieller Compiler wurde mit der FORTRAN II-Sprache geschrieben und ermöglichte das Schreiben sehr langer Programme durch den Computer. Das Verfahren basiert auf einer einfachen Verwendung von FORMAT-Anweisungen zum Generieren von maschinengeschriebenen Programmen."}
{"DOCID": "1184", "TEXT": "Ein schneller Speicherzuordner: Es wird ein schnelles Speicherbuchführungsverfahren beschrieben, das besonders für Listenstrukturoperationen und andere Situationen geeignet ist, die viele Größen von Blöcken beinhalten, die in Größe und Ort fest sind. Dieses Schema, das in LLLLLL oder L6 (Bell Telephone Laboratories Low-Level List Language) verwendet wird, stellt Blöcke von Computerregistern in mehreren verschiedenen Größen zur Verfügung: Die kleineren Blöcke werden durch sukzessives Halbieren größerer Blöcke erhalten, und die größeren Blöcke werden wiederhergestellt wenn ihre Teile gleichzeitig frei sind."}
{"DOCID": "1185", "TEXT": "Ein Programm zur Lösung des Pentomino-Problems durch die rekursive Verwendung von Makros: Es wird eine Codierungstechnik beschrieben, bei der bestimmte Makrobefehle Listen als Argumente erhalten und dadurch rekursiv verwendet werden. Die Diskussion deckt hauptsächlich ein Beispiel ab, in dem die Technik verwendet wird, um das Pentomino-Problem zu lösen – das Problem, 12 Pentominos ohne Überlappung in einen ebenen Bereich einzufügen, der aus 60 elementaren Quadraten besteht."}
{"DOCID": "1186", "TEXT": "Rekursive Lösung einer Klasse von kombinatorischen Problemen: Ein Beispiel: Kombinatorische Probleme, die die Auswahl von n Elementen aus einer Menge von m Elementen erfordern, können durch einen Rekursionsprozess gelöst werden, der analog zu dem für die Berechnung von Binomialkoeffizienten ist. Es werden mehrere spezifische Probleme analysiert, die allgemeine Technik dargelegt und ein ALGOL-Programm für eines der Probleme entwickelt."}
{"DOCID": "1187", "TEXT": "Hinweis zu einer ASCII-Oktal-Codetabelle (Standards)"}
{"DOCID": "1188", "TEXT": "Eine ALGOL-ähnliche Computerdesignsprache: Die Idee, eine Computerdesignsprache unter Verwendung einer ALGOL-ähnlichen Programmiersprache zu konstruieren, wird vorgestellt. Ein Computerdesigner kann von der Verwendung einer Designsprache auf einem höheren Niveau profitieren, genauso wie ein Computerbenutzer von einer Programmiersprache auf einem höheren Niveau profitieren kann. Die Zwecke und Anforderungen der Designsprache werden aufgezählt. Um die meisten Zwecke zu erreichen, muss ein Übersetzer einen Entwurf einer Computerlogik in einen Satz Boolescher Gleichungen übersetzen. Die Designsprache wird in Form von Vokabeln, Aussagen, Sequenzen und Mikroprogrammen präsentiert. Enthalten sind Beispiele für Bezeichner, Ausdrücke mit sowohl unären als auch binären Operatoren, Deklarationsanweisungen, Transferanweisungen, Endanweisungen, Austauschanweisungen, if-Anweisungen, do-Anweisungen, go to-Anweisungen, mehrere Sequenzen und ein Mikroprogramm."}
{"DOCID": "1189", "TEXT": "Zufällige Normalabweichung (Algorithmus 267 [G5])"}
{"DOCID": "1190", "TEXT": "Pseudo-Zufallszahlen (Algorithmus 266 [G5])"}
{"DOCID": "1191", "TEXT": "Vorrangfunktionen finden (Algorithmus 265 [L2])"}
{"DOCID": "1192", "TEXT": "Interpolation in einer Tabelle (Algorithmus 264 [E1])"}
{"DOCID": "1193", "TEXT": "Gomory 1 (Algorithmus 263 [H])"}
{"DOCID": "1194", "TEXT": "Einrichtung des ACM-Speichers und Prinzipien des IR-Systems für seinen Betrieb: Die Geschichte der Einrichtung des ACM-Speichers an der Moore School, University of Pennsylvania, wird kurz rezensiert. Zwei Prinzipien werden bei der Bereitstellung von Informationsdiensten als vorrangig dargestellt: (1) leichte Zugänglichkeit zu den Informationsdateien durch Benutzer, die mit der Dateiorganisation nicht vertraut sind, und (2) Wert des Dienstes, der die Benutzerkosten übersteigt. Diese Prinzipien dienen als Richtlinien für die Mechanisierung des ACM-Repository. Die Hauptmerkmale des Informationssystems sind der direkte Benutzerzugriff über die Online-Fernschreiberkonsole, der direkte Benutzerzugriff auf alle Details der Systemorganisation, das uneingeschränkte und erweiterbare Suchvokabular, der Benutzerzugriff über viele Facetten der Dokumentenindizierung und die stochastische Suche über den verknüpften Index Begriffe und andere Dateibeziehungen. Der erste Beitrag zum ACM-Repository bestand aus 315 Dokumenten, die sich hauptsächlich auf die frühe Forschung zu Compilern bezogen. Diese Dokumente wurden katalogisiert und indiziert, und der Katalog soll in Computing Reviews erscheinen. Das Indizierungssystem wird detailliert beschrieben. Der Hauptkatalog dient der Beschreibung der Dokumente, invertierte Listen werden vom Repository-System zur Recherche durch die Konzeptkoordination bereitgestellt."}
{"DOCID": "1195", "TEXT": "UPLIFTS-Lineardatei-Tandemsystem der Universität Pittsburgh: Eine Reihe von Computerprogrammen wurde entwickelt und ist nun betriebsbereit, um das lineare Dateisystem der National Aeronautics and Space Administration auf einem kombinierten Datenverarbeitungssystem IBM 1401-7090 zu verarbeiten. Die Programme sind insofern bemerkenswert, als sie logische Datensätze fester Länge und Blöcke fester Länge aus Quelldaten variabler Länge erstellen und die Ausgabe zur Optimierung der Verarbeitung auf dem IBM 7090-System formatieren. Die Programme sind vollständig selbstüberprüfend und testen sowohl die Gültigkeit als auch die Genauigkeit der Eingabematerialien, wie sie von der National Aeronautics and Space Administration bereitgestellt werden."}
{"DOCID": "1196", "TEXT": "Anwendungen von Differentialgleichungen in der allgemeinen Problemlösung: Eine große Klasse von Problemen, die zur digitalen Computerverarbeitung führen, kann in Begriffen der numerischen Lösung von Systemen gewöhnlicher Differentialgleichungen formuliert werden. Zur Lösung solcher Systeme existieren leistungsfähige Methoden. Eine gute Allzweckroutine zur Lösung solcher Systeme liefert ein mächtiges Werkzeug zur Bearbeitung vieler Probleme. Dies gilt im Hinblick auf die einfache Programmierung, die einfache Fehlersuche und die Minimierung der Computerzeit. Eine Reihe von Beispielen wird ausführlich besprochen."}
{"DOCID": "1197", "TEXT": "Finden von Nullstellen eines Polynoms durch den Q-D-Algorithmus: Ein von H. Rutishauser entwickeltes Verfahren, das gleichzeitig alle Nullstellen eines Polynoms findet, wurde an einer Reihe von Polynomen mit reellen Koeffizienten getestet. Dieses langsam konvergierende Verfahren (Quotient-Difference (Q-D)-Algorithmus) liefert Startwerte für einen Newton- oder einen Bairstow-Algorithmus für eine schnellere Konvergenz. Notwendige und hinreichende Bedingungen für die Existenz des Q-D-Schemas sind nicht vollständig bekannt; es kann jedoch zu einem Ausfall kommen, wenn Nullen gleiche oder nahezu gleiche Größenordnungen haben. In den meisten Fällen wurde Erfolg erzielt, wobei die Fehler normalerweise auf die gleiche Schwierigkeit zurückzuführen waren. In einigen Fällen kann Computerrundung zu Fehlern führen, die das Schema verderben. Selbst wenn der Q-D-Algorithmus nicht alle Nullen liefert, findet er normalerweise einen Großteil davon."}
{"DOCID": "1198", "TEXT": "Lösung eines Problems in der Concurrent Programming Control: Eine Anzahl weitgehend unabhängiger sequentiell-zyklischer Prozesse mit eingeschränkten Kommunikationsmöglichkeiten untereinander kann so gestaltet werden, dass zu jedem Zeitpunkt nur einer von ihnen im \"kritischen Abschnitt\" beschäftigt ist \" seines Zyklus."}
{"DOCID": "1199", "TEXT": "Ein Rechenzentrums-Simulationsprojekt: Heutige Rechenzentren basieren auf sich schnell ändernden Technologien von Hardware- und Softwaresystemen. Es ist daher schwierig, Entscheidungen auf Erfahrung zu stützen; In den meisten Fällen sind die Vorteile vergleichbarer Erfahrungen für eine bestimmte Problemsituation nicht verfügbar. In dieser Arbeit wird ein mathematisches Modell des Lockheed Central Computer Center formuliert, das den Betrieb eines Rechenzentrums in Bezug auf Informationsnetze, Entscheidungsprozesse und Steuerungsfunktionen beschreibt. Mit diesem Modell durchgeführte Experimente, die Ergebnisse der Experimente und die Anwendung der Ergebnisse werden diskutiert."}
{"DOCID": "1200", "TEXT": "Über umkehrbare Subroutinen und Computer, die rückwärts laufen: Es wird ein Computerdesign beschrieben, das es erlaubt, Subroutinen sowohl rückwärts als auch vorwärts auszuführen, entweder mit unveränderten Anweisungen oder ersetzt durch konjugierte Anweisungen. Es wird gezeigt, dass mit diesem Konzept eine Reihe neuer Subroutinentypen mit eher ungewöhnlichen Eigenschaften entwickelt werden können. Da diese Eigenschaften analog zu bestimmten Matrizenoperationen sind, wird für ihre Klassifizierung eine parallele Nomenklatur vorgeschlagen."}
{"DOCID": "1201", "TEXT": "Generierung von Permutationen in lexikografischer Reihenfolge (Algorithmus 202 [G6])"}
{"DOCID": "1202", "TEXT": "Normaler Zufall (Algorithmus 200 [G5])"}
{"DOCID": "1203", "TEXT": "Normdey (Algorithmus 121 [G5])"}
{"DOCID": "1204", "TEXT": "Zeichenstruktur und Zeichenparitätssinn für Serial-by-Bit-Datenkommunikation im amerikanischen Standardcode für den Informationsaustausch (vorgeschlagener amerikanischer Standard)"}
{"DOCID": "1205", "TEXT": "Ein Undergraduate-Programm in Informatik – vorläufige Empfehlungen"}
{"DOCID": "1206", "TEXT": "Die Selbstbeurteilungsmethode der Kurvenanpassung: Eine computerorientierte Methode zur Verarbeitung und Übermittlung numerischer Daten wird beschrieben. Die Instrumentenzuverlässigkeitsfaktoren (IRF), die genau die Zuverlässigkeitsgrenzen jeder gemessenen Information definieren, werden verwendet, um den maximal zulässigen Fehler (MPE) zu berechnen, der jedem Wert jeder Ordinate zugeordnet ist. Das Selbstbeurteilungsprinzip (SJP) wird verwendet, um falsche Informationen zu verwerfen und Mittelwerte der Parameter und ihrer MPEs in Bezug auf den IRF zu berechnen. Datenkompatibilitätstests mit einer beliebigen Anzahl verschiedener Gleichungen können schnell durchgeführt werden. Ansonsten werden hartnäckige Probleme leicht gelöst, und das Design vieler Experimente wird stark vereinfacht. Die rechnerischen und mathematischen Techniken, die verwendet werden, um Verzerrungen im SJP zu reduzieren, werden diskutiert. Unzulänglichkeiten in den statistischen und grafischen Methoden der Kurvenanpassung werden festgestellt."}
{"DOCID": "1207", "TEXT": "Bemerkungen zur Simulation Boolescher Funktionen"}
{"DOCID": "1208", "TEXT": "Simulation der Computerlogik durch Fortran-Arithmetik"}
{"DOCID": "1209", "TEXT": "Negativ- und Null-Indizes in Fortran II-Programmierung für IBM 1620"}
{"DOCID": "1210", "TEXT": "Dateiverarbeitung in FORTRAN: Dieser Hinweis beschreibt einige FORTRAN-Subroutinen, um die Verarbeitung von Banddateien zu erleichtern. Sie erlauben die symbolische Benennung von Informationsdateien, ohne die Idee der Einfachheit des gelegentlichen wissenschaftlichen Programmierers zu verletzen. Es werden einige Kommentare zur zweijährigen Verwendung dieser Subroutinen gegeben."}
{"DOCID": "1211", "TEXT": "Hinweis zur Speicherung von Strings: Es wird ein Verfahren zur Speicherung von Strings beschrieben, das Blöcke unbestimmter Größe verwendet und daher vollständig dynamisch ist. Seine Beziehung zu ähnlichen Schemata wird diskutiert."}
{"DOCID": "1212", "TEXT": "Nichtlineare Extrapolation und Zweipunkt-Grenzwertprobleme: Es wird vorgeschlagen, dass die Konvergenzeigenschaften des üblichen sukzessiven Approximationsschemas von Picard durch die Verwendung von nichtlinearen Extrapolationstechniken verbessert werden können. Ein Zahlenbeispiel ist angegeben."}
{"DOCID": "1213", "TEXT": "Dynamische Formatspezifikationen: Die Verwendung und Implementierung von zwei neuen FORTRAN-Formatumwandlungen werden diskutiert. Diese Formattypen geben dem FORTRAN-Programmierer die Kontrolle über Eingabe-/Ausgabespezifikationen zur Ausführungszeit."}
{"DOCID": "1214", "TEXT": "Einige Experimente zur algebraischen Manipulation durch Computer: Eine Reihe von Subroutinen, um algebraische Manipulationen auf dem IBM 7094-Computer zu ermöglichen, wurde in einen Listenprozessor, SLIP, geschrieben. Eine Reihe von vier Problemen mit zunehmendem Schwierigkeitsgrad wurde unter Verwendung dieser Routinen gelöst."}
{"DOCID": "1215", "TEXT": "Einige im ALCOR ILLINOIS 7090 verwendete Techniken: Ein ALGOL-Compiler wurde von der ALCOR-Gruppe für den IBM 7090 geschrieben. Einige wenig bekannte, aber wichtige Techniken beim Compiler-Schreiben werden zusammen mit organisatorischen Details dieses Compilers beschrieben. Timing-Schätzungen und ein Hinweis auf Compiler-Anforderungen werden ebenfalls gegeben."}
{"DOCID": "1216", "TEXT": "Symbolische Ableitungen ohne Listenverarbeitung, Subroutinen oder Rekursion: Es wurde eine Routine entwickelt, die die symbolische Ableitung einer absolut stetigen Elementarfunktion einer oder mehrerer Variablen berechnet und ausgibt. Listenverarbeitungssprachen werden nicht verwendet. Die Kettenregel wird angewendet und das Ergebnis bearbeitet, um Ergebnisse zu erzielen, die so elegant und effizient sind wie diejenigen, die durch manuelle Berechnung erhalten werden. Eine Teilmenge kann in einen Formelübersetzer eingebettet werden, um einen Differenzierungsoperator in eine \"algebraische\" Programmiersprache einzuführen."}
{"DOCID": "1217", "TEXT": "Abbildung von Partitionen in ganze Zahlen (Algorithmus 264 [A1])"}
{"DOCID": "1218", "TEXT": "Partitionsgenerator (Algorithmus 263 [A1])"}
{"DOCID": "1219", "TEXT": "Anzahl eingeschränkter Partitionen von N (Algorithmus 262 [A1])"}
{"DOCID": "1220", "TEXT": "9-J-Symbole (Algorithmus 261 [Z])"}
{"DOCID": "1221", "TEXT": "6-J-Symbole (Algorithmus 260 [Z])"}
{"DOCID": "1222", "TEXT": "Legendre-Funktionen für Argumente größer als eins (Algorithmus 259 [S16])"}
{"DOCID": "1223", "TEXT": "Hochgeschwindigkeitskompilierung von effizientem Objektcode: Ein Compiler mit drei Durchgängen mit den folgenden Eigenschaften wird kurz beschrieben: Die letzten beiden Durchgänge scannen eine Zwischensprache, die durch den vorhergehenden Durchlauf erzeugt wurde, im Wesentlichen in der umgekehrten Reihenfolge, in der sie erzeugt wurde, so dass die Der erste Durchgang ist der einzige, der die umfangreiche problemorientierte Eingabe lesen muss. Die doppelte Abtastung, eine in jeder Richtung, die von den ersten beiden Durchgängen durchgeführt wird, ermöglicht es dem Compiler, lokal konstante Ausdrücke und rekursiv berechenbare Ausdrücke aus Schleifen zu entfernen und den wichtigen Teil der Erkennung gemeinsamer Teilausdrücke zu erledigen. Eine Optimierung wie die effektive Verwendung von Indexregistern wird, obwohl sie ebenso wichtig ist, nicht diskutiert, da der Objektcode, der am effizientesten wäre, stark maschinenabhängig ist. Die Diskussion bezieht sich auf eine FORTRAN-ähnliche Sprache, obwohl die Technik auf die meisten algebraischen Sprachen anwendbar ist."}
{"DOCID": "1224", "TEXT": "Bestimmung einer Rechenzentrumsumgebung: Es wird eine Untersuchung beschrieben, bei der mehrere allgemein nicht verfügbare Parameter ermittelt werden, die eine Rechenzentrumsumgebung beschreiben. Die tatsächliche Datenerhebung und -reduzierung wird beschrieben, und die Ergebnisse eines Monats dieser Erhebung werden tabelliert und zusammengefasst."}
{"DOCID": "1225", "TEXT": "Der prädiktive Analysator und eine Pfadeliminierungstechnik: Einige der charakteristischen Merkmale eines prädiktiven Analysators, eines Systems zur syntaktischen Analyse, das jetzt in Harvard on und IBM 7094 in Betrieb ist, werden beschrieben. Die Vor- und Nachteile des Systems werden im Vergleich zu denen eines unmittelbaren Bestandteilanalysators diskutiert, der bei der RAND Corporation mit Robinsons englischer Grammatik entwickelt wurde. Darüber hinaus wird eine neue Technik zur Eliminierung wiederholter Pfade für einen prädiktiven Analysator beschrieben, der nun Effizienz sowohl in der Verarbeitungszeit als auch im Kernspeicherbedarf beanspruchen kann."}
{"DOCID": "1226", "TEXT": "Die Organisation strukturierter Dateien: Eine Datendatei ist ein integraler Bestandteil eines Datenverarbeitungssystems. In vielen Systemen kann die Auswahl einer Organisation für die Daten in der Datei entscheidend für die Betriebseffizienz des Systems sein. Dieses Dokument stellt dem Systemdesigner eine Informationsquelle zur Verfügung, die zehn Techniken beschreibt, die zum Organisieren strukturierter Daten eingesetzt werden können. Die Eigenschaften der beschriebenen Organisationen sind anwendungsunabhängig, wodurch der Entwickler eine Referenz erhält, die es ihm ermöglicht, die Anzahl der Dateiorganisationen zu begrenzen, die er für sein System berücksichtigen muss."}
{"DOCID": "1227", "TEXT": "Transport (Algorithmus 258 [H])"}
{"DOCID": "1228", "TEXT": "Baumsortierung 3 (Algorithmus 245 [M1])"}
{"DOCID": "1229", "TEXT": "Zufällige Permutation (Algorithmus 235 [G6])"}
{"DOCID": "1230", "TEXT": "Methode zur Silbentrennung am Ende einer gedruckten Zeile: Als Ergebnis der Anwendung mehrerer allgemeiner Regeln wird eine Beschreibung einer Silbentrennungsmethode präsentiert. Die von der Routine berücksichtigten Zeichensätze und das Verfahren werden kurz umrissen."}
{"DOCID": "1231", "TEXT": "Peephole-Optimierung: Redundante Anweisungen können während der letzten Stufe der Kompilierung verworfen werden, indem eine einfache Optimierungstechnik verwendet wird, die als Peephole-Optimierung bezeichnet wird. Das Verfahren wird beschrieben und es werden Beispiele gegeben."}
{"DOCID": "1232", "TEXT": "Darstellung des Standard-ECMA-7-Bit-Codes in Lochkarten (ECMA-Standard)"}
{"DOCID": "1233", "TEXT": "Konventionen für die Verwendung von Symbolen bei der Erstellung von Flussdiagrammen für Informationsverarbeitungssysteme (ein Standard-Arbeitspapier): Dieses Dokument soll einen Überblick über die verschiedenen Konventionen geben, die für die Verwendung von Flussdiagrammen für Informationsverarbeitungssysteme in Betracht gezogen werden. Die Konventionen werden auf die Verwendung der Symbole angewendet, die in den vorgeschlagenen American Standard Flowchart-Symbolen erscheinen, und nicht auf die Symbole an sich."}
{"DOCID": "1234", "TEXT": "Die Struktur eines weiteren ALGOL-Compilers: Eine Hochgeschwindigkeits-\"Top-Down\"-Methode der Syntaxanalyse, die das \"Backup\" der Quellzeichenfolge vollständig eliminiert, wurde in einer praktischen Makrosprache implementiert. Eine Simulationstechnik zur Kompilierzeit der Verwendung eines herkömmlichen Laufzeitstapels ermöglicht die Generierung von Code für Ausdrücke, die Speicherungen, Abrufe und Stapelzeigerbewegungen zur Laufzeit minimiert, während Rekursion und Nebeneffekte von Prozeduren richtig behandelt werden. Blockstruktur und Rekursion werden ohne die Notwendigkeit interpretierender Methoden zur Laufzeit gehandhabt. Das \"Kontextproblem\" bei der Übergabe von \"namentlich aufgerufenen\" Parametern an rekursive Prozeduren wird in einer Weise gelöst, die es erlaubt, die gängigen Fälle von einfachen Ausdrücken und Array-Bezeichnern besonders effizient zu behandeln."}
{"DOCID": "1235", "TEXT": "A Stochastic Approach to the Grammatical Coding of English: Ein Computerprogramm wird beschrieben, das jedes Wort in einem englischen Text seiner Formklasse oder Wortart zuordnet. Das Programm arbeitet mit relativ hoher Geschwindigkeit auf nur begrenztem Speicherplatz. Etwa die Hälfte der Wortereignisse in einem Korpus werden durch die Verwendung eines kleinen Wörterbuchs von Funktionswörtern und häufig vorkommenden lexikalischen Wörtern identifiziert. Einige Suffixtests und logische Entscheidungsregeln werden verwendet, um zusätzliche Wörter zu codieren. Schließlich werden die verbleibenden Wörter der einen oder anderen Klasse auf der Grundlage der wahrscheinlichsten Formklassen zugeordnet, die in den bereits identifizierten Kontexten auftreten. Die als Grundlage für diese Codierung verwendeten bedingten Wahrscheinlichkeiten wurden empirisch aus einem separaten handcodierten Korpus abgeleitet die Ergebnisse."}
{"DOCID": "1236", "TEXT": "Das SMART Automatic Document Retrieval System – Eine Illustration: Es wird ein vollautomatisches Dokumenten Retrieval System beschrieben, das auf dem IBM 7094 arbeitet. Das System zeichnet sich dadurch aus, dass mehrere hundert verschiedene Methoden zur Analyse von Dokumenten und Suchanfragen zur Verfügung stehen. Dieses Feature wird im Suchprozess genutzt, indem die genaue Abfolge der Operationen zunächst unbestimmt bleibt und die Suchstrategie an die Bedürfnisse der einzelnen Benutzer angepasst wird. Das System wird nicht nur verwendet, um eine reale Betriebsumgebung zu simulieren, sondern auch, um die Wirksamkeit der verschiedenen verfügbaren Verarbeitungsmethoden zu testen. Bisher erhaltene Ergebnisse scheinen darauf hinzudeuten, dass man sich im Allgemeinen auf eine gewisse Kombination von Analyseverfahren verlassen kann, um die gewünschten Informationen zu erhalten. Eine typische Suchanfrage wird im vorliegenden Report exemplarisch zur Veranschaulichung von Systemabläufen und Auswertungsverfahren verwendet."}
{"DOCID": "1237", "TEXT": "Umsetzung von Entscheidungstabellen in Computerprogramme: Mehrere Übersetzungsverfahren zur Umsetzung von Entscheidungstabellen in Programme werden vorgestellt und anschließend hinsichtlich Speicherbedarf, Ausführungszeit und Kompilierzeit bewertet. Die Prozeduren sind wertvoll als Anleitungen zum Handcodieren oder als Algorithmen für einen Compiler. Es werden sowohl eingeschränkte als auch erweiterte Tische analysiert. Neben der Tabellenanalyse wird die Natur tabellenorientierter Programmiersprachen und Features diskutiert. Es wird vorausgesetzt, dass der Leser mit der Natur von Entscheidungstabellen und herkömmlichen Definitionen vertraut ist."}
{"DOCID": "1238", "TEXT": "Eine Technik für integrierte Berichte aus einem Multi-Run-System: Die Anforderungen an ein Anforderungsbuchhaltungssystem für die San Francisco Overseas Supply Agency (OSA) umfassten Ausnahmeberichte an die OSA selbst. Die gleichzeitige Erfüllung der Meldepflicht und der Rechnungslegungspflichten führte zu konkreten Problemen im Systemdesign, insbesondere bei der Handhabung der Meldefunktion. Eine praktikable und zufriedenstellende Lösung wurde entwickelt, indem das Basissystem um zwei maßgeschneiderte Serviceläufe für die Berichtserstellung erweitert wurde. Diese beiden Läufe ermöglichten ein endgültiges System, das leichter zu debuggen, zu warten, effizient in der Produktion war und auf die sich ändernden Anforderungen von OSA reagierte."}
{"DOCID": "1239", "TEXT": "Graycode (Algorithmus 246 [Z])"}
{"DOCID": "1240", "TEXT": "Transport (Algorithmus 258 [H])"}
{"DOCID": "1241", "TEXT": "Havie Integrator (Algorithmus 257 [D1])"}
{"DOCID": "1242", "TEXT": "Modifiziertes Graeffe-Verfahren (Algorithmus 256 [C2])"}
{"DOCID": "1243", "TEXT": "Testen des Verständnisses des Unterschieds zwischen Call by Name und Call by Value in ALGOL 60"}
{"DOCID": "1244", "TEXT": "Bit-Manipulation in der Fortran-Sprache"}
{"DOCID": "1245", "TEXT": "Ein Fortran-n-Ary-Zähler"}
{"DOCID": "1246", "TEXT": "Tief verschachtelte Iterationen"}
{"DOCID": "1247", "TEXT": "Eine Betriebsumgebung für dynamisch-rekursive Computerprogrammiersysteme: In diesem Dokument wird eine kurze nichttechnische Einführung in OEDIPUS gegeben, ein Computerprogrammiersystem, das als Betriebsumgebung für dynamische und/oder rekursive Programme und Programmiersysteme dienen kann. Zu den verfügbaren Diensten gehören die dynamische Zuweisung von Speicher für zusammenhängende Blöcke beliebiger Größe, Ein- und Ausgabe für eine Hierarchie von Datentypen, eine öffentliche Pushdown-Liste für die automatische rekursive Programmierung, ein rudimentärer Compiler für die Unterprogrammkommunikation und Buchhaltung sowie Debugging-Hilfen."}
{"DOCID": "1248", "TEXT": "Über die automatische Vereinfachung von Computerprogrammen: In diesem Aufsatz wird das Problem vorgestellt, ein Programm zu schreiben, das jedes andere Programm untersucht und solche Vereinfachungen an ihm durchführt, die allein aus der Form des Argumentprogramms erkennbar sind, ohne zu wissen, was es ist soll tun."}
{"DOCID": "1249", "TEXT": "Aufgezeichnetes Magnetband für den Informationsaustausch (200 CPI, NRZI) (nach dem überarbeiteten vorgeschlagenen amerikanischen Standard)"}
{"DOCID": "1250", "TEXT": "Graphische Symbole für die Problemdefinition und -analyse – ein Standardarbeitspapier"}
{"DOCID": "1251", "TEXT": "American Standard und IFIP/ICC Vocabularies im Vergleich: Das „Proposed American Standard Vocabulary of Information Processing“ und das „IFIP/ICC Vocabulary of Terms Used in Information Processing“ werden analysiert und verglichen."}
{"DOCID": "1252", "TEXT": "Symbolische Notationen für statistische Tabellen und ein Ansatz zum automatischen Systemdesign: Die Erstellung statistischer Tabellen ist eine wichtige Funktion der Datenverarbeitungssysteme einiger Organisationen, und eine symbolische Notation für die Beschreibung von Tabellen hat sich als nützliche Hilfe bei der Dokumentation erwiesen . Eine solche Notation stellt auch den ersten Schritt bereit, um die Automatik zu einem mühsamen und zeitaufwändigen Teil des Systementwurfs und der Programmierung in vielen Computeranwendungen zu machen. Eine Notation wird beschrieben und es werden Vorschläge zur Umsetzung des übergeordneten Ziels gemacht."}
{"DOCID": "1253", "TEXT": "QUIKSCRIPT – eine SIMSCRIPT-ähnliche Sprache für den G-20: QUIKSCRIPT ist eine Simulationssprache, die auf SIMSCRIPT basiert und vollständig in einer algebraischen Sprache, 20-GATE, programmiert ist. Die QUIKSCRIPT-Sprache, ihre interne Implementierung und die Hauptunterschiede zwischen QUIKSCRIPT und SIMSCRIPT werden vorgestellt. Dieses Papier ist kein Programmierleitfaden für die Sprache, sondern ein Versuch, ihre Geschmacksrichtung zu präsentieren. Eine kurze Beschreibung von SIMSCRIPT ist ebenso enthalten wie eine ausreichende Beschreibung von 20-GATE, um dieses Material für den mit algebraischen Sprachen vertrauten Leser verständlich zu machen."}
{"DOCID": "1254", "TEXT": "Das Iterationselement: Eine kürzlich hinzugefügte MAD-Sprache hat die Iterationsstruktur der MAD THROUGH-Anweisung (entsprechend der ALGOL for-Anweisung und der FORTRAN DO-Anweisung) innerhalb von Ausdrücken verfügbar gemacht."}
{"DOCID": "1255", "TEXT": "Ein Verfahren zur Datenlistenverarbeitung mit Anwendung auf die EEG-Analyse: Es wird eine Reihe von Subroutinen diskutiert, die dazu bestimmt sind, bei der Programmierung von Berechnungen auf indizierten Zahlenlisten unter Verwendung von Maschinensprache oder einem symbolischen Assemblierungssystem zu helfen. Die am häufigsten durchgeführten Listenoperationen werden skizziert und logisch in fünf Gruppen eingeteilt. Als Beispiel wird die Berechnung der spektralen Leistungsdichte aus der Autokovarianzfunktion für eine Klasse von EEG-Signalen diskutiert."}
{"DOCID": "1256", "TEXT": "Dynamische Variablenformatierung"}
{"DOCID": "1257", "TEXT": "DEBUG – Eine Erweiterung zu aktuellen Online-Debugging-Techniken: Ein Verfahren zum Online-Debuggen in Assemblersprache, das mehrere der mit diesem Prozess charakteristischen Buchhaltungsaufgaben stark vereinfacht, wurde entwickelt und in einem Programm für den UNIVAC M-460-Computer implementiert in den Cambridge Research Laboratories der Air Force. Mit diesem Programm kann ein Online-Benutzer (in symbolischer Assemblersprache) eine beliebige Anzahl von Zeilen an jedem beliebigen Punkt seines zuvor zusammengestellten Programms im Kern einfügen oder löschen, wobei der Rest des Programms entsprechend verschoben wird."}
{"DOCID": "1258", "TEXT": "Ein erweitertes Arithmetikpaket: Auf vielen Gebieten, zum Beispiel der algebraischen Zahlentheorie, muss mit einer Genauigkeit gerechnet werden, die die normale Hardwarekapazität der meisten Maschinen übersteigt. In solchen Fällen bietet ein erweitertes Arithmetikpaket eine umfassende und einfach zu verwendende Möglichkeit, solche Arithmetik durchzuführen. Ein solches Paket wurde für den IBM 7090 codiert. Bei der Erörterung der allgemeinen Probleme, die mit dem Entwurf eines erweiterten arithmetischen Pakets verbunden sind, wird speziell auf dieses Programm Bezug genommen."}
{"DOCID": "1259", "TEXT": "Anwendungen von Binärzahlen in Computerroutinen: Eine Binärzahl kann als alternative Ausdrucksform für entweder eine Reihe von Buchstaben oder eine Dezimalzahl betrachtet werden. Es gibt dann drei äquivalente Ausdrücke, die leicht ineinander übersetzbar sind und jeweils unterschiedliche Eigenschaften haben. Es werden vier Beispiele gegeben, in denen die Form eines Ausdrucks in einen äquivalenten Ausdruck geändert wird, um Platz zu sparen oder Kraft zu gewinnen."}
{"DOCID": "1260", "TEXT": "Kleinste-Quadrate-Analyse von Resonanzspektren auf kleinen Computern: Das Problem der Analyse von Daten aus einem Mössbauer-Effekt-Experiment wird diskutiert. Durch die Verwendung des Cut-Step-Verfahrens für die Konvergenz und durch das Auferlegen physikalischer Beschränkungen für die funktionale Form der Berechnung ist es möglich, die Analyse auf einem kleinen Computer durchzuführen. Die Analyse wurde auf einem IBM 1410-Computer mit einem 40.000-BCD-Kernspeicher durchgeführt."}
{"DOCID": "1261", "TEXT": "Modellierung und Simulation digitaler Netzwerke: Die Simulation digitaler Netzwerke auf einem digitalen Computer bietet dem Ingenieur ein effektives Mittel zur Analyse von zeitquantisiertem logischem Verhalten. Das digitale Netzwerk wird als Satz zeitabhängiger oder zeitunabhängiger Boolescher Transformationen modelliert; wobei jede Transformation die Eingabe-Ausgabe-Beziehung eines Modellelements beschreibt, das den Netzwerkmodus umfasst. Die Einfachheit der Verwendung des FORTRAN IV-Programmiersystems als digitaler Netzwerksimulator wird diskutiert und illustriert. Diese Einfachheit ergibt sich aus einer gemeinsamen Modellierungstechnik, die auf kombinatorische und sequentielle digitale Netzwerke anwendbar ist, und einem systematischen Programmieransatz."}
{"DOCID": "1262", "TEXT": "Anweisungen in prozedurorientierter Sprache zur Erleichterung der parallelen Verarbeitung: Es werden zwei Anweisungen vorgeschlagen, die es einem Programmierer ermöglichen, der in einer prozedurorientierten Sprache schreibt, Programmabschnitte anzugeben, die parallel ausgeführt werden sollen. Die Aussagen sind DO TOGETHER und HOLD. Diese dienen zum Teil als Klammern beim Einrichten eines Bereichs des Parallelbetriebs und zum Teil zum Definieren jedes parallelen Pfads innerhalb dieses Bereichs. DO TOGETHERs können verschachtelt werden. Die Anweisungen sollten besonders effektiv für die Verwendung mit Computergeräten sein, die in der Lage sind, einen gewissen Grad an Rechen-Rechen-Überlappung zu erreichen."}
{"DOCID": "1263", "TEXT": "Metasprache und Syntaxspezifikation: Zwei Metasprachen werden beschrieben, eine ausreichend für die Tabellenspezifikation der ALGOL-Syntax, die andere mit zusätzlichen Metaoperatoren, die angemessen sind und für die formale Tabellenbeschreibung von Basic FORTRAN verwendet werden."}
{"DOCID": "1264", "TEXT": "BLNSYS-A 1401 Betriebssystem mit Braille-Fähigkeiten: BLNSYS ist ein Betriebssystem, das für einen 4K 1401 mit gemeinsamen optionalen Funktionen und zwei angeschlossenen Bandlaufwerken entwickelt wurde. Die gedruckte Ausgabe dieses Systems oder von ausführenden Programmen kann entweder in Englisch oder in Blindenschrift erfolgen. Obwohl dieses System für eine kleine Maschine mit minimaler Peripherieausrüstung geschrieben wurde, können Aufträge gestapelt werden, so dass die Kartenhandhabung und die verlorene Verarbeitungszeit auf ein Minimum reduziert werden. Dieses System führt einige oder alle der folgenden benutzerspezifischen Funktionen aus: SPS-Quelldecks zusammenstellen, Post-Liste erstellen, verdichtete oder nicht verdichtete Objektdecks erzeugen, Benutzerprogramm ausführen, Karteneingaben in ein Programm auflisten, gestanzte Ausgaben auflisten, einen Speicherauszug bereitstellen, ausführen ein Programm, das zur Ausführung als unkomprimiertes Objektdeck unter Debugging-Trace-Steuerung, Karte-zu-Braille-Konvertierung, Braille-Auflistungen der 7040 IBSYS-Stapelausgabe und Aktualisierung oder Duplizierung des Systembandes selbst übermittelt wird. Eingabe-Ausgabe-Subroutinen sind ebenfalls in dem System enthalten."}
{"DOCID": "1265", "TEXT": "Zur relativen Effizienz kontextfreier Grammatikerkenner: Eine Reihe unterschiedlicher Erkennungsverfahren, die zum Analysieren von Sätzen in Bezug auf eine kontextfreie Grammatik vorgeschlagen wurden, werden in diesem Artikel anhand eines gemeinsamen Geräts beschrieben. Jede Prozedur wird definiert, indem ein Algorithmus zum Erhalten eines nichtdeterministischen Turing-Maschinen-Erkenners angegeben wird, der äquivalent zu einer gegebenen kontextfreien Grammatik ist. Die Formalisierung der Turing-Maschine wurde gewählt, um eine besonders einfache Beschreibung der betrachteten Parsing-Verfahren zu ermöglichen. Es wurde versucht, die Erkennungseffizienzen für die definierten Verfahren zu vergleichen. Für einige einfache Grammatiken und Sätze wurde ein formaler Vergleich durchgeführt. Ein empirischer Vergleich der Erkennung von realistischeren Programmiersprachen wie LISP und ALGOL wurde mit Hilfe eines Programms durchgeführt, das die Turing-Maschine auf dem Univac M-460-Computer simuliert. Mehrere Algorithmen zum Erzeugen von Grammatiken, die einer gegebenen kontextfreien Grammatik äquivalent sind, wurden in Betracht gezogen, und die Steigerung der Erkennungseffizienz, die sie bieten, wurde empirisch untersucht."}
{"DOCID": "1266", "TEXT": "Überlegungen zum Zweck der FORTRAN-Standardisierung (Anhänge zum ASA FORTRAN-Standard)"}
{"DOCID": "1267", "TEXT": "Leistung von Systemen, die für die Datenübertragung verwendet werden Übertragungsrate von Informationsbits - Ein ASA-Tutorial-Standard: Informationsdurchsatz als Merkmal der Systemleistung wird diskutiert. Diese Erörterung umfasst die relevanten Aspekte der Informationsübertragung, der Bestimmung der Übertragungsrate von Informationsbits (TRIB), der Restfehler und der Standardmessbedingungen. Das Papier präsentiert auch eine geordnete Anordnung von Merkmalen und Parametern, die den Informationsdurchsatz beeinflussen, sowie einige Beispiele für Verfahren zur Bestimmung einer Durchsatzrate in Bezug auf TRIB. Es kommt zu dem Schluss, dass ein Leistungsmerkmal, das die Informationsrate beinhaltet, am besten als TRIB in Verbindung mit der Restfehlerrate ausgedrückt werden kann."}
{"DOCID": "1268", "TEXT": "Logarithmus einer komplexen Zahl (Algorithmus 243 [B3])"}
{"DOCID": "1269", "TEXT": "Berechnung von Fourier-Koeffizienten (Algorithmus [C6])"}
{"DOCID": "1270", "TEXT": "Zur ALGOL-Bildung: Automatische Benotungsprogramme: Zwei ALGOL-Benotungsprogramme werden für die Computerbewertung von ALGOL-Programmen von Schülern vorgestellt. Einer ist für ein Anfängerprogramm; es liefert Zufallsdaten und prüft Antworten. Die andere liefert einen forschenden Test der Zuverlässigkeit und Effizienz eines Integrationsverfahrens. Es gibt eine Aussage über die wesentlichen Eigenschaften eines Computersystems, damit Grader-Programme effektiv eingesetzt werden können."}
{"DOCID": "1271", "TEXT": "Sekundärschlüsselabruf unter Verwendung eines IBM 7090-1301-Systems: Das Sekundärschlüsselabrufverfahren beinhaltet die Erstellung von Sekundärspeicherlisten aus Primärdatensätzen. Suchanfragen werden durch logische Operationen auf geeigneten Listen erfüllt, wodurch ein vollständiger Satz von Adressen von primären Datensätzen erzeugt wird, die für die Anfrage relevant sind. Experimentelle Ergebnisse werden präsentiert und eine vergleichende Analyse gegeben."}
{"DOCID": "1272", "TEXT": "Erweiterung der Editierfunktion in der Sprachdatenverarbeitung: Bei der automatischen Abstraktion, der Zitatindizierung, der maschinellen Übersetzung und anderen ähnlichen Verfahren ist eine Editierung immer dann erforderlich, wenn das automatische Verfahren zu wünschen übrig lässt. Dieser Aufsatz diskutiert die Wirtschaftlichkeit des Editierens als eine Funktion des Umfangs der Textverdichtung bei Sprachverarbeitungsvorgängen und behauptet dann, dass das Editieren eher als Chance denn als unwillkommene Notwendigkeit betrachtet werden kann. \"Heavy Editing\", das über die bloße Korrektur und Verbesserung der Computerausgabe hinausgeht, wird durch die Verwendung einer Konkordanz bei der Vorbereitung eines Übersichtsartikels oder einer Vorlesung veranschaulicht. Es werden andere Möglichkeiten für umfangreiches Editieren beschrieben, darunter vor allem die Interpretation und Erweiterung der Computerausgabe in Prozessen wie der Faktorenanalyse. Es werden Anwendungen beschrieben, wie z. B. Faktorenanalyse. Beschrieben werden Anwendungen wie die schnelle, unvoreingenommene Auswertung einer großen Menge eingehender Post oder Telegramme, die zu zusammenfassenden Berichten führen, die weder von Menschen noch von Computern alleine erstellt werden können."}
{"DOCID": "1273", "TEXT": "Anmerkung zur Romberg-Quadratur: Es wird eine modifizierte Form der Romberg-Quadratur beschrieben, die weniger empfindlich gegenüber der Anhäufung von Rundungsfehlern ist als die herkömmliche."}
{"DOCID": "1274", "TEXT": "Zur numerischen Lösung eines N-Punkt-Randwertproblems für lineare gewöhnliche Differentialgleichungen: Es wird ein Verfahren zur numerischen Lösung des Randwertproblems für homogene lineare gewöhnliche Differentialgleichungen entwickelt. Das Verfahren erfordert zwei Runge-Kutta-Integrationen über das betrachtete Intervall und die Lösung eines linearen Gleichungssystems mit n-1 Unbekannten."}
{"DOCID": "1275", "TEXT": "Codestrukturen zum Schutz und zur Manipulation von Elementen mit variabler Länge (Korrigendum)"}
{"DOCID": "1276", "TEXT": "Noch eine weitere Verwendung für die FORTRAN II-Verkettung"}
{"DOCID": "1277", "TEXT": "Die Verwendung von Cobol-Subroutinen in Fortran-Hauptprogrammen"}
{"DOCID": "1278", "TEXT": "Numerische Methode von Wengert für partielle Ableitungen, Orbitbestimmung und Quasilinearisierung: In einem kürzlich erschienenen Artikel in den Mitteilungen der ACM schlug R. Wengert eine Technik zur maschinellen Auswertung der partiellen Ableitungen einer in analytischer Form gegebenen Funktion vor. Bei der Lösung nichtlinearer Randwertprobleme mittels Quasilinearisierung müssen viele partielle Ableitungen analytisch gebildet und anschließend numerisch ausgewertet werden. Das Verfahren von Wengert erscheint unter dem Gesichtspunkt der Programmierung sehr attraktiv für Gleichungen, die sonst nicht durchgeführt werden könnten."}
{"DOCID": "1279", "TEXT": "Verwendung eines bedingten Basiszahlensystems zur Codierung von Folgen korrelierter Zeichen: Es wird ein Verfahren zur relativ effizienten Codierung von Folgen von Zeichen beschrieben, die Vorgänger-Nachfolger-Auswahlregeln haben. Es wird gezeigt, dass das Verfahren jeder Sequenz eine eindeutige ganze Zahl zuweist und einen angemessen kompakten Satz von Werten erzeugt."}
{"DOCID": "1280", "TEXT": "Numerische Integration einer Differential-Differenz-Gleichung mit abnehmender Zeitverzögerung: Systeme, in denen variable Zeitverzögerungen vorhanden sind, kommen in der Biologie häufig vor. Variable Durchflussraten sind eine häufige Ursache für diese variablen Verzögerungen. Gegenwärtig existiert kein umfassendes Wissen über die Auswirkungen, die diese variablen Verzögerungen verursachen können. Hier wird eine Methode zum Reduzieren einiger Differential-Differenz-Gleichungen auf gewöhnliche Differentialgleichungen gezeigt, die dann leicht numerisch untersucht werden können. Nachfolgende Untersuchungen werden sich mit Situationen befassen, in denen mehrere Verzögerungen und von der Lösung selbst abhängige Verzögerungen vorhanden sind."}
{"DOCID": "1281", "TEXT": "Dateneingabe durch Frage und Antwort: In diesem Dokument wird ein Dateneingabeschema für einen Timesharing-Computer beschrieben. Anstatt Formatanweisungen zu verwenden, um die Eingabe zu bestimmen, fragt der Computer den Benutzer einzeln nach den erforderlichen Werten. Der Computer unterhält sich während des Eingabevorgangs mit dem Benutzer, prüft auf Fehler, stellt Standarddaten bereit und ermöglicht die Bearbeitung von eingegebenen Werten."}
{"DOCID": "1282", "TEXT": "Die Verwendung von FORTRAN in Subroutinen mit COBOL-Hauptprogrammen: Durch die Verwendung der richtigen COBOL-Codierungstechniken und die Berücksichtigung von Unterschieden in der Speicherzuweisung und den Bibliotheksroutinen zwischen den beiden Sprachen ist es möglich, FORTRAN IV-Subroutinen zu schreiben, die von COBOL-Hauptprogrammen aufgerufen werden können. Eine solche Technik ermöglicht es dem Programmierer, die nützlichsten Eigenschaften jeder Sprache zu nutzen und gleichzeitig ihre jeweiligen Nachteile zu minimieren."}
{"DOCID": "1283", "TEXT": "Matrixinversion (Algorithmus 231 [F1])"}
{"DOCID": "1284", "TEXT": "Bessel-Funktion für eine Menge ganzzahliger Ordnungen"}
{"DOCID": "1285", "TEXT": "Eigenwerte und Eigenvektoren einer reellen symmetrischen Matrix nach dem QR-Verfahren (Algorithmus 254 [F2])"}
{"DOCID": "1286", "TEXT": "Eigenwerte einer reellen symmetrischen Matrix nach dem QR-Verfahren (Algorithmus 253 [F2])"}
{"DOCID": "1287", "TEXT": "Vektorkopplung oder Clebsch-Gordan-Koeffizienten (Algorithmus 252 [Z])"}
{"DOCID": "1288", "TEXT": "CLP – The Cornell List Processor: In diesem Dokument werden die Höhepunkte von CLP vorgestellt, einer Unterrichtssprache, die an der Cornell University eingesetzt wurde und als Mittel zur Einführung von Simulations- und anderen Listenverarbeitungskonzepten dient. Die verschiedenen Vorteile von CLP werden diskutiert und Beispiele gegeben."}
{"DOCID": "1289", "TEXT": "Vorgeschlagener überarbeiteter American Standard Code for Information Interchange"}
{"DOCID": "1290", "TEXT": "Transparent-Mode Control Procedures for Data Communication, Using the American Standard Code for Information Interchange – A Tutorial: Dieses Dokument gibt die Überlegungen der Task Group X3.3.4 im Bereich der Transparent-Mode-Datenkommunikations-Steuerungsphilosophie wieder. Das Erscheinen dieses Papiers wurde (unter dem Namen \"Kontrolle der zweiten Ebene\") in dem früheren Tutorial-Papier \"Control Procedures for Data Communications\", Task Group-Dokument X3.3.4.44 vom Mai 1964 vorhergesagt. Das vorliegende Papier geht näher darauf ein Lösungen für die Probleme der Transparenz für die grundlegenden ASCII-Kommunikationssteuerzeichen, wie sie in dem oben erwähnten vorangegangenen Artikel umrissen wurden. Darüber hinaus werden die zusätzlichen Kontrollprobleme bei der Handhabung von Material wie offline verschlüsselten Daten oder Nicht-ASCII-Codes durch Systeme behandelt, die eine vollständige Zeichentransparenz bieten. Sie deckt keine Transparenzkonzepte ab, bei denen die normale Zeichenstruktur oder Modulationsrate eines Systems aufgegeben werden kann. In Verbindung mit dem früheren Tutoriumspapier wird dieses Papier voraussichtlich zu einem Vorschlag für die Standardisierung von Datenkommunikationssteuerverfahren unter Verwendung des amerikanischen Standardcodes für den Informationsaustausch führen."}
{"DOCID": "1291", "TEXT": "Tabellarische Eingabe von Daten"}
{"DOCID": "1292", "TEXT": "Über ein Division-und-Korrektur-Verfahren für die Division mit variabler Genauigkeit: In diesem Dokument wird ein Division-und-Korrektur-Verfahren für die Division mit variabler Genauigkeit in digitalen Computern beschrieben. Im Gegensatz zu den früheren Verfahren von Stein und Pope verwendet das vorliegende Verfahren eine geeignet gerundete Form des normalisierten Divisors, um eine Schätzung der Quotientenzeichen zu erhalten. Dies führt zu einer Korrektur der Schätzung von höchstens plus oder minus eins, um den exakten Quotientencharakter zu erhalten. Es wird angenommen, dass dieses Verfahren für Divisionsoperationen in zeichenorientierten Maschinen mit variabler Wortlänge weit verbreitet sein wird."}
{"DOCID": "1293", "TEXT": "Methode ist Zufall: Bestimmte nicht zufällige Eigenschaften eines häufig verwendeten Zufallszahlengenerators werden beschrieben und analysiert."}
{"DOCID": "1294", "TEXT": "Hinweis zur Gleitkomma-Arithmetik mit dreifacher Genauigkeit bei 132-Bit-Zahlen: In einem kürzlich erschienenen Artikel haben Gregory und Raney eine Technik für die Gleitkomma-Arithmetik mit doppelter Genauigkeit beschrieben. Eine ähnliche Technik kann für Gleitkommaarithmetik mit dreifacher Genauigkeit entwickelt werden, und es ist der Zweck dieser Anmerkung, diese Technik zu beschreiben. Nur der Multiplikations- und der Divisionsalgorithmus werden beschrieben, da der Additions-Subtraktions-Algorithmus durch eine triviale Modifikation des Algorithmus in der Arbeit von Gregory und Raney erhalten werden kann."}
{"DOCID": "1295", "TEXT": "PERT-Zeitberechnungen ohne topologische Ordnung: Eine vereinfachte Technik wird für PERT-Zeitberechnungen ohne topologische Ordnung vorgestellt. Jedem Ereignis ist ein eindeutiger Speicherplatz zugeordnet. Eine Aktivität wird durch einen Link repräsentiert. Ein Link ist definiert als ein Speicherplatz, der die Adresse eines anderen Speicherplatzes enthält. Die Zeitinformationen für eine Aktivität werden mit ihrem Link transportiert. Für ein typisches Netz kann die Mehrzahl der Aktivitäten durch jeweils eine 36-Bit-Zelle beschrieben werden. Der Rest verwendet jeweils zwei 36-Bit-Zellen. Die Links sind unidirektional; vorwärts während der T(E)-Berechnung (erwartete Abschlusszeit für eine Aktivität); rückwärts während der T(L)-Berechnung (spätestens zulässige Zeit für den Abschluss einer Aktivität). Die Berechnungen schreiten topologisch durch das Netz fort, obwohl das Netz im Kern nicht topologisch dargestellt wird."}
{"DOCID": "1296", "TEXT": "Aktiv (Algorithmus 205 [E4])"}
{"DOCID": "1297", "TEXT": "Steep1 (Algorithmus 203 [E4])"}
{"DOCID": "1298", "TEXT": "Adaptive numerische Integration nach der Simpson-Regel (Algorithmus 145 [D1])"}
{"DOCID": "1299", "TEXT": "Lösungen der Diophantischen Gleichung (Algorithmus 139 [A1])"}
{"DOCID": "1300", "TEXT": "Funktionsminimierung (Algorithmus 251[E4])"}
{"DOCID": "1301", "TEXT": "Auf ALGOL I/O-Konventionen"}
{"DOCID": "1302", "TEXT": "Parallele Signalgeschwindigkeiten für die Datenübertragung (vorgeschlagener amerikanischer Standard)"}
{"DOCID": "1303", "TEXT": "Eine Korrespondenz zwischen ALGOL 60 und der Lambda-Notation von Church: Teil II*"}
{"DOCID": "1304", "TEXT": "Ein Multi-Programming-System mit schneller Durchlaufzeit: In diesem Dokument werden grundlegende Merkmale, Systemeigenschaften und der Steueralgorithmus für ein Multi-Programming-System mit schneller Durchlaufzeit beschrieben."}
{"DOCID": "1305", "TEXT": "Die interne Struktur des FORTRAN CEP-Übersetzers: Der FORTRAN CEP-Übersetzer wandelt ein in der FORTRAN CEP-Sprache geschriebenes Quellprogramm in ein Objektprogramm um, das in der Sprache des CEP-Computers geschrieben ist. In dieser Arbeit wird nach einer Skizze des CEP-Rechners die interne Struktur des Übersetzers beschrieben. Der Schwerpunkt liegt auf der Kompilierung von Ausdrücken, Ein-/Ausgabelisten und indizierten Variablen."}
{"DOCID": "1306", "TEXT": "Eine Klasse eindeutiger Computersprachen: In diesem Artikel wird das Konzept einer vollständig verschachtelten Computersprache diskutiert, die ein Mittel zum Entwerfen von Computersprachen sein kann, die vollständig frei von Mehrdeutigkeiten wären. Hier werden auch mehrere Vorschläge für die Neudefinition von ALGOL als vollständig verschachtelte Sprache gegeben."}
{"DOCID": "1307", "TEXT": "A Lightpen-Controlled Program For On-Line Data Analysis: Dieses Dokument beschreibt eine Technik, die entwickelt wurde, um die Verwendung eines Datenverarbeitungssystems durch eine Person, insbesondere einen Wissenschaftler, zu erleichtern, der eng und hauptsächlich damit beschäftigt ist, die Bedeutung der verarbeiteten Daten zu interpretieren durch das System. Da eine solche Person oft nicht in der Lage ist, die Zeit aufzuwenden, die zum Beherrschen einer Programmiersprache erforderlich ist, ist es wichtig, dass sie beim Verfassen von Befehlen für den Computer unterstützt wird. Bei dem beschriebenen System muss der Benutzer das Vokabular der Sprache nicht lernen oder sich daran erinnern, da das Vokabular vor ihm auf \"Menüs\" mittels eines computergesteuerten Bereichs angezeigt wird. Er wählt die verschiedenen erforderlichen Wortschatzelemente aus, indem er mit dem Lichtstift darauf zeigt. Durch die Verwendung eines kleinen ungeordneten Satzes von Umschreibungsregeln, die als Ergebnis von Lichtgriffelauswahlen angewendet werden, erzeugt der Benutzer nur syntaktisch korrekte Befehle für das System. Er muss die Grammatik nicht lernen oder sich merken. Das Programm schränkt den Benutzer stark in der bestimmten Sprache ein, die er verwenden kann, aber die Methode zum Kommunizieren mit dem Programm lässt diese Einschränkungen ganz natürlich und uneingeschränkt erscheinen. Das Programm wird seit über zehn Monaten erfolgreich eingesetzt."}
{"DOCID": "1308", "TEXT": "Ein mathematisches Modell für die Beschreibung eines mechanischen Teils: Die Flexibilität eines mathematischen Modells nutzt die allgemeinen Informationsanforderungen von computergestütztem technischem Zeichnen, numerischer Steuerungsbanderzeugung und Berechnung physikalischer Eigenschaften. Durch vernünftige Steuerung der Kommunikationsanforderungen zwischen Mensch und Maschine sind verbesserte Ergebnisse gegenüber herkömmlichen Konstruktionsprozessen möglich. Eine englischähnliche Eingabesprache, die auf die Verwendung durch Zeichner und Designer zugeschnitten ist, beschreibt das Teil und spezifiziert die gewünschte Ausgabe. Ein Ansatz für das mathematische Modell besteht aus einer Gruppe von oberflächendefinierenden quadratischen Gleichungen, die durch ein System modularer Unterprogramme erstellt werden. Andere Unterprogramme wandeln das mathematische Modell in Anweisungen zum Antreiben automatischer Zeichenmaschinen und numerisch gesteuerter Werkzeugmaschinen um. Physische Teileeigenschaften, wie z. B. der Schwerpunkt, können von Unterprogrammen berechnet und in dynamischen Analysearbeiten verwendet werden. Das vorgeschlagene Gesamtsystem wird vorgestellt und Experimente und Demonstrationen werden diskutiert."}
{"DOCID": "1309", "TEXT": "Ein computerbenutzerorientiertes System: Es wurde ein Computersprachensystem entwickelt, das eine schnelle Erstellung von Managementberichten ermöglicht, unabhängig von Rechenkomplexität oder Formatvielfalt. Die Kosten sind so gering, dass für jeden Manager individuell zugeschnittene Berichte erstellt werden können. Das System erfordert eine anfängliche Vorbereitung großer Datenbanken, die Daten in elementarer Form enthalten. Die Verwendung von zwei speziellen Sprachen, EXTRACT und MATRAN, ermöglicht die selektive Extraktion jeder Datenuntermenge, die effiziente Verarbeitung durch jede Rechensequenz und die flexible Darstellung der Ergebnisse in tabellarischer oder grafischer Form. Matrixalgebra wird als grundlegendes Vehikel verwendet, um sowohl Manipulationen als auch Berechnungen durchzuführen."}
{"DOCID": "1310", "TEXT": "Eine schnelle Braille-Transliterationstechnik für bestimmte IBM-Maschinen"}
{"DOCID": "1311", "TEXT": "Effiziente Autokorrelation"}
{"DOCID": "1312", "TEXT": "Rekursion und Iteration"}
{"DOCID": "1313", "TEXT": "Konstruktion von Testproblemen der nichtlinearen Programmierung"}
{"DOCID": "1314", "TEXT": "Die Organisation von Symboltabellen: Eine effiziente Symboltabellenorganisation ist ein wichtiges Merkmal beim Entwurf jedes Compilers. Während der Konstruktion des Virginia ALGOL 60-Compilers für den Burroughs B205 war die Hauptüberlegung beim Design der Symboltabelle, dass die Erkennung von Identifikatoren und reservierten Wörtern so schnell wie möglich sein sollte. Die allgemeinen Merkmale der Technik werden beschrieben."}
{"DOCID": "1315", "TEXT": "Automatisierung des Radioisotopen-Rechenschaftssystems: Der Radioisotope Service des Veterans Administration Hospital, Omaha, Nebraska, verwendete drei Jahre lang ein manuelles System der Radioisotopen-Rechenschaftspflicht. Das zufriedenstellende, aber zeitraubende Verfahren wurde im Januar 1963 von einem manuellen auf ein vollautomatisches Computersystem umgestellt. Das Programm für gekaufte Radioisotope ist im FORMAT FORTRAN für den IBM 1620 Computer geschrieben. Ein zweites Programm zur Aufrechterhaltung der Rechenschaftspflicht für im Reaktor erzeugte Radioisotope ist in der Programmiersprache FORCOM geschrieben. Vom Reaktorbetriebspersonal wird ein Mindestmaß an Buchführung verlangt. Die Vorschriften der United States Atomic Energy Commission legen fest, dass Aufzeichnungen geführt werden. Dieses System liefert detaillierte Aufzeichnungen für jeden Behälter mit radioaktivem Material, der im Triga-Reaktor gekauft und/oder hergestellt wurde, und zeigt die erhaltenen, verwendeten und/oder an den Gesundheitsphysiker zur Entsorgung übergebenen Mengen an. Konsolidierte Aufzeichnungen enthalten Gesamtbeträge, die für einen bestimmten Zeitraum erhalten, verwendet und/oder entsorgt wurden. Gekaufte Radioisotope werden in Millicurie angegeben; Reaktor-erzeugte Radioisotope in Mikrocuries."}
{"DOCID": "1316", "TEXT": "Bessel-Funktionen erster Art (Algorithmus 236 [S17])"}
{"DOCID": "1317", "TEXT": "Poisson-Charlier-Polynome (Algorithmus 234 [S23])"}
{"DOCID": "1318", "TEXT": "Arccossin (Algorithmus 206 [B1])"}
{"DOCID": "1319", "TEXT": "Crout mit Ausgleich und Iteration (Algorithmus 135 [F4])"}
{"DOCID": "1320", "TEXT": "Inverse Permutation (Algorithmus 250 [G6])"}
{"DOCID": "1321", "TEXT": "Outreal N (Algorithmus [I5])"}
{"DOCID": "1322", "TEXT": "Nettofluss (Algorithmus 248 [H])"}
{"DOCID": "1323", "TEXT": "Eine Korrespondenz zwischen ALGOL 60 und der Lambda-Notation von Church: Teil I*: Dieses Papier beschreibt, wie ein Teil der Semantik von ALGOL 60 formalisiert werden kann, indem eine Korrespondenz zwischen Ausdrücken von ALGOL 60 und Ausdrücken in einer modifizierten Form der L-Notation von Church hergestellt wird. Zunächst wird ein Modell für Computersprachen und Rechenverhalten beschrieben, das auf den Begriffen der funktionalen Anwendung und der funktionalen Abstraktion basiert, aber auch Analoga für imperative Sprachmerkmale aufweist. Dann wird dieses Modell als \"abstrakte Objektsprache\" verwendet, in die ALGOL 60 abgebildet wird. Viele der Merkmale von ALGOL 60 tauchen als besondere Anordnungen einer kleinen Anzahl struktureller Regeln auf, was neue Klassifikationen und Verallgemeinerungen nahelegt. Die Korrespondenz wird zunächst informell beschrieben, hauptsächlich durch Illustrationen. Der zweite Teil der Arbeit gibt eine formale Beschreibung, d.h. einen \"abstrakten Compiler\" in die \"abstrakte Objektsprache\". Dies wird selbst in einer \"rein funktionalen\" Notation dargestellt, dh einer Notation, die nur Anwendung und Abstraktion verwendet."}
{"DOCID": "1324", "TEXT": "Beantwortung englischer Fragen per Computer: Eine Umfrage: Fünfzehn experimentelle Frage-Antwort-Systeme in englischer Sprache, die programmiert und in Betrieb sind, werden beschrieben und überprüft. Die Systeme reichen von einer Konversationsmaschine bis hin zu Programmen, die Sätze über Bilder bilden, und Systemen, die aus dem Englischen in logische Kalküle übersetzen. Systeme werden klassifiziert als listenstrukturierte datenbasierte, graphische datenbasierte, textbasierte und inferentielle Systeme. Prinzipien und Arbeitsweisen werden detailliert beschrieben und besprochen. Es wird geschlussfolgert, dass die Frage-Antwort-Datenbank von der anfänglichen Forschung in die frühe Entwicklungsphase übergegangen ist. Als schwierigste und wichtigste Forschungsfragen für die Weiterentwicklung von Allzweck-Sprachprozessoren gelten das Messen, der Umgang mit Mehrdeutigkeiten, das Übersetzen in formale Sprachen und das Durchsuchen großer Baumstrukturen."}
{"DOCID": "1325", "TEXT": "Fern-, Online- und Echtzeit-Computerdiagnose des klinischen Elektrokardiogramms: In diesem Dokument wird ein kurzer Bericht über die Hardware, Software, Systemkonfiguration und Funktion eines Systems für die Fern-, Online- und Echtzeit-Computerdiagnose des klinischen Elektrokardiogramms präsentiert klinische Elektrokardiogramme. Es scheint wahrscheinlich, dass Bemühungen dieser Art zu einer befriedigenden Lösung des Problems der automatischen Diagnose von Elektrokardiogrammen führen werden. Gegenwärtige Versuche der Autoren, die diagnostischen Möglichkeiten des vorliegenden Systems zu erweitern, befassen sich insbesondere mit der Erhöhung der Wiedergabetreue der adaptiven angepaßten Filter, der Entwicklung dreidimensionaler Musteranalyse, der Analyse der parallelen Elektrokardiograph-Computer-Diagnose-Interaktion und einer Untersuchung der Möglichkeit, wichtige, baumartige Verzweigungsentscheidungen früh in den Diagnoseprozess einzuführen."}
{"DOCID": "1326", "TEXT": "Grenznetzwerke: Es wird ein durchführbares Computerverfahren zum Bestimmen des vollständigen oder teilweisen Einschlusses willkürlich gegebener Punkte und Linien in Bezug auf einen Satz allgemeiner polygonaler Bereiche beschrieben, die einen ebenen begrenzten Bereich unterteilen. Ein Schema zur Computerdarstellung der Grenzen der Domänen und ein darauf basierender Algorithmus zur Auswertung der Inklusionsbeziehungen werden im Detail spezifiziert. Das Verfahren verwendet mehrere Ebenen von Auswahlkriterien, um die Anzahl der Zugriffe auf Hilfsspeichergeräte und die Menge an Grenzdaten, für die eine Verarbeitung erforderlich ist, zu reduzieren."}
{"DOCID": "1327", "TEXT": "Verwendung von Entscheidungstabellen in der Computerprogrammierung: Eine Entscheidungstabelle ist eine tabellarische Form zur Darstellung der Entscheidungslogik. Entscheidungstabellen haben viele inhärente Vorteile. Die zu veranschaulichende Technik macht sich diese Vorteile zunutze, indem sie es ermöglicht, direkt aus einer Entscheidungstabelle heraus zu programmieren. Die Technik basiert auf der Erzeugung eines binären Abbilds einer Entscheidungstabelle mit begrenztem Eintrag im Computerspeicher. Es kann auch ein binäres Abbild eines gegebenen Satzes von Eingabebedingungen erstellt werden. Dieses Datenbild wird verwendet, um das Bild der Entscheidungstabelle zu scannen, um zu der richtigen Vorgehensweise zu gelangen. Aus Sicht der Programmierung ergeben sich mehrere Vorteile: (1) die Menge des verwendeten Computerspeichers wird drastisch reduziert, (2) die Programmierung wird vereinfacht und (3) die Dokumentation ist kurz und klar."}
{"DOCID": "1328", "TEXT": "Weitere Bemerkungen zum Reduzieren von Trunkierungsfehlern"}
{"DOCID": "1329", "TEXT": "Simulation Boolescher Funktionen in einem Dezimalrechner"}
{"DOCID": "1330", "TEXT": "Automatisiertes Plotten von Flussdiagrammen auf einem kleinen Computer"}
{"DOCID": "1331", "TEXT": "Codestrukturen zum Schutz und zur Manipulation von Elementen variabler Länge: Wenn Elemente aus einer variablen Anzahl von Zeichen bestehen, die jeweils die gleiche Anzahl von Bits enthalten, werden bestimmte Steuerinformationen (Teilungssymbole) eingefügt, um ihre Trennungen zu markieren. Da Fehler bei der Identifizierung dieser Steuerzeichen zu ernsthaften Schwierigkeiten führen können, werden Verfahren zum Schutz dieser Symbole angegeben. Eine 6-Bit-Code-Zuweisung alphanumerischer Zeichen für Computer mit fester Wortlänge wird angegeben und ihre Eignung zur Fehlererkennung und Manipulation von Elementen mit variabler Länge wird gezeigt. Ebenfalls angedeutet ist seine Flexibilität bei bestimmten arithmetischen Operationen."}
{"DOCID": "1332", "TEXT": "Unterprogrammzusammenbau: Es wird eine Beschreibung eines Zusammenbausystems gegeben, das nur einen Durchlauf erfordert und keine Tabelle mit Informationen über die Unterprogrammbibliothek führt."}
{"DOCID": "1333", "TEXT": "Reduzierung von Rundungsfehlern durch kaskadierende Akkumulatoren: Bei der Akkumulation einer großen Anzahl von Größen wie bei der numerischen Integration kann die Summe selbst viel größer werden als die einzelnen Summanden. Dies führt zu einem Abschneidefehler. Ein Großteil dieses Fehlers kann mit kaskadierenden Akkumulatoren eliminiert werden, wie in einem kürzlich erschienenen Artikel von Wolfe erwähnt. Ein einfacherer und etwas flexiblerer Algorithmus wird vorgestellt, der auch den Fall negativer Summanden behandelt."}
{"DOCID": "1334", "TEXT": "Mechanisierung langweiliger Algebra: Die Newcomb-Operatoren der Planetentheorie: Ein Computerprogramm wurde geschrieben, um Formeltabellen für die Newcomb-Operatoren der Planetentheorie zu erzeugen. Die Newcomb-Operatoren werden als Polynome in zwei Variablen ausgedrückt, von denen eine für einen einfachen Differentialoperator und die andere für eine beliebige ganze Zahl steht. Die Polynome werden durch ein Wiederholungsschema erzeugt. Das Programm ist in FORTRAN codiert, wobei einfache Array-Manipulationstechniken verwendet werden, um die algebraischen Operationen durchzuführen. Formeln für über 100 Newcomb-Operatoren wurden vom Programm erstellt und fotografisch auf einem S-560 Photon-System gesetzt."}
{"DOCID": "1335", "TEXT": "Zeichensatz für optische Zeichenerkennung (vorgeschlagener amerikanischer Standard)"}
{"DOCID": "1336", "TEXT": "NPL: Highlights einer neuen Programmiersprache"}
{"DOCID": "1337", "TEXT": "EULER: Eine Verallgemeinerung von ALGOL und seine formale Definition"}
{"DOCID": "1338", "TEXT": "Zusätzliche Kommentare zu einem Problem bei der Steuerung der gleichzeitigen Programmierung"}
{"DOCID": "1339", "TEXT": "Ein Beitrag zur Entwicklung von ALGOL"}
{"DOCID": "1340", "TEXT": "Multiplexing von langsamen Peripheriegeräten: Die Philosophie eines Monitors, der es ermöglicht, langsame Ausgabegeräte zu multiplexen, wird vorgestellt."}
{"DOCID": "1341", "TEXT": "Ebenen von Computersystemen: Beim Aufbau aktueller Computersysteme neigen wir dazu, sie in \"Ebenen\" der Kontrolle, des Befehls und der Kommunikation zu unterteilen; Bei der Nutzung des Systems schlüsseln wir unsere Probleme entsprechend auf. Die fortgesetzte Verwendung einer solchen Struktur wirft Fragen über ihre Auswirkungen auf die Nützlichkeit zukünftiger Systeme auf, insbesondere im Hinblick auf solche Trends wie Timesharing, Parallelprogrammierung und schließlich lernende Systeme. In diesem Essay werden einige dieser Fragen gestellt und die allgemeine Haltung diskutiert, die wir einnehmen müssen, um das Problem weiter zu verfolgen."}
{"DOCID": "1342", "TEXT": "Transportproblem (Algorithmen 293 [H])"}
{"DOCID": "1343", "TEXT": "Havie Integrator (Algorithmus 257 [D1])"}
{"DOCID": "1344", "TEXT": "Statistische Berechnungen basierend auf algebraisch spezifizierten Modellen: Basierend auf einem maschinenlesbaren statistischen Modell und verwandten symbolischen Spezifikationen wird ein effizientes Verfahren zum Durchführen von Berechnungen für statistische Modelle ausgewogener vollständiger Natur vorgestellt. Fixes, gemischte und zufällige Analysen von Varianzmodellen werden berücksichtigt. Ein Verfahren zum Erhalten von Varianzkomponenten und berechneten F-Statistiken für die Modellterme ist enthalten."}
{"DOCID": "1345", "TEXT": "Tensorberechnungen auf dem Computer: Es wurde ein FORMAC-Programm geschrieben, das in der Lage ist, verschiedene interessierende Größen in der Tensorrechnung zu berechnen. Unter Verwendung dieses Codes wurden Christoffel-Symbole für 12 grundlegende orthogonale Koordinatensysteme berechnet."}
{"DOCID": "1346", "TEXT": "Über die Anwendung des Prozesses der Entzerrung von Maxima, um eine rationale Annäherung an bestimmte modifizierte Bessel-Funktionen zu erhalten: Der zweite Remes-Algorithmus, wie er ursprünglich für Polynome aufgestellt wurde, kann konvergieren oder nicht, wenn die Annäherungsfunktionen rational sind. Die wenigen in diesem Bereich bekannten Ergebnisse zeigen jedoch, wie effizient der Algorithmus sein kann, um Näherungen mit einem kleinen Fehler zu erhalten, viel mehr als im Polynomfall, in dem die beste Näherung sehr nahe direkt durch eine Reihenentwicklung erreicht werden kann. Das Ziel dieser Arbeit ist es, die Grenzen der Anwendbarkeit bestimmter Erweiterungen des Algorithmus auf den Fall zu untersuchen, in dem die Näherungen rational sind, sowie einige numerische Ergebnisse zu präsentieren."}
{"DOCID": "1347", "TEXT": "Allgemeines Fehlerempfindlichkeitsprogramm für zeitvariable Systeme: Die Bewertung der Empfindlichkeit zeitvariabler Systeme gegenüber Anfangsbedingungs- und Parameterfehlern durch die Varianzfortpflanzungstechnik beinhaltet die Bestimmung mehrerer systemabhängiger partieller Ableitungsmatrizen. Diese Anforderung hat zu getrennten Programmen für jedes untersuchte System geführt. Ein neues Programm bestimmt durch Verwendung der Wengert-Differenzierungstechnik automatisch die erforderlichen Matrizen aus spezifischen Systemgleichungen, die zur Ausführungszeit in Unterroutinenform geliefert werden, wodurch die Notwendigkeit individualisierter Programme eliminiert und die Weiterentwicklung extrem allgemeiner Computerprogramme vorausgesagt wird."}
{"DOCID": "1348", "TEXT": "FLOWTRACE, ein Computerprogramm zur Erstellung von Ablaufdiagrammen: Das FLOWTRACE-System erstellt Ablaufdiagramme von Programmen, die in \"fast jeder\" Programmiersprache geschrieben sind. Die meisten beschreiben die Syntax der Steueranweisungen in seiner Sprache; hierfür steht eine Metasprache zur Verfügung. Das resultierende Objektdeck wird verwendet, um beliebige Programme in der beschriebenen Sprache in einem Flussdiagramm darzustellen. Es werden mehrere Beispiele für FAP- und SNOBOL-Flussdiagramme gegeben. Es ist jedoch nicht notwendig, sich auf bestehende Sprachen zu beschränken. Man kann seine eigene Sprache auf jede \"gut strukturierte\" Weise definieren. Diese Funktion ist besonders nützlich, wenn nur Kommentare innerhalb eines Programms grafisch dargestellt werden sollen. Ein solcher Ansatz erlaubt die Dokumentation von beschreibenden Bemerkungen und vermeidet die Einbeziehung von Codierungsdetails."}
{"DOCID": "1349", "TEXT": "Computerkapazitäten an westeuropäischen Universitäten: Dieser Bericht über die Reise des Autors zu Universitäten in Westeuropa im Sommer 1966 gibt eine kurze Beschreibung der Computeraktivitäten an jeder besuchten Institution. Die Fähigkeiten der gegenwärtigen Ausrüstung variieren von mittlerem bis großem Maßstab; Viele Institutionen planen jedoch, in naher Zukunft komplexe Timesharing-Systeme zu erwerben. Der Stand der Technik hinkt nach Meinung des Autors dem auf diesem Kontinent hinterher. Diese Verzögerung wird auf vier Hauptfaktoren zurückgeführt: (a) die behindernde Organisation akademischer Verfahren; (b) die finanzielle Beziehung zwischen Universität und Regierung; (c) die untergeordnete Organisation der Rechenanlage; (d) der Mangel an professionellem Wissensaustausch. Die Auswirkungen dieser Beschränkungen werden erläutert."}
{"DOCID": "1350", "TEXT": "The Augmented Predictive Analyzer for Context-Free Languages-Its Relative Efficiency: Es wurde von Greibach bewiesen, dass für eine gegebene kontextfreie Grammatik G eine Standardform-Grammatik Gs konstruiert werden kann, die dieselben Sprachen generiert, wie sie von G generiert werden und deren Regeln alle die Form Z --> cY(1) ... Y(m), (m >= O) haben, wobei Z und Y(i) Zwischensymbole und c ein Endsymbol sind. Da der prädiktive Analysator in Harvard eine Standardformgrammatik verwendet, kann er die Sprache jeder kontextfreien Grammatik G akzeptieren, wenn eine äquivalente Standardformgrammatik Gs gegeben ist. Die Strukturbeschreibungen SD(Gs,X), die einem gegebenen Satz X durch den prädiktiven Analysator zugewiesen werden, unterscheiden sich jedoch gewöhnlich von den Strukturbeschreibungen SD(G,X), die demselben Satz durch die ursprüngliche kontextfreie Grammatik G zugewiesen wurden Gs wird abgeleitet. In Abschnitt 1 wird ein ursprünglich von Abbott stammender Algorithmus in Standardformgrammatik beschrieben, dessen Regeln jeweils in Standardform vorliegen, ergänzt durch zusätzliche Informationen, die seine Ableitung von der ursprünglichen kontextfreien Grammatik beschreiben. Eine Technik zum effektiven Durchführen der SD(Gs,X)-zu-SD(G,X)-Transformation wird ebenfalls beschrieben. In Abschnitt 2 wird der Augmented Predictive Analyzer als Parsing-Algorithmus für beliebige kontextfreie Sprachen mit zwei anderen Parsing-Algorithmen verglichen: einem selektiven Top-to-Bottom-Algorithmus ähnlich dem „Error Correcting Parsing Algorithm“ von Irons und einem unmittelbaren Konstituenten-Analysator, der ist eine Erweiterung des Algorithmus von Sakai-Cocke für normale Grammatiken. Der Vergleich basiert auf mehreren Effizienzkriterien, die Kernspeicheranforderungen, Komplexität der Programme und Verarbeitungszeit abdecken."}
{"DOCID": "1351", "TEXT": "Automatische Fehlergrenzen auf reellen Nullstellen rationaler Funktionen: Es wird ein Verfahren zum Implementieren einer intervallarithmetischen Version des Newton-Raphson-Verfahrens vorgeschlagen. Das Verfahren erfordert nur ein Startintervall, über dem die Nullstellen einer gegebenen rationalen Funktion zu lokalisieren sind. Das Verfahren stellt automatisch Grenzen für Rundungsfehler bereit."}
{"DOCID": "1352", "TEXT": "Automatische Integration einer Funktion mit einem Parameter: Zwei effiziente Verfahren zur automatischen numerischen Integration sind die Romberg-Integration und die adaptive Simpson-Integration. Für Integranden der Form f(x)g(x,a) mit a als Parameter wird gezeigt, dass das Romberg-Verfahren effizienter ist. Ein FORTRAN-Programm zeigt, wie diese höhere Effizienz erreicht werden kann."}
{"DOCID": "1353", "TEXT": "Techniken für die automatische Toleranzkontrolle bei der linearen Programmierung: In diesem technischen Hinweis werden die numerischen Schritte für die Simplex-Methode der linearen Programmierung überprüft und die im numerischen Verfahren erforderlichen Toleranzen definiert. Es werden objektive Kriterien für die Durchführung der numerischen Schritte des Verfahrens und die Berechnung der erforderlichen Toleranzen angegeben."}
{"DOCID": "1354", "TEXT": "Umwandlung von Entscheidungstabellen in Computerprogramme durch Regelmarkierungstechniken: Die Regelmaskentechnik ist ein Verfahren zum Umwandeln von Entscheidungstabellen mit begrenztem Eintrag in Computerprogramme. Neuere Diskussionen legen nahe, dass sie in vielen Fällen der Technik des Aufbaus von Netzwerken oder Bäumen vorzuziehen ist. Ein Nachteil der bisher vorgestellten Technik ist ihre Tendenz, Objektprogramme mit längerer Laufzeit als nötig zu erzeugen. In diesem Artikel wird eine Modifikation der Technik diskutiert, die sowohl Regelhäufigkeiten als auch die relativen Zeiten zum Auswerten von Bedingungen berücksichtigt. Dies kann die Laufzeit des Objektprogramms wesentlich verbessern."}
{"DOCID": "1355", "TEXT": "Reguläre Coulomb-Wellenfunktionen (Algorithmus 292)"}
{"DOCID": "1356", "TEXT": "Havie Integrator (Algorithmus 257 [D1])"}
{"DOCID": "1357", "TEXT": "Prüfungsplanung (Algorithmus 286 [H])"}
{"DOCID": "1358", "TEXT": "Syntax-Makros und erweiterte Übersetzung: Es wird ein Übersetzungsansatz beschrieben, der es einem ermöglicht, die Syntax und Semantik einer gegebenen Basissprache auf hoher Ebene durch die Verwendung eines neuen Formalismus, der als Syntax-Makro bezeichnet wird, zu erweitern. Syntax-Makros definieren String-Transformationen basierend auf syntaktischen Elementen der Basissprache. Es werden zwei Arten von Makros diskutiert und Beispiele für ihre Verwendung gegeben. Die bedingte Generierung von Makros basierend auf Optionen und Alternativen, die durch den Scan erkannt werden, wird ebenfalls beschrieben."}
{"DOCID": "1359", "TEXT": "Datenfilterung bei Anwendungen zur Speicherung und zum Abruf von Informationen: Die Manipulation von Datenstrings ist die komplexeste Verarbeitungsfunktion bei Anwendungen zur Speicherung und zum Abruf von Informationen. Die Manipulation von Datenstrings wird im Zusammenhang mit einer interpretativen Verarbeitungsumgebung diskutiert, die durch die Verwendung von Verfahrensanweisungen gesteuert wird. Die Abfolge von Verfahrensanweisungen wird von einer angenommenen Aufgabe abgeleitet, die in einer benutzerorientierten Quellsprache ausgedrückt wird. Jede Datenkette mit der strukturierten Datenumgebung (Datenbank) ist explizit oder implizit mit einer Formatdeklaration verbunden, die in einer Formatbibliothek liegt. Die mit der Datenkettenmanipulation verbundene Verarbeitungsmechanik wird gemäß einem verallgemeinerten Datenfilterkonzept entwickelt. Dies führt zur Implementierung eines zweiteiligen Datenfiltermoduls, das interne Verarbeitungsfunktionen erfüllt, indem es Datenfolgen durch Formatdeklarationen filtert, die seinen Eingangs- und Ausgangsports zugeordnet sind."}
{"DOCID": "1360", "TEXT": "Beschreibung der für die Datenübertragung verwendeten Systeme* (Ein ASA-Tutorial)"}
{"DOCID": "1361", "TEXT": "Rechteckige Löcher in zwölfreihigen Lochkarten* (vorgeschlagener amerikanischer Standard)"}
{"DOCID": "1362", "TEXT": "Code Extension in ASCII* (An ASA Tutorial): Der American Standard Code for Information Interchange (ASCII) enthält eine Reihe von Steuerzeichen, die mit dem Prinzip der Code-Erweiterung verbunden sind, also mit der Darstellung von Informationen, die nicht direkt durch Mittel darstellbar sind der Zeichen im Code. Die Verwendungsweise dieser Zeichen wurde bisher nicht vollständig beschrieben. Dieses Papier präsentiert eine Reihe von miteinander konsistenten Philosophien in Bezug auf Codeerweiterungsanwendungen und schlägt eine logische Folge von Doktrinen für die Anwendung der Codeerweiterungszeichen vor. Es wird zwischen Codeerweiterung und anderen Konzepten wie \"grafische Substitution\" oder \"syntaktische Darstellung\" unterschieden, die häufig verwendet werden, um ähnliche Anforderungen zu erfüllen. Außerdem werden bestimmte Themen behandelt, die sich nicht wirklich mit der Codeerweiterung befassen, die jedoch häufig in Diskussionen über Codeanwendungen damit verbunden sind. Das Material in diesem Dokument ist im Prinzip gleichermaßen auf den (vorgeschlagenen) internationalen ISO-7-Bit-Code für den Informationsaustausch anwendbar."}
{"DOCID": "1363", "TEXT": "Ein allgemeines Verfahren zur systematischen Intervallberechnung für die numerische Integration von Anfangswertproblemen: Es wird ein Verfahren zum kontinuierlichen Berechnen und Überwachen der Schrittgröße angegeben, die von einem selbststartenden numerischen Integrationsverfahren p-ter Ordnung verwendet werden soll, um ein Anfangswertproblem zu lösen. Die Prozedur verwendet eine Schätzung des Abschneidefehlers, um die Schrittgröße zu berechnen."}
{"DOCID": "1364", "TEXT": "Mathematische Experimente in Time-Lag-Modulation: Gleichungen der Form du/dt = g(u(t),u(h(t))) treten in vielen wissenschaftlichen Zusammenhängen auf. Die Autoren weisen auf einige interessante Eigenschaften der Lösung u'(t) = -u(t-1-k*sin(wt))+sin(at) hin. Diese Eigenschaften wurden mittels numerischer Lösung erhalten."}
{"DOCID": "1365", "TEXT": "Beseitigung monotoner Mathematik mit FORMAC: Das Programmiersystem FORMAC (FORMULA MAnipulation Compiler) bietet ein leistungsstarkes Werkzeug zur Durchführung mathematischer Analysen. Es ist eine Erweiterung von FORTRAN IV, die die Verwendung des Computers ermöglicht, um die langwierigen algebraischen Berechnungen durchzuführen, die in vielen verschiedenen Bereichen auftreten. Zu den Bereichen, in denen es erfolgreich eingesetzt wurde, gehören: Differentiation komplizierter Ausdrücke, Entwicklung abgeschnittener Potenzreihen, Lösung simultaner Gleichungen mit wörtlichen Koeffizienten, nichtlineare Maximum-Likelihood-Schätzung, Tensoranalyse und Generierung der Koeffizienten von Gleichungen in Keplerscher Bewegung. Diese Arten von Analysen, die bei der Lösung spezifischer praktischer Probleme in Physik, Technik, Astronomie, Statistik und Astronautik entstanden sind, werden in der Arbeit diskutiert. Neben der Verwendung für spezifische Problemlösungen kann FORMAC auch zur Automatisierung der Analysephase in bestimmten Produktionsprogrammen verwendet werden. Mehrere solcher Anwendungen werden vorgestellt."}
{"DOCID": "1366", "TEXT": "Computersimulation – Diskussion der Technik und Vergleich von Sprachen: Der Zweck dieses Papiers ist es, einen Vergleich einiger Computersimulationssprachen und einiger der am Vergleich von Softwarepaketen für digitale Computer beteiligten Sprachen zu präsentieren, die in Teil I diskutiert werden. Das Problem ist offensichtlich : Benutzer digitaler Computer müssen aus den verfügbaren Sprachen wählen oder ihre eigene schreiben. Insbesondere bei Schulung, Implementierung und Computerzeit können erhebliche Kosten entstehen, wenn eine ungeeignete Sprache gewählt wird. Immer mehr Computersimulationssprachen werden entwickelt: Vergleiche und Bewertungen bestehender Sprachen sind sowohl für Designer und Implementierer als auch für Benutzer nützlich. Der zweite Teil ist der Computersimulation und den Simulationssprachen gewidmet. Die rechnerischen Eigenschaften der Simulation werden diskutiert, wobei besonderes Augenmerk auf die Unterscheidung zwischen kontinuierlichen und diskreten Änderungsmodellen gelegt wird. Teil III präsentiert einen detaillierten Vergleich von sechs Simulationssprachen und -paketen: SIMSCRIPT, CLP, CSL, GASP, CPSS und SOL. Die Eigenschaften von jedem sind in einer Reihe von Tabellen zusammengefasst. Die Implikationen dieser Analyse für Programmierer von Sprachen, für Benutzer und für Implementierer werden entwickelt. Die Schlussfolgerung des Papiers ist, dass die jetzt verfügbaren Pakete für die Computersimulation Funktionen bieten, die keines der allgemeineren Pakete bietet, und dass die Analyse der Stärken und Schwächen jedes einzelnen Möglichkeiten aufzeigt, wie sowohl aktuelle als auch zukünftige Simulationssprachen und -pakete verbessert werden können ."}
{"DOCID": "1367", "TEXT": "Zeichenstruktur und Zeichenparitätssinn für parallele Datenkommunikation in ASCII* (vorgeschlagener amerikanischer Standard)"}
{"DOCID": "1368", "TEXT": "Systematische Erzeugung von Hamiltonkreisen: Für eine kombinatorische Matrix, die sowohl gerichtete als auch ungerichtete Bögen spezifizieren kann, beschreibt die Veröffentlichung ein Computerprogramm, das systematisch und erschöpfend alle Hamiltonkreise erzeugt. Spezielle Anwendung findet das \"Travelling Salesman\"-Problem."}
{"DOCID": "1369", "TEXT": "Halbrotationen im N-dimensionalen euklidischen Raum: Es wird ein iteratives Verfahren zum Bestimmen von Halbrotationen im n-dimensionalen euklidischen Raum beschrieben. Das Verfahren ist eine Variante des zyklischen Jacobi-Verfahrens und verwendet elementare Ebenenrotationen, um die Halbrotationsmatrix zu erhalten. Numerische Beispiele sind angegeben."}
{"DOCID": "1370", "TEXT": "Lineare Gleichungen, exakte Lösungen (Algorithmus 290 [F4])"}
{"DOCID": "1371", "TEXT": "Logarithmus der Gammafunktion (Algorithmus 291 [S14])"}
{"DOCID": "1372", "TEXT": "Direktsuche (Algorithmus 178 [E4])"}
{"DOCID": "1373", "TEXT": "Gamma-Funktion; Gamma-Funktion für Bereich 1 bis 2; Reziproke Gamma-Funktion zu Real-Argument; Gamma-Funktion; Logarithmus der Gammafunktion (Algorithmen 34[S14]; 54[S14]; 80[S14]; 221[S14]; 291[S14])"}
{"DOCID": "1374", "TEXT": "Bewertung der Determinante; Determinantenauswertung (Algorithmen 41[F3]; 269[F3])"}
{"DOCID": "1375", "TEXT": "Funktionsminimierung (Algorithmus 251 [E4])"}
{"DOCID": "1376", "TEXT": "Modifiziertes Graeffee-Verfahren (Algorithmus 256 [C2])"}
{"DOCID": "1377", "TEXT": "Pseudo-Zufallszahlen (Algorithmus 266 [G5])"}
{"DOCID": "1378", "TEXT": "Pseudo-Zufallszahlen (Algorithmus 266 [G5])"}
{"DOCID": "1379", "TEXT": "Eine endgültige Lösung für das Dangling-Else-Problem von ALGOL 60 und verwandten Sprachen: Das Dangling-Else-Problem besteht aus einer Klasse potenzieller Mehrdeutigkeiten in ALGOL-ähnlichen bedingten Anweisungen, deren Grundform „if B1 then if B2 then S1 else S2“ lautet, wobei B1 und B2 sind boolesche Ausdrücke und S1 und S2 sind grundlegende Anweisungen. Die Schwierigkeit liegt darin, ob man das else an das erste if oder an das zweite anhängt. Existierende Lösungen für das Problem sind entweder mehrdeutig oder unnötig restriktiv. Seien Sand S1 Aussagen. Wir definieren S als geschlossen, wenn „S sonst S1“ keine Aussage ist, und als offen, wenn „S sonst S1“ eine Aussage ist. Somit ist eine unbedingte Aussage eine geschlossene Aussage. Offene und geschlossene Bedingungsanweisungen werden durch Syntaxgleichungen so definiert, dass Offenheit und Geschlossenheit erhalten bleiben. In jedem Fall muss einem else immer eine geschlossene Anweisung vorangestellt werden. Es wird gezeigt, dass die Syntaxgleichungen eindeutig sind und dass eine Änderung der innerhalb der Syntaxgleichungen erforderlichen Anweisungstypen entweder zu Mehrdeutigkeiten oder unnötigen Einschränkungen führen würde."}
{"DOCID": "1380", "TEXT": "SIMULA – eine auf ALGOL basierende Simulationssprache: Dieses Dokument ist eine Einführung in SIMULA, eine Programmiersprache, die entwickelt wurde, um einem Systemanalytiker einheitliche Konzepte zur Verfügung zu stellen, die die präzise Beschreibung diskreter Ereignissysteme erleichtern. Eine Systembeschreibung dient auch als Quellsprachen-Simulationsprogramm. SIMULA ist eine Erweiterung von ALGOL 60, in der das wichtigste neue Konzept das der quasi-parallelen Verarbeitung ist."}
{"DOCID": "1381", "TEXT": "Einfluss von Computern auf den Lehrplan für Mathematik im Grundstudium: Die Verwendung von Computern, um die weit verbreitete Anwendung mathematischer Ideen zu ermöglichen, die Berechnungen in Wissenschaft und Technologie erfordern, ist für das Verständnis unserer gegenwärtigen Gesellschaft von äußerster Bedeutung. Das Interesse der Schüler an dieser Entwicklung ist sehr groß und sollte bei richtiger Nutzung zu einem viel besseren Verständnis mathematischer Konzepte sowie der Ideen der Programmierung und logischen Struktur führen, die durch den Einsatz von Computern in viele Bereiche eingeführt wurden. Das vorliegende Papier schlägt vor, dass der Teil des mathematischen Lehrplans für Grundschulabsolventen, der auf die Verwendung von Mathematik durch Personen vorbereitet, die keine professionellen Mathematiker sind, so modifiziert wird, dass er die Erweiterungen und Klarstellungen enthält, die aufgrund von Computern möglich sind. Eine frühzeitige Einführung in die Programmierung ist wünschenswert, um eine kontinuierliche Verwendung automatischer Berechnungen zur Veranschaulichung und Verdeutlichung mathematischer Konzepte zu ermöglichen. Nach der Analysis-Gleichungsphase sollte eine intensive Einführung in die Numerik in das aktuelle Curriculum aufgenommen werden. Zusätzlich zur Bereitstellung von Kompetenz in den am häufigsten verwendeten Computertechniken würde es eine anspruchsvollere Nutzung der fortgeschrittenen mathematischen Ideen ermöglichen, die mit komplexen Variablen und Transformationstheorien verbunden sind."}
{"DOCID": "1382", "TEXT": "Gewünschter Einfluss des Computers auf die Mathematik im Grundstudium: Hier werden drei Fragen zum Thema des Symposiums diskutiert. Der Autor untersucht einige Prognosen über Angebot und Nachfrage nach Mathematikern in den Vereinigten Staaten bis Mitte der 1970er Jahre, kommentiert kurz einige der Faktoren, die die beruflichen Aktivitäten von angewandten Mathematikern in den nächsten Jahren beeinflussen könnten, und erörtert in groben Zügen, wie diese Informationen können sich auf die Grundausbildung von Mathematikern beziehen."}
{"DOCID": "1383", "TEXT": "Implikationen des digitalen Computers für die Bildung in den mathematischen Wissenschaften: Der digitale Computer hat die Definition dessen, was in der Mathematik interessant ist, grundlegend verändert. Die Bedeutung der angewandten Logik in menschlichen Angelegenheiten ändert sich durch die Existenz der „logischen Maschine“. Das Ergebnis ist, dass man nicht mehr in einer einzigen mathematischen Disziplin, sondern in einem Komplex mathematischer Wissenschaften denken sollte."}
{"DOCID": "1384", "TEXT": "Mathematik für Bachelor-Informatiker: Die mathematischen Voraussetzungen für ein Bachelor-Studium der Informatik sind umstritten. Das Curriculum Committee der Association for Computing Machinery ist jedoch der Ansicht, dass diese Anforderungen im Wesentlichen die gleichen sind wie die mathematischen Inhalte von Bachelor-Programmen für Naturwissenschaften. Der Ausschuss ist der Ansicht, dass diese Anforderungen dem Studenten einen breiten mathematischen Hintergrund sichern und ihn in die Lage versetzen sollten, eine Vielzahl von Kursen in anderen wissenschaftlichen Disziplinen zu belegen. Das Anliegen des Komitees ist es, einen soliden wissenschaftlichen Zugang zur Informatik zu entwickeln."}
{"DOCID": "1385", "TEXT": "Computertechnologie im kommunistischen China, 1956-1965: Basierend auf Informationen aus Übersetzungen kommunistischer chinesischer Nachrichtenartikel und Zeitschriftenliteratur für die Zeit von 1965 wird die Computertechnologie in China unter den folgenden Überschriften untersucht: (1) anfängliche Planung, Organisation und Bildungsaspekte von Computertechnologie und Automatisierung; (2) Fortschritte bei der Maschinenentwicklung: zwei große spezifische Maschinen in den Jahren 1958-59 mit sowjetischer Hilfe; 1960-64 ein Vakuum aufgrund des Abzugs der sowjetischen Hilfe; dann vermutlich rein chinesische Maschinen von 1965 bis heute; (3) Computeranwendungen; (4) Trend Automatisierung: Steuerung von Produktionsprozessen statt Datenverarbeitung; und (5) die Kampagne \"Yun Ch'ou Hsueh\" (Wissenschaft der Operation und Programmierung) von 1958-60, während der versucht wurde, Konzepte wie lineare Programmierung den gewöhnlichen chinesischen Arbeitern und Bauern nahe zu bringen. Dem kommunistischen China wird eine marginale Computerkapazität zugesprochen, wobei die meisten seiner Maschinen wahrscheinlich binärer Natur sind; Mitte 1965 könnte jedoch ein Wendepunkt erreicht worden sein."}
{"DOCID": "1386", "TEXT": "Symbolisches Faktorisieren von Polynomen in mehreren Variablen: Ein Algorithmus zum Finden der symbolischen Faktoren eines multivariaten Polynoms mit ganzzahligen Koeffizienten wird vorgestellt. Der Algorithmus ist eine Erweiterung einer Technik, die von Kronecker verwendet wird, um zu beweisen, dass die Primfaktorzerlegung eines beliebigen Polynoms in einer endlichen Anzahl von Schritten gefunden werden kann. Der Algorithmus besteht aus dem Faktorisieren einzelner Variableninstanzen des gegebenen Polynoms durch das Kronecker-Verfahren und dem Einführen der verbleibenden Variablen durch Interpolation. Techniken zum Implementieren des Algorithmus und mehrere Beispiele werden diskutiert. Der Algorithmus verspricht ausreichend Leistung, um in einem Online-System für symbolische Mathematik effizient eingesetzt zu werden."}
{"DOCID": "1387", "TEXT": "Lösung von Systemen polynomischer Gleichungen durch Eliminierung: Das von Williams beschriebene Eliminierungsverfahren wurde in LISP und FORMAC codiert und zum Lösen von Systemen polynomischer Gleichungen verwendet. Es zeigt sich, dass das Verfahren im Fall kleiner Systeme sehr effektiv ist, wo es alle Lösungen liefert, ohne dass anfängliche Schätzungen erforderlich sind. Das Verfahren allein erscheint jedoch bei der Lösung großer Gleichungssysteme aufgrund des explosionsartigen Wachstums der Zwischengleichungen und der Gefahren, die beim Abschneiden der Koeffizienten entstehen, als ungeeignet. Es wird ein Vergleich mit Schwierigkeiten angestellt, die bei anderen Problemen in der nicht-numerischen Mathematik wie der symbolischen Integration und Vereinfachung zu finden sind."}
{"DOCID": "1388", "TEXT": "AUTOMAST: Automatische mathematische Analyse und symbolische Übersetzung: Ein Verfahren zum numerischen Lösen von Systemen gewöhnlicher Differentialgleichungen wird gezeigt, um auch symbolische Lösungen zu erzeugen. Das Verfahren basiert auf einer endlichen Taylor-Reihenentwicklung, die eine Schätzung des Fehlers im Endergebnis enthält. Es wird ein Computerprogramm beschrieben, das ein System solcher Gleichungen einliest und dann die Erweiterungen für alle abhängigen Variablen erzeugt. Die Erweiterungen werden symbolisch bestimmt, daher werden alle nicht numerischen Parameter in den ursprünglichen Gleichungen automatisch in die endgültigen Erweiterungen übernommen. So lässt sich der genaue Einfluss beliebiger Parameter auf die Problemlösung einfach darstellen."}
{"DOCID": "1389", "TEXT": "Beschreibung von L^6 durch einen Programmierer: Die Low-Linked-List-Sprache L^6 (ausgesprochen \"L-six\") der Bell Telephone Laboratories ist eine neue Programmiersprache für Manipulationen von Listenstrukturen. Es enthält viele der Funktionen, die solchen Listenprozessoren wie IPL, LISP, COMIT und SNOBOL zugrunde liegen, erlaubt dem Benutzer jedoch, viel näher an den Maschinencode heranzukommen, um schneller laufende Programme zu schreiben, den Speicher effizienter zu nutzen und ein breiteres System aufzubauen Vielzahl von verknüpften Datenstrukturen."}
{"DOCID": "1390", "TEXT": "CONVERT: Es wird eine Programmiersprache beschrieben, die auf Probleme anwendbar ist, die bequem durch Transformationsregeln beschrieben werden. Damit ist gemeint, dass Muster vorgeschrieben werden können, die jeweils einem Skelett zugeordnet sind, so dass eine Reihe solcher Paare durchsucht werden kann, bis ein Muster gefunden wird, das mit einem zu transformierenden Ausdruck übereinstimmt. Die Bedingungen für eine Übereinstimmung werden durch einen Code geregelt, der es auch ermöglicht, Unterausdrücke zu identifizieren und schließlich in das entsprechende Skelett einzusetzen. Die primitiven Muster und primitiven Skelette werden ebenso beschrieben wie das Prinzip, das ihre Ausarbeitung zu komplizierteren Mustern und Skeletten erlaubt. Die Vorteile der Sprache bestehen darin, dass sie es erlaubt, Transformationsregeln auf Listen und Arrays so einfach wie auf Strings anzuwenden, dass sowohl Muster als auch Skelette rekursiv definiert werden können und dass Programme folglich recht prägnant formuliert werden können."}
{"DOCID": "1391", "TEXT": "Computerexperimente in endlicher Algebra: Ein mittelgroßes Programmiersystem ist in MAD und FAP auf dem IBM 7094 geschrieben, um einige der Objekte der modernen Algebra zu manipulieren: endliche Gruppen, Abbildungen und Mengen von Abbildungen, Teilmengen und Mengen von Teilmengen, konstante ganze Zahlen und Wahrheitswerte. Das System wurde für den Betrieb in einer Time-Sharing-Umgebung entwickelt und kann als Lehrhilfe für den Studenten im Grundstudium der modernen Algebra sowie für den arbeitenden Wissenschaftler oder Ingenieur dienen, der sich mit der Teilmenge vertraut machen möchte."}
{"DOCID": "1392", "TEXT": "Erfahrung mit FORMAC Algorithm Design: Verschiedene Facetten des Designs und der Implementierung mathematischer Ausdrucksmanipulationsalgorithmen werden diskutiert. Konkrete Beispiele liefern FORMAC EXPAND und Differenzierungsalgorithmen, eine grundlegende FORMAC-Utility-Routine und ein Experiment zur Extraktion der Skelettstruktur eines Ausdrucks. Ein wiederkehrendes Thema ist die Notwendigkeit, ein übermäßiges Anschwellen der Zwischenausdrücke zu vermeiden, um die Kernspeicheranforderungen zu minimieren. Obwohl viele Details aus der FORMAC-Implementierung vorgestellt werden, wird ein Versuch unternommen, Prinzipien und Ideen von allgemeiner Relevanz beim Entwurf von Algorithmen zur Manipulation mathematischer Ausdrücke hervorzuheben."}
{"DOCID": "1393", "TEXT": "PM, A System for Polynomial Manipulation: PM ist ein IBM 7094-Programmsystem zur formalen Manipulation von Polynomen in einer beliebigen Anzahl von Variablen mit ganzzahligen Koeffizienten, deren Größe unbeschränkt ist. Einige der formalen Operationen, die von dem System durchgeführt werden können, sind Summen, Differenzen, Produkte, Quotienten, Ableitungen, Substitutionen und größere gemeinsame Teiler. PM basiert auf dem Listenverarbeitungssystem REFCO III, das beschrieben und mit den Systemen LISP und SLIP verglichen wird. Die PM-Subroutinen für die Arithmetik großer ganzer Zahlen werden als ein unabhängig nützliches Subsystem bildend beschrieben. PM wird in mehrfacher Hinsicht mit dem ALPAK-System verglichen, einschließlich der Wahl der kanonischen Formen für Polynome. Ein neuer Algorithmus für die Berechnung des größten gemeinsamen Teilers des Polynoms wird erwähnt, und Beispiele sind enthalten, um seine Überlegenheit zu veranschaulichen."}
{"DOCID": "1394", "TEXT": "Berechnung algebraischer Eigenschaften von Elementarteilchenreaktionen unter Verwendung eines digitalen Computers: Eine große Anzahl von Berechnungen in der Hochenergie-Elementarteilchenphysik beinhaltet die Manipulation komplizierter algebraischer Ausdrücke, die sowohl Tensor- als auch nichtkommutative Matrixgrößen enthalten. Viele dieser Berechnungen dauern mehrere Monate, obwohl die beteiligten Operationen einfachen Regeln folgen. In dieser Arbeit wird ein Programm beschrieben, das in LISP entwickelt wurde, um solche Probleme zu lösen. Die Art und Weise, wie diese Probleme auftreten, wird umrissen und ihre Darstellung im Computer diskutiert. Gegenwärtig dauert etwa sechs Monate menschlicher Arbeit auf einem IBM 7090 weniger als fünfzehn Minuten. Einschränkungen des gegenwärtigen Systems und Zukunftspläne werden ebenfalls skizziert."}
{"DOCID": "1395", "TEXT": "Zur Implementierung von AMBIT, einer Sprache zur Symbolmanipulation: Es wird eine kurze Beschreibung der Implementierungstechnik für die Ersetzungsregel der AMBIT-Programmiersprache gegeben. Der Algorithmus für den \"AMBIT-Scan\" und ein Beispiel seiner Anwendung werden angegeben. Der Algorithmus ist auf andere Mitglieder der Familie von Zeichenkettentransformationssprachen anwendbar, zu denen AMBIT gehört, und liefert eine Begründung für das Design der AMBIT-Sprache."}
{"DOCID": "1396", "TEXT": "Überblick über die Formelmanipulation: Der Bereich der Formelmanipulation wird mit besonderem Augenmerk auf die spezifischen Fähigkeiten der Differenzierung, Integration und die unterstützenden Fähigkeiten der Vereinfachung, Darstellungen und Ein-/Ausgabebearbeitung und Präzisionsarithmetik untersucht. Allgemeine Systeme – sowohl Batch als auch Online – werden beschrieben. Abschließend werden einige Programme zur Lösung spezifischer Anwendungen besprochen."}
{"DOCID": "1397", "TEXT": "Proceedings of the ACM Symposium on Symbolic and Algebraic Manipulation: Das ACM Symposium on Symbolic and Algebraic Manipulation brachte über vierhundert Personen zusammen, die sich für Programmiersprachen zur Manipulation algebraischer Formeln und Symbolketten, für ihre Anwendungen und für Algorithmen zu ihrer Implementierung interessierten. Achtundzwanzig Vorträge wurden präsentiert, gefolgt von einer lebhaften Podiumsdiskussion über zukünftige Richtungen. Für mehrere Interessengruppen wurden Abendveranstaltungen organisiert. Die Konferenz wurde vom ACM Special Interest Committee on Symbolic and Algebraic Manipulation gesponsert. Das Programmkomitee bestand aus dem Vorsitzenden Jean E. Sammet, Paul Abrahams, Thomas E. Cheatham, Max Goldstein und Douglas Mcllroy. Die Konferenzarrangements wurden von Lewis C. Clapp, Daniel Bobrow und James H. Griesmer getroffen. – Robert W. Floyd, Herausgeber"}
{"DOCID": "1398", "TEXT": "Robot Data Screening: A Solution to Multivariate Type Problems in the Biological and Social Sciences: Es wird ein neuer Ansatz zur Lösung multivariater Probleme skizziert, die üblicherweise in den Bio- und Sozialwissenschaften sowie in der Medizin anzutreffen sind. Dieser Ansatz verwendet eher ein \"logisches\" als ein \"statistisches\" Kriterium, durch das Variablen in einem deterministischen Modell gruppiert werden. Es werden Algorithmen entwickelt, durch die einige Variablen zur weiteren Analyse beibehalten werden, während andere eliminiert werden. Kriterien für die Annahme einer Variablen sowie den Abbruch des Suchvorgangs werden aus der Informationstheorie abgeleitet."}
{"DOCID": "1399", "TEXT": "Zur Top-to-Bottom-Erkennung und Linksrekursion: Es wird ein Verfahren angegeben, um strukturelle Beschreibungen in einer kontextfreien Grammatik zu erhalten, indem die Erkennung gemäß einer stark äquivalenten, linksrekursionsfreien Grammatik durchgeführt wird. Die Auswirkung des Zulassens von Nullzeichenfolgen in den Umschreibregeln wird diskutiert."}
{"DOCID": "1400", "TEXT": "Freitexteingaben in Hilfsroutinen: Durch die Verwendung einiger ziemlich einfacher Techniken ist es häufig möglich, ein Programm zu erzeugen, das Freitexteingaben akzeptiert. Die Techniken werden diskutiert und mit einer allgemeinen Bandmanipulationsroutine in Beziehung gesetzt."}
{"DOCID": "1401", "TEXT": "Quasilinearisierung und Eigenwertberechnung: Es werden mehrere Eigenwertprobleme für Systeme gewöhnlicher Differentialgleichungen betrachtet. Sie werden rechnerisch unter Verwendung der Quasilinerisierungstechnik aufgelöst, einem quadratisch konvergenten sukzessiven Approximationsschema, das mit der Newton-Raphson-Kantorovich-Methode verwandt ist."}
{"DOCID": "1402", "TEXT": "Teilschrittintegration: Eine Teilschrittintegrationsgleichung wird zur Verwendung mit der Adams- oder Adams-Bashforth-Methode zur Integration von Differentialgleichungen abgeleitet. Dieses Verfahren zum Erhalten von Funktionswerten an Punkten zwischen den Integrationspunkten ergibt eine mit der Integration vergleichbare Genauigkeit und erfordert keine Speicherung zusätzlicher Informationen wie bei Interpolationsverfahren."}
{"DOCID": "1403", "TEXT": "Ein Verfahren zum Finden der m kleinsten Werte einer monotonen Funktion, die auf geordneten Mengen positiver Ganzzahlen definiert ist: Der Minimalwert einer monoton ansteigenden Funktion, die auf einer teilweise geordneten Menge S definiert ist, wird auf der Menge der Minimalpunkte von S angenommen. Diese Beobachtung wird verwendet Entwicklung einer effizienten Methode zum Finden der m kleinsten Funktionswerte von monotonen Funktionen, die auf geordneten Paaren positiver ganzer Zahlen definiert sind. Das Verfahren lässt sich leicht erweitern, um monotone Funktionen einzubeziehen, die auf geordneten n-Tupeln definiert sind. Enthalten ist ein FORTRAN-Programm, das geschrieben wurde, um das Verfahren für einen bestimmten wichtigen Fall zu implementieren."}
{"DOCID": "1404", "TEXT": "Rechnerische Aspekte der multiplen Kovarianzanalyse an einer Multifaktorstruktur: Das rechnerische Vorgehen zur Analyse der multiplen Kovarianz in der Statistik wird anhand der Varianzanalyse diskutiert. Ein spezieller Operatorkalkül, der von Hartly entwickelt wurde, um die Varianzanalyse für Multifaktor-Experimente zu programmieren, wird erweitert, um die Analyse der Kovarianz abzudecken. Diese Erweiterung wird erreicht, indem die Verbindung zwischen der Kovarianzanalyse und der Varianzanalyse genutzt und ein neuer Operator eingeführt wird. Die Ergebnisse werden durch ein numerisches Beispiel zur Kovarianzanalyse veranschaulicht, in dem gezeigt wird, dass die grundlegenden Berechnungen von einem Varianzanalyseprogramm durchgeführt werden."}
{"DOCID": "1405", "TEXT": "Matrixtriangulation mit ganzzahliger Arithmetik (Algorithmus 287 [F1])"}
{"DOCID": "1406", "TEXT": "Lösung simultaner linearer diophantischer Gleichungen (Algorithmus 288 [F4])"}
{"DOCID": "1407", "TEXT": "Konfidenzintervall für ein Verhältnis (Algorithmus 289 [G1])"}
{"DOCID": "1408", "TEXT": "Das Eschenbach Drum Scheme: Die Hauptfunktion einer in Echtzeit arbeitenden Trommel besteht darin, Zugriffe schnell durchzuführen. Das übliche Mittel zur Erhöhung dieser Kapazität besteht darin, technische oder Hardware-Verbesserungen zu integrieren. In dieser Veröffentlichung wird das Problem nicht durch einen Austausch der Trommel angegangen, sondern vielmehr durch eine Modifizierung der Art und Weise, in der sie arbeitet. Zu Beginn wird eine Trommel funktional definiert. Dann wird ein einfaches Konstruktionsschema (Eschenbach) eingeführt, das die Zugriffsrate für so definierte Trommeln enorm erhöht. Es wird gezeigt, dass dies einem System ermöglicht, eine Aufgabe auszuführen, indem es weniger oder billigere Trommeln verwendet. Es wird vorgeschlagen, dass das Entwurfsschema zwar eine spezifische Verwendung hat, das zugrunde liegende Verfahren jedoch eine allgemeinere Anwendbarkeit hat. Dann stellt sich die Frage nach der Wirksamkeit des Trommelschemas. Um damit umzugehen, wird ein Effizienzstandard unter Berücksichtigung realistischer Echtzeitbedingungen entwickelt. Das Trommelschema wird dann so modelliert, dass es als Problem der Warteschlangentheorie analysiert werden kann. Somit kann festgestellt werden, ob das Trommelschema für seine Anwendung effizient genug ist. Während die Analyse des Trommelschemas wiederum einen spezifischen Nutzen hat, haben die ihr zugrunde liegenden Methoden eine allgemeinere Anwendbarkeit."}
{"DOCID": "1409", "TEXT": "NEBULA: Ein digitaler Computer, der einen 20-Mc-Glasverzögerungsleitungsspeicher verwendet: Die Oregon State University hat einen seriellen Digitalcomputer mittlerer Geschwindigkeit entworfen und gebaut, der Glasverzögerungsleitungen verwendet, die mit 22 Mc als Speicher zirkulieren. Die Designziele, wie sie ursprünglich in einem Spezialseminar konzipiert wurden, waren: (1) ein Forschungsprojekt im Computerdesign zu sein; (2) als Lernmaschine nutzbar zu sein; und (3) über leicht modifizierbare Hardware für die Grundlagenforschung im Computersystemdesign zu verfügen. Eine ungewöhnliche Informationsanordnung innerhalb des 22-Mc-Speichers ermöglicht eine einfache Schnittstelle mit der 340-Kc-Arithmetikeinheit, was zu einer effektiven Null-Latenzzeit führt und Möglichkeiten für einen assoziativen Speicher bietet. Die Arithmetikeinheit hat eine Befehlsstruktur, die großen parallelen Maschinen ähnlich ist, und verwendet durchgehend Flip-Flop-Arithmetik- und Steuerregister. Die gesamte Hardwareentwicklung wurde auf das Konzept der einfachen Modifizierung, ausgeklügelten Konsolensteuerungen für eine effektive Mensch-Maschine-Interaktion und niedrige Kosten ausgerichtet."}
{"DOCID": "1410", "TEXT": "Zwischenankunftsstatistik für Time-Sharing-Systeme: Die Optimierung der Performance von Time-Sharing-Systemen erfordert die Beschreibung der stochastischen Prozesse, die die Benutzereingaben und die Programmaktivität bestimmen. Dieses Papier bietet eine statistische Beschreibung des Benutzereingabeprozesses im SDC-ARPA-Allzweck-Time-Sharing-System (TSS). Es wird angenommen, dass der Eingabeprozess stationär ist und durch die Zwischenankunftszeitverteilung definiert ist. Die erhaltenen Daten scheinen die allgemeine Annahme, dass die Zwischenankunftszeiten seriell unabhängig sind, zufriedenstellend zu rechtfertigen. Die Daten scheinen, abgesehen von einer sehr groben Annäherung, die übliche Annahme einer Exponentialverteilung für die Zwischenankunftszeit nicht zu rechtfertigen. Eine viel zufriedenstellendere Annäherung an die Daten kann mit einer zweiphasigen oder dreiphasigen hyperexponentiellen Verteilung erhalten werden."}
{"DOCID": "1411", "TEXT": "Vergleich mehrerer Algorithmen zur Berechnung von Mittelwerten, Standardabweichungen und Korrelationskoeffizienten: Mehrere Algorithmen zur Berechnung grundlegender Statistiken werden anhand ihrer Leistung auf systematisch generierten Testdaten verglichen. Die berechneten Statistiken waren Mittelwert, Standardabweichung und Korrelationskoeffizient. Für jede Statistik enthielt der Algorithmus die üblichen Berechnungsformeln, eine Korrektur aufgrund eines akkumulierten Fehlerterms und eine rekursive Berechnung des aktuellen Werts der Statistik. Auch die üblichen Rechenformeln wurden in doppelter Genauigkeit ausgewertet. Bei einigen Berechnungen mit den üblichen Berechnungsformeln wurden große Fehler festgestellt. Die zuverlässigste Technik war die Korrektur der anfänglichen Schätzung durch Verwendung eines akkumulierten Fehlerterms. Um die Notwendigkeit zu beseitigen, die Daten zweimal zu durchlaufen, wurde vorgeschlagen, dass die anfängliche Schätzung des Mittelwerts aus einer Teilmenge der Daten erhalten wird."}
{"DOCID": "1412", "TEXT": "Das Konzept des Bankinformationssystems: Die meisten großen Geschäftsbanken sind bis zu dem Punkt fortgeschritten, an dem ihre Hauptbuchhaltungsanwendungen automatisiert wurden und eine ausgeklügeltere Verwendung von Datenverarbeitungsgeräten angestrebt wird. Dies hat in Verbindung mit der Verfügbarkeit von Ausrüstung, die für eine Verarbeitung mit direktem Zugriff in Echtzeit gut geeignet ist, in einigen Banken zur Entwicklung des Ansatzes einer zentralen Datei einer Datenbank in Richtung eines Bankinformationssystems geführt. Das Bankinformationssystem dient nun dem zweifachen Zweck, Echtzeit-Antworten auf Anfragen über den Status einzelner Konten bereitzustellen und komplexere Kombinationen von Informationen zur Verwendung durch das Management bereitzustellen. Beide Verarbeitungsarten stützen sich auf einen gemeinsamen Datenspeicher, der in der Zentraldatei mit direktem Zugriff enthalten ist. Diese Datenbank enthält Indizes, die den Querverweis von Kontoinformationen erleichtern, so dass alle Beziehungen zwischen Bank und Kunde erkannt werden können. Bei der Einführung des Konzepts des Bankinformationssystems ist ein schrittweiser Ansatz für Kontoquerverweise und Dateikonvertierung am vernünftigsten. Im Allgemeinen muss dieses System mit anderen Computeranwendungen, die bereits in der Bank vorhanden sind, eine Schnittstelle bilden."}
{"DOCID": "1413", "TEXT": "Eine Vision von Technologie und Bildung: Bildungstechnologie ist derzeit ziemlich in Mode. Hier, wie in vielen anderen Bereichen oder Aspekten der Technologie, werden Änderungen, die in der nächsten oder zweiten Generation möglich sind, jetzt als Ideen, Entdeckungen oder Erfindungen bezeichnet. Ungewiss ist, ob das Potenzial zum Tatsächlichen wird und wenn ja, in welchem ​​Zeitraum. Diese Unwissenheit rührt größtenteils von Unwissenheit über die gesellschaftliche Reaktion auf potenzielle technologische Veränderungen her. Das Ziel dieses Beitrags ist es, eine Vision von potenzieller Bildungstechnologie zu präsentieren und Fragen zu den Formen der sozialen Reaktion und Anpassung aufzuwerfen, die wahrscheinlich durch eine solche Vision hervorgerufen werden."}
{"DOCID": "1414", "TEXT": "Zwölfreihiger Lochkartencode für den Informationsaustausch* (vorgeschlagener amerikanischer Standard)"}
{"DOCID": "1415", "TEXT": "Automatische Ableitung von Mikrosätzen: Die Zerlegung von langen, komplexen englischen Sätzen in kürzere, kernähnliche Satzbestandteile (Mikrosätze) wurde oft als ein Weg zum automatischen Abrufen von Nachrichten in natürlicher Sprache vorgeschlagen. Um die Aussichten eines solchen Schrittes zu erkunden, versuchten die Autoren 1963, ein allgemeines Programm zur Ableitung von Mikrosätzen aus längeren Sätzen vorzubereiten, die vom Harvard Multipath Analysis Program syntaktisch analysiert worden waren. Die Grundidee war, Subjekt, Verb und Objekt (falls vorhanden) aus jedem Satz zu extrahieren und diese Materialien zu einem grammatikalischen Mikrosatz zusammenzusetzen. In diesem Artikel wird ein Programm beschrieben, das entworfen wurde, um mit der Baumstrukturausgabe des Analysators zu arbeiten, und die erzeugten Mikrosätze sind ausgestellt. Die Autoren kommen zu dem Schluss, dass Mikrosätze in der erreichten Qualität zwar keine unmittelbaren Aussichten auf eine Verbesserung der Leistung automatischer Nachrichtenabrufsysteme eröffnen, aber einen praktischen Wert in Mensch-Maschine-Systemen haben können, die menschliche Monitore verwenden, um die bevorzugte syntaktische Interpretation eines Satzes auszuwählen."}
{"DOCID": "1416", "TEXT": "Eine Fortran-Technik zur Vereinfachung der Eingabe in Berichtsgeneratoren: Typische Berichtsgeneratoren ermöglichen die Erstellung von Standardformularen beim Tabellieren einer Magnetbanddatei; Das Extrahieren von nicht standardmäßigen Informationssätzen mit geeigneter Anmerkung erfordert ein mühsames Formulardesign. Es wird ein Verfahren zur Informationsextraktion beschrieben, das die Berechnung geeigneter FORTRAN-FORMAT-Anweisungen beinhaltet, das dieses Problem bekämpft."}
{"DOCID": "1417", "TEXT": "Skaleneffekte und das IBM System/360: Kostenfunktionen zwischen fünf System/360-Modellen werden durch Untersuchungen von Unterrichtszeiten, Programmkernen und einem \"typischen\" Unterrichtsmix analysiert. Es werden Vergleiche zwischen den hier entwickelten Daten und dem Groschschen Gesetz angestellt, das auf einen Großteil der Daten anwendbar zu sein scheint. Beträchtliche Größenvorteile sind zweifellos bei Computergeräten vorhanden."}
{"DOCID": "1418", "TEXT": "Prüfungsplanung (Algorithmus 286 [ZH])"}
{"DOCID": "1419", "TEXT": "Tschebyscheff-Quadratur (Algorithmus 279 [D1])"}
{"DOCID": "1420", "TEXT": "Ein neuer einheitlicher Pseudozufallszahlengenerator: Ein neuer multiplikativer kongruenter Pseudozufallszahlengenerator wird diskutiert, bei dem der Modulus die größte Primzahl innerhalb der Akkumulatorkapazität ist und der Multiplikator eine primitive Wurzel dieser Primzahl ist. Dieser Generator besteht die üblichen statistischen Tests und zusätzlich erscheinen die niedrigstwertigen Bits genauso zufällig wie die höchstwertigen Bits – eine Eigenschaft, die Generatoren mit Modulus 2^k nicht besitzen."}
{"DOCID": "1421", "TEXT": "Ein Beitrag zur Entwicklung von ALGOL: Eine Programmiersprache, die ALGOL 60 in vielerlei Hinsicht ähnlich ist, aber eine große Anzahl von Verbesserungen enthält, die auf sechs Jahren Erfahrung mit dieser Sprache basieren, wird im Detail beschrieben. Teil I besteht aus einer Einführung in die neue Sprache und einer Zusammenfassung der Änderungen, die an ALGOL 60 vorgenommen wurden, zusammen mit einer Diskussion der Motive hinter ihren Visionen. Teil II ist eine strenge Definition der vorgeschlagenen Sprache. Teil III beschreibt eine Reihe von vorgeschlagenen Standardprozeduren, die mit der Sprache verwendet werden sollen, einschließlich Einrichtungen für Eingabe/Ausgabe."}
{"DOCID": "1422", "TEXT": "Perforiertes Papierband mit elf Sechzehntel Zoll (vorgeschlagener amerikanischer Standard)"}
{"DOCID": "1423", "TEXT": "Ein einfacher Algorithmus zur Berechnung des verallgemeinerten Inversen einer Matrix: Das verallgemeinerte Inverse einer Matrix ist in der Analyse wichtig, da es eine Erweiterung des Konzepts eines Inversen darstellt, das für alle Matrizen gilt. Es hat auch viele Anwendungen in der numerischen Analyse, aber es wird nicht weit verbreitet verwendet, weil die existierenden Algorithmen ziemlich kompliziert sind und beträchtlichen Speicherplatz benötigen. Es wurde eine einfache Erweiterung des herkömmlichen Orthogonalisierungsverfahrens zum Invertieren nicht-singulärer Matrizen gefunden, die mit wenig zusätzlichem Aufwand und ohne zusätzlichen Speicherbedarf die verallgemeinerte Inverse liefert. Der Algorithmus gibt die verallgemeinerte Umkehrung für jede m mal n-Matrix A an, einschließlich des Sonderfalls, wenn m + n und A nicht singulär ist, und des Falls, wenn m > n und Rang (A) = n. Im ersten Fall liefert der Algorithmus die gewöhnliche Inverse von A. Im zweiten Fall liefert der Algorithmus die gewöhnliche Transformationsmatrix der kleinsten Quadrate INV(A'A)A' und hat den Vorteil, den Signifikanzverlust zu vermeiden, der zur Bildung des Produkts führt A'A ausdrücklich."}
{"DOCID": "1424", "TEXT": "Automatische Analyse elektronischer digitaler Schaltungen unter Verwendung von Listenverarbeitung: Es wird eine Abbildung von schwarzen Diagrammen digitaler Schaltungen auf Listenstrukturen zusammen mit einem für die Steuerdaten 3600 geschriebenen Listenverarbeitungsprogramm beschrieben, das diese Abbildung verwendet, um automatisch eine Schaltungsanalyse durchzuführen."}
{"DOCID": "1425", "TEXT": "Flussdiagramme, Turingmaschinen und Sprachen mit nur zwei Bildungsregeln: Im ersten Teil der Arbeit werden Flussdiagramme vorgestellt, um u.a. Abbildungen einer Menge in sich selbst. Obwohl nicht jedes Diagramm in eine endliche Anzahl gegebener Basisdiagramme zerlegbar ist, wird dies auf semantischer Ebene durch eine geeignete Erweiterung der gegebenen Menge und der darin definierten Grundabbildungen wahr. Es werden zwei Normalisierungsverfahren von Flussdiagrammen angegeben. Das erste hat drei Basisdiagramme; die zweite, nur zwei. Im zweiten Teil der Arbeit wird die zweite Methode auf die Theorie der Turingmaschinen angewendet. Jeder Turing-Maschine, die mit einem Zwei-Wege-Halbband ausgestattet ist, ist eine ähnliche Maschine zugeordnet, die im Wesentlichen die gleiche Arbeit verrichtet, aber an einem Band arbeitet, das von der ersten erhalten wurde, indem abwechselnd leere Quadrate eingestreut wurden. Die neue Maschine gehört zu der an anderer Stelle vorgestellten Familie, die durch Zusammensetzung und Iteration aus den beiden Maschinen L und R erzeugt wird. Diese Familie ist eine richtige Unterfamilie der ganzen Familie der Turing-Maschinen."}
{"DOCID": "1426", "TEXT": "Eine Simulation der Krankenhauseinweisungspolitik: Es wird eine Studie beschrieben, die verschiedene Aufnahmerichtlinien eines großen spezialisierten Krankenhauses simuliert. Ziel ist es, bessere Richtlinien zur Stabilisierung der Aufnahme- und Volkszählungsraten festzulegen und gleichzeitig ein einigermaßen volles Krankenhaus aufrechtzuerhalten. Es wurden verschiedene Arten von Richtlinien untersucht: Zulassung auf der Grundlage von Prozentsätzen der Entlassungssätze, Entlassungssätze plus oder minus einer Konstante und feste Genehmigungen unabhängig von Entlassungssätzen. Die letzte Typenrichtlinie führte zu stabileren simulierten Ergebnissen, und in der Praxis wurden Verbesserungen realisiert."}
{"DOCID": "1427", "TEXT": "Simulation von Radioisotopen-Scans per Computer: Beim Radioisotopen-Scannen, einem Gebiet, das in der medizinischen Diagnostik zunehmend an Bedeutung gewinnt, ist der Scan ein zweidimensionales Muster aus Punkten. Bereiche mit erhöhter Quellenaktivität werden auf dem Scan durch Bereiche mit erhöhter Punktdichte dargestellt. Um die Ausgabe von Scannern mit verschiedenen Eigenschaften zu untersuchen, wurde ein Programm geschrieben, das Radioisotopenscans simuliert, für einen PDP-1-Computer mit zusätzlichem Plattenspeicher und Kathodenstrahlröhrenanzeige. Frühere und gegenwärtige Forschung unter Verwendung der Ausgabe des Simulators hat gezeigt, dass die Flexibilität des Systems wichtig ist. Die Struktur dieses Programms kann bei der Simulation der Ausgabe eines beliebigen quantenbegrenzten Systems nützlich sein."}
{"DOCID": "1428", "TEXT": "SHOCK III, ein Computersystem als Hilfsmittel bei der Behandlung von Patienten in kritischem Zustand: SHOCK III, ein digitales Online-Computersystem zur Unterstützung von Ärzten, Krankenschwestern und medizinischem Personal bei der Überwachung und Meldung von Patienten in kritischem Zustand, wird beschrieben."}
{"DOCID": "1429", "TEXT": "Matrixreduktion unter Verwendung der ungarischen Methode zur Generierung von Schulstundenplänen: Die Anwendung der ungarischen Methode von Kuhn auf das Problem der Matrixreduktion, wie sie in Gotliebs Methode zur Stundenplangenerierung benötigt wird, wird beschrieben. Das Verfahren eignet sich sowohl für Hand- als auch für Computerberechnungen. Es werden Vorrichtungen zur Verbesserung der Effizienz des Basisalgorithmus diskutiert."}
{"DOCID": "1430", "TEXT": "Gleitkommakonvertierung mit mehrfacher Genauigkeit von Dezimal zu Binär und umgekehrt: Die Gleitkommakonvertierung von Dezimal zu Binär und Binär zu Dezimal wird häufig unter Verwendung einer Tabelle der Potenzen 10^i (z. B. positive Ganzzahl) durchgeführt. zum Umwandeln von der Basis 10 in die Basis 2, und unter Verwendung einer Tabelle der Koeffizienten einer Polynomnäherung von 10^x, (0<=x<1) zum Umwandeln von der Basis 2 in die Basis 10. Diese Tabellen nehmen einen großen Speicherbereich ein im Fall einer Konvertierung mit nicht einfacher Genauigkeit. Dieses Papier zeigt, dass eine einzige kleine Tabelle für eine Fließkomma-Konvertierung von Dezimal zu Binär und umgekehrt mit jeder brauchbaren Genauigkeit ausreicht."}
{"DOCID": "1431", "TEXT": "Über eine Speicherabbildungsfunktion für Datenstrukturen: Einige grundlegende Tatsachen über bestimmte Datenstrukturen werden überprüft, und es wird ein effizienter Algorithmus vorgestellt, um eine Speicherabbildungsfunktion für eine Struktur aus der Definition der Struktur zu konstruieren."}
{"DOCID": "1432", "TEXT": "Einbau von Nicht-Standard-Eingabe/Ausgabe-Geräten in FORTRAN-Systeme: Ein FORTRAN-System kann leicht modifiziert werden, um Eingabe/Ausgabe mit Nicht-Standard-Medien auf der gleichen Basis zu handhaben, auf der es die Standard-Medien handhabt. Dies erfolgt durch Bereitstellen einer Zeichenbehandlungs-Unterroutine, die für das Nicht-Standard-Medium geeignet ist und so eingerichtet ist, dass sie von einem ansonsten unbenutzten Ausgabeanweisungstyp oder einer Einheitsnummer aufgerufen wird. Dieses Verfahren wurde verwendet, um die Ausgabe von alphanumerischen Informationen auf einem digitalen Graphenplotter zu steuern."}
{"DOCID": "1433", "TEXT": "Eine Anmerkung zum Entwurf linearer Programmieralgorithmen: Ein kombinatorisches Problem: Da lineare Programmiermodelle immer größer werden, werden viele tatsächliche Daten, die gespeichert werden müssen, oft auf Magnetband oder -platte gespeichert, und folglich steigt der Verbrauch unverhältnismäßig schnell an der Rechenzeit. Um diesen Aufwand zu reduzieren, werden immer größere Anstrengungen unternommen, um effizientere Algorithmen zu entwerfen. Dieses Papier soll die Bemühungen unterstützen. Es wird versucht, einige Merkmale der Art und Weise zu finden, wie eine Pivot-Spalte gefunden wird. Die Anzahl der Wiederholungen einer bestimmten Übertragung von Daten vom Band zum Kernspeicher wird berücksichtigt. Nach einiger Vereinfachung wird das Problem allgemein formuliert. Die erzeugende Funktion der Wahrscheinlichkeitsverteilung und die momenterzeugende Funktion der Anzahl der Wiederholungen wird gefunden. Asymptotische Formeln werden für die Momente unter Verwendung eines Ergebnisses aus einer Arbeit von S. Narumi [1] angegeben. Die Ergebnisse können angewendet werden, um sehr effiziente Routinen zu schreiben, die nach einem Extremwert in einer Tabelle suchen. Formeln bieten in diesem Fall eine Möglichkeit, die Computerzeiten zu berechnen."}
{"DOCID": "1434", "TEXT": "Ein Monte-Carlo-Algorithmus für die Zuweisung von Schülern zu Klassen: Eine Technik der Zufallsauswahl wird durch die Anwendung auf das Problem der Zuweisung von Schülern zu einem festen Zeitplan von Kursen veranschaulicht. Unter Verwendung der Technik ist es möglich, Schwierigkeiten zu verringern oder zu beseitigen, die sich ergeben, wenn ein beliebter Abschnitt gefüllt und geschlossen wird, bevor alle Studenten, die ihn anfordern und benötigen, geplant worden sind. Die Effektivität der automatischen Terminplanung bleibt erhalten, ohne dass das Privileg der Schüler verloren geht, Lieblingslehrer auszuwählen."}
{"DOCID": "1435", "TEXT": "Design von Computersimulationsexperimenten für industrielle Systeme: Das Ziel dieses Beitrags ist es, Hintergrundinformationen über die vorhandene Literatur zu experimentellen Designtechniken bereitzustellen, die auf das Design von Computersimulationsexperimenten für industrielle Systeme anwendbar sein können. Obwohl ein Hauptaugenmerk auf Varianzanalysetechniken gelegt wird, werden drei andere Techniken der Datenanalyse in Betracht gezogen - multiple Ranking-Verfahren, sequentielles Sampling und Spektralanalyse. Das Papier behandelt vier spezifische experimentelle Entwurfsprobleme und mehrere Techniken zu ihrer Lösung. Die vier experimentellen Designprobleme sind: (1) das Problem der stochastischen Konvergenz, (2) das Problem der Faktorauswahl, (3) das Motivproblem und (4) das Problem der vielen Antworten."}
{"DOCID": "1436", "TEXT": "Austausch zweier Datenblöcke (Algorithmus 284 [K2])"}
{"DOCID": "1437", "TEXT": "Das Mutual Primal-Dual-Verfahren (Algorithmus 285 [H])"}
{"DOCID": "1438", "TEXT": "Ein Verfahren zum Lokalisieren von Nullstellen komplexer Funktionen: Ein Verfahren zum Berechnen des Index oder der Windungszahl wird entwickelt und auf das Problem angewendet, Nullstellen von Funktionen von der Ebene in die Ebene zu finden."}
{"DOCID": "1439", "TEXT": "Mechanisierung des Kurvenanpassungsprozesses: DATAN: Ein Prozess zum Anpassen einer Kurve an angenäherte Daten und das Problem, das er für den Ingenieur-Programmierer erzeugt, wird definiert. Es wurde auch ein Ansatz definiert und ein System für die SRU 1107 geschrieben, um einen Hauptteil dieses Prozesses zu mechanisieren. Die Techniken, die entwickelt wurden, um die Mechanisierung zu erreichen, sind größtenteils empirisch und für ihre Information nur von den tatsächlichen Datenpunkten abhängig."}
{"DOCID": "1440", "TEXT": "Startnäherungen für die Quadratwurzelberechnung auf IBM System/360: Mehrere Startnäherungen für die Quadratwurzelberechnung nach dem Newton-Verfahren werden in einem Formular dargestellt, um ihre Verwendung in IBM System/360-Quadratwurzelroutinen zu erleichtern. Diese Annäherungen schließen mehrere für den Bereich [1/16, 1] ein, der das Intervall von primärem Interesse auf IBM System/360 ist."}
{"DOCID": "1441", "TEXT": "Methoden der numerischen Integration, die auf ein System mit trivialen Funktionsauswertungen angewendet werden: Es wurde eine Studie durchgeführt, um zu bestimmen, welche Methoden der numerischen Integration die geringste Rechenzeit für eine bestimmte Menge an Abschneidefehlern erfordern, wenn sie auf ein bestimmtes System gewöhnlicher Differentialgleichungen angewendet werden, bei denen Funktionsauswertungen durchgeführt werden sind relativ trivial. Neuere Methoden nach Butcher and Gear werden mit klassischen Runge-Kutta-, Kutta-Nystrom- und Adams-Methoden verglichen. Einige der neueren Ein-Schritt-Methoden von Butcher haben sich als etwas überlegen herausgestellt, aber keine Methode hat bei der Anwendung auf dieses spezielle Problem einen großen Vorteil gegenüber den anderen."}
{"DOCID": "1442", "TEXT": "Bespieltes Magnetband für den Informationsaustausch (800 CPI, NRZI)* (vorgeschlagener amerikanischer Standard)"}
{"DOCID": "1443", "TEXT": "Eine Methode zum Finden der Schätzung der kleinsten Quadrate des Schnittpunkts zweier Spiralen im Raum: Wenn die spiralförmigen Flugbahnen zweier geladener Teilchen, die sich von einem gemeinsamen Punkt in einem Magnetfeld entfernen, aus Messungen an den Spuren rekonstruiert werden, werden die rekonstruierten Spuren gestört durch Mess- und andere Fehler und überschneiden sich im Allgemeinen nicht. Es wird ein Verfahren zum Anpassen der rekonstruierten Spuren nach der Methode der kleinsten Quadrate angegeben, so dass sie sich schneiden."}
{"DOCID": "1444", "TEXT": "Ein Algorithmus zum Generieren von projektiven Reduktionsformeln für Matrixelemente von Vielelektronen-Wellenfunktionen: Eine ALGOL-Prozedur wird zum automatischen Generieren von Formeln für Matrixelemente angegeben, die in der Variationslösung der Schrödinger-Gleichung für Vielelektronensysteme auftreten."}
{"DOCID": "1445", "TEXT": "Einsatz des Computers zur Einführung in die Statistik: Es war schon immer offensichtlich, dass die Rechenhilfe des Computers eine Änderung der Lehrpläne in Mathematik, Statistik, Physik, Ingenieurwissenschaften und anderen Studiengängen erzwingt. Nicht so offensichtlich sind die vielen pädagogischen Hilfen, die der Computer bei der Vermittlung des Unterrichtsstoffs bieten kann. Die Möglichkeiten, den Studenten ein besseres technisches und konzeptionelles Verständnis der Statistik zu vermitteln, wurden mehrere Jahre am College of Medicine der University of Cincinnati erforscht und werden hier beschrieben."}
{"DOCID": "1446", "TEXT": "Tschebyscheff-Quadratur (Algorithmus 279 [D1])"}
{"DOCID": "1447", "TEXT": "Abszissen und Gewichte für Gregory-Quadratur [D1])"}
{"DOCID": "1448", "TEXT": "Abszissen und Gewichte für die Romberg-Quadratur (Algorithmus 281 [D1])"}
{"DOCID": "1449", "TEXT": "Ableitungen (Algorithmus 282 [S22])"}
{"DOCID": "1450", "TEXT": "Gleichzeitige Verschiebung von Polynomwurzeln, falls reell und einfach (Algorithmus 283 [C2])"}
{"DOCID": "1451", "TEXT": "Runge-Kutta-Integration (Algorithmus 9 [D2])"}
{"DOCID": "1452", "TEXT": "Kutta-Merson (Algorithmus 218 [D2]"}
{"DOCID": "1453", "TEXT": "Eine nichtrekursive Methode zur Syntaxspezifikation: Die Verwendung der Kleene-Notation für reguläre Ausdrücke zur Beschreibung der Syntax algebraischer Sprache, insbesondere von ALGOL, wird in diesem Artikel beschrieben. Ein FORTRAN-II-Computerprogramm zum Ausführen des Eliminationsalgorithmus von Gorn, ähnlich der Gaußschen Elimination für lineare Systeme algebraischer Gleichungen, wird beschrieben. Dies wurde auf zahlreiche kleinere Sprachen angewendet, einschließlich einiger Untersprachen von ALGOL. Ein Handberechnungsergebnis der Anwendung des Algorithmus auf das gesamte ALGOL ist gegeben, wodurch die überarbeitete ALGOL-1960-Syntax in vollständig nichtrekursiven Ausdrücken ausgedrückt wird, soweit es ihren kontextfreien Teil betrifft. Diese Beschreibung ist in vielerlei Hinsicht weitaus intuitiver verständlich als die vorherige rekursive Beschreibung, wird vorgeschlagen. Das Papier enthält auch Ergebnisse des Maschinenprogramms, das keinen Vereinfachungsalgorithmus enthält."}
{"DOCID": "1454", "TEXT": "Eine einfache benutzerorientierte Compiler-Quellsprache zum Programmieren automatischer Testgeräte: Für den Nichtprogrammierer steigt die Schwierigkeit bei der Verwendung einer Sprache schnell mit der Anzahl nicht problemorientierter Konventionen. Eine einfache Sprache, wenn auch unelegant, die den Hintergrund des Benutzers als Teil des Problems betrachtet, kann effektiver sein als eine Ausgangssprache mit subtilen und leistungsfähigeren Fähigkeiten. Die in diesem Dokument beschriebene Sprache wird verwendet, um Computerprogramme zu schreiben, die elektronische Geräte testen. Da dieser Testprozess wenige komplexe Ideen enthält, besteht wenig Bedarf an der Eleganz und Redundanz einer stark syntaxorientierten Sprache. Für das Problem genügt eine einfache und direkte Sprache. Die späteren Benutzer dieser Sprache sind Militärdepots, von denen nicht erwartet werden kann, dass sie über Computerprogrammierkenntnisse oder eine signifikante Programmierausbildung verfügen. Für diesen nicht programmierorientierten Benutzer war es wichtig, eine Sprache mit vertrauten technischen Anweisungen zu erstellen; Programmierorientierte Konventionen hätten seine Aufgabe unnötig erschwert."}
{"DOCID": "1455", "TEXT": "TRAC, eine verfahrensbeschreibende Sprache für die reaktive Schreibmaschine: Es wird eine Beschreibung der Sprache TRAC (Text Reckoning And Compiling) und des Verarbeitungsalgorithmus gegeben. Die TRAC-Sprache wurde als Basis eines Softwarepakets für die reaktive Schreibmaschine entwickelt. In der TRAC-Sprache kann man Prozeduren zum Akzeptieren, Benennen und Speichern beliebiger Zeichenketten von der Schreibmaschine schreiben; um beliebige Zeichenfolgen in irgendeiner Weise zu ändern; um jeden String jederzeit als ausführbare Prozedur oder als Namen oder als Text zu behandeln; und zum Ausdrucken einer beliebigen Zeichenfolge. Die TRAC-Sprache basiert auf einer Erweiterung und Verallgemeinerung des Programmierkonzepts des \"Makros\" auf Zeichenketten. Durch die Fähigkeit von TRAC, Definitionen von Prozeduren zu akzeptieren und zu speichern, können die Fähigkeiten der Sprache unbegrenzt erweitert werden und mit Zeichenketten, ganzen Zahlen und booleschen Vektorvariablen umgehen."}
{"DOCID": "1456", "TEXT": "Speicherung und Abruf von Bedeutungsaspekten in gerichteten Graphstrukturen: Ein experimentelles System, das LISP verwendet, um ein konzeptionelles Wörterbuch zu erstellen, wird beschrieben. Das Wörterbuch verbindet mit jedem englischen Wort syntaktische Informationen, Definitionsmaterial und Verweise auf die Kontexte, in denen es verwendet wurde, um andere Wörter zu definieren. Als Definitionsmaterial werden Beziehungen wie Klassenzugehörigkeit, Besitz und aktive oder passive Handlungen verwendet. Die resultierende Struktur dient als leistungsfähiges Vehikel für die Erforschung der Logik der Fragebeantwortung. Es werden Beispiele für Methoden zur Eingabe von Informationen und zur Beantwortung einfacher englischer Fragen gegeben. Eine wichtige Schlussfolgerung ist, dass LISP und andere Listenverarbeitungssprachen zwar ideal zum Erzeugen komplexer assoziativer Strukturen geeignet sind, aber für die Sprachverarbeitung in großem Maßstab ungeeignete Vehikel sind – zumindest solange, bis sie den Hilfsspeicher als kontinuierliche Erweiterung des Kernspeichers verwenden können."}
{"DOCID": "1457", "TEXT": "Datenmanipulations- und Programmierprobleme beim automatischen Informationsabruf: Automatische Informationsabrufprogramme erfordern die Manipulation einer Vielzahl unterschiedlicher Datenstrukturen, einschließlich linearem Text, dünnbesetzten Matrizen und Baum- oder Listenstrukturen. Die wichtigsten Datenmanipulationen, die in automatischen Informationssystemen durchgeführt werden müssen, werden zunächst kurz betrachtet. Anschließend werden verschiedene Datendarstellungen untersucht, die zur Beschreibung strukturierter Informationen verwendet wurden, und die Eigenschaften verschiedener Verarbeitungssprachen werden im Hinblick auf die zu implementierenden Verfahren umrissen. Die Vorteile dieser Programmiersprachen für die Abrufanwendung werden untersucht, und es werden Vorschläge für die Gestaltung von Programmiereinrichtungen zur Unterstützung des Informationsabrufs gemacht."}
{"DOCID": "1458", "TEXT": "Online-Programmierung: Nach dem Übergang von der Offline- zur Online-Programmierung sind eine Reihe von Änderungen in den Arbeitsbedingungen festzustellen. Diese Änderungen in der Umgebung erfordern entsprechende Änderungen in den Prozessen rund um das Produzieren und Auschecken von Programmen. In der Hauptsache ist es nicht die Programmiersprache selbst, die geändert werden muss, um eine Einrichtung für den Online-Benutzer bereitzustellen; es ist das System, das die Programmiersprache umgibt. In diesem Beitrag werden die Online-Umgebung und ihre Auswirkung auf die Programmierung diskutiert."}
{"DOCID": "1459", "TEXT": "Anforderungen an Echtzeitsprachen: Echtzeitsprachen haben andere Anforderungen als andere Programmiersprachen aufgrund der speziellen Natur ihrer Anwendungen, der Umgebung, in der ihre Objektprogramme ausgeführt werden, und der Umgebung, in der sie kompiliert werden können. Es müssen nicht die Spracherweiterungen sein, die letztendlich die Entwicklungen auf diesem Gebiet vorantreiben. Fortschritte können erzielt werden, indem die speziellen Kompilier- und Ausführungssystemprobleme angegangen werden, die gelöst werden müssen."}
{"DOCID": "1460", "TEXT": "Entwicklung des Meta-Assembler-Programms: Ein verallgemeinerter Assembler, der als \"Meta-Assembler\" bezeichnet wird, wird beschrieben. Der Meta-Assembler wird definiert und Faktoren, die zu seiner Entwicklung beigetragen haben, werden vorgestellt. Es wird beschrieben, wie ein Meta-Assembler dazu gebracht wird, als Assembler-Programm zu funktionieren. Abschließend wird die Auswirkung von Meta-Assemblern auf das Compiler-Design diskutiert."}
{"DOCID": "1461", "TEXT": "Zusammenfassung der Diskussion zu Betriebssystemen"}
{"DOCID": "1462", "TEXT": "Mehrstufige Betriebssysteme: Die Basissoftware für alle neueren Computer baut auf der allgemein anerkannten Notwendigkeit von Standardbetriebssystemen auf. Dies bedeutet, dass alle Anwendungen – egal wie groß, komplex oder zeitaufwändig sie sind – unter (oder genauer gesagt auf) dem Standardsystem laufen müssen. Große Anwendungen erfordern Überwachungsmonitore, die ähnliche Probleme behandeln wie die Betriebssysteme, jedoch auf einer anderen Ebene. Manchmal ist noch eine dritte oder sogar eine vierte solcher Ebenen erforderlich oder wünschenswert. Dies führt natürlich zu dem Konzept von Mehrebenensystemen – vertikal ähnlich, aber horizontal unterschiedlich. Die richtige Aufteilung der Verantwortung zwischen den Ebenen führt zu größerer Effizienz und weniger logischer Komplexität, während die Fähigkeiten tatsächlich verbessert werden."}
{"DOCID": "1463", "TEXT": "Mehr zu Extensible Machines: Eines der hervorstechendsten Merkmale von Extensible Machines (EM) ist die Möglichkeit, Systemsteuerung über Programm-zu-Programm- und Programm-zu-Daten-Verknüpfungen (z. B. Adressverbindung) bereitzustellen. Es ist die Absicht dieses Papiers, die Bemerkungen bezüglich Programm-zu-Programm- und Programm-zu-Daten-Verknüpfung zu erweitern und zu verdeutlichen, die in der vorherigen Veröffentlichung der Autoren zu den EM-Konzepten enthalten waren, und schließlich die Verwendung von Verknüpfungen nachzuzeichnen Mechanismen durch verschiedene Ebenen von Programmiersprachen."}
{"DOCID": "1464", "TEXT": "Ein ALGOL-Compiler: Konstruktion und Verwendung in Bezug auf ein ausgeklügeltes Betriebssystem: Ein ALGOL-Übersetzer wurde vorbereitet und in das IBSYS-Betriebssystem integriert. Assembler- und \"Go\"-Features von IBSYS erlauben eine sofortige Ausführung mit optionalen Listings, Decks und Debugging-Informationen. Unter Verwendung der Kettenfunktion von IBSYS können Verbindungen, die in MAP oder FORTRAN sowie ALGOL geschrieben sind, vom ALGOL-Hauptprogramm aufgerufen werden. Darüber hinaus können in MAP codierte Prozeduren in jedes ALGOL-Programm aufgenommen werden. Obwohl die Montage- und Ladezeit die Kompilierzeit übersteigt, ist die Gesamtzeit zufriedenstellend und der Benutzer erhält eine Leichtigkeit und Erleichterung, die dies vollständig kompensieren."}
{"DOCID": "1465", "TEXT": "Programmübersetzung als allgemeines Datenverarbeitungsproblem angesehen: Effizienz diktiert, dass die Gesamteffektivität eines Compilers mit allen verfügbaren Mitteln gesteigert werden muss. Damit ein Compiler eine beträchtliche Lebensdauer hat, braucht er eine klare logische Struktur, Zuverlässigkeit und solide Datenverarbeitungstechniken. Ein Compiler muss auf festen Konventionen basieren, um Effizienz und Zuverlässigkeit zu bewahren; leere Optionen und Standardkonventionen verstoßen gegen dieses Diktum. Die Verwendung von Strukturen zur Verknüpfung verschiedener Teile eines Programms und die Einsparung von Merkmalen fördern die Klarheit und Zuverlässigkeit."}
{"DOCID": "1466", "TEXT": "Zusammenfassung der Diskussion über grafische Sprachen"}
{"DOCID": "1467", "TEXT": "Ein grafisches Servicesystem mit variabler Syntax: Die Mensch-Maschine-Interaktion in vielen Arbeitsgebieten sollte in naher Zukunft durch die Verwendung interaktiver grafischer Sprachen erheblich erleichtert werden. Um eine Vielzahl von Kommunikationsprozeduren für den Anzeigeumfang bereitzustellen, wird ein Grafikdienstsystem entwickelt, das als ein verallgemeinerter Grafiksprachenübersetzer fungiert, um die Definition sowie die Verwendung neuer Grafiksprachen zu unterstützen."}
{"DOCID": "1468", "TEXT": "Syntaxgesteuerte Interpretation von Bildklassen: Ein beschreibendes Schema für Bildklassen, das auf Kennzeichnungstechniken unter Verwendung von Parallelverarbeitungsalgorithmen basiert, wurde vom Autor vor einigen Jahren vorgeschlagen. Seitdem wurde viel daran gearbeitet, dies auf Blasenkammerbilder anzuwenden. Der ursprünglich für ein IBM 7094-System geschriebene Parallelverarbeitungssimulator wurde jetzt für ein CDC 3600-System umgeschrieben. Dieses Papier beschreibt Modelle, indem es ihre spezifische Anwendung auf Blasenkammerbilder betrachtet. Wie die in dieser Phase generierte Beschreibung in ein größeres „Gesprächs“-Programm eingebettet werden kann, wird anhand eines konkreten, ausgearbeiteten Beispiels erläutert. Eine partielle generative Grammatik für \"handgeschriebene\" englische Buchstaben wird angegeben, ebenso wie einige computergenerierte Ausgaben, die diese Grammatik und den zuvor erwähnten Parallelverarbeitungssimulator verwenden."}
{"DOCID": "1469", "TEXT": "The Next 700 Programming Languages: Eine Familie von nicht implementierten Computersprachen wird beschrieben, die dazu bestimmt ist, Unterschiede im Anwendungsbereich durch einen einheitlichen Rahmen zu überbrücken. Dieses Framework diktiert die Regeln für die Verwendung von benutzergeprägten Namen und die Konventionen für die Charakterisierung funktionaler Beziehungen. Innerhalb dieses Rahmens spaltet sich das Design einer bestimmten Sprache in zwei unabhängige Teile. Eine davon ist die Wahl des schriftlichen Erscheinungsbilds von Programmen (oder allgemeiner ihre physische Darstellung). Die andere ist die Auswahl der abstrakten Entitäten (wie Zahlen, Zeichenfolgen, Listen von ihnen, funktionale Beziehungen zwischen ihnen), auf die in der Sprache Bezug genommen werden kann. Das System ist eher auf „Ausdrücke“ als auf „Aussagen“ ausgerichtet. Es enthält ein nicht prozedurales (rein funktionales) Subsystem, das darauf abzielt, die Klasse von Benutzeranforderungen zu erweitern, die durch eine einzelne Druckanweisung erfüllt werden können, ohne die wichtigen Eigenschaften zu opfern, die herkömmliche rechtsseitige Ausdrücke leicht zu konstruieren und zu verstehen machen."}
{"DOCID": "1470", "TEXT": "Die Struktur von Programmiersprachen: Das Folgende wird als Hauptkomponenten jeder Programmiersprache identifiziert: (1) die elementare Programmanweisung, (2) Mechanismen zum Verknüpfen von elementaren Anweisungen miteinander, (3) die Mittel, mit denen ein Programm Dateneingaben erhalten kann. Mehrere alternative Formen jeder dieser Komponenten werden beschrieben, verglichen und bewertet. Viele Beispiele, häufig aus Listenverarbeitungssprachen, veranschaulichen die beschriebenen Formen. Elementare Programmanweisungen haben normalerweise die Form von Befehlen, Anforderungen oder impliziten Spezifikationen. Ein Befehl ist eine zwingende Anweisung, die die auszuführende Aktion befiehlt. Eine Anforderung beschreibt die zu erreichende Wirkung, ohne etwas über die zu ergreifenden Maßnahmen zu sagen. Eine implizite Spezifikation ähnelt einer Anforderung, aber der Programmierer muss verstehen, welche Maßnahmen ergriffen werden, um den gewünschten Effekt zu erzielen. Subroutinen können explizit, durch Ausführungsaufruf oder durch Funktionszusammenstellung eingegeben werden. Explizit aufgerufene Unterprogramme erfordern im Allgemeinen spezielle Verknüpfungskonventionen. Ein Ausführen-Unterprogrammaufruf ist syntaktisch nicht von einer grundlegenden Anweisung der Programmiersprache zu unterscheiden. Die Funktionskomposition ist eine bequeme Alternative zum expliziten Aufruf. Die drei wichtigsten Möglichkeiten, Eingaben für Routinen zu erhalten, sind (1) durch Verweisen auf die Daten selbst, (2) durch Verweisen auf die Daten durch einen \"Namen\" und (3) durch implizites Verweisen darauf mittels Variablen oder Funktionen. Namen sind nützliche Einstiegspunkte in dauerhafte Datenstrukturen, können aber in anderen Zusammenhängen fehlerverursachende Ablenkungen sein. Der Autor diskutiert Vorteile, Nachteile und Faktoren, die die Wahl einer Komponentenform für eine Sprache beeinflussen. Abschließend schlägt er die Entwicklung von Programmiersprachen hin zu einer vor, die die bequemsten Möglichkeiten zum Strukturieren von Programmen, Organisieren von Systemen und Referenzieren von Daten ermöglicht."}
{"DOCID": "1471", "TEXT": "Programmiersemantik für multiprogrammierte Berechnungen: Die Semantik ist für eine Reihe von Metaanweisungen definiert, die Operationen ausführen, die für das Schreiben von Programmen in multiprogrammierten Computersystemen wesentlich sind. Diese Metaanweisungen beziehen sich auf die parallele Verarbeitung, den Schutz getrennter Berechnungen, die Programmfehlerbeseitigung und die gemeinsame Nutzung von Speichersegmenten und anderen Computerobjekten zwischen Benutzern, deren Namen hierarchisch strukturiert sind. Die betrachtete Sprachentwicklung liegt auf halbem Weg zwischen einer Assemblersprache und einer fortgeschrittenen algebraischen Sprache."}
{"DOCID": "1472", "TEXT": "Beschreibung eines Universitäts-Rechenzentrums mit hoher Kapazität und schnellem Turnaround: Das Betriebssystem für das UNIVAC 1107 am Case Institute wird überprüft. Interessant ist das System aufgrund der geringen Durchlaufzeiten, des hohen Durchsatzes und des fehlenden Bedienpersonals. Durchlaufzeiten unter 5 Minuten und ein Auftragsvolumen von über 75.000 pro Quartal wurden gemeldet."}
{"DOCID": "1473", "TEXT": "Die Stabilität des Runge-Kutta-Verfahrens vierter Ordnung zur Lösung von Differentialgleichungssystemen: Es wird das Problem des Stabilitätsbereichs des Runge-Kutta-Verfahrens vierter Ordnung zur Lösung von Differentialgleichungssystemen untersucht. Dieser Bereich kann mittels linearer Transformation charakterisiert, aber nicht in geschlossener Form angegeben werden. In der Arbeit wird dieser Bereich durch den elektronischen Digitalrechner Z22 bestimmt."}
{"DOCID": "1474", "TEXT": "Tests probabilistischer Modelle für die Fortpflanzung von Rundungsfehlern: Bei jeder längeren Berechnung wird im Allgemeinen angenommen, dass der kumulierte Effekt von Rundungsfehlern in gewissem Sinne statistisch ist. Der Zweck dieses Papiers ist es, genaue Beschreibungen bestimmter probabilistischer Modelle für Rundungsfehler zu geben und dann eine Reihe von Experimenten zum Testen der Gültigkeit dieser Modelle zu beschreiben. Es wird geschlussfolgert, dass die Modelle im Allgemeinen sehr gut sind. Diskrepanzen sind sowohl selten als auch mild. Die Testtechniken können auch verwendet werden, um mit verschiedenen Arten von Spezialarithmetik zu experimentieren."}
{"DOCID": "1475", "TEXT": "Dribble Posting einer Masterdatei: Viele Geschäftsanwendungen verwenden sequenzielle Magnetbänder anstelle von Speichertechniken mit wahlfreiem Zugriff, um eine sehr kleine Anzahl von Transaktionen anhand einer umfangreichen Masterdatei zu verarbeiten. In solchen Situationen kann es sich als wirtschaftlich erweisen, das Erstellen einer neuen Hauptdatei während jedes Aktualisierungslaufs zu vermeiden, indem stattdessen ein Dribbling-Hauptbuch erstellt wird, das nur diejenigen Hauptdateikonten enthält, die eine Aktivität erfahren haben."}
{"DOCID": "1476", "TEXT": "Kontrollverfahren für die Datenkommunikation – Ein ASA-Fortschrittsbericht: Das Sektionskomitee X.3 der American Standards Association hat eine seiner Arbeitsgruppen, X3.3.4, mit der Verantwortung betraut, „funktionelle Kontrollanforderungen und -merkmale für den Betrieb zu definieren und zu spezifizieren von digitalen Datenerzeugungs- und -empfangssystemen, die durch ein Kommunikationssystem miteinander verbunden sind.\" Diese Bemühungen richten sich hauptsächlich auf Systeme, die den American Standard Code for Information Interchange (ASCII) verwenden. Dieses Papier stellt einen Fortschrittsbericht über die Arbeit dieser Gruppe hin zu einem Vorschlag für eine nationale und internationale Normung auf dem Gebiet der Kontrollverfahren dar. Es beschreibt sowohl die alte als auch die neue Arbeit der Arbeitsgruppe. Die neue Arbeit wird im Detail vorgestellt, während die Arbeit, die in früheren Veröffentlichungen [\"Control Procedures for Data Communication\", Task Group document X3.3.4/44, May 1964: \"Transparent-Mode Control Procedures for Data Communication\", Task Group Dokument X3.3.4/58, Dezember 1964: Comm. ACM 8 (April 1965), 203-206; \"Control Procedures for Data Communications\", Task Group document X3.3.4/60, March, 1965] wird hier in zusammenfassender Form festgehalten. Viele der hierin beschriebenen Konzepte und Prinzipien wurden der Internationalen Organisation für Normung über frühere Papiere vorgelegt und sind nun in Arbeitspapieren dieser Organisation enthalten."}
{"DOCID": "1477", "TEXT": "EULER: Eine Verallgemeinerung von ALGOL und seine formale Definition: Teil II*"}
{"DOCID": "1478", "TEXT": "Exponentielle Kurvenanpassung (Algorithmus 275 [E2])"}
{"DOCID": "1479", "TEXT": "Eingeschränkte exponentielle Kurvenanpassung (Algorithmus 276 [E2])"}
{"DOCID": "1480", "TEXT": "Berechnung der Chebyshev-Reihenkoeffizienten (Algorithmus 277[C6])"}
{"DOCID": "1481", "TEXT": "Graphenplotter (Algorithmus 278 [J6])"}
{"DOCID": "1482", "TEXT": "BUGSYS: Ein Programmiersystem für die Bildverarbeitung – nicht zum Debuggen: BUGSYS ist ein Bildverarbeitungs- und Messsystem, das von einer Bildeingabe in den Computerspeicher abhängt. BUGSYS kann für viele Arten von Anwendungen verwendet werden. Insbesondere haben die Autoren das System zur Analyse linearer Graphen verwendet. Das Hauptkonzept des Systems ist die Verwendung einer Sammlung programmierbarer Zeiger, die als eine Familie von \"Bugs\" visualisiert werden."}
{"DOCID": "1483", "TEXT": "Ein Vergleich der FORTRAN-Sprachimplementierung für mehrere Computer: Es wird ein Feature-by-Feature-Vergleich von fünf verschiedenen Implementierungen von FORTRAN IV durchgeführt, die drei verschiedene Hersteller repräsentieren. Es wird eine Tabelle erstellt, die, wo möglich, die Verwendung jedes Merkmals in jeder Implementierung zeigt. Es werden nur die Elemente angezeigt, die sich von FORTRAN II unterscheiden oder zu FORTRAN II hinzugefügt wurden."}
{"DOCID": "1484", "TEXT": "Eine Sprache zur Beschreibung der Funktionen synchroner Systeme*: Bevor mit dem Entwurf eines Systems begonnen wird, sollte dessen genaue Funktion spezifiziert werden. Es wird vorgeschlagen, zu diesem Zweck eine computerorientierte Sprache zu verwenden. Die Unzulänglichkeiten der Standardprogrammiersprachen zur Beschreibung von Systemen werden diskutiert und ein Dialekt von ALGOL eingeführt, der zur Beschreibung synchroner Systeme geeignet ist. Diese Beschreibungen können zusätzlich zur Übermittlung von Systemspezifikationen für die Simulation und den automatischen Entwurf des beschriebenen Systems verwendet werden."}
{"DOCID": "1485", "TEXT": "Die Struktur von Programmiersprachen: In diesem Artikel werden die Hauptkomponenten jeder Programmiersprache wie folgt identifiziert: (1) die elementare Programmanweisung, (2) Mechanismen zur Verknüpfung elementarer Anweisungen miteinander, (3) die Mittel, mit denen ein Programm Daten erhalten kann Eingänge. Mehrere alternative Formen jeder dieser Komponenten werden ebenfalls beschrieben, verglichen und bewertet. Viele Beispiele, häufig aus Listenverarbeitungssprachen, veranschaulichen die beschriebenen Formen. Die Vor- und Nachteile und Faktoren, die die Wahl einer Form von Komponenten für eine Sprache beeinflussen, werden diskutiert, und der Beitrag schließt mit dem Vorschlag, dass sich Programmiersprachen zu einer entwickeln, die die bequemsten Möglichkeiten zum Strukturieren von Programmen, Organisieren von Systemen und Referenzieren von Daten ermöglicht ."}
{"DOCID": "1486", "TEXT": "Eine Umprogrammiermaschine: In diesem Dokument wird ein Modellprogrammiersystem beschrieben, das von einer Programmiersprache gesteuert wird und eine Bibliothek zum Speichern der Elemente des Benutzers hat. Es werden Regeln zum Transformieren von in der Sprache geschriebenen Programmen und zum Neuanordnen der Elemente in der Bibliothek angegeben, so dass sie ihre gemeinsamen Teile teilen. Es werden einige Spekulationen darüber angestellt, wie die mechanische Erkennung gemeinsamer Teile oder Muster von Bibliothekselementen einem Benutzer helfen könnte, seine Probleme zu lösen, und über die Beziehungen zwischen dem Verhalten der Umprogrammiermaschine und menschlichem intelligentem Verhalten."}
{"DOCID": "1487", "TEXT": "ELIZA-Ein Computerprogramm zum Studium der Kommunikation in natürlicher Sprache zwischen Mensch und Maschine: ELIZA ist ein Programm, das innerhalb des MAC-Time-Sharing-Systems am MIT arbeitet und bestimmte Arten von Konversation in natürlicher Sprache zwischen Mensch und Computer ermöglicht. Eingabesätze werden anhand von Dekompositionsregeln analysiert, die durch im Eingabetext vorkommende Schlüsselwörter ausgelöst werden. Antworten werden durch Reassemblierungsregeln generiert, die ausgewählten Dekompositionsregeln zugeordnet sind. Die grundlegenden technischen Probleme, mit denen sich ELIZA beschäftigt, sind: (1) die Identifizierung von Schlüsselwörtern, (2) die Entdeckung eines minimalen Kontexts, (3) die Wahl geeigneter Transformationen, (4) die Generierung von Antworten in Abwesenheit von Schlüsselwörtern , und (5) die Bereitstellung einer Bearbeitungsmöglichkeit für ELIZA-\"Skripte\". Eine Erörterung einiger für den ELIZA-Ansatz relevanter psychologischer Probleme sowie zukünftiger Entwicklungen schließt den Beitrag ab."}
{"DOCID": "1488", "TEXT": "Programmierung von Entscheidungstabellen in FORTRAN, COBOL oder ALGOL: Ein einfacher, breit angelegter Ansatz zur Programmierung von Entscheidungstabellen in FORTRAN oder COBOL wird entwickelt und vorgestellt. Mit Eingaben in Standardform, wie sie in der Veröffentlichung definiert sind, kann die Programmierung jeder Entscheidungstabelle mit einer oder zwei FORTRAN-Anweisungen oder mit zwei COBOL-Anweisungen erfolgen, wenn das Verb COMPUTE im COBOL-Prozessor verfügbar ist. Es wird gezeigt, dass das Verfahren auch anwendbar ist, wenn es mehr als zwei sich gegenseitig ausschließende Zustände von einer, zwei oder mehr Tabellenbedingungen gibt. Es wird weiterhin gezeigt, dass Bedingungen mit mehreren Zuständen in Entscheidungstabellen oft die Programmierung vereinfachen können. Das skizzierte Verfahren hat den weiteren Vorteil, dass alle möglichen Kombinationen von Bedingungen berücksichtigt werden. Es wird gezeigt, dass das vorgeschlagene Verfahren leicht in ALGOL implementiert werden kann."}
{"DOCID": "1489", "TEXT": "Daten-, Dokumentations- und Entscheidungstabellen: In betrieblichen Datenverarbeitungssystemen ist es notwendig, Daten, Dateien, Programme und Entscheidungsregeln so definieren und dokumentieren zu können, dass sowohl (1) ihr wechselnder Informationsgehalt als auch (2) ihre ständige Interaktion. Die tabellarische Beschreibung macht dies möglich, besonders objektiv, durchgängig und kosten- und zeitsparend, wenn Systeme analysiert und Programme erstellt oder modifiziert werden müssen. Um zu zeigen, wie schnell tabellarische Techniken ein unbekanntes System beherrschbar machen, werden ein ausführliches Beispiel und ein Selbsttest bereitgestellt."}
{"DOCID": "1490", "TEXT": "Perforiertes 1-Zoll-Papierband für den Informationsaustausch (vorgeschlagener amerikanischer Standard)"}
{"DOCID": "1491", "TEXT": "EULER: Eine Verallgemeinerung ALGOL und ihre formale Definition: Teil I*: Es wird eine Methode zur Definition von Programmiersprachen entwickelt, die eine strenge Beziehung zwischen Struktur und Bedeutung einführt. Die Struktur einer Sprache wird durch eine Phrasenstruktursyntax definiert, die Bedeutung in Bezug auf die Auswirkungen, die die Ausführung einer Folge von Interpretationsregeln auf einen festen Satz von Variablen ausübt, der Umgebung genannt wird. Es besteht eine Eins-zu-eins-Entsprechung zwischen syntaktischen Regeln und Interpretationsregeln, die durch die Folge entsprechender syntaktischer Reduktionen bestimmt wird, die eine Analyse bilden. Die einzelnen Interpretationsregeln werden anhand einer elementaren und naheliegenden algorithmischen Notation erläutert. Es wird eine konstruktive Methode zur Bewertung eines Textes bereitgestellt und für bestimmte entscheidbare Sprachklassen deren Eindeutigkeit bewiesen. Als Beispiel wird eine Verallgemeinerung von ALGOL ausführlich beschrieben, um zu demonstrieren, dass Konzepte wie Blockstruktur, Prozeduren, Parameter usw. mit dieser Methode angemessen und präzise definiert werden können."}
{"DOCID": "1492", "TEXT": "Serrev (Algorithmus 273 [C1])"}
{"DOCID": "1493", "TEXT": "Generierung einer von Hilbert abgeleiteten Testmatrix (Algorithmus 274 [F1])"}
{"DOCID": "1494", "TEXT": "Vollständiges elliptisches Integral zweiter Art (Algorithmus 56 [S21])"}
{"DOCID": "1495", "TEXT": "Lösung transzendentaler Gleichungen durch Reihenumkehrung: Es wird ein Algorithmus entwickelt, um die Lösung Y der Gleichung F(Y) = G(X) als Potenzreihe in (X - X0) auszudrücken, wenn f und g als Potenzreihen gegeben sind, und die Wurzel Y0, ist bei Y=X0 bekannt. Der Algorithmus wird für die Gleichung Y^Y = X dargestellt, d. h. (1+y)*ln(1+y) = ln(1+x)."}
{"DOCID": "1496", "TEXT": "Eine formale Semantik für Computersprachen und ihre Anwendung in einem Compiler-Compiler: Eine semantische Metasprache wurde entwickelt, um die Bedeutungen von Anweisungen in einer großen Klasse von Computersprachen darzustellen. Diese Metasprache war die Grundlage für die Konstruktion eines effizienten, funktionierenden Compiler-Compilers. Eine informelle Diskussion der Metasprache am Beispiel eines vollständigen Übersetzers für eine kleine Sprache wird vorgestellt."}
{"DOCID": "1497", "TEXT": "Über die Normalisierungsanforderung des Divisors bei „Teile-und-Korrektur“-Methoden: Dieses Papier präsentiert eine Analyse der Normalisierungsanforderung des Divisors bei einer „Teile-und-Korrektur“-Methode. Diese Analyse wird unter der Bedingung durchgeführt, dass nicht mehr als eine Korrektur erforderlich ist, um den wahren Quotientencharakter aus der Versuchsschätzung zu erhalten, die aus der Division eines Segments mit zwei Genauigkeiten jedes partiellen Rests durch einen geeignet gerundeten Divisor mit einfacher Genauigkeit erhalten wird. (Diese segmentierte Division wird hier als eine (2, 1)-Präzisionsbasisdivision bezeichnet.) Es wurde festgestellt, dass die Normierungsanforderung auf einen kleineren Bereich von Teilern eingeengt werden könnte, vorausgesetzt, dass die Grße des Zeichens neben dem führenden Zeichen des Teiler ist bekannt. Wenn jedoch die Normalisierung eliminiert werden soll, müssen geeignete Segmente von Operanden mit höherer Genauigkeit für die Basisdivision ausgewählt werden. Es wird auch die Möglichkeit in Betracht gezogen, die Normalisierung durch eine Erhöhung der Anzahl von Korrekturen an der Quotientenschätzung zu eliminieren, die von einer (2, 1)-Präzisionsbasisdivision erhalten wird. Es wird gezeigt, dass ein solches Schema nur für kleine Radien wirtschaftlich ist."}
{"DOCID": "1498", "TEXT": "ALCOR Illinois 7090/7094 Post Mortem Dump: Eine Dump-Technik für in ALGOL 60 geschriebene Programme wird beschrieben. Diese Technik liefert eine verständliche Analyse eines erfolglosen Berechnungsprozesses in Bezug auf das ursprüngliche Quellprogramm."}
{"DOCID": "1499", "TEXT": "Chebyschev Curve-Fit (überarbeitet) (Algorithmus 318 [E2])"}
{"DOCID": "1500", "TEXT": "Chebyschev-Kurvenanpassung (Algorithmus 91 [E2])"}
{"DOCID": "1501", "TEXT": "Eigenvektoren einer 2n x 2n-Matrix: Es ist bekannt, dass die Eigenwerte einer bestimmten 2n x 2n-Matrix durch Verwendung von zwei kleineren Matrizen der Ordnung n erhalten werden können, die leicht konstruiert werden können. Es wird ein Algorithmus angegeben, um die Eigenvektoren der 2n x 2n-Matrix durch Verwendung der Eigenvektoren der kleineren Matrizen zu erhalten."}
{"DOCID": "1502", "TEXT": "Ein Online-Editor: Ein interaktives Online-System zur Testbearbeitung wird ausführlich beschrieben, mit Anmerkungen zur theoretischen und experimentellen Begründung seiner Form. Der Schwerpunkt des gesamten Systems liegt darauf, dem Benutzer maximalen Komfort und Leistung zu bieten. Bemerkenswerte Merkmale sind die Fähigkeit, jedes Textstück zu verarbeiten, die Inhaltssuchfunktion und die zeichenweisen Bearbeitungsvorgänge. Der Editor ist eingeschränkt programmierbar."}
{"DOCID": "1503", "TEXT": "Eine SIMSCRIPT-FORTRAN-Fallstudie: Zwei Programme für ein Fahrzeugdispositionsmodell, eines geschrieben in 7040 SIMSCRIPT und das andere in 7040 FORTRAN IV, werden verglichen. Der Vergleich erfolgt im Hinblick auf grundlegende Programmentwurfsentscheidungen, Speicheranforderungen, verbrauchte Computerzeit und die Leichtigkeit, Änderungen vorzunehmen. Im SIMSCRIPT-Programm konzentrieren sich die primären Entwurfsüberlegungen auf die Auswahl von Modellvariablen, Modelländerungsereignissen und Modelltests. Beim FORTRAN-Programm beziehen sich grundlegende Entwurfsprobleme auf die Darstellung des Zeitverlaufs, die Speicherzuweisung und die Organisation von Eingabedaten. Der Vergleich dieser unterschiedlich gestalteten Programme zeigt, dass das SIMSCRIPT-Programm mehr Computerspeicher und mehr Computerzeit verbraucht, aber weniger Programmänderungen erfordert, um Modellrevisionen einzuführen."}
{"DOCID": "1504", "TEXT": "Algorithmen zum Finden eines fundamentalen Satzes von Zyklen für einen ungerichteten linearen Graphen: Angesichts der Adjazenzmatrix des Graphen findet der in diesem Artikel vorgestellte Algorithmus einen aufspannenden Baum und konstruiert dann den Satz von fundamentalen Zyklen. Unser Algorithmus ist um ein Verhältnis von N/3 (N ist die Anzahl der Knoten) langsamer als ein von Welch vorgestellter Algorithmus, erfordert aber weniger Speicherplatz. Bei Graphen mit einer großen Anzahl von Knoten und Kanten ist unser Algorithmus dem von Welch überlegen, wenn der Speicherplatz begrenzt ist; Wenn die Diagramme jedoch klein oder der Maschinenspeicher sehr groß ist, ist der Algorithmus von Welch überlegen. Zeitschätzungen und Speicheranforderungen für beide Verfahren werden vorgestellt."}
{"DOCID": "1505", "TEXT": "Eine Systemorganisation für die Ressourcenzuweisung: Dieses Papier stellt ein System für die Ressourcenverwaltung vor, das die Konzepte „Prozess“, „Einrichtung“ und „Ereignis“ verwendet B. für die Ressourcenzuweisung. Es wird jedoch ein grundlegendes Gerüst bereitgestellt, in dem ein Systemanalytiker Lösungen für Ressourcenverwaltungsprobleme ausdrücken kann. Das Papier ist in eine Tutorial-Präsentation, eine Beschreibung der Systemprimitiven und eine kleine Sammlung von Beispielen für die Verwendung von unterteilt die Primitiven."}
{"DOCID": "1506", "TEXT": "Der LACONIQ-Monitor: Time-Sharing für Online-Dialoge: Der LACONIQ-Monitor (Laboratory Computer Online Inquiry) wurde hauptsächlich entwickelt, um nicht-numerische Anwendungen wie das Abrufen sehr großer Dateien durch einen „Dialog“ zwischen einem Systembenutzer und einer Abrufanwendung zu unterstützen . Der Monitor wurde so konzipiert, dass er mit einem kleinen Computer (einem IBM System 360/30) funktionieren konnte. Daher waren Techniken zur Ressourcenallokation wichtig. Aus diesem Grund wurden die Nutzung von Kernspeichern, Rechenanlagen und Input-Output geplant. Ein ungewöhnliches Merkmal des Systems ist, dass es eher ereignisgesteuert als uhrgesteuert ist. Die Programmsegmente, die von den entfernten CRT-Konsolen zur Ausführung aufgerufen werden, werden ausnahmslos bis zur Vollendung ausgeführt, anstatt \"ausgerollt\" zu werden, um zu einem späteren Zeitpunkt zurückgebracht zu werden."}
{"DOCID": "1507", "TEXT": "A Multiprogramming Environment for Online Data Acquisition and Analysis: Ein experimentelles System zur Erfassung und Analyse großer Datenmengen aus wissenschaftlichen Experimenten wird beschrieben. Seine Architektur und Implementierung basiert weitgehend auf bestimmten Zielen und Merkmalen eines allgemeinen Datenanalyseschemas. Frühe Anwendungen waren auf die Untersuchung von Daten ausgerichtet, die in der biologischen Forschung gewonnen wurden. Einige der Probleme, auf die der gewählte Ansatz stößt, werden diskutiert."}
{"DOCID": "1508", "TEXT": "Magnetbandetiketten für den Informationsaustausch (vorgeschlagener USA-Standard)"}
{"DOCID": "1509", "TEXT": "Aufgezeichnetes Magnetband für den Informationsaustausch (200 CPI, NRZI) (vorgeschlagener USA-Standard)"}
{"DOCID": "1510", "TEXT": "Finden einer Lösung von N Funktionsgleichungen in N Unbekannt (Algorithmus 314 [C5])"}
{"DOCID": "1511", "TEXT": "Die gedämpfte Taylor-Reihenmethode zum Minimieren einer Summe von Quadraten und zum Lösen von Systemen nichtlinearer Gleichungen"}
{"DOCID": "1512", "TEXT": "Lösung simultaner nichtlinearer Gleichungen (Algorithmus 316[C5])"}
{"DOCID": "1513", "TEXT": "PERMUTATION (Algorithmus 317 [G6])"}
{"DOCID": "1514", "TEXT": "Über den erwarteten Gewinn durch die Anpassung von Matching-Term-Retrieval-Systemen: Ein Dateianpassungsverfahren, das auf der Maximierung des erwarteten Bayes-Gewinns basiert, der für Matched-Term-Retrieval-Systeme vorgeschlagen wird. Der erwartete Gewinn und seine Wahrscheinlichkeitsverteilung werden abgeleitet als Funktion von: (1) dem vorherigen Anteil weggelassener Terme und (2) dem Trennungskoeffizienten zwischen zwei Verteilungen, die Werten einer Anpassungsstatistik entsprechen. Ein Beispiel bewertet die Verstärkungsparameter für ein typisches Informationsabrufsystem."}
{"DOCID": "1515", "TEXT": "A Computer System for Inference Execution and Data Retrieval: Dieses Papier stellt ein RAND-Projekt vor, das sich mit der Verwendung von Computern als Assistenten bei der logischen Analyse großer Sammlungen von Faktendaten befasst. Zu diesem Zweck wurde ein System namens Relational Data File entwickelt. Die relationale Datendatei wird kurz detailliert und Probleme, die sich aus ihrer Implementierung ergeben, werden diskutiert."}
{"DOCID": "1516", "TEXT": "Automatische Datenkomprimierung: Die in den letzten Jahren zu beobachtende „Informationsexplosion“ macht es unerlässlich, dass die Speicheranforderungen für alle Informationen auf einem Minimum gehalten werden. In diesem Dokument wird ein vollautomatischer und schneller dreiteiliger Kompressor beschrieben, der mit \"jedem\" Informationskörper verwendet werden kann, um langsame externe Speicheranforderungen stark zu reduzieren und die Informationsübertragungsrate durch einen Computer zu erhöhen. Das System entschlüsselt die komprimierten Informationen auch automatisch Artikel für Artikel, wenn dies erforderlich ist. Die drei Komprimiererkomponenten, die separat verwendet werden können, um ihre spezifischen Aufgaben zu erfüllen, werden diskutiert: NUPAK für die automatische Komprimierung numerischer Daten, ANPAK für die automatische Komprimierung \"beliebiger\" Informationen und IOPAK für die weitere Komprimierung von Informationen, auf denen gespeichert werden soll Klebeband oder Karten."}
{"DOCID": "1517", "TEXT": "Methoden zur Analyse von Daten aus Computersimulationsexperimenten: Dieser Beitrag befasst sich mit dem Problem der Analyse von Daten, die durch Computersimulationen von Wirtschaftssystemen erzeugt werden. Wir wenden uns zunächst einer hypothetischen Firma zu, deren Betrieb durch ein Einzelkanal-Mehrstations-Warteschlangenmodell dargestellt wird. Das Unternehmen versucht, den erwarteten Gesamtgewinn für die kommende Periode zu maximieren, indem es einen von fünf Betriebsplänen auswählt, wobei jeder Plan eine bestimmte Marketingstrategie, eine Zuweisung produktiver Inputs und Gesamtkosten beinhaltet. Die Ergebnisse der simulierten Aktivität unter jedem Plan werden einem F-Test, zwei multiplen Vergleichsmethoden und einer multiplen Ranking-Methode unterzogen. Wir veranschaulichen, vergleichen und bewerten diese Techniken. Die Arbeit vertritt die Position, dass die vom Experimentator gewählte besondere Analysetechnik (möglicherweise keine der oben genannten) Ausdruck seines experimentellen Ziels sein sollte: Der F-Test testet die Homogenität der Pläne; multiple Vergleichsmethoden quantifizieren ihre Unterschiede; und mehrere Ranking-Methoden identifizieren direkt den einen besten Plan oder die besten Pläne."}
{"DOCID": "1518", "TEXT": "Ein experimentelles Modell von System/360: Das Problem der Vorhersage der Leistung moderner Computersysteme ist gewaltig. Eine allgemeine Technik, die dieses Problem lösen kann, ist die makroskopische Simulation. Dieses Dokument berichtet über die Anwendbarkeit dieser Technik auf System/360. Das Papier beschreibt ein experimentelles Modell von System/360 – seine Hardware, Software und seine Umgebung. Die von dem Modell erzeugten Maße der Systemleistung bestehen aus Statistiken bezüglich Durchlaufzeit, Durchsatz, Hardwarenutzung, Softwarenutzung und Warteschlangenprozessen. Das Modell ist in SIMSCRIPT mechanisiert und besteht aus etwa 1750 Anweisungen. Ein Hilfsprogramm, der Job Generator, erstellt automatisch die Eigenschaften von System/360-Jobs, die simuliert werden."}
{"DOCID": "1519", "TEXT": "GEORGE 3-A Allzweck-Time-Sharing und Betriebssystem: Es wird ein Betriebssystem beschrieben, das auf einer großen Vielfalt von Konfigurationen des I.C.T. 1900 und kann eine große Anzahl von Online-Konsolenbenutzern handhaben, während gleichzeitig mehrere Offline-Jobs (Hintergrundjobs) ausgeführt werden. Das System ist nicht auf einen der beiden Modi ausgerichtet und kann entweder ein Stapelverarbeitungssystem (wie ATLAS Supervisor, IBSYS oder GECOS) oder ein Mehrfachzugriffssystem (ähnlich für den Benutzer CTSS oder MULTICS) oder beides gleichzeitig sein, je nachdem auf der Installation, die den Scheduler anpassen kann. Sowohl Online-Benutzer als auch Offline-Jobs verwenden eine gemeinsame Befehlssprache. Das System enthält einen mehrstufigen geräteunabhängigen Dateispeicher."}
{"DOCID": "1520", "TEXT": "Absolutwert und Quadratwurzel einer komplexen Zahl (Algorithmus 312 [A2])"}
{"DOCID": "1521", "TEXT": "Mehrdimensionaler Partitionsgenerator (Algorithmus 313 [A1])"}
{"DOCID": "1522", "TEXT": "Tschebyscheff-Quadratur (Algorithmus 279 [D1])"}
{"DOCID": "1523", "TEXT": "SHARER, ein Time-Sharing-System für den CDC 6600: Ein Time-Sharing-System, das in das standardmäßige Stapelverarbeitungssystem für den CDC 6600 eingebettet ist, wird beschrieben. Das System ist universell und dateibasiert und stellt Einrichtungen für Dateieingabe, Manipulation, Bearbeitung, Kompilierung und Konversationsausführung bereit. Es verwendet ein einfaches Schema zur Systemerweiterung für eine Maschine mit nur einer Verschiebung und einem speichergebundenen Register. Es wurde kein Versuch unternommen, wiedereintretenden Code zu verwenden oder Segmentierung oder Paging zu simulieren. Die Implementierungszeit betrug ungefähr sechs Mannjahre, wobei der Großteil des Codes in FORTRAN geschrieben wurde."}
{"DOCID": "1524", "TEXT": "Ein Abbruchkriterium für das Finden der Wurzel eines Polynoms: Bei der Suche nach der Wurzel eines Polynoms ist es im Allgemeinen schwierig zu wissen, wann eine Zahl als adäquate Annäherung an die Wurzel zu akzeptieren ist. In dieser Arbeit wird ein Algorithmus vorgestellt, der es erlaubt, den Iterationsprozess auf der Grundlage berechneter Schranken für den Rundungsfehler zu beenden, der bei der Auswertung des Polynoms auftritt. Dieses Stoppkriterium wurde an zahlreichen Beispielen getestet und hat sich als zufriedenstellendes Mittel zum Akzeptieren einer komplexen Zahl als Nullstelle eines reellen Polynoms erwiesen."}
{"DOCID": "1525", "TEXT": "Zur Berechnung der schnellen Fourier-Transformation: Cooley und Tukey haben einen schnellen Algorithmus zur Berechnung komplexer Fourier-Transformationen vorgeschlagen und große Zeiteinsparungen bei der Verwendung zur Berechnung großer Transformationen auf einem digitalen Computer gezeigt. Da n eine Zweierpotenz ist, ist die Rechenzeit für diesen Algorithmus proportional zu n log2 n, eine wesentliche Verbesserung gegenüber anderen Verfahren mit Rechenzeit proportional zu n^2. In diesem Artikel wird der schnelle Fourier-Transformationsalgorithmus kurz besprochen und es werden schnelle Differenzgleichungsmethoden zur genauen Berechnung der benötigten trigonometrischen Funktionswerte angegeben. Das Problem der Berechnung einer großen Fourier-Transformation auf einem System mit virtuellem Speicher wird betrachtet und eine Lösung vorgeschlagen. Diese Methode wurde verwendet, um komplexe Fourier-Transformationen der Größe n = 2 ^ 16 auf einem Computer mit 2 ^ 15 Wörtern Kernspeicher zu berechnen; dies übersteigt um den Faktor acht die maximale Radix-Zwei-Transformationsgröße bei fester Zuordnung dieser Menge an Kernspeicher. Das Verfahren wurde auch verwendet, um große gemischte Radix-Transformationen zu berechnen. Ein Skalierungsplan zum Berechnen der schnellen Fourier-Transformation mit Festkomma-Arithmetik wird ebenfalls angegeben."}
{"DOCID": "1526", "TEXT": "Multiprogramming unter einer Page-on-Demand-Strategie: Ein Multiprogramming-Modell für ein bestimmtes Computersystem unter Verwendung einer Page-on-Demand-Strategie wird entwickelt. Die Analyse dieses Modells wird verwendet, um die Leistung (gemessen durch die durchschnittliche Nutzung der CPU) vorherzusagen, wenn Benutzerprogramme typisch für solche sind, die aus einer interaktiven Time-Sharing-Umgebung stammen. Auch die Auswirkung mehrerer Hardwaremodifikationen wird analysiert. Ein Parameter, der einfach aus den Hardwareeigenschaften und den Programmstatistiken berechnet wird, wird vorgeschlagen, um die Wirkung der Mehrfachprogrammierung zu messen."}
{"DOCID": "1527", "TEXT": "Ein Verfahren zur Beantwortung von Fragen auf Grammatikbasis: Der Gegenstand dieses Artikels ist ein Verfahren zum automatischen Abrufen bestimmter Segmente gespeicherter Informationen, die entweder explizit oder implizit dargestellt sind, durch Fragen, die in Sätzen natürlicher Sprache gestellt werden. Dieses Verfahren verwendet eine Satzerkennungsvorrichtung für die Klasse der Grammatiken, die korrekt zwischen den grammatikalischen und ungrammatischen Sätzen einer natürlichen Sprache entscheiden wird. Es ist aus folgendem Grund möglich, eine Erkennungsvorrichtung dieser Art zu verwenden: Viele Daten sind vollständig als eine Menge von Sätzen in einer natürlichen Sprache ausdrückbar, eine Menge, die erschöpfend und ausschließlich durch eine Grammatik erzeugt werden kann. Basierend auf den Regeln dieser Grammatik bewertet ein Satzerkenner Sätze, Fragen in der normalen Situation. Da die Erkennungsfunktion nur für den Fall erfolgreich ist, dass die gestellte Frage aus dem Satz von Sätzen gezogen wird, die die Daten ausdrücken, oder genauer gesagt, grammatikalisch in Bezug auf die Grammatik für diesen Satz von Sätzen ist, ist die Satzerkennung selbst ein Verfahren zum Abrufen von Informationen. Wenn die Erkennungsfunktion erfolgreich ist, repräsentiert ihr Wert die angeforderten Informationen."}
{"DOCID": "1528", "TEXT": "Drei Fonts von computergezeichneten Buchstaben: Detaillierte Beschreibungen werden für drei Fonts von Buchstaben gegeben. Buchstabenformen werden vollständig durch Zahlen beschrieben. Die grundlegenden Vektoren haben eine allgemeine Form, so dass die Schriftarten leicht auf einer Vielzahl von Computern und Kathodenstrahlröhren gezeichnet werden können. Die Schriftarten umfassen römische Groß- und Kleinbuchstaben, mathematische Zeichen sowie griechische Groß- und Kleinbuchstaben. Das Design der Schriftarten wird beschrieben. Der Hauptbeitrag dieses Papiers betrifft jedoch die Schriftarten selbst."}
{"DOCID": "1529", "TEXT": "Dekompositionsprogrammierung Eine Analyse der Matrixsubstruktur: Ein Mineralölmischungsproblem wurde analysiert, um die primalen und primal-dualen Dekompositionsalgorithmen zu vergleichen. Im Verlauf der Analyse wurde eine Unterstruktur entdeckt, die für die relative Leistung der beiden Algorithmen und für ihre absolute Leistung im Vergleich zu einer Standard-Primal-Simplex-Lösung ohne Zerlegung relevant ist."}
{"DOCID": "1530", "TEXT": "Der ML/I-Makroprozessor: Ein Mehrzweck-Makroprozessor namens ML/I wird beschrieben. ML/I wurde auf dem PDP-7 und I.C.T. Atlas 2 Computer und ist als Werkzeug gedacht, das es Benutzern ermöglicht, jede vorhandene Programmiersprache zu erweitern, indem sie neue Anweisungen und andere syntaktische Formen ihrer eigenen Wahl und in ihre eigene Notation integrieren. Dadurch kann relativ einfach eine vollständige benutzerorientierte Sprache aufgebaut werden."}
{"DOCID": "1531", "TEXT": "The Remaining Trouble Spots in ALGOL 60: Dieses Papier listet die in der Sprache ALGOL 60 verbleibenden Unklarheiten auf, die seit der Veröffentlichung des überarbeiteten ALGOL 60-Berichts im Jahr 1963 festgestellt wurden."}
{"DOCID": "1532", "TEXT": "Die Hardware-Software-Komplementarität"}
{"DOCID": "1533", "TEXT": "A Marovian Model of the University of Michigan Executive System: Ein mathematisches Modell des Exekutivsystems eines Computers wird postuliert und seine Parameter mit Hilfe umfangreicher Daten über den Betrieb des Systems geschätzt. Obwohl vereinfachende Annahmen getroffen werden, stimmen die vom Modell vorhergesagten Ergebnisse ziemlich gut mit den tatsächlichen Ergebnissen überein. Das Modell wird verwendet, um die Auswirkungen von Änderungen im Exekutivsystem und in einem seiner Compiler zu untersuchen. Weitere Anwendungen des Modells werden diskutiert."}
{"DOCID": "1534", "TEXT": "DAD, der C.S.I.R.O. Betriebssystem: Das Design und die Implementierung des C.S.I.R.O. Betriebssystem DAD ausführlich beschrieben. Dieses System ist für den Control Data 3600 unter Verwendung eines großen Drum-Backing-Speichers ausgelegt und soll die Integration eines entfernten Konsolen-(Anzeige-)Subsystems in eine herkömmliche Job-Stack-Umgebung ermöglichen. Die Verwendung der Trommeln, das Puffern von Ein- und Ausgabe auf langsamen Peripheriegeräten und die Ausführung normaler Job-Stack-Arbeiten werden beschrieben. Das Anzeigesubsystem wird nur so beschrieben, wie es sich in den Rest des Systems integriert. Die Techniken, die sich bei der Entwicklung von DAD als nützlich erwiesen haben, werden angegeben, und es wird eine Bewertung der Gültigkeit verschiedener Designentscheidungen vorgenommen. Leistungszahlen, die auf mehreren Betriebsmonaten basieren, sind tabellarisch aufgeführt."}
{"DOCID": "1535", "TEXT": "Ein Kommentar zur Indexregisterzuordnung: Es wird eine Technik vorgestellt, um die Aufzählung zu reduzieren, die durch ein bekanntes Verfahren für eine optimale Indexregisterzuordnung in geradlinigen Programmen erforderlich ist. Diese Technik basiert auf der Konstruktion eines Verknüpfungsdiagramms, das bei jedem Schritt das zukünftige Auftreten von Indizes zeigt, die in Indexregister geladen werden müssen. Dieses Diagramm bestimmt im Voraus die erforderliche Registerkonfiguration bei bestimmten Schritten des Programms, so dass das Programm in getrennte Teile unterteilt wird, auf die das Zuordnungsverfahren unabhängig angewendet werden kann."}
{"DOCID": "1536", "TEXT": "Dynamische Berechnung von Ableitungen: Es wird gezeigt, wie das Verfahren von Wengert zur Berechnung von Ableitungen bequem implementiert werden kann, indem vom Compiler generierte komplexe Additionen, Subtraktionen und Verknüpfungen mit komplexen arithmetischen Subroutinen verwendet werden. Die Auswertung einer Funktion und einer Ableitung erfolgt parallel wie bei Wengerts Verfahren, wobei jedoch die \"imaginären\" Teile der als komplex deklarierten Variablen die Werte der Ableitungen der Realteile tragen. Diese Technik bietet eine einfache Möglichkeit, die Ableitungen einer Funktion zu berechnen, ohne dass explizite Formeln für die Ableitungen abgeleitet und zur Auswertung programmiert werden müssen."}
{"DOCID": "1537", "TEXT": "Primzahlgenerator 1 (Algorithmus 310 [A1])"}
{"DOCID": "1538", "TEXT": "Primzahlgenerator 2 (Algorithmus 311 [A1])"}
{"DOCID": "1539", "TEXT": "Primzahlgenerator 1; Primzahlgenerator 2 (Algorithmus 35[A1]; Algorithmus 310[A1]; Algorithmus 311[A1])"}
{"DOCID": "1540", "TEXT": "Ein Algorithmus zur Unterrichtsplanung mit Sektionspräferenz: Ein Algorithmus zur Zuordnung von Studenten zu Klassen in einem festen Zeitplan, der es Studenten ermöglicht, Sektionen innerhalb von Kursen zu bevorzugen, wird angegeben. Wenn sie mit dem Ziel ausgewogener Abschnitte vereinbar sind, werden diese Präferenzen berücksichtigt. Der Algorithmus ist von Natur aus stochastischer als Monte Carlo. Es werden Ergebnisse angegeben, die es mit einem Nicht-Präferenz-Zuweisungsalgorithmus vergleichen."}
{"DOCID": "1541", "TEXT": "Eine Sprache zur Modellierung und Simulation dynamischer Systeme: Das allgemeine Ziel dieser Sprache ist es, sowohl die Modellierungs- als auch die experimentellen Aspekte von Simulationsstudien zu erleichtern. Die Fähigkeit, Systeme mit hochgradig interaktiven Prozessen darzustellen, ist ein wesentliches Merkmal. Das Wesen der Sprache und die Rolle des Prozesskonzepts wird anhand eines erweiterten Beispiels dargestellt."}
{"DOCID": "1542", "TEXT": "Eine mikroprogrammierte Implementierung von EULER auf IBM System/360 Modell 30: Ein experimentelles Verarbeitungssystem für die algorithmische Sprache EULER wurde in Mikroprogrammierung auf einem IBM System/360 Modell 30 unter Verwendung einer zweiten Nur-Lese-Speichereinheit implementiert. Das System besteht aus einem mikroprogrammierten Compiler und einem mikroprogrammierten String-Language-Interpreter und aus einem E/A-Steuerprogramm, das in 360-Maschinensprache geschrieben ist. Das System wird beschrieben, und die Ergebnisse werden im Hinblick auf das Mikroprogramm und den erforderlichen Hauptspeicherplatz sowie die erhaltene Compiler- und Interpreterleistung angegeben. Die Rolle der Mikroprogrammierung wird betont, die eine neue Dimension in der Verarbeitung von interpretativem Code eröffnet. Die Struktur und der Inhalt einer höheren Sprache können durch eine geeignete Interpretationssprache angepasst werden, die effizient durch Mikroprogramme auf vorhandener Computerhardware ausgeführt werden kann."}
{"DOCID": "1543", "TEXT": "Computerformulierung der Bewegungsgleichungen unter Verwendung von Tensornotation: Es wird ein Mittel beschrieben, um den Anwendungsbereich digitaler Computer über die Stufe der numerischen Datenverarbeitung hinaus zu erweitern und die Notwendigkeit menschlicher Beteiligung bei der Formulierung bestimmter Arten von Computerproblemen zu verringern. Durch die Verwendung des Tensorkalküls und einer Computersprache, die entworfen wurde, um symbolische mathematische Berechnungen zu erleichtern, wurde ein Verfahren entwickelt, bei dem ein digitaler Computer verwendet werden kann, um nicht-numerische Arbeiten auszuführen, d. h. symbolische algebraische Manipulation und Differentiation. Um die beteiligten Techniken zu veranschaulichen, wurde ein digitaler Computer verwendet, um die Bewegungsgleichungen einer Punktmasse in einem allgemeinen orthogonalen krummlinigen Koordinatensystem abzuleiten. Da diese Operation eine Formulierung in Form von Differentialkoeffizienten erster und zweiter Ordnung beinhaltet, liefert sie eine gute Demonstration der Fähigkeit eines Computers, nicht-numerische Arbeit zu leisten und den Formulierungsprozess zu unterstützen, der normalerweise der Stufe der numerischen Datenverarbeitung vorausgeht. Darüber hinaus dient dieses spezielle Problem dazu, die Vorteile der verwendeten mathematischen Techniken zu veranschaulichen. Mit dem dafür vorbereiteten Programm leitet der Computer die Bewegungsgleichungen in jedem vom Benutzer gewünschten Koordinatensystem ab. Die Ergebnisse werden für die folgenden Koordinatensysteme präsentiert: zylindrisch polar, sphärisch polar und verlängert kugelförmig."}
{"DOCID": "1544", "TEXT": "Tele-CUPL: Ein Telefon-Time-Sharing-System: Es wird ein Mehrzweck-Computersystem mit Fernzugriff beschrieben, das Telefone mit Zwölftastentastatur als Terminals verwendet. Die Audioausgabe wird direkt an die Telefonterminals geliefert, aber das System wird normalerweise in Verbindung mit entfernt angeordneten Hochgeschwindigkeitsdruckgeräten verwendet. Das System ist eine kompatible Erweiterung eines bestehenden Stapelverarbeitungssystems. Ein wesentliches Element des Systems ist ein Schema zum Übertragen alphanumerischer Informationen durch einzelne Anschläge auf einer numerischen Tastatur. Der programmierte Scanner verwendet den Kontext, um die Mehrdeutigkeit bei der Übertragung zu beseitigen."}
{"DOCID": "1545", "TEXT": "Rechtliche Schutzmaßnahmen zur Gewährleistung des Datenschutzes in einer Computergesellschaft"}
{"DOCID": "1546", "TEXT": "Auf dem Weg zu Standards für handschriftliche Null und Oh"}
{"DOCID": "1547", "TEXT": "Gammafunktion mit beliebiger Genauigkeit (Algorithmus 309 [S14])"}
{"DOCID": "1548", "TEXT": "Analysieren von Entscheidungstabellen: Die Verringerung der Größe von Entscheidungstabellen kann durch mehrere Techniken erreicht werden. Die in diesem Artikel betrachteten Techniken beziehen sich auf das Analysieren von Entscheidungstabellen im Hinblick auf horizontale und vertikale Datenstrukturen, Jobidentität, Hardware- und Jobprioritäten und Kontextbeziehungen. Eine solche Analyse beruht auf einigen Konventionen für die Verknüpfung von Entscheidungstabellen."}
{"DOCID": "1549", "TEXT": "Ein effizientes maschinenunabhängiges Verfahren zur Garbage Collection in verschiedenen Listenstrukturen: Ein Verfahren zum Zurückgeben von Registern an die freie Liste ist ein wesentlicher Bestandteil jedes Listenverarbeitungssystems. In diesem Papier werden frühere Lösungen des Wiederherstellungsproblems überprüft und verglichen. Ein neuer Algorithmus wird vorgestellt, der deutliche Vorteile hinsichtlich Geschwindigkeit und Speicherauslastung bietet. Die Routine zum Implementieren dieses Algorithmus kann in der Listensprache geschrieben werden, mit der sie verwendet werden soll, wodurch ein gewisses Maß an Maschinenunabhängigkeit sichergestellt wird. Abschließend wird die Anwendung des Algorithmus auf eine Reihe verschiedener in der Literatur vorkommender Listenstrukturen angegeben."}
{"DOCID": "1550", "TEXT": "Ein Vergleich von Stapelverarbeitung und sofortiger Bearbeitungszeit: Es wird eine Studie über die Programmieranstrengungen von Studenten in einem Einführungskurs in die Programmierung vorgestellt und die Auswirkungen einer sofortigen Bearbeitungszeit (einige Minuten) im Gegensatz zu einer herkömmlichen Stapelverarbeitung mit Bearbeitungszeiten von einigen Stunden dargestellt untersucht. Unter den verglichenen Punkten sind die Anzahl der Computerdurchläufe pro Fahrt zum Rechenzentrum, die Programmvorbereitungszeit, die Tastendruckzeit, die Debugging-Zeit, die Anzahl der Durchläufe und die verstrichene Zeit vom ersten bis zum letzten Durchlauf für jedes Problem. Auch wenn die Ergebnisse durch die Tatsache beeinflusst werden, dass „Bonuspunkte“ für die Bewältigung eines Programmierproblems in weniger als einer festgelegten Anzahl von Durchläufen vergeben wurden, spricht einiges dafür, „Instant“ gegenüber „Batch“ zu unterstützen."}
{"DOCID": "1551", "TEXT": "Über das Kompilieren von Algorithmen für arithmetische Ausdrücke: Dieses Dokument behandelt Algorithmen bezüglich arithmetischer Ausdrücke, die in einem FORTRAN IV-Compiler für einen HITAC-5020-Computer mit n Akkumulatoren verwendet werden. Die Algorithmen erzeugen einen Objektcode, der die Häufigkeit des Speicherns und Wiederherstellens der Teilergebnisse der arithmetischen Ausdrücke in Fällen minimiert, in denen mehrere Akkumulatoren vorhanden sind."}
{"DOCID": "1552", "TEXT": "Das AED-Free-Storage-Paket: Das grundlegendste zugrunde liegende Problem in ausgeklügelten Softwaresystemen mit komplizierten, sich ändernden Datenstrukturen ist die dynamische Speicherzuweisung für eine flexible Problemmodellierung. Das kostenlose Speicherpaket des AED-1-Compilersystems ermöglicht es, verfügbare Speicherblöcke zu erhalten und zur Wiederverwendung zurückzugeben. Der insgesamt verfügbare Speicherplatz ist in eine Hierarchie freier Speicherzonen unterteilt, von denen jede ihre eigenen Eigenschaften hat. Blöcke können von beliebiger Größe sein, und spezielle Vorkehrungen ermöglichen eine effiziente Handhabung ausgewählter Größen, eine Kontrolle der Zertrümmerung und Speicherbereinigung und die gemeinsame Nutzung von physischem Raum zwischen Zonen. Die Routinen des Pakets führen automatisch High-Level-Funktionen aus, ermöglichen aber auch den Zugriff und die Steuerung feiner interner Details."}
{"DOCID": "1553", "TEXT": "Kontextuelles Verstehen durch Computer: Eine Weiterentwicklung eines Computerprogramms (ELIZA), das in der Lage ist, sich in natürlicher Sprache zu unterhalten, wird diskutiert. Die Bedeutung des Kontexts sowohl für das menschliche als auch für das maschinelle Verständnis wird betont. Es wird argumentiert, dass die Angemessenheit des in einem bestimmten Gespräch erreichten Verständnisniveaus vom Zweck dieses Gesprächs abhängt und dass ein absolutes Verständnis sowohl von Menschen als auch von Maschinen unmöglich ist."}
{"DOCID": "1554", "TEXT": "Eine Computertechnik zum Anzeigen von n-dimensionalen Hyperobjekten: Ein digitaler Computer und ein automatischer Plotter wurden verwendet, um dreidimensionale stereoskopische Filme der dreidimensionalen parallelen und perspektivischen Projektionen von vierdimensionalen Hyperobjekten zu erzeugen, die sich im vierdimensionalen Raum drehen. Die beobachteten Projektionen und ihre Bewegungen waren eine direkte Erweiterung der dreidimensionalen Erfahrung, aber es wurde kein tiefes „Gefühl“ oder Einsicht in die vierte räumliche Dimension erhalten. Die Technik kann auf n-Dimensionen verallgemeinert und auf jedes n-dimensionale Hyperobjekt oder jede Hyperfläche angewendet werden."}
{"DOCID": "1555", "TEXT": "Symmetrische Polynome (Algorithmus 305 [C1])"}
{"DOCID": "1556", "TEXT": "Permutationen mit Wiederholungen (Algorithmus 306 [G6])"}
{"DOCID": "1557", "TEXT": "Symmetrische Gruppenzeichen (Algorithmus 307 [A1])"}
{"DOCID": "1558", "TEXT": "Generierung von Permutationen in pseudolexikographischer Reihenfolge (Algorithmus [G6])"}
{"DOCID": "1559", "TEXT": "Permutationsgenerator; Permutation in lexikographischer Reihenfolge; Permutieren; Erzeugung von Permutationen in lexikographischer Reihenfolge (Algorithmus 87[G6]; Algorithmus 102[G6]; Algorithmus 130[G6]; Algorithmus 202[G6])"}
{"DOCID": "1560", "TEXT": "Transport; Transportproblem (Algorithmus 258[H]; Algorithmus 293[H])"}
{"DOCID": "1561", "TEXT": "Das Mutual Primal-Dual-Verfahren (Algorithmus 285 [H])"}
{"DOCID": "1562", "TEXT": "Airy-Funktion (Algorithmus 301 [S20])"}
{"DOCID": "1563", "TEXT": "Eine Methode zum Auffinden von Hamiltonpfaden und Rittertouren: Die Verwendung der Warnsdorffschen Regel zum Auffinden einer Rittertour wird verallgemeinert und auf das Problem angewendet, einen Hamiltonpfad in einem Graphen zu finden. Eine graphentheoretische Begründung für die Methode wird gegeben."}
{"DOCID": "1564", "TEXT": "Beschreibung des Grundalgorithmus im DETAB/65-Vorprozessor: Der Grundalgorithmus für die Umwandlung von Entscheidungstabellen in COBOL-Code ist im Generatorteil des DETAB/65-Vorprozessors enthalten. Der Generator analysiert eine Entscheidungstabelle und erzeugt einfache bedingte COBOL-Anweisungen. Durch die Verwendung von Warteschlangentechniken und umfangreicher Indizierung sowie durch die Ausgabe des Codes, während er generiert wird, Zeile für Zeile, wird Kernspeicher eingespart. Die einzige angestrebte Optimierung ist die Eliminierung offensichtlich unnötiger Tests bei bestimmten Bedingungen in der Entscheidungstabelle. Da der Präprozessor und die damit verbundene Sprache für COBOL-Benutzer entwickelt wurden, wurde der Präprozessor in einer modularen Form in erforderliches COBOL-61 geschrieben."}
{"DOCID": "1565", "TEXT": "Ein sprachunabhängiger Makroprozessor: Es wird ein Makroprozessor beschrieben, der mit fast jeder Quellsprache verwendet werden kann. Es bietet alle Funktionen, die normalerweise mit einer Makroeinrichtung verbunden sind, plus die Fähigkeit, willkürliche Transformationen der Argumentzeichenfolgen vorzunehmen. Das Programm wird am Basser Computing Department, University of Sydney, Sydney, Australien, verwendet, um Text für acht verschiedene Compiler zu verarbeiten."}
{"DOCID": "1566", "TEXT": "Optimale Startwerte für die Newton-Raphson-Berechnung von SQRT(x): Es wird das Problem betrachtet, Startwerte für die Newton-Raphson-Berechnung von SQRT(x) auf einem Digitalrechner zu erhalten. Es wird gezeigt, dass die herkömmlich verwendeten besten einheitlichen Annäherungen an SQRT(x) keine optimalen Startwerte liefern. Das Problem, optimale Startwerte zu erhalten. Das Problem, optimale Startwerte zu erhalten, wird dargelegt und einige grundlegende Ergebnisse werden bewiesen. Eine Tabelle optimaler Polynom-Startwerte ist angegeben."}
{"DOCID": "1567", "TEXT": "Zur Darstellung symmetrischer Polynome: Im Lichte der Theorie der symmetrischen Gruppe werden Beziehungen zwischen bestimmten symmetrischen Polynomen angegeben. Ein solcher Ansatz vereint frühere Arbeiten und gibt Einblick in bereits veröffentlichte Arbeiten von Aaron Booker. Eine Verallgemeinerung von Graeffes Wurzelquadrattechnik zur Bestimmung der Wurzeln eines Polynoms wird vorgeschlagen."}
{"DOCID": "1568", "TEXT": "Zeichnen einer Funktion von drei unabhängigen Variablen: Es wird ein Verfahren zum Konstruieren eines Näherungsdiagramms einer Funktion von drei unabhängigen Variablen entwickelt. Das Diagramm ähnelt einer herkömmlichen Konturkarte, außer dass es drei Skalen gibt, um die unabhängigen Variablen darzustellen. Skalenwerte der drei unabhängigen Variablen werden vektoriell addiert, und der Wert der Funktion wird dann aus den Werten gelesen, die nahegelegenen Konturen zugeordnet sind."}
{"DOCID": "1569", "TEXT": "Implementieren von Phrasenstrukturproduktionen in PL/I: Es wird ein Verfahren zum Implementieren der Produktionen einer kontextfreien Phrasenstrukturgrammatik in einer PL/I-Prozedur beschrieben, deren Struktur und Anweisungen der Struktur und Notation der Grammatik entsprechen."}
{"DOCID": "1570", "TEXT": "String-Verarbeitungstechniken: Die interne Organisation von String-Verarbeitungssystemen wird diskutiert. Sechs Techniken für Datenstrukturen werden vorgestellt und bewertet auf der Grundlage von: (1) Erzeugung von Zeichenketten; (2) Untersuchung von Saiten; und (3) Veränderung von Saiten. Auch die Betriebsgeschwindigkeit, die Speicheranforderungen, die Auswirkungen auf das Paging und die Bequemlichkeit des Programmierers werden berücksichtigt. Eine der Techniken, Einzelwort-verknüpfte Blöcke, wird in einem Beispiel verwendet, das eine Implementierung einer SNOBOL-String-Verarbeitungssprache auf einem IBM System/360 demonstriert."}
{"DOCID": "1571", "TEXT": "Ein benutzerorientiertes zeitgeteiltes Online-System: Ein bestehendes System und geplante Ergänzungen innerhalb des Datenverarbeitungslabors des Brain Research Institute an der UCLA werden beschrieben. Das System stellt einen Versuch dar, den Forschungsmitarbeitern des Instituts die Möglichkeit zu geben, auf möglichst direkte und einfache Weise direkt mit einem hochentwickelten digitalen Rechenkomplex zu interagieren. Es wird erwartet, dass mit der Anhäufung von Erfahrungen bei der Verwendung des vorliegenden Systems durch die Bestimmung von Schnittstellenparametern zwischen dem Biowissenschaftler und dem Digitalcomputer erhebliche Fortschritte im Systemdesign möglich sein werden."}
{"DOCID": "1572", "TEXT": "Die Simulation von Time-Sharing-Systemen: Die Entwicklung neuer Time-Sharing-Systeme im großen Maßstab hat eine Reihe von Problemen für das Rechenzentrumsmanagement aufgeworfen. Für diese Systeme muss nicht nur eine geeignete Hardwarekonfiguration entwickelt, sondern auch entsprechende Softwareanpassungen vorgenommen werden. Leider reagieren diese Systeme oft nicht so auf Änderungen, wie es die Intuition vorschlagen würde, und es gibt nur wenige Anleitungen, die bei der Analyse von Leistungsmerkmalen helfen. Die Entwicklung eines umfassenden Simulationsmodells zur Unterstützung der Untersuchung dieser Fragen wird in diesem Beitrag beschrieben. Das resultierende Modell hat ein Allzweckdesign und kann verwendet werden, um eine Vielzahl von Time-Sharing-Systemen zu untersuchen. Es kann auch verwendet werden, um beim Entwurf und der Entwicklung neuer Time-Sharing-Algorithmen oder -Techniken zu helfen. Aus Gründen der Effizienz und besseren Anwendbarkeit wurde das Modell in einer begrenzten FORTRAN-Teilmenge implementiert, die mit den meisten FORTRAN IV-Compilern kompatibel ist. Der Nutzen der Simulation wird anhand einer Studie des Timesharing-Systems IBM 360/67 demonstriert."}
{"DOCID": "1573", "TEXT": "Ein adaptives Quadraturverfahren mit zufälligen Panelgrößen (Algorithmus [D1])"}
{"DOCID": "1574", "TEXT": "Normalkurvenintegral (Algorithmus 304 [S15])"}
{"DOCID": "1575", "TEXT": "Unvollständiges Beta-Verhältnis (Algorithmus 179 [S14])"}
{"DOCID": "1576", "TEXT": "Eigenwerte einer reellen symmetrischen Matrix nach dem QR-Verfahren (Algorithmus 253 [F2])"}
{"DOCID": "1577", "TEXT": "Eigenwerte und Eigenvektoren einer reellen symmetrischen Matrix nach dem QR-Verfahren (Algorithmus 254 [F2])"}
{"DOCID": "1578", "TEXT": "Verallgemeinerte Anpassung der kleinsten Quadrate durch orthogonale Polynome (Algorithmus 296 [E2])"}
{"DOCID": "1579", "TEXT": "Echte Fehlerfunktion, ERF(x) (Algorithmus 123 [S15])"}
{"DOCID": "1580", "TEXT": "Fehlerfunktion – Großes X (Algorithmus 180 [S15])"}
{"DOCID": "1581", "TEXT": "Komplementäre Fehlerfunktion – Großes X (Algorithmus 181 [S15])"}
{"DOCID": "1582", "TEXT": "GAUSS (Algorithmus 209 [S15])"}
{"DOCID": "1583", "TEXT": "Normalverteilungsfunktion (Algorithmus 226 [S15])"}
{"DOCID": "1584", "TEXT": "Verfahren für die Normalverteilungsfunktionen (Algorithmus 272 [S15])"}
{"DOCID": "1585", "TEXT": "Normalkurvenintegral (Algorithmus 304 [S15])"}
{"DOCID": "1586", "TEXT": "Ein verallgemeinerter Bairstow-Algorithmus: Der Bairstow-Algorithmus wird auf den Fall eines Polynoms verallgemeinert, das selbst eine lineare Kombination von Polynomen ist, die eine Rekursion mit drei Termen erfüllen. Konvergenzeigenschaften des Verfahrens werden abgeleitet."}
{"DOCID": "1587", "TEXT": "Speicherzuweisung in einem bestimmten iterativen Prozess: Ein Verfahren zur Kernspeicherzuweisung in einem bestimmten iterativen Prozess wird beschrieben und es werden Schätzungen der erforderlichen Maschinenzeit angegeben. Das Verfahren ist auf iterative Prozesse anwendbar, bei denen einmal gewählte Eingabedatenelemente nie wieder benötigt werden. Bei diesem Verfahren werden die Eingabedaten kontinuierlich verschoben und der bereitgestellte Platz auf die Ausgabetabellen verteilt, wenn ein Überlauf auftritt. Es werden einige wichtige Sonderfälle betrachtet, in denen eine erhebliche Vereinfachung eintritt."}
{"DOCID": "1588", "TEXT": "PL/I-Listenverarbeitung: Die Konzepte der Listenverarbeitung wurden in die PL/I-Sprache eingeführt. Mit diesen neuen Einrichtungen ist es möglich, PL/I-Prozeduren zu schreiben, die mit einfachen und komplexen Datenlistenorganisationen arbeiten. Die meisten Listenverarbeitungssprachen haben unter ihrer Unfähigkeit gelitten, direkt mit komplexen Datenstrukturen umzugehen und/oder unter ihrer Unfähigkeit, den vollständigen Bereich von Programmiersprachenoperationen an den Datenlistenstrukturen durchzuführen. Diese beiden Probleme wurden in den Listenverarbeitungseinrichtungen von PL/I beseitigt. Die grundlegenden Konzepte der Listenverarbeitung und die Philosophie der PL/I-Spracherweiterungen werden diskutiert. Darüber hinaus werden mehrere detaillierte Beispiele für die Listenverarbeitung bereitgestellt."}
{"DOCID": "1589", "TEXT": "DIALOG: Ein dialogorientiertes Programmiersystem mit grafischer Orientierung: DIALOG ist eine algebraische Sprache zur Online-Nutzung mit einer grafischen Eingabe-Ausgabe-Konsole. Es ist eine Rechenhilfe für den gelegentlichen Benutzer, die grundlegende Möglichkeiten zur grafischen und numerischen Eingabe und Anzeige, zur Online- und Offline-Programmvorbereitung und -speicherung und zur Hardcopy-Präsentation der Ergebnisse bietet. Die Nutzung des Systems erfordert ein Minimum an Erfahrung oder Einweisung, da das Wachstum einer überlagerten Systemsteuersprache verhindert wurde und es keine prozessororientierten Anweisungen wie Variablentyp- oder Dimensionsdeklarationen gibt. Darüber hinaus interagiert der Prozessor in der Online-Situation zeichenweise mit der grafischen Tastatur, um die Wahl des Programmierers von Eingabesymbolen auf diejenigen zu beschränken, die syntaktisch korrekt sind. Seit Februar 1966 ist DIALOG am Forschungsinstitut IIT im täglichen Betrieb."}
{"DOCID": "1590", "TEXT": "Tonhöhenperiodenbestimmung von Sprachlauten: Es wird ein Computerverfahren beschrieben, das Tonhöhenperioden durch die Erkennung der Spitzenstruktur der Sprachwellenform bestimmt. Sprachgeräusche wurden durch ein Mikrofon und einen Analog-Digital-Wandler abgetastet, der an ein verbundenes IBM 7090-PDP-1-System angeschlossen war. Diese Äußerungen wurden mit dem normalen Geräuschpegel des Computerraums aufgezeichnet, waren jedoch in keiner Weise bandkomprimiert oder phasenverzerrt. Eine auf der Sprachwelle definierte Folge von Operationen wählt eine Liste von Punkten entlang der Wellenform als Kandidaten für Tonhöhenmarkierungen aus. Diese Marker werden durch ein Fehlererkennungs- und Korrekturverfahren validiert. Etwa 95 Prozent der Tonhöhenperioden wurden auf dem IBM 7090 innerhalb von 1- bis 2-facher Echtzeit korrekt erkannt."}
{"DOCID": "1591", "TEXT": "Ein Modell für ein multifunktionales Lehrsystem: Ein Lehrsystemmodell, das in ein Betriebssystem eines großen Computers integriert wurde, wird beschrieben. Das Modell übergab die Kontrolle an das Betriebssystem, um andere Funktionen als das Lehren auszuführen, und erlangte dann die Kontrolle zurück, um das Lehren wieder aufzunehmen. Das Lehrsystem (ABAC-II) wurde geschrieben, um unter dem Betriebssystem (IBSYS) für das IBM 7044 Graphic System zu laufen. Da das Lehrsystem automatisch beendet und neu geplant wird, könnte ein Student, der einen Kurs studiert, der an einem Kathodenstrahl-Anzeigeterminal präsentiert wird, leicht zwischen dem Studentenmodus und dem Programmiermodus umschalten. Bei letzterem standen ihm die vollen Ressourcen des Betriebssystems (Sprachprozessoren, Compiler, Bibliothek und Benutzerprogramme) zur Verfügung. Er könnte zum Beispiel ein Programm schreiben, assemblieren, debuggen und am Terminal ausführen, das in irgendeiner Sprache geschrieben ist, die von dem Betriebssystem verarbeitet wird. Ein Kurs könnte daher Textmaterial enthalten, das mit Programmierproblemen verschachtelt ist, die der Student lösen könnte, ohne das Terminal zu verlassen. Übungen in Simulation und Spielen könnten ebenfalls angeboten werden. Die Implikationen eines Lehrsystems mit diesem Grad an Flexibilität für die industrielle und leitende Ausbildung sowie die akademische Ausbildung werden diskutiert. Darüber hinaus werden auch die Vorteile dieses Systemtyps für Computerprogrammierung und -betrieb betrachtet."}
{"DOCID": "1592", "TEXT": "Zeichenfolgenähnlichkeit und Rechtschreibfehler: Das Problem der Programmierung eines Computers zur Bestimmung, ob eine Zeichenkette ein Rechtschreibfehler eines gegebenen Wortes ist, wurde betrachtet. Eine Reihe von Algorithmen wurde evaluiert – einige wurden von anderen Autoren vorgeschlagen, andere vom Autor. Diese Techniken wurden an einer Sammlung von Rechtschreibfehlern von Schülern verschiedener Klassenstufen getestet. Während viele der Methoden eindeutig unbefriedigend waren, ergaben einige nur 2,1 Prozent falsche Bestimmungen."}
{"DOCID": "1593", "TEXT": "Eine einfache Technik für die digitale Teilung: Eine einfache und wirtschaftliche Methode für die digitale Teilung wird beschrieben. Das Verfahren eignet sich für Divisoren, deren führendes Zeichen entweder Basis kleiner eins oder Eins ist, wobei das nächste Zeichen gleich Null ist; außerdem ist das Verfahren direkt und benötigt nur halb so viele arithmetische Operationen wie eine von Gilman beschriebene Variante des Harvard-Iterationsverfahrens, das für ähnliche Divisoren geeignet ist."}
{"DOCID": "1594", "TEXT": "Ein Algorithmus zur Generierung von Permutationen: Es wird ein Algorithmus beschrieben, der bei wiederholter Anwendung alle Permutationen von K Elementen generiert. Es werden nur die zuvor generierte Permutation, die Konstante K und ein temporärer Index benötigt. Beginnend mit einer bestimmten Reihenfolge von K Elementen (abcd) erzeugt eine wiederholte Anwendung des Algorithmus K-1 zusätzliche Permutationen durch K-1 aufeinanderfolgende Rotationen. Aus der anfänglichen kreisförmigen Anordnung von K Objekten kann eine andere kreisförmige Anordnung erhalten werden, indem die K-1 niedrigsten Elemente gedreht werden. Für jede neue K-1-Kreisreihenfolge kann ein weiterer K-2 erhalten werden, indem die niedrigsten K-2-Elemente gedreht werden. Wenn Sie auf diese Weise fortfahren, erzeugen Anwendungen des Algorithmus alle (K-1)! zirkuläre Ordnungen, oder da jede zirkuläre Ordnung K Permutationen ergibt, erzeugt der Algorithmus alle K! Permutationen."}
{"DOCID": "1595", "TEXT": "Über die Computeraufzählung endlicher Topologien: Das Problem der Aufzählung der Anzahl von Topologien, die aus einer endlichen Punktmenge gebildet werden können, wird sowohl theoretisch als auch rechnerisch betrachtet. Bestimmte grundlegende Ergebnisse werden ermittelt, die zu einem Algorithmus zur Aufzählung endlicher Topologien führen, und berechnete Ergebnisse werden für n <= 7 angegeben. Ein interessantes Nebenergebnis der Berechnungsarbeit war die Aufdeckung eines theoretischen Fehlers, der in die Literatur eingeführt worden war; die Verwendung des Computers in der Kombinatorik stellt chronologisch gesehen eine frühe Anwendung dar, und dieses Nebenergebnis unterstreicht seine anhaltende Nützlichkeit auf diesem Gebiet."}
{"DOCID": "1596", "TEXT": "Airy-Funktion (Algorithmus 301 [S20])"}
{"DOCID": "1597", "TEXT": "Vektor gespeichertes Array transponieren (Algorithmus 302 [K2])"}
{"DOCID": "1598", "TEXT": "Anpassung der kleinsten Quadrate durch orthogonale Polynome (Algorithmus 28 [E2])"}
{"DOCID": "1599", "TEXT": "Numerische Lösung der Polynomgleichung (Algorithmus 300 [C2])"}
{"DOCID": "1600", "TEXT": "Tschebyscheff-Quadratur (Algorithmus 279 [D1])"}
{"DOCID": "1601", "TEXT": "Parallele numerische Verfahren zur Lösung von Gleichungen: Klassische iterative Verfahren zur numerischen Lösung von Gleichungen liefern auf jeder Stufe eine einzige neue Näherung an die betreffende Wurzel. Es wird eine Technik zur Entwicklung numerischer Verfahren angegeben, die in jeder Stufe mehrere Annäherungen an eine Lösung einer Gleichung liefern. Die verschiedenen Näherungen, die in jeder Iteration erhalten werden, sind rechnerisch unabhängig, was die Verfahren in einer Parallelverarbeitungsumgebung interessant macht. Die Konvergenz wird sichergestellt, indem bei jeder Iteration die \"besten Informationen\" extrahiert werden. Es werden mehrere Familien numerischer Prozeduren entwickelt, die die Technik der Prozeduren in einer Parallelverarbeitungsumgebung verwenden, und Messungen dieser Statistiken werden berichtet. Diese Messungen werden in einer Parallelverarbeitungsumgebung interpretiert. In einer solchen Umgebung sind die erhaltenen Verfahren Standardalgorithmen überlegen."}
{"DOCID": "1602", "TEXT": "POSE: A Language for Posing Problems to a Computer: Eine Sprache, POSE, wird beschrieben, die eine drastische Abkehr vom FORTRAN/ALGOL-Typ darstellt, obwohl sie FORTRAN-Formeln und logische Darstellungen verwendet (und tatsächlich FORTRAN VI als Teilmenge enthält). Mit der neuen Sprache muss der Benutzer sein Problem nur noch in „gleichungsähnlicher“ Form beschreiben. Das Lösungsverfahren wird automatisch in Verbindung mit der Übersetzung von der Gleichungsform in die Computeranweisung bereitgestellt. Auf diese Weise kann der Benutzer der POSE-Sprache schwierige Berechnungsprobleme (wie die Lösung von Differentialgleichungen) lösen, ohne Kenntnisse über numerische Methoden oder die Feinheiten der Computer-Unterprogrammlogik zu benötigen. Im wesentlichen sind alle jetzt für die FORTRAN-Programmierung erforderlichen Schreiboperationen automatisiert worden, so daß sich der POSE-Programmierer nicht mit diesen Einzelheiten befassen muß."}
{"DOCID": "1603", "TEXT": "Ein Multiprogramming-Monitor für kleine Maschinen: INT, ein kombinierter Hardware-/Software-Monitor, der zur Steuerung einer breiten Vielfalt von Echtzeit-Eingabe-/Ausgabegeräten entwickelt wurde, wird beschrieben. Die einfachen Hardwareergänzungen stellen eine einheitliche Gerät-zu-Maschine-Schnittstelle für Elemente wie Tastaturen, grafische Eingabegeräte und Intervallzeitgeber bereit. Die Software entlastet das Benutzerprogramm von den Einzelheiten des Ein-/Ausgabe-Timings, der Pufferung und der Task-Planung und stellt die Fähigkeit zur parallelen Verarbeitung bereit. Benutzerprogramme kommunizieren mit dem Monitor über einen kleinen Satz von Metaanweisungen, die hauptsächlich aus Aufrufen von Unterprogrammen in Maschinensprache bestehen."}
{"DOCID": "1604", "TEXT": "Weiterführende Analyse einer Rechenzentrumsumgebung: Empirische Verteilungen von Programmlängen, Ausführungszeiten, Verarbeitungszeiten und Ladezeiten von über 10.000 in einer universitären Rechenzentrumsumgebung betreuten Arbeitsplätzen werden vorgestellt. Die Daten werden nach bestimmten Merkmalen von Benutzern und Jobs unterteilt, um ausgewählte empirische bedingte Verteilungen dieser Zeiteigenschaften sowie statistische Maße anderer interessanter Eigenschaften zu erhalten. Die Ergebnisse werden im Hinblick auf die Eigenschaften des untersuchten Systems interpretiert."}
{"DOCID": "1605", "TEXT": "Ein experimenteller Vergleich von Time-Sharing und Batch-Verarbeitung: Die Effektivität für die Programmentwicklung des MIT-kompatiblen Time-Sharing-Systems (CTSS) wurde mit der des IBM IBSYS-Batch-Processing-Systems mittels eines statistisch angelegten Experiments verglichen. Jedem einer Gruppe von vier Programmierthemen wurde ein identischer Satz von vier Programmierproblemen zugewiesen. Systemexterne Einflüsse, wie beispielsweise die Reihenfolge der Problemlösung, Programmierer- und Problemeigenschaften, wurden als Gestaltungsfaktoren im Experiment spezifiziert. Daten wurden für sechs Variablen (z. B. Programmiererzeit, Computerzeit, verstrichene Zeit usw.) erhalten, die als endgültig für die \"Systemeffektivität\" angesehen wurden, und Varianzanalysetechniken wurden verwendet, um Systemunterschiede in diesen Variablen nach fälligen Differenzen abzuschätzen zu den Designfaktoren eliminiert worden waren. Die statistische Analyse der experimentellen Ergebnisse lieferte starke Hinweise auf wichtige Systemunterschiede sowie eine Kritik des experimentellen Designs selbst mit Implikationen für weitere Experimente."}
{"DOCID": "1606", "TEXT": "Chi-Quadrat-Integral (Algorithmus 299 [S15])"}
{"DOCID": "1607", "TEXT": "Coulomb-Wellenfunktionen (Algorithmus 300 [S22])"}
{"DOCID": "1608", "TEXT": "Numerische Integration von Funktionen, die einen Pol haben: Es ist üblich, Funktionen numerisch zu integrieren, die irgendwo außerhalb des Integrationsbereichs divergieren. Selbst wenn die Divergenz ziemlich weit entfernt auftritt, sind Integrationsformeln wie die von Simpson, die auf der Anpassung eines Polynoms beruhen, normalerweise ungenau: In der Nähe eines Pols sind sie sehr schlecht. Es wird ein Verfahren beschrieben, das Formeln liefert, die Funktionen dieser Art genau integrieren, wenn die Reihenfolgen und Positionen der Pole bekannt sind. Es werden explizite Formeln angegeben, die auf einem automatischen Computer einfach zu verwenden sind. Es wird gezeigt, dass sie für einige andere Singularitäten sowie Pole verwendet werden können. Wenn das Integral konvergiert, kann die Integration zur Singularität durchgeführt werden. Die Genauigkeit der Integration mit einem Pol zweiter Ordnung wird diskutiert und als Beispiel wird die neue Formel mit der von Simpson verglichen. Die neuen Formeln sind auch weit vom Pol entfernt nützlich, während ihr Vorteil in Polnähe überwältigend ist."}
{"DOCID": "1609", "TEXT": "Terminierung von Lehrveranstaltungsprüfungen per Computer: Ein neuer Ansatz für das Problem der Terminierung von Lehrveranstaltungsprüfungen wird vorgestellt. Grundsätzlich kann in zwei Schritten ein Prüfungsplan gefunden werden, der eine Mindestzahl von Prüfungsterminen vorsieht und der Bedingung genügt, dass kein Studierender zwei Prüfungen gleichzeitig ablegen muss. Zunächst werden Lehrveranstaltungen, deren Prüfungstermine im selben Zeitraum liegen, auf alle möglichen Arten zusammengefasst. Dann wird eine Mindestanzahl dieser Gruppen ausgewählt, sodass jeder Kurs mindestens einmal enthalten ist. Durch das Entfernen mehrfacher Vorkommen von Kursen und das anschließende Einplanen jeder Gruppe in einen anderen Zeitraum kann ein minimaler Zeitplan erhalten werden. Bekannte Algorithmen zur Durchführung dieser Prozeduren sind unerschwinglich teuer. Es werden Annäherungen an das oben skizzierte ideale Verfahren gegeben, die mit sehr geringem Zeitaufwand nicht minimale, aber machbare Zeitpläne liefern. Ergebnisse von Experimenten unter Verwendung dieser Techniken werden angegeben. Diese sind ermutigend und weisen darauf hin, dass sich weitere Experimente lohnen würden."}
{"DOCID": "1610", "TEXT": "Ein Verfahren zur Lösung von Transportproblemen mit hohen Matrizen: Es wird ein Verfahren zur Lösung des Transportproblems mit einer Kostenmatrix mit wenigen Spalten vorgestellt. Die Computerimplementierung dieser Methode zeigt, dass sie sehr schnell und effizient ist. Anwendungen sind sowohl für das Personalklassifizierungsproblem als auch für das klassische Transportproblem angezeigt. Ein Beispiel wird detailliert ausgearbeitet."}
{"DOCID": "1611", "TEXT": "Planung von Projektnetzwerken: Einige der grundlegenden Konzepte und Terminologien von Projektnetzwerken werden entwickelt. Der in das C-E-I-R-proprietäre Planungssystem RAMPS (Resource Allocation and Multi-Project Scheduling) integrierte Critical-Path-Algorithmus wird beschrieben. Die Fehlererkennungs- und Netzwerkanalysefunktionen des Algorithmus werden ebenfalls beschrieben."}
{"DOCID": "1612", "TEXT": "Top-to-Bottom-Parsing rehabilitiert?: Dieser Hinweis befasst sich mit der Effizienz des Top-to-Bottom-Parsing-Algorithmus, wie er in Verbindung mit Grammatiken von Programmiersprachen verwendet wird. So wird gezeigt, dass das Nachvollziehen unrentabler Pfade oft durch eine geeignete Umordnung der die Grammatik bestimmenden Produktionen eliminiert werden kann. Die wesentliche Schwäche des Verfahrens liegt im Umgang mit komplizierten syntaktischen Strukturen, die in der Praxis nur spärlich besetzt sind, z. B. arithmetische Ausdrücke."}
{"DOCID": "1613", "TEXT": "One-Pass-Kompilierung von arithmetischen Ausdrücken für einen Parallelprozessor: Unter der Annahme, dass ein Prozessor eine Vielzahl von arithmetischen Einheiten haben kann, sollte ein Compiler für einen solchen Prozessor Objektcode erzeugen, um einen Vorteil aus einer möglichen Parallelität des Betriebs zu ziehen. Die meisten derzeit bekannten Kompilierungstechniken sind für einen solchen Prozessor ungeeignet, da sie Ausdrucksstrukturen erzeugen, die seriell ausgewertet werden müssen. Hier wird eine Technik vorgestellt, um arithmetische Ausdrücke zu Strukturen zu kompilieren, die mit einem hohen Grad an Parallelität ausgewertet werden können. Der Algorithmus ist eine Variante der sogenannten \"Top-Down\"-Analysetechnik und erfordert nur einen Durchlauf des Eingabetextes."}
{"DOCID": "1614", "TEXT": "Ein Vorschlag für Definitionen in ALGOL: Eine Erweiterung von ALGOL wird vorgeschlagen, um der Sprache neue Datentypen und Operatoren hinzuzufügen. Definitionen können in jeder Blocküberschrift vorkommen und mit dem Block enden. Sie sind fester Bestandteil des Programms und nicht in der Sprache festgelegt. Auch das Verhalten bestehender Operatoren kann neu definiert werden. Die Verarbeitung von Texten mit definierten Kontexten verfügt über eine „Ersetzungsregel“, die unnötige Iterationen und Zwischenspeicherungen eliminiert. Beispiele für Definitionssätze werden für reelle und komplexe Matrizen, komplexe Zahlen, Dateiverarbeitung und Listenmanipulation gegeben."}
{"DOCID": "1615", "TEXT": "Ein Algorithmus zum Erzeugen von Wurzelortdiagrammen: Es wird eine Technik zum Verwenden eines digitalen Computers zum Zeichnen von sowohl gewöhnlichen als auch zeitverzögerten Wurzelortdiagrammen beschrieben. Gewöhnliche Diagramme werden viel schneller und genauer als je zuvor gezeichnet. Zeitverzögerungsdiagramme, die vorher unmöglich zu erhalten waren, werden mit der gleichen Geschwindigkeit und Genauigkeit wie gewöhnliche Diagramme gezeichnet."}
{"DOCID": "1616", "TEXT": "Tensor Calculations on Computer: Anhang: Im Haupttext der Arbeit [Comm. ACM 9, 12 (Dec. 196), 864] wurde ein FORMAC-Programm diskutiert, das in der Lage ist, verschiedene interessierende Größen im Tensorkalkül zu berechnen. Dieser Anhang ist als Beispiel für die Programmausgabe gedacht. Chrisoffel-Symbole, die für 12 grundlegende orthogonale Koordinatensysteme berechnet wurden, sind aufgelistet."}
{"DOCID": "1617", "TEXT": "Eigenwerte und Eigenvektoren des symmetrischen Systems (Algorithmus 297 [F2])"}
{"DOCID": "1618", "TEXT": "Bestimmung der Quadratwurzel einer positiv bestimmten Matrix (Algorithmus 298 [F1])"}
{"DOCID": "1619", "TEXT": "Fehlerfreie Methoden für statistische Berechnungen: Neely hat Rechenfehler erörtert, die von einigen Algorithmen erzeugt werden, die zur Berechnung verschiedener Statistiken verwendet werden. In der vorliegenden Arbeit werden Verfahren beschrieben, die fehlerfrei, einfach im Konzept und gewöhnlich weniger kostspielig in der Maschinenzeit sind als die von Neely erwähnten."}
{"DOCID": "1620", "TEXT": "Verfahren zum Bewerten von Polynomnäherungen in Funktionsauswertungsroutinen: Das Verfahren der verschachtelten Multiplikation wird üblicherweise in Funktionsauswertungsroutinen verwendet, um Näherungspolynome auszuwerten. In den letzten Jahren wurden neue Polynomauswertungsverfahren entwickelt, die weniger Multiplikationen erfordern als verschachtelte Multiplikationen und daher für die Verwendung in Funktionsauswertungsroutinen vorzuziehen sein können. Obwohl einige dieser Verfahren aufgrund von Rundungsfehlerschwierigkeiten praktisch nicht nützlich zu sein scheinen, haben sich mehrere Verfahren zum Bewerten von Polynomen niedrigen Grades als zufriedenstellend erwiesen. Drei solcher Verfahren werden beschrieben und veranschaulicht."}
{"DOCID": "1621", "TEXT": "Computersatz von ALGOL: Eine Anwendung des computergestützten Satzes wird vorgestellt. Es wird ein Arbeitsverfahren zum Veröffentlichen von ALGOL durch computergestützte Übersetzung von der Hardware- in die Referenzdarstellung, computergestützte Planung des typografischen Layouts und computergestützte Steuerung einer Setzmaschine beschrieben. Es wird darauf hingewiesen, dass Experten in Wissenschaft, Technik und Programmierung eine korrekte ALGOL-Dokumentation garantiert wird, ohne wertvolle Zeit und Kraft für typografische Überlegungen und Korrekturlesen aufzuwenden."}
{"DOCID": "1622", "TEXT": "Ein effizientes Verfahren zur Erzeugung abgeschlossener Teilmengen: Es wird ein effizienter Algorithmus zur Erzeugung von Teilmengen einer Menge S beschrieben, die Bedingungen der Form erfüllen: „Wenn s(i) ein Mitglied der Teilmenge ist, dann muss es auch s(j) sein ein Mitglied der Teilmenge.\" Der Algorithmus wurde in der WISP-Sprache programmiert und erfolgreich auf dem IBM 7094 in Verbindung mit einer Routine zur Erkennung von Rückkopplungen in multidimensionalen iterativen Netzwerken ausgeführt."}
{"DOCID": "1623", "TEXT": "Eine Anwendung von FORMAC: Es wird ein Problem der nichtlinearen Schaltungsanalyse angegeben und die Art und Weise, wie es mit FORMAC gelöst wurde, angegeben. Die Lösung des Problems mit FORMAC war bemerkenswert, da mehrere andere Methoden, die versucht wurden, fehlschlugen. Das Problem ist einfach (obwohl von Hand nicht zu lösen), beinhaltete aber dennoch eine aufwändige Verwendung der FORMAC-Sprache. Das Programm war ziemlich groß und nutzte praktisch jeden Befehl. Insbesondere machte es ausgiebigen Gebrauch vom PART-Befehl. Mehrere Tricks waren notwendig, um einige der Mängel des FORMAC-Systems zu umgehen. Diese Abhandlung befasst sich mehr mit der Verwendung von Programmiertechniken in FORMAC als mit dem eigentlichen technischen Problem, obwohl Leser möglicherweise an dem Problem interessiert sind, weil es in einem allgemeinen (mathematischen) Sinn formuliert ist und auch auf anderen Gebieten als der Schaltungsanalyse von Interesse sein könnte ."}
{"DOCID": "1624", "TEXT": "Automatische Dimensionierung: Es werden Beispiele für Algorithmen beschrieben, die eine automatische Speicherreservierung ohne die Notwendigkeit expliziter Array-Deklarationen bewerkstelligen."}
{"DOCID": "1625", "TEXT": "Über die automatische Vereinfachung von quellsprachlichen Programmen: Methoden zur Vereinfachung, die automatisch auf Programme angewendet werden können, die in einer ALGOL-ähnlichen Sprache geschrieben sind, werden diskutiert. Die Vereinfachungen basieren auf der Form des Programms und dem Wissen, das ein Prozessor erlangt, ohne zu verstehen, was das Programm tun soll. Diese Verfahren wurden in einem Prozessor namens SURE implementiert, der ein in JOVIAL geschriebenes Programm akzeptiert und ein äquivalentes JOVIAL-Programm ausgibt, das kürzer sein und schneller als das Original ausgeführt werden kann. SURE wird beschrieben, einige der Probleme, die bei der automatischen Verbesserung auf der Quellsprachenebene auftreten, werden diskutiert, und es werden weitere Arten automatischer Programmverbesserung vorgeschlagen."}
{"DOCID": "1626", "TEXT": "Struktur eines LISP-Systems mit zweistufiger Speicherung: In einem idealen Listenverarbeitungssystem wäre genügend Kernspeicher vorhanden, um alle Daten und Programme aufzunehmen. In diesem Artikel werden eine Reihe von Techniken beschrieben, die verwendet wurden, um ein LISP-System aufzubauen, das eine Trommel als Hauptspeichermedium verwendet, mit einem überraschend geringen Zeitaufwand für die Verwendung dieses langsamen Speichergeräts. Zu den Techniken gehören die sorgfältige Segmentierung von Systemprogrammen, die Zuweisung von virtuellem Speicher, um eine Adressarithmetik zur Typbestimmung zu ermöglichen, und ein spezieller Algorithmus zum Erstellen angemessen linearisierter Listen. Es wird ein Schema zum Binden von Variablen beschrieben, das in dieser Umgebung gut ist und eine vollständige Kompatibilität zwischen kompilierten und interpretierten Programmen ohne spezielle Deklarationen ermöglicht."}
{"DOCID": "1627", "TEXT": "Anwendung des Ebenenwechsels auf eine mehrstufige Speicherorganisation: Es wird eine Technik zum Organisieren der Geräte eines Computerspeichersystems beschrieben. Diese als Mehrebenenspeicher bezeichnete Technik stellt ein Mittel bereit, um die Anforderungen für sehr große Speicherkapazitäten bestimmter Datenverwaltungs- und Informationswiedergewinnungssysteme wirtschaftlich zu erfüllen. Das Konzept des Ebenenwechsels wird eingeführt und seine Anwendung auf das Mehrebenengeschäft wird diskutiert. Es wird ein mögliches Mittel zum physikalischen Organisieren der Informationen zur effizienten Nutzung des Mehrebenenspeichers vorgestellt."}
{"DOCID": "1628", "TEXT": "Die Entstehung eines Berufs: Die Computerprogrammierung befasst sich mit einer enormen Vielfalt von Aktivitäten und wird von Menschen mit sehr unterschiedlichen Hintergründen ausgeübt. Es scheint klar zu sein, dass sich ein Teil, aber nicht alle dieser Aktivitäten zu einem bestimmten Berufsfeld entwickeln, aber dass der Umfang dieses aufstrebenden Berufs und einige seiner wirtschaftlichen, sozialen und pädagogischen Merkmale noch keineswegs genau definiert sind. In diesem Papier werden diese Fragen untersucht und einige Meinungen dazu geäußert."}
{"DOCID": "1629", "TEXT": "Stat-Pack: Ein biostatistisches Programmierpaket: Ein Paket von FORTRAN-Statistikprogrammen zur Verwendung auf fast jeder kleinen bis mittleren Größe (40.000 Zeichen oder 8.000 Wörter), für die ein FORTRAN II-Compiler existiert, wird beschrieben und seine Verfügbarkeit angekündigt. Die Hauptdesignkriterien Benutzerfreundlichkeit, einfache Modifizierung, Flexibilität der Eingabe und Details der Ausgabe werden beschrieben."}
{"DOCID": "1630", "TEXT": "Computerdarstellung planarer Regionen durch ihre Skelette: Jede Region kann als Vereinigung maximaler Nachbarschaften ihrer Punkte betrachtet werden und kann durch die Zentren und Radien dieser Nachbarschaften spezifiziert werden; Dieses Set ist eine Art \"Skelett\" der Region. Der zur Darstellung eines Bereichs auf diese Weise erforderliche Speicherplatz ist vergleichbar mit dem, der erforderlich ist, wenn er durch Codierung seiner Grenze dargestellt wird. Darüber hinaus scheint die Skelettdarstellung Vorteile zu haben, wenn es notwendig ist, wiederholt zu bestimmen, ob Punkte innerhalb oder außerhalb des Bereichs liegen, oder um mengentheoretische Operationen an Bereichen durchzuführen."}
{"DOCID": "1631", "TEXT": "Testen eines Zufallszahlengenerators: Die ersten 1.000.000 Zahlen, die von dem im General Purpose Systems Simulator (GPSS) verwendeten Zufallszahlengenerator erzeugt wurden, wurden statistischen Tests unterzogen. Die Tests werden beschrieben und die Ergebnisse der Tests werden präsentiert. Diese speziellen Tests zeigen, dass die Zahlen zufriedenstellend sind. Es wird empfohlen, auf alle in Computersimulationen verwendeten Zufallszahlen geeignete Tests anzuwenden."}
{"DOCID": "1632", "TEXT": "Programmieren des tabellarischen Varianzanalyseverfahrens für faktorielle Experimente: Es wird gezeigt, wie einfach das tabellarische Varianzanalyseverfahren für vollständige faktorielle Experimente in einer FORTRAN-Sprache programmiert werden kann. Bei diesem Verfahren wird die Gesamtquadratsumme in orthogonale Quadratsummen mit einem einzigen Freiheitsgrad aufgeteilt; Haupteffekt- und Wechselwirkungsquadratsummen werden dann durch geeignetes Poolen der Quadratsummen der einzelnen Freiheitsgrade erhalten. Programmsegmente zur Durchführung des Verfahrens werden vorgestellt. Modifikationen zur Handhabung hierarchischer Designs und replizierter Experimente werden erwähnt. Ein FORTRAN II-Programm für einen IBM 7094 wird kurz beschrieben."}
{"DOCID": "1633", "TEXT": "Ein modifiziertes Newton-Verfahren für Polynome: Ein modifiziertes Newton-Verfahren für Polynome wird diskutiert. Es wird angenommen, dass man Näherungen für alle Wurzeln des Polynoms hat. Es werden drei Variationen beschrieben. Wenn die Wurzeln einfach sind, wird gezeigt, dass unter geeigneten Bedingungen zwei der Variationen kubisch konvergieren."}
{"DOCID": "1634", "TEXT": "27 Bit sind nicht genug für 8-stellige Genauigkeit: Aus der Ungleichung 10^8 < 2^27 schließen wir wahrscheinlich, dass wir 8-stellige dezimale Gleitkommazahlen genau durch 27-Bit-Gleitkommazahlen darstellen können. Wir benötigen jedoch 28 signifikante Bits, um einige 8-stellige Zahlen genau darzustellen. Im Allgemeinen können wir zeigen, dass wenn 10^p < 2^q-1, dann q signifikante Bits immer genug für eine p-stellige Dezimalgenauigkeit sind. Schließlich können wir eine kompakte 27-Bit-Gleitkommadarstellung definieren, die 28 signifikante Bits für Zahlen von praktischer Bedeutung ergibt."}
{"DOCID": "1635", "TEXT": "Parameter für Pseudo-Runge-Kutta-Verfahren: Ziel dieses Hinweises ist es, eine Auswahl der freien Parameter in Pseudo-Runge-Kutta-Verfahren dritter und vierter Ordnung mit zwei Punkten vorzustellen. Diese Wahl von Parametern bewirkt, dass eine Grenze des Hauptteils des Abschneidefehlerterms nahe dem Minimum für das Verfahren vierter Ordnung und dem Minimum für das Verfahren dritter Ordnung liegt."}
{"DOCID": "1636", "TEXT": "Invariante Einbettung und die numerische Integration von Randwertproblemen für instabile lineare Systeme gewöhnlicher Differentialgleichungen: In so unterschiedlichen Bereichen wie dem Strahlungstransport in planetaren Atmosphären und der optimalen Lenkung und Steuerung treten Zweipunkt-Randwertprobleme für instabile Systeme auf, die stark verkomplizieren die numerische Lösung. Es wird eine invariante Einbettungstechnik vorgestellt, die zur Überwindung dieser häufig auftretenden Instabilitäten nützlich ist, und die Ergebnisse einiger numerischer Experimente werden angegeben."}
{"DOCID": "1637", "TEXT": "Probleme der statistischen Analyse von Simulationsexperimenten: Der Vergleich von Mittelwerten und der Länge von Stichprobendatensätzen: Die Forschung zur statistischen Analyse von Simulationsexperimenten mit autokorrelierten Zeitreihen wird fortgesetzt. Es wird gezeigt, wie die Längen von Probenaufzeichnungen geschätzt werden, die erforderlich sind, um bestimmte große Probenergebnisse bei der Stabilitätsmessung zu verwenden. Analogien zwischen autokorrelierten Daten und unabhängigen Beobachtungen werden beschrieben. Es wird ein Weg vorgeschlagen, um die Differenz des Mittelwerts zweier Experimente zu testen. Es wird gezeigt, wie sich die Varianz des Stichprobenmittelwerts auf das Spektrum des Erzeugungsprozesses bezieht, und die Schätzung der interessierenden Größen wird beschrieben. Die Ergebnisse erweitern die Möglichkeiten der statistischen Spektralanalyse in Anwendung auf Simulationsexperimente."}
{"DOCID": "1638", "TEXT": "Sortieren durch Ersetzungsauswahl: Beim Sortieren durch Ersetzungsauswahl wird die erwartete Länge einer Sequenz beginnend mit dem i-ten Element (i>1) als 2F bewiesen, in Übereinstimmung mit einer Vermutung von E. H. Friend, wobei F die Zahl von ist Speicherzellen verwendet. Die erwartete Länge der j-ten Folge wird als F mal einem Polynom j-ten Grades in e bestimmt, so dass sich der Wert dieses Polynoms 2 nähert, wenn j sich unendlich nähert. Rekursive Formeln werden sowohl für den Mittelwert als auch für die Standardabweichung der Länge der j-ten Sequenz erhalten. Die mathematischen Beweise dieser Ergebnisse basieren auf der Annahme, dass n, die Anzahl der zu sortierenden Elemente, unendlich ist, aber es wird gezeigt, dass der Fehler aufgrund der Endlichkeit von n schnell gegen Null geht, wenn n zunimmt."}
{"DOCID": "1639", "TEXT": "Exponentielle Kurvenanpassung (Algorithmus 295 [E2])"}
{"DOCID": "1640", "TEXT": "Verallgemeinerte kleinste Quadratanpassung durch orthogonale Polynome (Algorithmus 296 [E2])"}
{"DOCID": "1641", "TEXT": "Eine Verwendung von schnellen und langsamen Speichern in Listenverarbeitungssprachen: Es wird ein Schema beschrieben, das eine wesentliche Erhöhung des zum Speichern von Listenstrukturdaten verwendeten Speicherplatzes ermöglicht. Es besteht darin, einen inhomogenen Speicher, der aus schnellen (Kern) und langsamen (Platte oder Trommel) Speichern besteht, auf eine Ebene zu reduzieren. Der im langsamen Speicher verfügbare Platz wird in Seiten unterteilt, die jeweils eine bestimmte Anzahl von Maschinenwörtern enthalten. Die Reduktion auf einen einstufigen Speicher erfolgt durch ein Programm, das die am häufigsten aufgerufenen Seiten im schnellen Speicher belässt. Wenn eine neue Seite aus dem langsamen Speicher angefordert wird, wird die Seite im Kern mit der längsten Inaktivitätsperiode zurück in den langsamen Speicher übertragen. Das vollständige Schema wurde in Verbindung mit einer LISP-Einbettung in ALGOL unter Verwendung eines IBM 7044 mit 32k Kernspeicher und Platten implementiert. Der Speicherplatzgewinn war etwa 100-fach. Wie so oft bei Programmieranwendungen ist der Preis für den zusätzlichen Speicherplatz Computerzeit. Obwohl die Festplatten eine 10^4-mal langsamere Zugriffszeit als der Kern haben, zeigen Tests, dass die tatsächliche Verlangsamung zwischen 3 und 10 variiert, abhängig von der Anzahl der im Fast Store verfügbaren Seiten."}
{"DOCID": "1642", "TEXT": "Time-Sharing auf einem Computer mit kleinem Speicher: Es werden Techniken vorgestellt, um Time-Sharing auf einem Computer mit kleinem Hauptspeicher attraktiv zu machen. Unter „klein“ wird verstanden, dass immer nur ein Anwenderprogramm plus Monitor in den Speicher passt. Die Techniken hängen davon ab, zwei Ebenen des Sekundärspeichers zu haben: Ebene 1, mehrfach größer als der Hauptspeicher und ziemlich schnell; und Level 2, um ein Vielfaches größer und langsamer als Level 1."}
{"DOCID": "1643", "TEXT": "Eine Verbesserung der iterativen Methoden der Polynomfaktorisierung: Methoden der Polynomfaktorisierung, die die Nullstellen jeweils einzeln finden, erfordern die Division des Polynoms durch den akzeptierten Faktor. Es wird gezeigt, wie die Genauigkeit dieser Division erhöht werden kann, indem die Variable sowohl in aufsteigender als auch in absteigender Potenz dividiert wird und ein Schnittpunkt gewählt wird, der ein sehr einfach berechnetes Fehlerkriterium minimiert."}
{"DOCID": "1644", "TEXT": "Zur Berechnung von Polynomen der kleinsten Quadrate: Rundungsfehler, die während der digitalen Berechnung eines Polynoms der kleinsten Quadrate akkumuliert werden, machen das berechnete Polynom nur zu einer Annäherung an das wahre Polynom der kleinsten Quadrate. Ein einfaches Verfahren zum Anpassen des konstanten Terms des berechneten Polynoms, um eine bessere Annäherung an das wahre Polynom der kleinsten Quadrate zu erhalten, wird beschrieben."}
{"DOCID": "1645", "TEXT": "Eine Anmerkung zur Berechnung von Approximationen an die Exponentialfunktion: Es werden zwei Methoden diskutiert, die nahezu minimale rationale Approximationen an die Exponentialfunktion ergeben und gleichzeitig die wünschenswerte Eigenschaft beibehalten, dass die Approximation für negative Werte des Arguments der Kehrwert der Approximation für ist entsprechende positive Werte. Diese Verfahren führen zu Näherungen, die den üblicherweise verwendeten Konvergenten des Gaußschen Kettenbruchs für die Exponentialfunktion weit überlegen sind. Koeffizienten und Fehler sind für die Intervalle [-.5*ln 2, .5*ln 2] und [-ln 2, ln 2] angegeben."}
{"DOCID": "1646", "TEXT": "DITRAN-A-Compiler mit Schwerpunkt auf Diagnose: DITRAN (Diagnostic FORTRAN) ist eine Implementierung von ASA Basic FORTRAN mit ziemlich umfangreichen Fehlerprüffunktionen sowohl zur Kompilierzeit als auch während der Ausführung eines Programms. Der Bedarf an verbesserten Diagnosefähigkeiten und einige Ziele, die von jedem Compiler erfüllt werden müssen, werden diskutiert. Aufmerksamkeit wird dem Design und der Implementierung von DITRAN und den besonderen Techniken geschenkt, die verwendet werden, um die diagnostischen Merkmale bereitzustellen. Die Behandlung von Fehlermeldungen durch einen allgemeinen Makroansatz wird beschrieben. Spezielle Funktionen, die Unterrichtshilfen für die Verwendung durch Ausbilder bereitstellen, werden vermerkt."}
{"DOCID": "1647", "TEXT": "WATFOR – The University of Waterloo FORTRAN IV Compiler: WATFOR ist ein In-Core-Load-and-Go-Compiler, der im Betriebssystem IBM 7040/44 implementiert wurde. FORTRAN IV wurde als Quellsprache ausgewählt, um eine maximale Sprachkompatibilität mit anderen verfügbaren Kompilierungssystemen, insbesondere dem IBM 7040/44 FORTRAN IV-System, zu erreichen. Der Hauptvorteil des WATFOR-Compilers besteht darin, dass er FORTRAN IV-Programme mit Geschwindigkeiten von bis zu 100 Anweisungen pro Sekunde übersetzt. Da sich der Compiler im Kern befindet, gibt es praktisch keinen System-Overhead, und daher können große Stapel von \"Schüler\"-Programmen sehr effizient verarbeitet werden. Der Compiler bietet außerdem eine umfangreiche Fehlerdiagnose, sowohl während der Kompilierung als auch während der Ausführungsphase eines Programmlaufs. Dieses Merkmal macht das System sowohl für Lernende als auch für erfahrene Benutzer attraktiv."}
{"DOCID": "1648", "TEXT": "Einheitlicher Zufall (Algorithmus 294 [G5])"}
{"DOCID": "1649", "TEXT": "Datengesteuerte Eingabe-Ausgabe in FORTRAN: Eine Anweisung, die der NAMELIST-Anweisung von FORTRAN IV ähnlich ist, wurde in den FORTRAN 63-Compiler eingebaut. Die FORTRAN 63-Implementierung ermöglicht eine größere Flexibilität und Einfachheit als das FORTRAN IV-Merkmal. Die Hollerith-Namen, der Ort, der Modus und die Dimensionen einer Variablen können mit Hilfe von Standard-FORTRAN-Anweisungen entdeckt werden. Verfahren zur Verwendung dieser Informationen werden in Bezug auf datengesteuerte Eingabe- und Ausgaberoutinen für allgemeine Zwecke veranschaulicht; einige andere Verwendungen wie Matrizenmanipulation werden diskutiert."}
{"DOCID": "1650", "TEXT": "Ein vereinheitlichendes Rechenverfahren für die Analyse vollständiger faktorieller Experimente: Ein Rechenverfahren, das zur Berechnung von Quadratsummen bei der Varianzanalyse vollständiger faktorieller Experimente und bei der Berechnung von Haupteffekt- oder Wechselwirkungsmittelwerten verwendet werden kann, wird beschrieben. Das Verfahren wird als vereinheitlichend erläutert, da ein Verfahren für eine Vielzahl von Zwecken verwendet werden kann, die zuvor jeweils unterschiedliche Verfahren erfordern. Die Programmiervorteile eines solchen Verfahrens liegen auf der Hand. Folgende Varianten werden diskutiert: (1) die Standard-Varianzanalyse; (2) Analysen, bei denen bestimmte Ebenen eines oder mehrerer Faktoren weggelassen werden; (3) getrennte Analysen für einige Stufen eines Faktors oder für Kombinationen von Stufen von mehr als einem Faktor. Diese werden gleichzeitig durchgeführt; (4) die Berechnung von Haupteffekt- oder Wechselwirkungsmittelwerten. Der Mittelwert erwartet die Daten in Standardreihenfolge und belässt die Daten in dieser Reihenfolge, sodass viele Analysen derselben Daten ohne Neuanordnung durchgeführt werden können. Die Gesamtquadratsumme, ausschließlich einer Replikationsquadratsumme, wird in alle Polynomzerlegungen und deren Wechselwirkungen mit jeweils einem Freiheitsgrad zerlegt. Dies gilt auch dann, wenn Faktoren ungleichmäßig verteilte Faktorstufen haben."}
{"DOCID": "1651", "TEXT": "Eine interpretierende Eingaberoutine für lineare Programmierung: In diesem beschreibenden Artikel wird ein Eingabecode vorgestellt, der die Dateneingabe in jede Lösungsroutine für lineare Programmierung stark vereinfacht, zur späteren Verwendung entweder als pädagogisches Gerät oder zum Lösen eher kleiner LP-Probleme. Diese letztere (begrenzte) Verwendung ergibt sich überhaupt nicht aus inhärenten Einschränkungen im Code selbst, sondern aus einer Effizienzbewertung: Große LP-Probleme würden zweifellos von einem Eingabesystem profitieren, das besser für die Handhabung von Massendaten geeignet ist als der beschriebene Eingabecode. Vom Standpunkt eines Benutzers aus erscheint die Eingabe fast genau wie eine Lehrbuchdarstellung des LP-Problems (nur begrenzt durch die Unfähigkeit eines Keypunch, Indizes usw. zu schreiben). Der Eingabeinterpreter scannt spaltenweise, daher ist keine Datenaufbereitung mit festem Format erforderlich. Der Benutzer kann auch, nur unter sehr allgemeinen Anforderungen, freizügig redaktionelle Kommentare im gesamten Eingabedeck als Hilfe bei der Identifizierung, z. B. von Zeilenbeschränkungen, verwenden. Der Artikel enthält Beispiele für Eingaben, Ausgaben aus einer derzeit verwendeten Lösungsroutine und ein Skelett-Flussdiagramm des Eingabeinterpreters."}
{"DOCID": "1652", "TEXT": "Ein Code für nicht-numerische Informationsverarbeitungsanwendungen in Online-Systemen: Ein Code wurde speziell entwickelt, um die internen Informationsverarbeitungsvorgänge innerhalb eines Online-Computersystems in Bezug auf nicht-numerische Anwendungen zu vereinfachen und die Übertragungsrate der Informationskanalverknüpfung zu maximieren das System und der Systembenutzer. Der Kodex findet direkte Anwendung auf Probleme in Bereichen wie Informationsabruf, Dokumentenklassifizierung, computergestützter Unterricht und Textbearbeitung. Dieser als IPC (Information Processing Code) bezeichnete Code ist ein 8-Bit-Codesatz, der so konstruiert ist, dass 7-, 6-, 5- und 4-Bit-Teilsätze leicht aus dem Basissatz abgeleitet werden können. Der Codesatz ist so organisiert, dass einfache binäre Operationen zwischen den numerischen, alphabetischen, Sondersymbol- und Steuerzeichencodes unterscheiden können. Die Anzahl verwendbarer Zeichen innerhalb der Basissatzgröße kann entweder durch Verwendung von Umschaltcodes, die in dem Satz enthalten sind, oder durch geeignete Interpretation von ansonsten nicht zugewiesenen Codes auf der Grundlage der Anforderungen lokaler Umgebungen erweitert werden."}
{"DOCID": "1653", "TEXT": "Bewertung der Systemleistung: Erhebung und Bewertung: Der Stand der Technik der Systemleistungsbewertung wird überprüft und Bewertungsziele und -probleme werden untersucht. Durchsatz, Turnaround und Verfügbarkeit werden als grundlegende Leistungskennzahlen definiert; Overhead und CPU-Geschwindigkeit werden relativiert. Die Angemessenheit von Anweisungsmischungen, Kerneln, Simulatoren und anderen Tools wird ebenso diskutiert wie Fallstricke, die bei ihrer Verwendung auftreten können. Analyse, Simulation und Synthese werden als drei Bewertungsebenen dargestellt, die sukzessive immer größere Mengen an Informationen erfordern. Die zentrale Rolle der Messung bei der Leistungsbewertung und bei der Entwicklung von Bewertungsmethoden wird untersucht."}
{"DOCID": "1654", "TEXT": "Das Bildungsprogramm einer Universität in Informatik: Nach einem Überblick über die Leistungsfähigkeit moderner Computer wird Informatik auf verschiedene Weise definiert. Es werden die Ziele der Informatikausbildung genannt und behauptet, dass diese an einer nordamerikanischen Universität nur durch eine Informatikfakultät erreicht werden. Als Beispiel wird das Programm der Stanford University betrachtet. Die Anhänge enthalten Silben von Ph.D. Eignungsprüfungen für die Informatikabteilung von Stanford."}
{"DOCID": "1655", "TEXT": "Codeerweiterungsverfahren für den Informationsaustausch* (vorgeschlagener USA-Standard)"}
{"DOCID": "1656", "TEXT": "Verfahren für den Standardisierungsprozess* (Vorgeschlagener USA-Standard)"}
{"DOCID": "1657", "TEXT": "Implementierung des SHASER2 Time-Sharing-Systems: Es wird ein einfacher Mechanismus zur Ausführung eines Teils eines Programms mit eigenem Speicherschutz beschrieben. Dadurch kann ein solches Programm als Unterbetriebssystem fungieren. Eine verbesserte Version des Time-Sharing-Systems SHAER, die diese Funktion verwendet, wird beschrieben."}
{"DOCID": "1658", "TEXT": "Analyse von Algorithmen für das Null-Eins-Programmierproblem: Dieses Papier befasst sich mit einer Übersicht und Untersuchung mehrerer vorhandener Algorithmen für das Null-Eins-Programmierproblem. Rechenerfahrung wird zusammengefasst. Die Maschinenzeit und der Speicherbedarf mehrerer Algorithmen werden über mehrere Testprobleme kleiner und mittlerer Größe verglichen. Computerexperimente geben noch wenig Hoffnung, Probleme mit über 100 Variablen mit vertretbarem Aufwand an Maschinenzeit zu lösen."}
{"DOCID": "1659", "TEXT": "Computerlinguistik in einem Ph.D. Informatikprogramm: Dieser Bericht enthält Empfehlungen für ein Studienprogramm zur Computerlinguistik in einem Ph.D. Informatik Programm. Es wird eine Klassifikation der in der Computerlinguistik enthaltenen Fachgebiete vorgestellt und zehn Lehrveranstaltungen in diesen Gebieten beschrieben. Eine grundlegende Bibliographie der Computerlinguistik ist beigefügt."}
{"DOCID": "1660", "TEXT": "Index nach Thema zu Algorithmen, 1960-1968"}
{"DOCID": "1661", "TEXT": "Multint (Algorithmus 32 [D1])"}
{"DOCID": "1662", "TEXT": "Eigenwerte und Eigenvektoren einer reellen allgemeinen Matrix [F2])"}
{"DOCID": "1663", "TEXT": "Zufallszahlengenerator, der die Poisson-Verteilung erfüllt [G5])"}
{"DOCID": "1664", "TEXT": "Ein Algorithmus zum Ableiten der Gleichungen der mathematischen Physik durch symbolische Manipulation: Es wird ein Verfahren beschrieben, bei dem ein digitaler Computer verwendet werden kann, um die Gleichungen der mathematischen Physik in jedem vom Benutzer angeforderten krummlinigen Koordinatensystem abzuleiten. Die Wirksamkeit der Technik wird demonstriert, indem sie verwendet wird, um die Navier-Stokes-Gleichungen der Fluidbewegung und die Kontinuitätsgleichung abzuleiten. Um diese Gleichungen durch dieses Verfahren abzuleiten, muss der Benutzer nur die Koordinatentransformationsgleichungen kennen, die die krummlinigen Koordinaten von Interesse mit einer orthogonalen kartesischen Triade in Beziehung setzen. Wenn dieses Programm verwendet wird und die Koordinatentransformationsgleichungen als Eingabe zugeführt werden, leitet der Computer die Navier-Stokes-Gleichungen und die Kontinuitätsgleichung ab. Die erhaltenen Gleichungen sind relativ zu dem krummlinigen Koordinatensystem, das durch die als Eingabe verwendeten Transformationsgleichungen angegeben ist. In diesem Papier liegt der Schwerpunkt eher auf theoretischen Überlegungen und Methoden als auf Programmierungsdetails. Die Ergebnisse werden für zylindrische Polarkoordinatensysteme und sphärische Polarkoordinatensysteme präsentiert."}
{"DOCID": "1665", "TEXT": "Automatische Generierung effizienter lexikalischer Prozessoren unter Verwendung von Finite-State-Techniken: Die praktische Anwendung der Theorie endlicher Automaten zur automatischen Generierung lexikalischer Prozessoren wird in diesem Tutorial-Artikel unter Verwendung des AED RWORD-Systems behandelt, das am M.I.T. als Teil des AED-1-Systems. Dieses System akzeptiert als Eingabe eine Beschreibung der Mehrzeichenelemente oder von Wörtern, die in einer Sprache zulässig sind, die in Form einer Teilmenge von regulären Ausdrücken gegeben ist. Die Ausgabe des Systems ist ein lexikalischer Prozessor, der eine Zeichenkette liest und sie zu den durch die regulären Ausdrücke definierten Elementen kombiniert. Jedes Ausgabeelement wird durch eine Codenummer zusammen mit einem Zeiger auf einen Speicherblock identifiziert, der die Zeichen und die Zeichenanzahl in dem Element enthält. Die vom System produzierten Prozessoren basieren auf endlichen Zustandsmaschinen. Jeder Zustand einer \"Maschine\" entspricht einer eindeutigen Bedingung in der lexikalischen Verarbeitung einer Zeichenkette. Bei jedem Zustand wird ein Zeichen gelesen und die Maschine wechselt in einen neuen Zustand. Bei jedem Übergang werden basierend auf dem bestimmten gelesenen Zeichen geeignete Maßnahmen ergriffen. Das System ist seit 1966 in Betrieb, und die erzeugten Prozessoren haben im Vergleich zu sorgfältig handcodierten Programmen, die dieselbe Aufgabe erfüllen, eine günstige Geschwindigkeit. Lexikalische Prozessoren für AED-O und MAD gehören zu den vielen, die produziert wurden. Die verwendeten Techniken sind unabhängig von der Art der zu bewertenden Elemente. Wenn das Wort \"Ereignisse\" die Zeichenfolge ersetzt, können diese Prozessoren als verallgemeinerte Entscheidungsfindungsmechanismen beschrieben werden, die auf einer geordneten Abfolge von Ereignissen beruhen. Dadurch kann das System in einer Reihe von Anwendungen außerhalb des Bereichs der lexikalischen Verarbeitung verwendet werden. So bequem diese Vorteile auch sein mögen, Geschwindigkeit ist der wichtigste Aspekt. Beim Entwerfen eines Systems zur automatischen Generierung eines lexikalischen Prozessors war das Ziel ein Prozessor, der das Sichern oder erneute Lesen vollständig eliminiert, der fast so schnell ist wie handcodierte Prozessoren, der die Sprache analysiert und Fehler erkennt und der bequem und praktisch ist Einfach zu verwenden."}
{"DOCID": "1666", "TEXT": "Lösung linearer Programme in 0-1 Variablen durch implizite Aufzählung (Algorithmus 341 [H])"}
{"DOCID": "1667", "TEXT": "Wurzeln von Polynomen durch Wurzelquadrierung und resultierende Routine (Algorithmus 340 [C2])"}
{"DOCID": "1668", "TEXT": "Ein Algol-Verfahren für die schnelle Fourier-Transformation mit beliebigen Faktoren (Algorithmus 339 [C6])"}
{"DOCID": "1669", "TEXT": "Algol-Prozeduren für die schnelle Fourier-Transformation (Algorithmus 338 [C6])"}
{"DOCID": "1670", "TEXT": "Entsprechungen von 8-Bit- und Hollerith-Codes für Computerumgebungen (ein USASI-Tutorial-Standard)"}
{"DOCID": "1671", "TEXT": "A Phonological Rule Tester: Das Design und die Implementierung eines Systems zur Linderung des Problems der Regelbewertung für den Linguisten im Bereich der Phonologie werden vorgestellt. Es erlaubt dem Benutzer, online Sätze von Regeln zu definieren, die innerhalb des in The Sound Patterns of English von Chomsky und Halle, 1968, vorgestellten Rahmens aufgestellt werden können, um Phoneme als Bündel spezifizierter Unterscheidungsmerkmale zu definieren, um Daten als Strings von Phonemen mit zu definieren zugeordnete grammatikalische Struktur, um die Auswirkung der Anwendung von Regeln auf die Daten zu testen und sowohl die Definitionen als auch die Ergebnisse zu speichern. Die im Detail beschriebene Regelanwendungseinrichtung wurde durch Übersetzen linguistischer Regeln in Regeln in FLIP, einem formatgesteuerten Listenprozessor, der in LISP eingebettet ist, implementiert. Dies vereinfachte die Systemkonstruktion und bot dem Linguisten ausgefeilte Fähigkeiten. Das System ist in BBN LISP auf dem Computer Scientific Data System 940 geschrieben und für die interaktive Online-Nutzung ausgelegt, wobei die Kontrolle nach Ausführung jedes Befehls an den Benutzer zurückgegeben wird."}
{"DOCID": "1672", "TEXT": "Praktische Fehlerkoeffizienten bei der Integration periodischer analytischer Funktionen nach der Trapezregel: Theoretische und praktische Werte von Fehlerkoeffizienten, die nützlich sind, um den Fehler bei der Integration periodischer analytischer Funktionen mit der Trapezregel zu begrenzen, sind für verschiedene Bereiche der Parameter tabelliert."}
{"DOCID": "1673", "TEXT": "Annäherungslösung von Anfangsrandwellengleichungsproblemen durch Randwerttechniken: Eine neue Randwerttechnik wird für die Behandlung von Anfangsrandwertproblemen für lineare und leicht nichtlineare Wellengleichungen vorgeschlagen. Mehrere anschauliche Beispiele werden angeboten, um die Leichtigkeit zu demonstrieren, mit der die Methode angewendet werden kann."}
{"DOCID": "1674", "TEXT": "Einzeilige Zufallszahlengeneratoren und ihre Verwendung in Kombinationen: Einige einzeilige Zufallszahlengeneratoren, d. h. Generatoren, die einen einzigen FORTRAN-Befehl erfordern, werden diskutiert, und einige kurze FORTRAN-Programme, die mehrere solcher Generatoren mischen, werden beschrieben. Ziel ist die Bereitstellung von Methoden zur direkten Einbindung von Zufallszahlengeneratoren in FORTRAN-Programme mittels weniger Inline-Anweisungen. Die Vorteile sind Geschwindigkeit (Vermeidung der Verknüpfung mit und von einer Unterroutine), Bequemlichkeit und Vielseitigkeit. Jeder, der mit Generatoren experimentieren möchte, indem er entweder selbst Kongruenzgeneratoren verwendet oder mehrere Generatoren mischt, um eine Zusammensetzung mit potenziell besseren statistischen Eigenschaften als die derzeit verfügbaren Bibliotheksgeneratoren bereitzustellen, möchte vielleicht einige der hier besprochenen einfachen FORTRAN-Programme in Betracht ziehen."}
{"DOCID": "1675", "TEXT": "Eine Anmerkung zu einer Relevanzschätzung und ihrer Verbesserung: In diesem Beitrag wird die Wirkung einer Iteration des Verbesserungsverfahrens untersucht. Es wird gezeigt, dass Anwendungen des Verbesserungsfaktors über das erste Mal hinaus wirkungslos sind und dass der Faktor nur ein Skalierungsfaktor ist."}
{"DOCID": "1676", "TEXT": "Der LRLTRAN-Compiler: Umfangreiche Softwareprobleme sehen sich einer Organisation gegenüber, die mehrere verschiedene Computer besitzt und häufig neue anschafft. Um die Kohäsion aufrechtzuerhalten, muss ein System entwickelt werden, das in einer Hochsprache geschrieben ist, das Maschinenabhängigkeiten minimiert und diejenigen isoliert, die notwendig sind. Eine Sprache und ein Compiler für die Sprache werden hier diskutiert. Die Sprache mit dem Namen LRLTRAN ist ein stark erweitertes FORTRAN. Der Tree-Pass-Compiler verwendet intern eine polnische Postfix-Notation (Pass I bis Pass II) und eine Baumdarstellung, die als \"zusammengesetzte Blockierungstabelle\" bezeichnet wird (Pass I bis Pass III). In Durchgang II und DO-Schleife findet eine maschinenunabhängige Optimierung und in Durchgang III eine maschinenabhängige Optimierung statt."}
{"DOCID": "1677", "TEXT": "Speicherorganisation in Programmiersystemen: Das System der Programm- und Datendarstellung, das seit fünf Jahren auf dem Computer der Rice University verwendet wird, wird beschrieben. Jede logische Einheit im Speicher belegt einen Block aufeinanderfolgender Speicherplätze. Jeder Block ist durch ein Codewort gekennzeichnet und kann ein Programm, einen Datenvektor oder Codewörter enthalten, die wiederum Blöcke kennzeichnen, um Arrays zu bilden. Diese Speicheranordnung wird mit ihren realisierten Vorteilen oder Programmiersystemen diskutiert: Einfachheit der programmierten Adressierung, Flexibilität der Datenstrukturen, Effizienz der Speichernutzung, Variabilität der Systemzusammensetzung während der Ausführung, Mittel zur Verknüpfung zwischen Programmen und von Programmen zu Daten und Grundlage für die Speicherung Schutz. Die Anwendung gekennzeichneter Blöcke kann auf Bereiche der Timesharing- und Multimedia-Speichersteuerung ausgeweitet werden. Anhand von Erfahrungen bei rice werden einige Ideen zu solchen Erweiterungen vorgestellt."}
{"DOCID": "1678", "TEXT": "Automaten, formale Sprachen, abstraktes Umschalten und Berechenbarkeit in einem Ph.D. Informatikprogramm: Eine Reihe von Kursen sind in den Bereichen Automaten, formale Sprachen, abstraktes Umschalten und Berechenbarkeit aufgeführt, die einem Doktoranden zur Verfügung stehen könnten. Studentin der Informatik. Eine kurze Katalogbeschreibung jedes Kurses wird angewendet und die Rolle jedes Kurses im Graduiertenprogramm wird diskutiert."}
{"DOCID": "1679", "TEXT": "A Fast Fourier Transform Algorithm for Real-Valued Series: Ein neues Verfahren zur Berechnung der komplexen, diskreten Fourier-Transformation von reellwertigen Zeitreihen wird vorgestellt. Dieses Verfahren wird für ein Beispiel beschrieben, bei dem die Anzahl der Punkte in der Reihe eine ganzzahlige Zweierpotenz ist. Dieser Algorithmus bewahrt die Ordnung und Symmetrie des Cooley-Turkey-Algorithmus für die schnelle Fourier-Transformation, während er die Zwei-zu-Eins-Reduktion der Berechnung und Speicherung bewirkt, die erreicht werden kann, wenn die Reihe real ist. Ebenfalls diskutiert werden Hardware- und Software-Implementierungen des Algorithmus, die nur (N/4) log2 (N/2) komplexe Multiplikations- und Additionsoperationen durchführen und die nur N reale Speicherstellen beim Analysieren jedes N-Punkt-Datensatzes benötigen."}
{"DOCID": "1680", "TEXT": "Ein Anzeigeverarbeitungs- und Lernsystem für allgemeine Zwecke: ADEPT (ein Anzeige-beschleunigtes Verarbeitungs- und Lernsystem) wird beschrieben. Dieses System wurde entwickelt, um die Kommunikation zwischen Mensch und Computer zu verbessern, indem eine Anzeigeeinheit verwendet wird, um das Tutoring mit anderen Computeroperationen wie Simulation, Programmierung und Informationsabruf zu verschachteln. Es ist in FORTRAN IV (G) für das IBM System/360, Modell 40, und die Anzeigeeinheit IBM 2250 unter Betriebssystem/360 geschrieben. Adept ist ein katalogisiertes Programm, das das Standardbetriebssystem steuert, indem es sich selbst automatisch beendet und neu plant, ihm zugewiesene Computerressourcen aufgibt und die Kontrolle an das Betriebssystem abgibt, um andere Aufgaben auszuführen. Es erweitert die Leistungsfähigkeit und Flexibilität des computergestützten Unterrichts, indem es Schülern, Lehrern und anderen Benutzern sofort alle Ressourcen (systemkatalogisierte Programme) des Betriebssystems zur Verfügung stellt. Sprachprozessoren und Compiler, Simulationsmodelle, mathematische Lösungstechniken, gespeicherte Daten und alle anderen Bibliotheks- und Benutzerprogramme können ohne Neuprogrammierung in Lehrmaterial integriert werden. Veranschaulichungen der verschiedenen Anwendungen werden präsentiert und ihre Implikationen werden diskutiert."}
{"DOCID": "1681", "TEXT": "Easy English, eine Sprache zum Abrufen von Informationen über eine entfernte Schreibmaschinenkonsole: Easy English ist eine natürliche Befehlssprache, die entwickelt wurde, um die Kommunikation zwischen Mensch und Maschine über eine entfernte Schreibmaschinenkonsole zu vereinfachen. Es wurde zum Abrufen von Dokumenten aus einer computergestützten Datenbank, den Dateien des Moore School Information Systems Laboratory, entwickelt. Anforderungen werden in einer standardisierten syntaktischen Form formuliert (Beispiele davon werden vorgestellt), und diese Form wird dann in eine äquivalente Abfrage umgewandelt, die in der ursprünglichen symbolischen Befehlssprache des Abrufsystems ausgedrückt wird, die kurz beschrieben wird. Die Funktionsweise von easy English wird durch Veranschaulichung der Transformationen detailliert, die bei einer Beispielanforderung bis zu dem Punkt durchgeführt werden, an dem die Anforderungszeichenfolge an das System gesendet wird. Ein Makro-Flussdiagramm von Easy English ist enthalten, und ein Anhang enthält den Ausdruck einer Abrufdemonstration."}
{"DOCID": "1682", "TEXT": "Die Implementierung eines BASIC-Systems in einer Multiprogramming-Umgebung: Die Implementierung eines BASIC-Systems eines entfernten Terminals im Zusammenhang mit einem bestehenden Multiprogramming-Computersystem, dem Burroughs B5500, wird beschrieben. Diese Implementierung kombiniert eine einzigartige Mischung aus Maschinensprache und interpretativen Techniken mit einem inkrementellen Compiler."}
{"DOCID": "1683", "TEXT": "Boolesche Matrixverfahren zur Erkennung einfacher Präzedenzgrammatiken: Es wird ein mechanisches Verfahren abgeleitet, um zu bestimmen, ob eine gegebene kontextfreie Phrasenstrukturgrammatik eine einfache Präzedenzgrammatik ist. Dieses Verfahren besteht aus elementaren Operationen auf geeignet definierten booleschen Matrizen. Die Anwendung des Verfahrens auf Operatorgrammatiken wird ebenfalls gegeben."}
{"DOCID": "1684", "TEXT": "Mehrdeutigkeit in Entscheidungstabellen mit begrenztem Eintrag: Die Verwendung von Entscheidungstabellen als Werkzeug in der Systemanalyse und zur Programmspezifikation wird jetzt akzeptiert. 1963 wurden Redundanz-, Widerspruchs- und Vollständigkeitsregeln für eintragungsbegrenzte Tabellen veröffentlicht. Diese dienen in der Regel der Überprüfung, ggf. mit vorangegangener Umstellung von erweiterter auf eintragungsbeschränkte Form. Prozessoren, die Tabellen automatisch in konventionellere Programme übersetzen, stützen ihre Diagnosemöglichkeiten normalerweise auf diese Regeln. In diesem Papier wird vorgeschlagen, dass diese Regeln unbefriedigend sind und dass der wichtige Aspekt der Überprüfung darin besteht, Mehrdeutigkeiten aus Tabellen zu beseitigen. Mehrdeutigkeit wird definiert und diskutiert, und ein Verfahren zur Erstellung von ausgecheckten Entscheidungstabellen wird vorgeschlagen. Die theoretische Grundlage des verwendeten Algorithmus wird geschaffen. Die Wichtigkeit gut gestalteter diagnostischer Einrichtungen in Entscheidungstabellenprozessoren wird betont."}
{"DOCID": "1685", "TEXT": "GAN, ein System zum Generieren und Analysieren von Aktivitätsnetzwerken: GAN, ein System zum Generieren von Aktivitätsnetzwerken, dient der Zeitersparnis bei der Erstellung von Aktivitätsnetzwerken und dem komfortablen Umgang mit Netzwerkprogrammen. Eine definierende Beschreibung einer Programmiersprache, die zum Erzeugen von Aktivitätsnetzwerken aus einem Satz von Standardnetzwerken entwickelt wurde, wird präsentiert. Außerdem wird eine allgemeine Idee einer Sprache zum Durchführen von Berechnungen in Aktivitätsnetzwerken (Planungsaktivitätsnetzwerke) gegeben."}
{"DOCID": "1686", "TEXT": "Computersynthese von Hologrammen für 3-D-Anzeige: Optische und digitale Holographie werden überprüft. Das mathematische Modell und die Berechnungstechniken des digitalen holographischen Prozesses der Autoren werden diskutiert und Anwendungen der Computerholographie werden vorgeschlagen. Computerhologramme wurden aus dreidimensionalen Objekten hergestellt, die selbst bei weißem Licht originalgetreue Rekonstruktionen liefern. Ein neuer Ansatz basierend auf Punktaperturen für das Bild wird diskutiert. Fotografien der aus digitalen Hologrammen rekonstruierten Bilder werden präsentiert."}
{"DOCID": "1687", "TEXT": "Nettofluss (Algorithmus 248 [H])"}
{"DOCID": "1688", "TEXT": "Nettofluss (Algorithmus 248 [H])"}
{"DOCID": "1689", "TEXT": "Berechnung eines Polynoms und seiner Ableitungswerte nach dem Horner-Schema (Algorithmus 337 [C1])"}
{"DOCID": "1690", "TEXT": "Nettofluss (Algorithmus 336 [H])"}
{"DOCID": "1691", "TEXT": "A Comparison of the Correlational Behavior of Random Number Generators for the IBM 360: Hutchinson gibt an, dass der \"neue\" (prime modulo) multiplikative kongruente Pseudozufallsgenerator, der D. H. Lehmer zugeschrieben wird, die üblichen statistischen Tests für Zufallszahlengeneratoren bestanden hat. Es wird hier empirisch gezeigt, dass Generatoren dieses Typs Sequenzen erzeugen können, deren Autokorrelationsfunktionen bis zu einer Verzögerung von 50 für viele multiplikative Konstanten Beweise für Nicht-Zufälligkeit aufweisen. Ein von Tausworthe vorgeschlagener alternativer Generator, der irreduzible Polynome über dem Körper der Charakteristik zwei verwendet, erweist sich als frei von diesem Defekt. Anschließend wird die Anwendbarkeit dieser beiden Generatoren auf IBM 360 diskutiert. Da die Computerwortgröße das statistische Verhalten eines Generators beeinflussen kann, sind die älteren gemischten und einfachen kongruenten Generatoren, obwohl sie ausgiebig auf Computern mit 36 ​​oder mehr Bits pro Wort getestet wurden, möglicherweise keine optimalen Generatoren für den IBM 360."}
{"DOCID": "1692", "TEXT": "Numerische Lösung eines Wärmeübertragungsproblems mit dünnen Platten: Es wird die numerische Lösung eines linearen Gleichungssystems betrachtet, das sich aus einer diskreten Annäherung an ein Wärmeübertragungsproblem mit dünnen Platten ergibt. Die langsame Konvergenz punktiterativer Verfahren wird analysiert und es wird gezeigt, dass sie durch eine der Randbedingungen verursacht wird. Die Schwierigkeit kann durch eine iterative Standardtechnik beseitigt werden."}
{"DOCID": "1693", "TEXT": "GPL, eine wirklich universelle Programmiersprache: Eine wirklich universelle Programmiersprache, GPL, wird beschrieben, die Einrichtungen zum Erstellen (innerhalb der Sprache) neuer Datentypen sowie Einrichtungen für Operationen enthält, die auf ihnen ausgeführt werden. Die Grundsprache ist minimal in dem Sinne, dass kein Grundelement mit hoher Effizienz in den Objektprogrammen von den anderen abgeleitet werden kann. Konstrukte wie die ALGOL 60 for-Anweisungen und if-Anweisungen sind nicht grundlegend; sie sind besondere Arten von Verfahren. Neue \"Symbole\" (unterstrichene Wörter in ALGOL 60) werden implizit durch die Verwendung in anderen Deklarationen definiert. Da Wortteile definierbar sind, werden gepackte Wörter genauso einfach gehandhabt wie ganze Wörter. \"Adress\"-Variablen (Zeiger) sind in voller Allgemeinheit enthalten."}
{"DOCID": "1694", "TEXT": "Ein Algorithmus für die Wahrscheinlichkeit der Vereinigung einer großen Anzahl von Ereignissen: Es wird ein Algorithmus vorgestellt, der die Wahrscheinlichkeit für die Vereinigung von n unabhängigen und sich nicht gegenseitig ausschließenden Ereignissen effizient auswertet. Das Problem besteht darin, die Summen der Produkte aller möglichen Kombinationen von n Variablen in minimaler Zeit und Speicherplatz auszuwerten."}
{"DOCID": "1695", "TEXT": "PLEXUS – Ein Online-System zur Modellierung neuronaler Netze: PLEXUS wird beschrieben, ein System, das es einem Benutzer ermöglicht, ein neuronales Netz zu konstruieren und zu spezifizieren, die vom Netz erzeugten Ausgabedaten zu analysieren und Netze zu speichern und abzurufen Daten aus einer Bibliothek. Das System, das vollständig von einer digitalen Anzeigeeinheit aus bedient wird, interagiert direkt mit dem Benutzer und ermöglicht einfache und schnelle Übergänge zwischen den verschiedenen Phasen des Modellierungsprozesses. PLEXUS soll die neurophysiologische Forschung ergänzen, sodass die systematische Entwicklung neuronaler Modelle mit experimenteller Arbeit koordiniert werden kann. PLEXUS-Netzwerke sind aus Komponenten aufgebaut, die einzelne Neuronen, externe Stimuli und Verbindungsfasern darstellen, wobei jede Komponente von relativ detaillierter Natur ist. Es ist auch vorgesehen, experimentelle Daten als Eingabe für ein Netzwerk zu verwenden. Bequeme Mittel zum Spezifizieren und Modifizieren eines Netzwerks und umfangreiche Fehlerprüffähigkeiten werden bereitgestellt. Daten, die sich aus der Simulation eines Netzwerks ergeben, können durch eine Vielzahl von Techniken analysiert werden, die von Untersuchungen der groben Eigenschaften der Daten bis zur Bestimmung detaillierter statistischer Eigenschaften reichen."}
{"DOCID": "1696", "TEXT": "Ein Algorithmus zum Identifizieren der ergodischen Teilketten und Übergangszustände einer stochastischen Matrix: Ein Algorithmus zum Identifizieren der ergodischen Teilketten und Übergangszustände einer stochastischen Matrix wird vorgestellt. Anwendungen in der Markov-Erneuerungsprogrammierung und in der Konstruktion von Codes variabler Länge werden besprochen, und ein Aktualisierungsverfahren zum Umgang mit bestimmten Sequenzen stochastischer Matrizen wird diskutiert. Rechenzeiten werden experimentell untersucht und mit denen einer anderen kürzlich vorgeschlagenen Methode verglichen."}
{"DOCID": "1697", "TEXT": "Grafische Eingabe/Ausgabe von Nichtstandardzeichen: Ein in Harvard entwickeltes System zum grafischen Eingeben und Ausgeben von Nichtstandardzeichen auf einem Computer wird gedruckt. Prinzipiell kann das System mit jeder Orthographie umgehen, allerdings ist es derzeit auf 4000 chinesische Schriftzeichen und einige mathematische Symbole beschränkt. Neue Charaktere können dem Repertoire des Systems durch graphische Eingabe auf einem Anzeigegerät hinzugefügt werden. Die Texteingabe erfolgt über ein Anzeigegerät oder ein Rand-Tablet. Die Organisation und der Betrieb des gegenwärtigen Systems werden beschrieben, und es wird eine Erörterung der relativen Vorzüge eines solchen Systems gegeben. Abbildungen der Computereingabe und -ausgabe chinesischer Schriftzeichen sind enthalten."}
{"DOCID": "1698", "TEXT": "Ein statistisches Modell für das Konsolenverhalten in Mehrbenutzercomputern: Die Fähigkeit eines Computersystems, effizient mit der Außenwelt zu kommunizieren, ist ebenso wichtig wie seine Fähigkeit, Berechnungen effizient durchzuführen. Es ist ziemlich schwierig, einen bestimmten Benutzer zu charakterisieren, aber ziemlich einfach, die gesamte Benutzergemeinschaft zu charakterisieren. Basierend auf den Eigenschaften dieser Gemeinschaft haben wir eine hypothetische „virtuelle Konsole“ postuliert. Es wird nicht behauptet, dass sich eine virtuelle Konsole wie eine tatsächliche Konsole verhält, aber die gesamte Sammlung virtueller Konsolen modelliert die Sammlung tatsächlicher Konsolen. Mit dem Modell beantworten wir Fragen wie: Wie viele Prozesse warten auf Konsoleneingaben? Was ist die maximale Rate, mit der ein Prozess ausgeführt werden kann? Welche Grenzen können für die Gesamtpufferanforderungen gesetzt werden? Antworten auf diese und ähnliche Fragen werden in bestimmten Aspekten des Betriebssystemdesigns benötigt."}
{"DOCID": "1699", "TEXT": "Experimentelle Bewertung des Informationsabrufs durch eine Fernschreibmaschine: An der Moore School wurden Experimente zur Bewertung der Fähigkeiten mechanisierter Informationsabrufsysteme mit Schwerpunkt auf interaktiver (Mensch-Maschine-)Sprache und einigen mechanischen und psychologischen Einschränkungen in ihrem Design durchgeführt Labor für Informationssysteme. Die Grundannahme der Forschung ist, dass ein Informationsabfragesystem, das einen Mensch-Maschine-Dialog an einem Fernabfrageterminal bereitstellt, einem Suchenden viele der Werkzeuge zur Verfügung stellen sollte, die ihm zur Verfügung stünden, wenn er seine Suche tatsächlich in einer Bibliothek oder einem Archiv durchführen würde von Dokumenten. Zu den Faktoren, die bei der Bewertung eines solchen Systems involviert sind, gehören Benutzerfreundlichkeit, Lernzeit und Effektivität des tatsächlichen Abrufs. Drei Experimente und die daraus resultierenden Schlussfolgerungen werden detailliert dargestellt."}
{"DOCID": "1700", "TEXT": "PEEKABIT, Computer-Nachkomme von Lochkarten-PEEKABOO, für die Suche in natürlicher Sprache: Die „Peekaboo“-Idee aus Lochkarten-Informationsabrufmethoden wurde mit der Idee des überlagerten Lochens gepaart, um eine Programmiertechnik zu entwickeln, die die Computerlaufzeit bei einer Testsuche halbiert von 33.000 Sachregistereinträgen. Ein Suchprogramm, das das Gerät verwendet, ist seit Ende 1963 in Betrieb. Wenn ein Artikel in das Geschäft eingegeben wird, wird eine 18-Byte-Maske aus den bedeutungsvollen Wörtern des Artikels unter Verwendung der inklusiven ODER-Operation erstellt. Wenn zur Suchzeit das logische Produkt (unter Verwendung der UND-Operation) dieser Maske und einer ähnlich konstruierten Fragemaske nicht gleich der Fragemaske ist, dann sind ein oder mehrere Fragewörter in dem Speicherelement nicht vorhanden. Eine Gleichheit ist schlüssig; Die Wörter des Artikels müssen ausgepackt und mit Fragewörtern verglichen werden. Der aktuelle Speicher besteht aus über 600.000 Sachregistereinträgen, die jeweils durchschnittlich 60 Zeichen umfassen. Längere Texte, wie zum Beispiel Abstracts, könnten von mehreren Masken verarbeitet werden."}
{"DOCID": "1701", "TEXT": "Synchrone Signalisierungsraten für die Datenübertragung* (vorgeschlagener USA-Standard)"}
{"DOCID": "1702", "TEXT": "Kommentar zu Mr. Mooers' Paper"}
{"DOCID": "1703", "TEXT": "Anpassung an Standards und Identifizierung von Programmiersprachen: Die Benutzeröffentlichkeit wünscht eine Standardisierung und zuverlässige Identifizierung von Programmiersprachen und verwandten Diensten. Eine Möglichkeit, diese Ziele zu erreichen, wird durch die Methoden veranschaulicht, die für die interaktive Sprache TRAC T-64 und ihre verwandte Sprachfamilie übernommen wurden. Eine erdrückende Starrheit, die normalerweise mit Standardisierung verbunden ist, wird durch eine neue Anpassungstechnik vermieden, die dem Benutzer zugänglich ist, um lokale Variationen mit der Sprache zu ermöglichen. An der organisatorischen Quelle der Sprache wird eine explizite Standardisierung der Sprache vorgenommen. Die Verwendung der Organisationsmarke (TRAC) in den veröffentlichten Standards und darauf aufbauenden Diensten bietet eine zuverlässige öffentliche Identifizierung. Diese Verfahren können sinnvoll auf andere Programmiersprachen und Computerdienste angewendet werden."}
{"DOCID": "1704", "TEXT": "Minimale Mehrkostenkurve (ALgorithmus 217 [H])"}
{"DOCID": "1705", "TEXT": "Ein Satz grundlegender Eingabe-Ausgabe-Prozeduren (Algorithmus 335 [15]): Mittels der Grundelemente in Symbol, Outsymbol und Länge, wie von der Algorithms Policy dieser Zeitschrift gefordert [Comm. ACM 10 (Nov. 67), 729] wird ein grundlegender Satz von Input-Output-Prozeduren definiert, der auf Qualität und Flexibilität abzielt. Outreal ist beispielsweise als abgeleitete Prozedur geschrieben; es gibt unter Verwendung der Festkomma- oder Gleitkommadarstellung aus und rundet richtig. Durch den expliziten Aufruf der Prozeduren decompose integer und decompose real können Varianten leicht geschrieben werden. Die dringend empfohlene Praxis des Echos von Eingaben wird durch eine Teilmenge abgeleiteter Prozeduren (ioi, ior, iob, ioa) vereinfacht. Die Dokumentation der Ausgabe in Form von äquivalenten ALGOL-Anweisungen wird auch bereitgestellt, wenn die Untermenge oti, otr, otb, ota verwendet wird. Der Berkeley-Stil zum Bereitstellen von Informationen über die Form der Ausgabe unter Verwendung vorheriger Aufrufe von Prozeduren, wie z. B. dem realen Format, wird definiert. Eine Verwendung des Parameters outchannel zur Bereitstellung von Informationen zur gleichzeitigen Ausgabe auf mehreren Kanälen wird vorgeschlagen. Der Zusammenhang zwischen den deklarierten Prozeduren ist tabellarisch dargestellt."}
{"DOCID": "1706", "TEXT": "CHAMP-Character Manipulation Procedures: Eine neue Programmierspracheneinrichtung zur Symbolmanipulation wird beschrieben. String-Prozeduren können in einem Standard-ALGOL-Kontext deklariert und aufgerufen werden. ALGOL-Prozeduren können wiederum durch String-Prozeduren aufgerufen werden, so dass numerische und symbolische Prozesse bequem zusammen programmiert werden können. Verkettung und eine Variante des Mustervergleichs von SNOBOL bilden eine Reihe primitiver Befehle. Diese werden zu bedingten Ausdrücken zusammengesetzt, die verwendet werden sollen, um alternative Berechnungsmuster bereitzustellen. Arrays von Zeichenfolgen werden mithilfe von Quantifizierern verarbeitet. Die Klasse von Dingen, die einem Bezeichner zugeordnet werden können, kann durch ein in der Notation ausgedrücktes Verfahren eingeschränkt werden. Die Sprachfunktionen wurden im ALGOL-Compiler für den Burroughs B5500 implementiert."}
{"DOCID": "1707", "TEXT": "Generierung positiver Testmatrizen mit bekannten positiven Spektren: Es sind genügend Bedingungen gegeben, damit eine echte Matrix einer positiven Matrix ähnlich ist. Dieses Ergebnis wird verwendet, um eine Ähnlichkeitstransformation zu konstruieren, die, wenn sie auf eine bestimmte obere Dreiecksmatrix angewendet wird, eine positive Matrix mit einem vorher zugewiesenen positiven Spektrum ergibt."}
{"DOCID": "1708", "TEXT": "Eine Anmerkung zur Effizienz einer LISP-Berechnung in einer ausgelagerten Maschine: Das Problem der Verwendung von zwei Speicherebenen für Programme wird im Kontext eines LISP-Systems untersucht, das einen Kernspeicher als Puffer für einen großen virtuellen Speicher verwendet, der auf einem Trommel. Details zum Timing werden für ein bestimmtes Problem angegeben."}
{"DOCID": "1709", "TEXT": "Eine Modifikation der Technik von Efroymson für die schrittweise Regressionsanalyse: Die üblicherweise für die schrittweise multiple lineare Regression verwendete Berechnungstechnik erfordert die Speicherung einer n · n-Matrix von Daten. Wenn die Anzahl der Variablen n groß ist, belastet diese Anforderung die Speicherkapazität der derzeit verwendeten Maschinen. Die annähernde Symmetrie der beteiligten Matrizen erlaubt eine Modifikation, die nur die Hälfte des Speichers und der Berechnungen des herkömmlichen Algorithmus erfordert, und dieser zusätzliche Speicher ermöglicht die Analyse von Problemen, die mehr Variablen enthalten. Alternativ ermöglicht es die Analyse von Problemen, die die gleiche Anzahl von Variablen enthalten, wobei jedoch alle Berechnungen mit doppelter Genauigkeit durchgeführt werden."}
{"DOCID": "1710", "TEXT": "ASP-A Ringimplementiertes assoziatives Strukturpaket: ASP ist ein assoziatives Datenstrukturpaket für allgemeine Zwecke, in dem eine beliebige Anzahl von Datenelementen und eine beliebige Anzahl von Beziehungen zwischen diesen Datenelementen dargestellt werden kann. Es wird eine spezielle Bildsprache beschrieben, die sich zum Zeichnen von ASP-Strukturen auf Papier als sehr nützlich erwiesen hat. ASP-Strukturen werden mit Hilfe einer Reihe von Makroaufrufen aufgebaut und manipuliert, die im Anhang skizziert sind. Der Schwerpunkt liegt eher auf der Philosophie des Systems als auf einer bestimmten Implementierung, obwohl ausreichende Informationen enthalten sind, um dem Leser zu ermöglichen, seine eigene Implementierung von ASP zu erstellen."}
{"DOCID": "1711", "TEXT": "Wenn Ihr Computer einen Anwalt braucht: Mögliche Haftung für Fahrlässigkeit, für andere unerlaubte Handlungen (z. Eigentümer und Leasinggeber von Computern können auf potenzielle rechtliche Probleme aufmerksam gemacht werden. Der Schwerpunkt liegt auch auf Problemstellen bei der Auftragsvergabe für Datenverarbeitungsdienste, bei der Automatisierung von Aufzeichnungen, bei der Entscheidung, ob bestimmte Vorgänge automatisiert werden sollen oder nicht, und bei der Einhaltung von Gesetzen und Vorschriften in Bezug auf die Aufzeichnung. Es werden Informationen über Patente, Urheberrechte und den Schutz von Geschäftsgeheimnissen für Programme sowie das Problem der Verwendung von urheberrechtlich geschütztem Material in Informationsspeicher- und -abrufsystemen gegeben, einschließlich der anstehenden Urheberrechts- und Patentrevisionsrechnungen."}
{"DOCID": "1712", "TEXT": "Wiederherstellung von Platteninhalten nach Systemausfall: Es wird ein Verfahren diskutiert, mit dem nach einer Systemfehlfunktion der Inhalt von Plattendateien auf den Stand zum Zeitpunkt des Ausfalls wiederhergestellt werden kann."}
{"DOCID": "1713", "TEXT": "Zur Überwindung der Paralyse hoher Priorität in Multiprogramming-Systemen: Eine Fallgeschichte: Paralyse hoher Priorität ist die Verschlechterung, die in Multiprogramming-Systemen auftreten kann, wenn die Planung hauptsächlich auf vorab zugewiesenen Prioritäten basiert. Es kann gemildert werden, indem der Planungsalgorithmus modifiziert wird, um die Anzahl der gleichzeitig aktiven Programme zu maximieren. Die Fallgeschichte in diesem Aufsatz zeigt zwei allgemeine Methoden auf, durch die die Gleichzeitigkeit erhöht werden kann. Mögliche Verfeinerungen des Planungsalgorithmus für zukünftige Verbesserungen werden kurz betrachtet."}
{"DOCID": "1714", "TEXT": "Verfahren für die Normalverteilung (Algorithmus 272 [S15])"}
{"DOCID": "1715", "TEXT": "Direktsuche (Algorithmus 178 [E4])"}
{"DOCID": "1716", "TEXT": "Normale zufällige Abweichungen (Algorithmus 334 [G5])"}
{"DOCID": "1717", "TEXT": "Erzeugen von Primimplikanten über ternäre Codierung und Dezimalarithmetik: Dezimalarithmetik, ternäre Codierung von Würfeln und topologische Überlegungen werden in einem Algorithmus verwendet, um die Extremale und Primimplikanten von Booleschen Funktionen zu erhalten. Der in der FORTRAN-Sprache programmierte Algorithmus benötigt im Allgemeinen weniger Speicher als andere Minimierungsverfahren und behandelt DON'T CARE-Terme auf effiziente Weise."}
{"DOCID": "1718", "TEXT": "„Logische“ Arithmetik auf Computern mit Zweierkomplement-Binärarithmetik: Es werden Algorithmen zur Multiplikation und Division von vorzeichenlosen ganzzahligen Operanden vorgestellt, an denen die normalerweise für Vorzeichen reservierten Ziffern als signifikante arithmetische Ziffern mit positivem Gewicht teilnehmen."}
{"DOCID": "1719", "TEXT": "Eine Methodik zur Berechnung und Optimierung der Echtzeit-Systemleistung: Die ständig zunehmende Größe, Komplexität, Anzahl von Typen und Kosten von Datenverarbeitungssystemen führen zu einer ernsthaften Überprüfung der Kriterien und Methoden zur Berechnung und Optimierung von Daten innerhalb von Regierung und Industrie Kosten und Leistung des Verarbeitungssystems. Echtzeit-Datenverarbeitungssysteme, wie sie durch das automatisierte Flugreservierungssystem verkörpert sind, werden in diesem Papier diskutiert. Kriterien zur Leistungsbewertung werden beschrieben; eine Methode zur Berechnung und Optimierung wird skizziert; und das Verfahren durch Ausführen eines Teils der Leistungsberechnung und der Optimierung eines trommelorientierten Nachrichtenvermittlungssystems veranschaulicht wird."}
{"DOCID": "1720", "TEXT": "Informatik-Curricula auf Master-Niveau: Es werden die Ergebnisse einer Untersuchung der von Master-Studierenden an 25 US-amerikanischen Universitäten geleisteten Studienleistungen präsentiert und einige allgemeine Anmerkungen zu den Schwerpunkten dieser Programme gemacht."}
{"DOCID": "1721", "TEXT": "Bestimmung der Schnittpunkte zweier ebener Kurven mit Hilfe von Differentialgleichungen: Es wird ein neues Verfahren vorgeschlagen, um die Schnittpunkte zweier ebener Kurven zu berechnen. Bei der Entwicklung des Verfahrens wird die Theorie der singulären Punkte aus einem System von zwei Differentialgleichungen verwendet. Der zu bestimmende Schnittpunkt wird mit einem solchen singulären Punkt identifiziert und entsprechende Modifikationen werden auf das System angewendet, um sicherzustellen, dass der singuläre Punkt stabil ist, d. h. alle Integrale, die in der Nachbarschaft des singulären Punktes beginnen, werden sich diesem Punkt immer nähern, wenn das Integral Parameter geht gegen unendlich. Außerdem wird ein Verfahren zum systematischen Suchen nach allen Schnittpunkten in einem vorgegebenen rechteckigen Bereich beschrieben."}
{"DOCID": "1722", "TEXT": "Verfahren zur Konvergenzverbesserung für einige uneigentliche Integrale: Bei der numerischen Integration eines uneigentlichen Integrals der ersten Art ist es üblich, das Integral abzuschneiden, wenn die durch die letzte Iteration erzielte Änderung kleiner als eine vorbestimmte Konstante ist. Die Effizienz solcher Integrationsschemata kann häufig durch Verwendung neuerer Fortschritte in der Theorie nichtlinearer Transformationen verbessert werden; jedoch für einige wichtige Integrale, z. Integrale, deren Integranden rationale Polynome sind, bringen diese Transformationen keine große Verbesserung. In diesem Artikel werden mehrere Methoden zur Konvergenzverbesserung entwickelt, die die Konvergenz einiger uneigentlicher Integrale, einschließlich der Integrale rationaler Polynome, erheblich verbessern."}
{"DOCID": "1723", "TEXT": "Computerkonstruktion von Projektnetzwerken: Projektnetzwerke werden in PERT und CPM verwendet. Es wird ein Algorithmus zum Aufbauen von Projektnetzwerken direkt aus den Projektvorrangbeziehungen angegeben. Der Algorithmus erzeugt \"Dummy\"-Aktivitäten und ordnet die Bögen und Knoten topologisch an. Die Anzahl der erzeugten Knoten ist für die gegebenen Vorrangbeziehungen minimal. Es wurde experimentell in FORTRAN II für den IBM 7094 programmiert."}
{"DOCID": "1724", "TEXT": "Eine verallgemeinerte Teildurchlauf-Blocksortierung: Der Entwurf einer Teildurchlauf-Blocksortierung mit einem beliebigen Schlüsselbereich und einer beliebigen Anzahl von Arbeitsdateien wird beschrieben. Das Design ist eine Verallgemeinerung des Partial Pass Column Sort von Ashenhurst und des Amphisbaenic Sort von Nagler. Die Leistung der Sortierung ist für verschiedene Größen der Eingabedatei und die Anzahl der Arbeitsdateien tabelliert. Das Problem der Kombination einer Blocksortierung mit internen Sortierungen und die optimale Verwendung von Direktzugriffsspeichern wird berücksichtigt."}
{"DOCID": "1725", "TEXT": "Ein einfacher Beweis von Lewins Theorem zum geordneten Abrufen von assoziativen Erinnerungen: Ein effizientes Verfahren zum geordneten Abrufen von binären Wörtern aus einem assoziativen Gedächtnis, wie es von Lewin beschrieben wird, basiert auf der Verwendung spezieller Ausleseschaltungen, die die im Individuum vorhandenen Ziffernwerte anzeigen Ziffernspalten des Speichers. Somit zeigen die Schaltungen an, ob die einzelnen Ziffernspalten Ziffern beider Werte oder nur eines Wertes enthalten oder überhaupt keine Ziffern enthalten (d. h. dass der Speicher leer ist). Die Verwendung dieser Schaltungen, die in dieser Veröffentlichung als Spaltenwertindikatoren bezeichnet werden, verringert die Anzahl der Speicherzugriffe, die erforderlich sind, um eine Reihe unterschiedlicher Wörter aus dem Speicher der Reihe nach abzurufen, beträchtlich. Lewin beweist, dass für das Auslesen von m verschiedenen Binärworten nach dem beschriebenen Verfahren 2m - 1 Speicherzugriffe notwendig sind. (Damit beweist er, dass die Anzahl der notwendigen Speicherzugriffe bei seinem Verfahren, anders als bei anderen Verfahren, unabhängig von der Wortlänge ist.) In dieser Arbeit wird ein sehr einfacher Beweis dieses Satzes aus einigen elementaren Aspekten der Mengenstruktur abgeleitet Binärzahlen werden präsentiert."}
{"DOCID": "1726", "TEXT": "Vorläufige Untersuchung von Techniken zum automatisierten Lesen von unformatiertem Text: Verfahren zur Umwandlung von unstrukturiertem Druckmaterial in Computercode werden experimentell untersucht. Ein bedienergesteuerter Modus, abhängig von der menschlichen Abgrenzung der verschiedenen Bereiche der Seite zum Führen des Scanners, wird mittels eines Joysticks und einer CRT-Anzeige implementiert. Dieser Modus, für den einige Leistungsdaten erhalten werden, gilt als geeignet für die Verarbeitung von sehr kompliziertem Material, wie z. B. Fachzeitschriften. Für einfacheres Material, zum Beispiel die „Anspruchs“-Abschnitte von Patenten, und bei Anwendungen, bei denen die äußerste Genauigkeit nicht erforderlich ist, wird ein unüberwachter Modus befürwortet. Hier werden die Textanteile der Seite während eines schnellen Prescans durch eine rudimentäre Form der Häufigkeitsanalyse lokalisiert. Diese Bereiche werden dann erneut mit einer höheren Auflösung abgetastet, die für die Zeichenerkennung geeignet ist. Fehlerquoten in der Größenordnung von 0,1 Prozent werden bei einem einfachen Problem erhalten, bei dem es um Fotografien von Zählertafeln von Telefongesellschaften geht. Andere Angelegenheiten im Zusammenhang mit dem Design eines Mehrzweck-Seitenlesegeräts, wie beispielsweise die Segmentierung von gedrucktem Text, die Möglichkeit des Timesharing des Scanners, der interaktive Mensch-Maschine-Betrieb und die Faksimile-Wiedergabe von Illustrationen, werden diskutiert."}
{"DOCID": "1727", "TEXT": "Eine Möglichkeit, Häufigkeiten von Sprüngen in einem Programm zu schätzen: Für die Segmentierung eines Programms ist es nützlich, eine vernünftige Schätzung der Werte von S(ij) zu haben, wobei S(ij) der Mittelwert der Anzahl von Sprüngen von der ist i-te Anweisung bis zur j-ten Anweisung in der Laufzeit. In den Fällen, in denen die S(ij) direkt geschätzt werden, muss generell die Struktur des gesamten Programms berücksichtigt werden; daher ist es für den Programmierer und/oder den Übersetzer sehr schwierig, eine gute Schätzung von S(ij) zu erhalten. Es ist einfacher, nicht S(ij) zu schätzen, sondern die Größen P(ij)=S(ij)*C(i)/SUM[S(ij), j=1,N], wobei C(i) beliebig ist positive Konstante für jedes i. Obwohl die P(ij) für jedes i proportional zu S(ij) sind, ist die Schätzung von P(ij) einfacher, weil wir nur die \"Wahrscheinlichkeiten\" von Ereignissen schätzen müssen, bei denen die Anweisung i nach der Anweisung I(i) ausgeführt wird ). Diese Schätzung kann oft durchgeführt werden, ohne die Struktur des gesamten Programms zu berücksichtigen. Im ersten Teil der Arbeit wird unter Verwendung der Theorie der Markov-Ketten ein Algorithmus zur Berechnung von S(ij) aus P(ij) gefunden, und es werden einige Möglichkeiten zum Erhalten von Schätzungen von P(ij) angegeben . Im zweiten Teil wird eine Variante dieses Algorithmus hergeleitet, die die Notwendigkeit einer Berechnung mit großen Matrizen vermeidet."}
{"DOCID": "1728", "TEXT": "Weitere experimentelle Daten zum Verhalten von Programmen in einer Paging-Umgebung: Es werden Ergebnisse einer empirischen Studie zusammengefasst, die auf die Messung des Programmbetriebsverhaltens in solchen Multiprogramming-Systemen gerichtet ist, in denen Programme in Seiten fester Länge organisiert sind. Die aus der interpretativen Ausführung einer Reihe von Seitenprogrammen gesammelten Daten werden verwendet, um die Häufigkeit von Seitenfehlern zu beschreiben, d. h. die Häufigkeit jener Zeitpunkte, zu denen ein ausführendes Programm eine Seite mit Daten oder Befehlen benötigt, die sich nicht im Hauptspeicher (Kernspeicher) befinden. Diese Daten werden auch zur Bewertung von Seitenersetzungsalgorithmen und zur Bewertung der Auswirkungen auf die Leistung von Änderungen in der Speichermenge verwendet, die ausführenden Programmen zugewiesen wird."}
{"DOCID": "1729", "TEXT": "Minit-Algorithmus für lineare Programmierung (Algorithmus 333 [H])"}
{"DOCID": "1730", "TEXT": "Jacobi-Polynome (Algorithmus 332 [S22])"}
{"DOCID": "1731", "TEXT": "Gaußsche Quadraturformeln (Algorithmus 331 [D1])"}
{"DOCID": "1732", "TEXT": "Faktorielle Varianzanalyse (Algorithmus 330 [G1])"}
{"DOCID": "1733", "TEXT": "Verteilung nicht unterscheidbarer Objekte in unterscheidbare Slots (Algorithmus [G6])"}
{"DOCID": "1734", "TEXT": "Tschebyscheff-Lösung für ein überbestimmtes lineares System (Algorithmus 328 [F4])"}
{"DOCID": "1735", "TEXT": "Ein Terminmarkt für Computerzeit: Zur Vergabe von Computerzeit wird ein Auktionsverfahren beschrieben, das es ermöglicht, den Preis der Computerzeit mit der Nachfrage zu schwanken und die relative Priorität der Benutzer zu steuern, damit wichtigere Projekte einen besseren Zugang erhalten. Diese Auktion ist frei von den periodischen Schwankungen der Computernutzung, die oft mit monatlichen Zeitzuteilungsschemata verbunden sind."}
{"DOCID": "1736", "TEXT": "Überschriftenformat für die Datenübertragung (Ein USAAI-Tutorial – Standards)"}
{"DOCID": "1737", "TEXT": "Ein globaler Parser für kontextfreie Phrasenstrukturgrammatiken"}
{"DOCID": "1738", "TEXT": "Schreiben eines groben Debugging-Programms für den erfahrenen Benutzer: Derzeit verfügbare Online-Debugging-Routinen sind für den erfahrenen Benutzer oft unbefriedigend, da sie unnötig starre und komplizierte Eingabeformate erfordern, es dem Benutzer erschweren, Tippfehler zu korrigieren, und übermäßig viel Speicher mit komplizierten Funktionen verbrauchen . Bei einem Debugging-Programm ist es von größter Wichtigkeit, dass das Programm einfach, flexibel und hocheffizient zu verwenden ist. Die Kommunikation zwischen dem Benutzer und dem Debugging-Programm kann verbessert werden, indem bestimmte Techniken verwendet werden, die auf die meisten Online-Debugging-Programme anwendbar sind. Diese Techniken werden vorgestellt und durch ihre Verwendung in OPAK (oktales Paket), einem Debugging-Programm, das für den PDP-5/8 und den SDS-930 codiert ist, veranschaulicht. Der Kompromiss zwischen der Wirtschaftlichkeit der Kernspeicherung von Hilfsprogrammen und dem Einbau eleganter Debugging-Funktionen wird diskutiert."}
{"DOCID": "1739", "TEXT": "Suchalgorithmus für reguläre Ausdrücke: Es wird ein Verfahren zum Auffinden spezifischer Zeichenketten beschrieben, die in Zeichentext eingebettet sind, und eine Implementierung dieses Verfahrens in Form eines Compilers wird diskutiert. Der Compiler akzeptiert einen regulären Ausdruck als Quellsprache und erzeugt ein IBM 7094-Programm als Objektsprache. Das Objektprogramm akzeptiert dann den zu durchsuchenden Text als Eingabe und erzeugt jedes Mal ein Signal, wenn eine im Text eingebettete Zeichenfolge mit dem gegebenen regulären Ausdruck übereinstimmt. Beispiele, Probleme und Lösungen werden ebenfalls vorgestellt."}
{"DOCID": "1740", "TEXT": "Ein kostengünstiges Braille-Terminalgerät: Die aktive Nutzung von Timesharing-Einrichtungen für blinde Programmierer erfordert ein Braille-Terminalsystem. Es werden Details für den Bau eines Braillers aus einem Fernschreiber des Modells 33 gegeben, indem der Druckkopf modifiziert und die Elastizität der Walze erhöht wird. Es wird eine Beschreibung der zum Betrieb des Braillers erforderlichen Programmierung gegeben."}
{"DOCID": "1741", "TEXT": "BRAD: Das Brookhaven Raster Display: Es wurde ein Multikonsolen-Computeranzeigesystem entwickelt, das sehr reichhaltige Anzeigen zu niedrigen Stückkosten bietet. Jede BRAD-Konsole (Brookhaven Raster Display) kann Zehntausende von Punkten oder bis zu 4000 Zeichen bei 30 Bildern pro Sekunde darstellen. Nach einer anfänglichen Investition in ein Anzeigesystem von 50.000 US-Dollar kostet jede Anzeige mit Fernschreiber weniger als 3.000 US-Dollar. Die angewandte Technik besteht in der programmgesteuerten Erzeugung eines binären Bildes der gewünschten Anzeige in einem Computer. Das Bild wird auf einen rotierenden Trommelspeicher geschrieben. Unabhängige Leseköpfe zeigen kontinuierlich das Bild an, das durch überstrichene horizontale Linien erzeugt wird. Als Anzeigegerät dient ein handelsüblicher TV-Monitor. Die Technik hat zwei Nachteile. Ein Computer muss jedes anzuzeigende Bild berechnen. Außerdem ist die \"Zeige\"-Interaktion schwieriger. Dies liegt daran, dass die Zeigefunktion nur die Koordinaten des Punktes auf dem Bildschirm liefert. Die Umkehrung des Kartenerzeugungsprozesses ist erforderlich, um die Koordinaten des Punktes auf dem Bildschirm zu berechnen. Die Umkehrung des Kartenerzeugungsprozesses ist erforderlich, um die Koordinaten an dem ausgewählten Punkt im Eingaberaum zu berechnen."}
{"DOCID": "1742", "TEXT": "Zum Design von Anzeigeprozessoren: Die Flexibilität und Leistung, die im Datenkanal für eine Computeranzeige benötigt werden, werden berücksichtigt. Um effizient zu arbeiten, muss ein solcher Kanal über eine ausreichende Anzahl von Anweisungen verfügen, damit er am besten als kleiner Prozessor und nicht als leistungsstarker Kanal verstanden wird. Da festgestellt wurde, dass sukzessive Verbesserungen des Anzeigeprozessordesigns auf einem kreisförmigen Pfad liegen, kann man durch das Vornehmen von Verbesserungen zum ursprünglichen einfachen Design plus einem neuen Allzweckcomputer für jede Reise zurückkehren. Der Grad der physischen Trennung zwischen Anzeige und übergeordnetem Computer ist ein Schlüsselfaktor bei der Entwicklung von Anzeigeprozessoren."}
{"DOCID": "1743", "TEXT": "Zuverlässige Vollduplex-Dateiübertragung über Halbduplex-Telefonleitungen: Ein praxiserprobtes Schema zum Erzielen einer zuverlässigen Duplexübertragung über eine Halbduplex-Kommunikationsleitung wird vorgestellt, und um die Schwierigkeit des Problems zu demonstrieren, ein weiteres ähnliches Schema, das nur geringfügig ist unzuverlässig, wird ebenfalls angezeigt. Ein Flussdiagramm für das zuverlässige Schema und einige interessante Beispiele werden gegeben."}
{"DOCID": "1744", "TEXT": "Stabile numerische Methoden zum Erhalten der Tschebyscheff-Lösung für ein überbestimmtes Gleichungssystem: Eine Implementierung des Austauschalgorithmus von Stiefel zur Bestimmung einer Tschebyscheff-Lösung für ein überbestimmtes System linearer Gleichungen wird vorgestellt, die eine Gaußsche LU-Zerlegung mit Zeilenaustausch verwendet. Die Implementierung ist rechnerisch stabiler als die üblicherweise in der Literatur angegebenen. Es wird eine Verallgemeinerung des Stiefel-Algorithmus entwickelt, die den gelegentlichen Austausch von zwei Gleichungen gleichzeitig erlaubt."}
{"DOCID": "1745", "TEXT": "Ein Positionspapier zu Computer und Kommunikation: Der effektive Betrieb des freien Unternehmertums bei der Schaffung der angestrebten Informationsdienstindustrie hängt von drei Errungenschaften ab: (1) der Umstrukturierung unserer Informationsverarbeitungsindustrie, so dass eine klare Aufteilung der Kosten zwischen Computer und Kommunikation erfolgt , und die Entwicklung von Informationsdiensten; (2) die weit verbreitete Nutzung von Konzepten für Mehrzugriffssysteme, damit Informationsdienste sich an der Nutzung von Computeranlagen beteiligen können und damit die Kosten für deren Aufbau angemessen sind; und (3) die Entwicklung öffentlicher, nachrichtenvermittelter Kommunikationsdienste, damit angemessene Vorkehrungen für die Informationssicherheit getroffen werden."}
{"DOCID": "1746", "TEXT": "Schutz in einem Informationsverarbeitungsdienstprogramm: Eines der kritischen Probleme beim Entwurf eines Informationsverarbeitungsdienstprogramms, das eine flexible gemeinsame Nutzung von Benutzerinformationen ermöglicht, ist der Datenschutz. Eine Lösung für dieses Problem wird diskutiert."}
{"DOCID": "1747", "TEXT": "Drei Kriterien zum Entwerfen von Computersystemen zum Erleichtern des Debuggens: Der Designer eines Computersystems sollte explizite Kriterien zum Akzeptieren oder Zurückweisen vorgeschlagener Systemmerkmale übernehmen. Drei mögliche Kriterien dieser Art sind Eingabeaufzeichnungsfähigkeit, Eingabespezifizierbarkeit und asynchrone Reproduzierbarkeit der Ausgabe. Diese Kriterien implizieren, dass ein Benutzer, wenn er es wünscht, alle Einflüsse, die den Inhalt und Umfang der Ausgabe seines Computers beeinflussen, entweder kennen oder kontrollieren kann. Um den Umfang der Kriterien zu definieren, werden der Begriff einer abstrakten Maschine einer Programmiersprache und der Begriff eines virtuellen Computers erläutert. Beispiele für Anwendungen der Kriterien betreffen das Lesen einer Uhrzeituhr, die Synchronisation paralleler Prozesse, den Schutz in multiprogrammierten Systemen und die Zuordnung von Fähigkeitsindizes."}
{"DOCID": "1748", "TEXT": "Eine Scheduling-Philosophie für Mehrprozessorsysteme: Es wird eine Sammlung grundlegender Ideen präsentiert, die von verschiedenen Mitarbeitern in den letzten vier Jahren entwickelt wurden, um einen geeigneten Rahmen für den Entwurf und die Analyse von Mehrprozessorsystemen bereitzustellen. Die Begriffe Prozess und Zustandsvektor werden diskutiert, und die Natur grundlegender Operationen an Prozessen wird betrachtet. Einige der Verbindungen zwischen Prozessen und Schutz werden analysiert. Ein sehr allgemeiner Ansatz zum prioritätsorientierten Scheduling wird beschrieben und seine Beziehung zu herkömmlichen Interrupt-Systemen wird erläutert. Einige Aspekte der zeitorientierten Planung werden berücksichtigt. Die Implementierung des Scheduling-Mechanismus wird im Detail analysiert und die Machbarkeit einer Implementierung in Hardware festgestellt. Abschließend werden mehrere Methoden zur Verzahnung der Ausführung unabhängiger Prozesse vorgestellt und verglichen."}
{"DOCID": "1749", "TEXT": "Die Struktur des „THE“-Multiprogramming-Systems: Es wird ein Multiprogramming-System beschrieben, bei dem alle Aktivitäten auf mehrere aufeinander folgende Prozesse verteilt sind. Diese sequentiellen Prozesse sind auf verschiedenen hierarchischen Ebenen angeordnet, in denen jeweils eine oder mehrere unabhängige Abstraktionen implementiert sind. Die hierarchische Struktur erwies sich als entscheidend für die Überprüfung der logischen Solidität des Entwurfs und der Korrektheit seiner Umsetzung."}
{"DOCID": "1750", "TEXT": "Überlegungen beim Entwurf eines Mehrcomputersystems mit erweitertem Kernspeicher: Die Verwendung großer Mengen von adressierbarem (aber nicht ausführbarem) schnellem Direktzugriffsspeicher zum Erhöhen der Multiprogrammierleistung eines Mehrcomputersystems wird diskutiert. Das allgemeine Design der Hardwareanordnung und der Softwarekomponenten und Funktionen eines solchen Systems basieren auf einer geplanten Konfiguration von zwei CDC 6600, die sich eine Million Wörter erweiterten Kernspeichers teilen. Bei der Verallgemeinerung eines solchen Entwurfs wird besonderes Augenmerk auf die Schätzung der erwarteten Gewinne im Vergleich zur herkömmlichen Konfiguration separater und unabhängiger Computer ohne erweiterten Kernspeicher gelegt. Es wird eine Beobachtung bezüglich der Verwendung von konventionellen, langsameren Direktzugriffsspeichervorrichtungen anstelle des schnelleren Speichers gemacht."}
{"DOCID": "1751", "TEXT": "Das Working-Set-Modell für das Programmverhalten: Der wahrscheinlich grundlegendste Grund für das Fehlen einer allgemeinen Behandlung der Ressourcenzuweisung in modernen Computersystemen ist ein angemessenes Modell für das Programmverhalten. In dieser Arbeit wird ein neues Modell, das \"Working Set Model\", entwickelt. Der einem Prozess zugeordnete Arbeitssatz von Seiten, der als die Sammlung seiner zuletzt verwendeten Seiten definiert ist, stellt Wissen bereit, das für die dynamische Verwaltung von Seitenspeichern von entscheidender Bedeutung ist. „Prozess“ und „Arbeitssatz“ werden als Manifestationen der gleichen fortwährenden Berechnungsaktivität gezeigt; dann werden \"Prozessorbedarf\" und \"Speicherbedarf\" definiert; und Ressourcenallokation wird als das Problem des Ausgleichs von Anforderungen und verfügbarer Ausrüstung formuliert."}
{"DOCID": "1752", "TEXT": "Ressourcenverwaltung für ein Time-Sharing-Betriebssystem mittlerer Größe: Aufgabenplanung und Ressourcenausgleich für eine Paging-Maschine mit virtuellem Speicher mittlerer Größe werden in Bezug auf eine kombinierte Stapelverarbeitungs- und Time-Sharing-Umgebung diskutiert. Es wird eine Zusammenfassung der implementierten Task-Scheduling- und Paging-Algorithmen gegeben, und die Ergebnisse der Vergleichssimulation werden dargestellt, indem die Entwicklung der Algorithmen durch sechs Vorgängerversionen verfolgt wird. Während der gesamten Erörterung wird besondere Betonung auf das Ausbalancieren der Systemleistung relativ zu den Eigenschaften aller Systemressourcen gelegt. Simulationsergebnisse in Bezug auf alternative Hardwareeigenschaften und die Auswirkungen von Programmmischungen und Ladevariationen werden ebenfalls präsentiert."}
{"DOCID": "1753", "TEXT": "Virtueller Speicher, Prozesse und gemeinsame Nutzung in MULTICS: Einige grundlegende Konzepte, die beim Design des MULTICS-Betriebssystems involviert sind, werden eingeführt. MULTICS-Konzepte von Prozessen, Adressraum und virtuellem Speicher werden definiert und die Verwendung von Paging und Segmentierung wird erklärt. Die Mittel, mit denen Benutzer Prozeduren und Daten gemeinsam nutzen können, werden erörtert, und der Mechanismus, mit dem symbolische Referenzen dynamisch in Adressen virtueller Maschinen umgewandelt werden, wird im Detail beschrieben."}
{"DOCID": "1754", "TEXT": "Dynamische Speicherzuweisungssysteme: In vielen neueren Computersystemdesigns wurden Hardwareeinrichtungen bereitgestellt, um die Probleme der Speicherzuweisung zu erleichtern. Ein Verfahren zur Charakterisierung dynamischer Speicherzuweisungssysteme – gemäß den bereitgestellten funktionalen Fähigkeiten und den verwendeten zugrunde liegenden Techniken – wird vorgestellt. Der Hauptzweck des Papiers besteht darin, eine nützliche Perspektive bereitzustellen, aus der die Nützlichkeit verschiedener Hardwareeinrichtungen beurteilt werden kann. Eine kurze Übersicht über Speicherzuweisungseinrichtungen in mehreren repräsentativen Computersystemen ist als Anhang beigefügt."}
{"DOCID": "1755", "TEXT": "Proceedings of the ACM Symposium on Operating System Principles"}
{"DOCID": "1756", "TEXT": "Hollerith-Lochkartencode* (vorgeschlagener USA-Standard)"}
{"DOCID": "1757", "TEXT": "Datencode für Kalenderdatum für den Datenaustausch von Maschine zu Maschine* (vorgeschlagener USA-Standard)"}
{"DOCID": "1758", "TEXT": "Symmetrische Polynome (Algorithmus 305 [C1])"}
{"DOCID": "1759", "TEXT": "Transportproblem (Algorithmus 293 [H])"}
{"DOCID": "1760", "TEXT": "Normalkurvenintegral (Algorithmus 304 [S15])"}
{"DOCID": "1761", "TEXT": "Chi-Quadrat-Integral (Algorithmus 299 [S15])"}
{"DOCID": "1762", "TEXT": "Dilogarithmus (Algorithmus 327 [S22])"}
{"DOCID": "1763", "TEXT": "Wurzeln von Polynomgleichungen niedriger Ordnung (Algorithmus 326 [C2])"}
{"DOCID": "1764", "TEXT": "Podiumsdiskussion über Computeranerkennung: Sitzung 19 der ACM-Konferenz zum 20. Jahrestag am 31. August 1967 trug den Titel Bildung, Designexperimente und Computeranerkennung. Die zweite Hälfte bestand aus einer Podiumsdiskussion zum Thema Computerverständnis, die von Elliot I. Organick organisiert und geleitet wurde. Die vier Diskussionsteilnehmer waren Charles H. Davidson, Bernard A. Galler, Richard, W. Hamming und Alan J. Perlis. Nachdem sie vorbereitete Erklärungen abgegeben hatten, wurden die Podiumsteilnehmer von Andries van Dam und Arthur B. Kohn, die in der ersten Hälfte Vorträge gehalten hatten, an der Diskussion beteiligt. Dies ist eine Abschrift der Podiumsdiskussion, komprimiert von Dr. Organick und bearbeitet von ihm und den Podiumsteilnehmern. Einige Bemerkungen bezogen sich auf Referate von van Dam und Kahn oder auf die Diskussion in der ersten Hälfte der Sitzung. Entsprechende Abhandlungen sind in den Literaturhinweisen enthalten."}
{"DOCID": "1765", "TEXT": "Ausgaben, Mittelquellen und Nutzung digitaler Computer für Forschung und Lehre in der Hochschulbildung: 1964-65 mit Projektionen für 1968-69: Das Southern Regional Education Board veröffentlichte einen vollständigen Bericht über eine Umfrage, die es zur Bestimmung der Finanzierung und Charakterisierung der durchgeführt hatte Nutzung von Computern für Forschung und Lehre an Hochschulen in den Vereinigten Staaten. Die Stichprobenerhebung wird beschrieben und die Schätzungen für diese Gesamtpopulation werden präsentiert."}
{"DOCID": "1766", "TEXT": "Quasilinearisierung und Schätzung von Differentialoperatoren aus Eigenwerten: Bei einem gegebenen linearen gewöhnlichen Differentialoperator, der mehrere unbekannte Konstanten und eine Anzahl seiner Eigenwerte enthält, werden die Werte der unbekannten Konstanten geschätzt. Es wird eine genaue Formulierung bereitgestellt und ein effektives numerisches Lösungsverfahren angegeben. Die Ergebnisse einiger Computerexperimente sind angegeben."}
{"DOCID": "1767", "TEXT": "Eine allgemeine grafische Sprache: Die interaktive Verwendung von Computern mit grafischen Terminals wird es ermöglichen, viele neue Probleme mit Maschinen zu lösen. Um eine Vielzahl von Anwendungen handhaben zu können, ist es zweckmäßig, eine Allzweck-Grafiksprache zu entwickeln, die auf einer Reihe von Grafikgeräten nützlich ist. Es wurde ein System entworfen, um eine solche Sprache schnell und kostengünstig zu erzeugen. Eine mit dem System entwickelte Modellgrafiksprache wird vorgestellt."}
{"DOCID": "1768", "TEXT": "Ein globaler Parser für kontextfreie Phrasenstrukturgrammatiken: Ein Algorithmus zum Analysieren jeder kontextfreien Phrasenstrukturgrammatik und zum Erzeugen eines Programms, das dann jeden Satz in der Sprache parsen (oder anzeigen kann, dass der gegebene Satz ungültig ist) wird beschrieben. Der Parser ist vom Typ \"top-to-bottom\" und rekursiv. Eine Anzahl heuristischer Prozeduren, deren Zweck es ist, den Grundalgorithmus zu verkürzen, indem schnell festgestellt wird, dass bestimmte Teilketten des Eingabesatzes nicht den nichtterminalen Zielsymbolen entsprechen können, sind enthalten. Sowohl der Generierungsalgorithmus als auch der Parser wurden in RCA SNOBOL implementiert und erfolgreich auf einer Reihe von künstlichen Grammatiken und auf einer Teilmenge von ALGOL getestet. Eine Reihe von Routinen zum Extrahieren von Daten über eine Grammatik, wie zum Beispiel Mindestlängen von N-ableitbaren Zeichenfolgen und mögliche Präfixe, werden angegeben und können abgesehen von ihrer Anwendung in diesem speziellen Kontext von Interesse sein."}
{"DOCID": "1769", "TEXT": "Die expandierende Welt der Computer: Der Fortschritt der automatischen Informationsverarbeitung wird durch neun Hauptbarrieren behindert: Geographie, Kosten, Problemkomplexität, Mensch-Maschine-Kommunikation, unzureichende Sensoren, mangelndes Verständnis, Entfernung, Zeit und Größe. Der Hauptanreiz für die Überwindung dieser Barrieren ist der universelle Bedarf an Informationsverarbeitung, der immer dringlicher wird, da sich der größere Teil der menschlichen Arbeitstätigkeit von der Produktion auf die Dienstleistung verlagert. Computerentwicklungen in den Bereichen Hardware, Programmierung, Timesharing, Bildung, Datenkommunikation und Displays werden danach beurteilt, wie effektiv sie diese Barrieren beseitigen, und ihre Potenziale zum Durchbrechen von Barrieren weisen auf eine fortgesetzte schnelle Expansion hin. Problemorientierte Sprachen sind auf der ganzen Front besonders effektiv. Auch Online-Computer und Time-Sharing haben bei dieser Maßnahme einen hohen Stellenwert. Bildung und gesteigertes Verständnis sind grundlegend für alle Fortschritte mit dem Computer. Dieses komplexe, aber leistungsstarke Instrument ist das wichtigste, das Regierungen und Wissenschaftlern zur Verfügung steht, um die Probleme zu untersuchen, die durch die Bevölkerungsexplosion entstehen, und um mögliche Lösungen zu analysieren."}
{"DOCID": "1770", "TEXT": "Regeln der Ethik in der Informationsverarbeitung: Der Hintergrund und die Motivation für die Verabschiedung einer Reihe von Richtlinien für professionelles Verhalten in der Informationsverarbeitung durch den ACM-Rat am 11. November 1966 werden beschrieben. Es wird eine kurze Geschichte ethischer Kodizes in anderen Berufen gegeben. Es werden einige Gründe für und gegen die Annahme ethischer Regeln betrachtet und mehrere Abschnitte der ACM-Richtlinien analysiert. Ziel ist es, über diesen wichtigen Aspekt unseres Berufs zu informieren sowie zum Nachdenken und Interesse anzuregen."}
{"DOCID": "1771", "TEXT": "CURRICULUM 68 -- Recommendations for Academic Programs in Computer Science -- A Report of the ACM Curriculum Committee on Computer Science: Dieser Bericht enthält Empfehlungen zu akademischen Programmen in Informatik, die vom ACM Curriculum Committee on Computer Science entwickelt wurden. Es wird eine Klassifikation der in der Informatik enthaltenen Fachgebiete vorgestellt und 22 Lehrveranstaltungen in diesen Gebieten beschrieben. Voraussetzungen, Katalogbeschreibungen, detaillierte Gliederungen und kommentierte Bibliographien für diese Kurse sind enthalten. Spezielle Empfehlungen, die sich aus den vorläufigen Empfehlungen des Komitees von 1965 entwickelt haben, werden für Bachelor-Studiengänge gegeben. Es werden Graduiertenprogramme in Informatik diskutiert und einige Empfehlungen für die Entwicklung von Masterstudiengängen gegeben. Wege zur Entwicklung von Leitlinien für Promotionsprogramme werden diskutiert, aber keine konkreten Empfehlungen ausgesprochen. Die Bedeutung von Servicekursen, Nebenfächern und Weiterbildungen in der Informatik wird betont. Aufmerksamkeit wird der Organisation, dem Personalbedarf, den Computerressourcen und anderen Einrichtungen geschenkt, die für die Implementierung von Informatik-Lehrprogrammen erforderlich sind."}
{"DOCID": "1772", "TEXT": "USASCSOCR Tastaturanordnung mit zwei Gehäusen* (vorgeschlagener USA-Standard)"}
{"DOCID": "1773", "TEXT": "Allgemeine alphanumerische Tastaturanordnung für den Informationsaustausch* (vorgeschlagener USA-Standard)"}
{"DOCID": "1774", "TEXT": "Programmüberlagerungstechniken: Die allgemeinen Merkmale von Programmüberlagerungssystemen werden beschrieben. Drei Haupttypen – automatisch, halbautomatisch und nichtautomatisch – werden klassifiziert, und die Programmiertechniken werden als Funktion der Maschinenhardware und anderer Systemmerkmale erklärt. Die Implementierung einer halbautomatischen Overlay-Einrichtung in einem multiprogrammierten System auf dem CDC 6600 wird detailliert beschrieben, mit besonderem Bezug auf Echtzeitanwendungen."}
{"DOCID": "1775", "TEXT": "Anpassung der Inversen einer symmetrischen Matrix, wenn zwei symmetrische Elemente geändert werden (Algorithmus 325 [F1])"}
{"DOCID": "1776", "TEXT": "Maxflow (Algorithmus 324 [H])"}
{"DOCID": "1777", "TEXT": "Generierung von Permutationen in lexikografischer Reihenfolge (Algorithmus 323 [G6])"}
{"DOCID": "1778", "TEXT": "F-Verteilung (Algorithmus 322 [S14])"}
{"DOCID": "1779", "TEXT": "t-Test-Wahrscheinlichkeiten (Algorithmus [S14])"}
{"DOCID": "1780", "TEXT": "Harmonische Analyse für symmetrisch verteilte Daten (Algorithmus 320 [C6])"}
{"DOCID": "1781", "TEXT": "Übersetzer-Schreibsysteme: Ein kritischer Überblick über die jüngsten Bemühungen, das Schreiben von Übersetzern von Programmiersprachen zu automatisieren, wird präsentiert. Das formale Studium der Syntax und ihre Anwendung auf das Schreiben von Übersetzern werden in Abschnitt II besprochen. Verschiedene Ansätze zur Automatisierung der postsyntaktischen (semantischen) Aspekte des Übersetzerschreibens werden in Abschnitt III und mehrere verwandte Themen in Abschnitt IV erörtert."}
{"DOCID": "1782", "TEXT": "Eine bei der Fourier-Analyse nützliche numerische Integrationsformel: Es wird eine numerische Integrationsformel vorgestellt, die ungleiche Abtastintervalle verwendet. Die Intervalle sind auf einer logarithmischen Skala gleich beabstandet. Eine solche Formulierung ist bei der Fourier-Analyse nützlich, um die Genauigkeit und Benutzerfreundlichkeit zu verbessern. Ein vollständiger Satz von Formeln für die numerische Fourier-Analyse ist angegeben."}
{"DOCID": "1783", "TEXT": "Ein-und-Aus-Konvertierungen: Mit einer Ein-und-Aus-Konvertierung meinen wir, dass eine Gleitkommazahl in einer Basis in eine Gleitkommazahl in einer anderen Basis konvertiert und dann wieder in eine Gleitkommazahl in der ursprünglichen Basis konvertiert wird . Für alle Kombinationen von Rundungs- und Kürzungskonvertierungen wird die Frage berücksichtigt, wie viele signifikante Ziffern in der Zwischenbasis benötigt werden, damit solche In-and-Out-Konvertierungen die ursprüngliche Zahl (wenn möglich) oder zumindest signifikante Ziffer zurückgeben."}
{"DOCID": "1784", "TEXT": "Praktische Fehlerkoeffizienten zum Schätzen von Quadraturfehlern für analytische Funktionen: Alle veröffentlichten Fehlerkoeffizienten zum Schätzen von Quadraturfehlern für analytische Funktionen wurden unter der Annahme berechnet, dass die Quadraturregel für Polynome bis zu einem bestimmten Grad exakt war. Da diese Regeln gerundete Werte für die Abszissen und Gewichte verwenden und da die wahren Werte der Integrale einiger der fraglichen Polynome einen unendlichen binären Ausdruck haben, ist die Quadraturregel nicht exakt. Daher müssen diese Fehler bei der Berechnung praktischer Fehlerkoeffizienten berücksichtigt werden."}
{"DOCID": "1785", "TEXT": "Scatter-Storage-Techniken: Scatter-Storage-Techniken als Methode zur Implementierung der Symboltabellen von Assemblern und Compilern werden besprochen und eine Reihe von Möglichkeiten vorgestellt, sie effektiver zu nutzen. Viele der nützlichsten Varianten der Techniken sind dokumentiert."}
{"DOCID": "1786", "TEXT": "Ein verbesserter Hash-Code für Scatter-Speicherung: Eingeführt wird ein Hash-Codierungsverfahren, das eher auf Festkomma-Division als auf Multiplikation oder logischen Operationen basiert. Durch diese neue Methode kann die Hash-Tabelle nahezu beliebig lang werden. Auch eine neue Methode zur Handhabung von Kollisionen wird diskutiert. Diese als quadratische Suche bekannte Methode ist schneller als die zufällige Suche und frei von „Clustern“, die sich bei einer linearen Suche bilden."}
{"DOCID": "1787", "TEXT": "Verwendung von Übergangsmatrizen beim Kompilieren: Es wird ein Algorithmus beschrieben, der aus einer geeigneten BNF-Grammatik einen effizienten Links-Rechts-Erkenner für Sätze der entsprechenden Sprache konstruiert. Der Erkennertyp, der in einer Reihe von Compilern verwendet wird, arbeitet mit einem Kellerspeicher und mit einer Übergangsmatrix. Zwei Beispiele veranschaulichen, wie solche Erkenner effektiv für andere Zwecke als die übliche Syntaxprüfung verwendet werden können."}
{"DOCID": "1788", "TEXT": "Auf dem Weg zu einem allgemeinen Prozessor für Programmiersprachen: Es wurden viele Anstrengungen unternommen, um einen besseren Weg zur Implementierung einer Programmiersprache auf höherer Ebene zu entwickeln als durch die Konstruktion eines völlig neuen Compilers, aber bisher hat sich keiner als allgemein zufriedenstellend erwiesen. In diesem Artikel wird behauptet, dass eine Programmiersprache am besten funktional als ein Körper von Makrobefehlen beschrieben wird und dass der Makroaufruf eine kanonische Form darstellt, in der eine Programmiernotation beschrieben werden kann. Eine unterstützende Diskussion der logischen und historischen Rolle der Makroinstruktion wird präsentiert. Diskutiert werden auch der Konflikt zwischen Maschinenunabhängigkeit und Objektprogrammeffizienz sowie die Frage, wo die größten Schwierigkeiten beim Compilerbau liegen."}
{"DOCID": "1789", "TEXT": "Logarithmus der Gammafunktion (Algorithmus 291 [S14])"}
{"DOCID": "1790", "TEXT": "Müllers Methode zum Finden von Wurzeln einer beliebigen Funktion (Algorithmus 196 [C5])"}
{"DOCID": "1791", "TEXT": "Dreiecksfaktoren modifizierter Matrizen (Algorithmus 319 [F1])"}
{"DOCID": "1792", "TEXT": "Explorative experimentelle Studien zum Vergleich der Online- und Offline-Programmierleistung: Zwei explorative Experimente wurden bei der System Development Corporation durchgeführt, um die Debugging-Leistung von Programmierern zu vergleichen, die unter Bedingungen des Online- und Offline-Zugriffs auf einen Computer arbeiten. Dies sind die ersten bekannten Studien, die die Leistung von Programmierern unter kontrollierten Bedingungen für Standardaufgaben messen. Statistisch signifikante Ergebnisse beider Experimente zeigten ein schnelleres Debuggen unter Online-Bedingungen, aber die vielleicht wichtigste praktische Erkenntnis betrifft die auffälligen individuellen Unterschiede in der Leistung des Programmierers. Methodologische Probleme, die bei der Planung und Durchführung dieser Experimente auftreten, werden beschrieben; Einschränkungen der Ergebnisse werden aufgezeigt; Hypothesen werden präsentiert, um Ergebnisse zu berücksichtigen; und es werden Vorschläge für weitere Forschungen gemacht."}
{"DOCID": "1793", "TEXT": "Darstellung alphamerischer Zeichen für die Informationsverarbeitung* (vorgeschlagener amerikanischer nationaler Standard)"}
{"DOCID": "1794", "TEXT": "Ein schneller Zufallszahlengenerator für IBM 360"}
{"DOCID": "1795", "TEXT": "Optimaler Code für serielle und parallele Berechnungen"}
{"DOCID": "1796", "TEXT": "Index nach Thema Algorithmen, 1969"}
{"DOCID": "1797", "TEXT": "Lösung linearer Programme in 0-1 (Algorithmus 341 [H])"}
{"DOCID": "1798", "TEXT": "Coulomb-Wellenfunktionen (Algorithmus 300 [S22])"}
{"DOCID": "1799", "TEXT": "Elementarfunktionen durch Kettenbrüche (Algorithmus 229 [B1])"}
{"DOCID": "1800", "TEXT": "PSIF (Algorithmus 147 [S14])"}
{"DOCID": "1801", "TEXT": "Varianzanalyse für ausgewogene Experimente (Algorithmus 367 [G2])"}
{"DOCID": "1802", "TEXT": "Regression unter Verwendung bestimmter direkter Produktmatrizen (Algorithmus 366 [G2])"}
{"DOCID": "1803", "TEXT": "Komplexe Wurzelfindung (Algorithmus 365 [C5])"}
{"DOCID": "1804", "TEXT": "Einfärben polygonaler Bereiche (Algorithmus 364 [Z])"}
{"DOCID": "1805", "TEXT": "Produktivität von multiprogrammierten Computern – Fortschritt bei der Entwicklung eines analytischen Vorhersageverfahrens: Multiprogramming, wie es hier diskutiert wird, ist ein Computerbetriebsmodus, bei dem sich zwei oder mehr Programme gleichzeitig im Prozessorspeicher befinden und ablaufen, wobei jedes die gleiche zentrale Prozessoreinheit (CPU) verwendet Input-Output (I/O)-Kanäle. Diese Programme werden je nach Berechtigung (Bereitschaft zur Durchführung) und Priorität tatsächlich mit Unterbrechungen und einzeln durchgeführt. Es ist nützlich, sie als kontinuierlich und gleichzeitig fortschreitend darstellen zu können, jedes mit einer effektiven Geschwindigkeit, die möglicherweise nur einen Bruchteil dessen ausmacht, was es ohne die anderen Programme erreichen würde. Die effektive Fortschrittsrate jedes Programms ist empfindlich gegenüber vielen detaillierten Merkmalen seiner selbst und seiner Mitbewohner, und die Simulation war die beste verfügbare Methode, um sie vorherzusagen. Dieses Papier stellt die Ergebnisse des Fortschritts bei der Entwicklung einer Alternative zur Simulation vor, einer simulationsgetesteten iterativen Berechnung dieser Raten unter bestimmten Situationen. Der Algorithmus reagiert empfindlich auf die meisten Faktoren, die das Phänomen steuern, einschließlich nichtquantitativer oder topologischer Merkmale der Programmstrukturen."}
{"DOCID": "1806", "TEXT": "Zur Downhill-Methode: Die Downhill-Methode ist eine numerische Methode zur Lösung komplexer Gleichungen f(z) = 0, bei der die einzige Einschränkung darin besteht, dass die Funktion w = f(z) analytisch sein muss. Es wird eine Einführung in diese Methode gegeben und ein kritischer Überblick über die einschlägige Literatur gegeben. Obwohl die Methode theoretisch immer konvergiert, zeigt sich, dass ein grundlegendes Dilemma besteht, das in der praktischen Anwendung zum Scheitern führen kann. Um diese Schwierigkeit zu vermeiden und die Konvergenzrate zu einer Wurzel zu verbessern, werden einige Modifikationen des ursprünglichen Verfahrens vorgeschlagen und ein Programm (FORTRAN) auf der Grundlage des modifizierten Verfahrens wird in Algorithmus 365 angegeben. Einige numerische Beispiele sind enthalten."}
{"DOCID": "1807", "TEXT": "Optimierung von Ausdrücken in Fortran: Es wird ein Verfahren zur Optimierung der Berechnung von arithmetischen und indizierenden Ausdrücken eines Fortran-Programms vorgestellt. Das Verfahren basiert auf einer linearen Analyse der Definitionspunkte der Variablen und der Verzweigungs- und DO-Schleifenstruktur des Programms. Die Ziele der Verarbeitung sind (1) redundante Berechnungen zu eliminieren, wenn auf gemeinsame Unterausdruckswerte Bezug genommen wird, (2) invariante Berechnungen aus DO-Schleifen zu entfernen, (3) Indizes mit DO-Iterationsvariablen effizient zu berechnen, und (4) zu sorgen für eine effiziente Nutzung des Indexregisters. Das vorgestellte Verfahren erfordert mindestens einen Compiler mit drei Durchgängen, von denen der zweite rückwärts gescannt wird. Es wurde bei der Entwicklung mehrerer FORTRAN-Compiler verwendet, die sich als hervorragender Objektcode erwiesen haben, ohne die Kompilierungsgeschwindigkeit wesentlich zu verringern."}
{"DOCID": "1808", "TEXT": "Fortgeschrittene kryptografische Techniken für Computer: Es werden kryptografische Techniken behandelt, die verwendet werden können, um die Vertraulichkeit von Informationen zu wahren, die von Computern verarbeitet werden. Besonderes Augenmerk wird auf die einzigartigen Eigenschaften von Computerdateien gelegt, die viele kryptografische Verfahren wenig brauchbar machen. Relative Sicherheit, Kosten und bevorzugte Methoden sind in diesem Dokument enthalten."}
{"DOCID": "1809", "TEXT": "Numerische Analysis in einem Ph.D. Informatik-Programm: Numerische Analysis ist die Lehre von Methoden und Verfahren, die verwendet werden, um \"näherungsweise Lösungen\" für mathematische Probleme zu erhalten. Der Schwerpunkt liegt auf wissenschaftlichem Rechnen. Die Schwierigkeiten der Bildung in einem so breiten Bereich drehen sich um die Frage nach Herkunft und Schwerpunkt. Der Studiengang Numerische Analysis im Fachbereich Informatik soll das Bewusstsein für die Problematik der Computerimplementierung und experimenteller Verfahren betonen. Nichtsdestotrotz ist ein solider Hintergrund in angewandter Mathematik erforderlich."}
{"DOCID": "1810", "TEXT": "Ist das automatische \"Falten\" von Programmen effizient genug, um das manuelle zu ersetzen?: Der Vorgang des \"Faltens\" eines Programms in den verfügbaren Speicher wird diskutiert. Messungen von Brown et al. und von Nelson über einen automatischen Faltmechanismus einfachen Designs, eine im IBM Research Center von Belady, Nelson, O'Neil und anderen gebaute Demand-Paging-Einheit, die es erlaubt, ihre Qualität mit der manuellen Faltung zu vergleichen, werden diskutiert, und Es zeigt sich, dass das Gerät bei einiger Sorgfalt bei der Verwendung unter den getesteten Bedingungen zufriedenstellend funktioniert, obwohl es über eine Speicher-zu-Speicher-Schnittstelle mit einem sehr großen Geschwindigkeitsunterschied arbeitet. Die Nachteile des Vorfaltens, das erforderlich ist, wenn das Falten von Hand erfolgt, werden untersucht, und es wird gezeigt, dass eine Reihe wichtiger Schwierigkeiten, die Computer heute belasten, aus dieser Quelle entstehen oder durch diese verschlimmert werden. Es wird der Schluss gezogen, dass ein Klappmechanismus wahrscheinlich ein normaler Bestandteil der meisten Computersysteme werden wird."}
{"DOCID": "1811", "TEXT": "Eine Fallstudie zur Programmierung für Parallelprozessoren: Eine bejahende Teilantwort wird auf die Frage gegeben, ob es möglich ist, Parallelprozessor-Computersysteme zu programmieren, um die Ausführungszeit für nützliche Probleme effizient zu verkürzen. Parallelprozessorsysteme sind Multiprozessorsysteme, bei denen mehrere der Prozessoren gleichzeitig getrennte Aufgaben eines einzelnen Jobs ausführen können, wodurch sie zusammenarbeiten, um die Lösungszeit eines Rechenproblems zu verkürzen. Die Prozessoren haben unabhängige Befehlszähler, was bedeutet, dass jeder Prozessor sein eigenes Aufgabenprogramm relativ unabhängig von den anderen Prozessoren ausführt. Die Kommunikation zwischen kooperierenden Prozessoren erfolgt mittels Daten im Speicher, die von allen Prozessoren gemeinsam genutzt werden. Ein Programm zur Bestimmung der Stromverteilung in einem elektrischen Netzwerk wurde für ein Parallelprozessor-Rechensystem geschrieben, und die Ausführung dieses Programms wurde simuliert. Die aus Simulationsläufen gesammelten Daten demonstrieren die effiziente Lösung dieses Problems, das typisch für eine große Klasse wichtiger Probleme ist. Es wird gezeigt, dass sich bei richtiger Programmierung die Lösungszeit bei Verwendung von N Prozessoren dem 1/N-fachen der Lösungszeit für einen einzelnen Prozessor nähert, während eine falsche Programmierung tatsächlich zu einer Erhöhung der Lösungszeit mit der Anzahl der Prozessoren führen kann. Die Stabilität des Lösungsverfahrens wurde ebenfalls untersucht."}
{"DOCID": "1812", "TEXT": "Mehr zu Fortran-Zufallszahlengeneratoren"}
{"DOCID": "1813", "TEXT": "Generierung von Permutationen in pseudolexikografischer Reihenfolge (Algorithmus 308 [G6])"}
{"DOCID": "1814", "TEXT": "Direktsuche (Algorithmus 178 [E4])"}
{"DOCID": "1815", "TEXT": "Direktsuche (Algorithmus 178 [E4])"}
{"DOCID": "1816", "TEXT": "Verallgemeinerte Anpassung der kleinsten Quadrate durch orthogonale Polynome (Algorithmus 296 [E2])"}
{"DOCID": "1817", "TEXT": "Berechnung von Fourier-Koeffizienten (Algorithmus 255 [C6])"}
{"DOCID": "1818", "TEXT": "Zugehörige Legendre-Funktionen erster Art für reelle oder imaginäre Argumente (Algorithmus 47 [S16])"}
{"DOCID": "1819", "TEXT": "Komplexe Fehlerfunktion (Algorithmus 363 [S15])"}
{"DOCID": "1820", "TEXT": "Erzeugung zufälliger Permutationen (Algorithmus 362 [G6])"}
{"DOCID": "1821", "TEXT": "Permanente Funktion einer quadratischen Matrix I und II (Algorithmus 361 [G6])"}
{"DOCID": "1822", "TEXT": "Shortest-Path Forest mit topologischer Ordnung (Algorithmus [H])"}
{"DOCID": "1823", "TEXT": "Faktorielle Varianzanalyse (Algorithmus [G1])"}
{"DOCID": "1824", "TEXT": "APAREL-A Parse-Request Language: APAREL wird beschrieben: Diese Sprache ist eine Erweiterung einer algorithmischen Sprache (PL/I), die die Mustervergleichsfähigkeiten bereitstellt, die normalerweise nur in Spezialsprachen wie SNOBOL4 und TMG zu finden sind. Diese Fähigkeit wird durch Analyseanforderungen bereitgestellt, die in einem BNF-ähnlichen Format angegeben sind. Diese Parse-Requests bilden eine eigene Programmiersprache mit speziellen Sequenzierungsregeln. Nach erfolgreichem Abschluss einer Parsing-Anfrage wird ein zugehöriges Stück PL/I-Code ausgeführt. Dieser Code steht zur Verwendung zur Verfügung, da normales PL/I die verschiedenen Teile (auf allen Ebenen) der Analyse aneinanderreiht. Es hat auch als normale PL/I-Variablen die Information darüber, welche der verschiedenen Alternativen erfolgreich waren, zur Verfügung. Bequeme Einrichtungen für mehrere Input-Output-Ströme, die Initiierung von Sequenzen von Parse-Anforderungen als Subroutine und semantische Prüfungen zur Parse-Zeit sind ebenfalls enthalten. APAREL hat sich beim Aufbau eines leistungsstarken SYNTAX- und FUNCTION-Makrosystems, eines Präprozessor-Debugsystems für algebraische Sprachen, eines Online-Befehlsparsers, eines Übersetzers für datenlose Programmierung und als allgemeiner String-Manipulator bewährt."}
{"DOCID": "1825", "TEXT": "Ein praktisches Verfahren zum Konstruieren von LR(k)-Prozessoren: Ein praktisches Verfahren zum Konstruieren von LR(k)-Prozessoren wird entwickelt. Diese Prozessoren sind in der Lage, eine Eingabe während eines einzelnen No-Backup-Scans in einer Anzahl von Schritten zu erkennen und zu parsen, die gleich der Länge der Eingabe plus der Anzahl von Schritten in ihrer Ableitung ist. Die hier vorgestellte Technik basiert auf dem von Knuth beschriebenen ursprünglichen Verfahren, verringert jedoch sowohl den Aufwand, der erforderlich ist, um den Prozessor zu konstruieren, als auch die Größe des hergestellten Prozessors. Dieses Verfahren beinhaltet das Unterteilen der gegebenen Grammatik in eine Anzahl kleinerer Teile. Wenn ein LR(k)-Prozessor für jeden Teil konstruiert werden kann (unter Verwendung des Knuth-Algorithmus) und wenn bestimmte Bedingungen in Bezug auf diese einzelnen Prozessoren erfüllt sind, dann kann ein LR(k)-Prozessor für die gesamte Grammatik für sie konstruiert werden. Unter Verwendung dieses Verfahrens wurde ein LR(1)-Parser für ALGOL erhalten."}
{"DOCID": "1826", "TEXT": "Ein LISP-Garbage-Collector für Computersysteme mit virtuellem Speicher: In diesem Artikel wird ein Garbage-Collection-Algorithmus für Listenverarbeitungssysteme beschrieben, die innerhalb sehr großer virtueller Speicher arbeiten. Das Ziel des Algorithmus ist mehr die Verdichtung des aktiven Speichers als die Entdeckung des freien Speichers. Da der freie Speicherplatz nie wirklich erschöpft ist, fällt die Entscheidung für die Garbage Collection nicht leicht; Daher werden verschiedene Kriterien dieser Entscheidung diskutiert."}
{"DOCID": "1827", "TEXT": "Leistungsüberwachung in einem Time-Sharing-System: Es wird eine Software-Messeinrichtung beschrieben, die Teil eines Allzweck-Time-Sharing-Systems ist. Die Date Collection Facility (DCF) wurde im Michigan Terminal System (MTS) für das System/360-Modell 67 implementiert. Sie dient dem Zweck, das Verhalten und die Leistung von Betriebssystemen und Benutzerprogrammen zu überwachen. Die Gesamtstruktur von MTS wird skizziert, um die Implementierung des DCF zu erläutern. Ereignisse im System werden innerhalb des Supervisors identifiziert und aufgezeichnet und von einem Hilfsprogramm zur Offline-Verarbeitung auf Magnetband abgelegt. Ereignisse in Anwenderprogrammen, die nichts mit Systemaktionen zu tun haben, werden mit einem Supervisor-Ruf aufgezeichnet. Der Zeitpunkt des Auftretens jedes Ereignisses wird genau aufgezeichnet, und Datenelemente werden weiter nach Job und Typ identifiziert. Der mit der Datenerfassung verbundene Overhead und seine Beeinträchtigung normaler Jobs werden sorgfältig analysiert, und beide haben sich als minimal erwiesen. Es werden mehrere Beispiele für Informationen gegeben, die mit der Einrichtung erhalten wurden, und für Anwendungen, bei denen sie nützlich waren. Es werden einige allgemeine Richtlinien für den Aufbau zukünftiger Überwachungsprogramme angeboten."}
{"DOCID": "1828", "TEXT": "Synchronisation in einer Datenbank, auf die parallel zugegriffen wird: Das folgende Problem wird betrachtet: Bei einer gegebenen Datenbank, die gleichzeitig von mehr als einem Prozess manipuliert werden kann, was sind die Regeln für die Synchronisation, die die Menge an erlaubter paralleler Aktivität maximieren werden. Es wird angenommen, dass die Datenbasis als Graph dargestellt werden kann. Ein Beispiel einer solchen Datenbank ist eine Hierarchie von Verzeichnissen für ein Online-Dateisystem. Methoden zur Synchronisation von Prozessen werden untersucht; ihre Validität wird diskutiert und ihre Leistung verglichen."}
{"DOCID": "1829", "TEXT": "Ein interaktiver grafischer Anzeigemonitor in einer Stapelverarbeitungsumgebung mit Fernzugriff: Ein Grafikmonitorprogramm wird beschrieben. Es wurde an der Carnegie-Mellon University für den CDC G21-Computer entwickelt, der ein universelles Stapelverarbeitungssystem mit Fernzugriff ist. Das vorhandene G21-System und die Grafikhardware werden beschrieben. Der Grafikmonitor ist ein residenter Hilfsmonitor, der als Reaktion auf Befehle des menschlichen Benutzers umfassende Managementfähigkeiten über das Grafiksystem bereitstellt. Es reagiert auch auf Befehle von einem Benutzerprogramm über eine ähnliche Schnittstelle, bei der Routineaufrufe den Platz manueller Aktionen einnehmen. So können Mensch und Programm über das Medium des Grafikmonitors auf symmetrischer und gleichberechtigter Basis interagieren. Die Wahl, die bei der Gestaltung des Grafikmonitors angesichts der Beschränkungen der vorhandenen Hardware und des Computersystems getroffen wurde, wird diskutiert. Die Struktur des Monitorprogramms und die Mensch- und Programmschnittstellen werden beschrieben. Es gibt auch eine transiente Swapping-Version mit einem kleinen Resident-Teil und einer Vorkehrung für getauschte gebrauchte Submonitore."}
{"DOCID": "1830", "TEXT": "Abrufzeiten für eine gepackte invertierte Direktzugriffsdatei"}
{"DOCID": "1831", "TEXT": "Ein Kommentar zu optimalen Baumstrukturen"}
{"DOCID": "1832", "TEXT": "Minimax Logarithmischer Fehler"}
{"DOCID": "1833", "TEXT": "Eine Mehrdeutigkeit in der Beschreibung von ALGOL 60"}
{"DOCID": "1834", "TEXT": "Eine axiomatische Grundlage für die Computerprogrammierung: In diesem Aufsatz wird versucht, die logischen Grundlagen der Computerprogrammierung zu erforschen, indem Techniken verwendet werden, die zuerst beim Studium der Geometrie angewendet und später auf andere Zweige der Mathematik ausgedehnt wurden. Dies beinhaltet die Erläuterung von Sätzen von Axiomen und Schlußregeln, die zum Beweis der Eigenschaften von Computerprogrammen verwendet werden können. Es werden Beispiele für solche Axiome und Regeln gegeben und ein formaler Beweis eines einfachen Theorems gezeigt. Abschließend wird argumentiert, dass sich aus der Verfolgung dieser Themen wichtige Vorteile sowohl in Theorie als auch in Praxis ergeben können."}
{"DOCID": "1835", "TEXT": "Die IITRAN-Programmiersprache: Die für die Verwendung durch Studenten entwickelte IITRAN-Sprache und ihre wichtigen Merkmale werden beschrieben. IITRAN ist eine prozedurorientierte Sprache mit einer einstufigen Blockstruktur und einer Vielzahl von Datentypen. Mehrere neuartige und leistungsstarke Funktionen sind enthalten. Es wird eine Diskussion der zu befolgenden Gestaltungsprinzipien in einer Schülersprache gegeben."}
{"DOCID": "1836", "TEXT": "Eine neue Methode zur Bestimmung linearer Präzedenzfunktionen für Präzedenzgrammatiken: Die Präzedenzbeziehungen einer Präzedenzgrammatik können durch eine zweidimensionale Präzedenzmatrix präzise beschrieben werden. Häufig können die Informationen in der Matrix präziser durch ein Paar von Vektoren dargestellt werden, die als lineare Vorrangfunktionen bezeichnet werden. Es wird ein neuer Algorithmus vorgestellt, um die linearen Vorrangfunktionen zu erhalten, wenn die Vorrangmatrix gegeben ist; Es wird gezeigt, dass dieser Algorithmus mehrere Rechenvorteile besitzt."}
{"DOCID": "1837", "TEXT": "Ein Algol-Faltungsverfahren basierend auf der schnellen Fourier-Transformation (Algorithmus 345 [C6])"}
{"DOCID": "1838", "TEXT": "Normalkurvenintegral (Algorithmus 304 [S15])"}
{"DOCID": "1839", "TEXT": "Singulärwertzerlegung einer komplexen Matrix (Algorithmus 358 [F1, 4,5])"}
{"DOCID": "1840", "TEXT": "Ein effizienter Primzahlgenerator (Algorithmus 357 [A1])"}
{"DOCID": "1841", "TEXT": "Ein Primzahlgenerator nach dem Treesort-Prinzip (Algorithmus 356 [A1])"}
{"DOCID": "1842", "TEXT": "Ein Algorithmus zum Generieren von Ising-Konfigurationen (Algorithmus 355 [Z])"}
{"DOCID": "1843", "TEXT": "Die Wahl der Basis: Es wird ein digitaler Computer betrachtet, dessen Speicherworte aus N r-Zustands-Vorrichtungen plus zwei Vorzeichenbits (Zwei-Zustands-Vorrichtungen) zusammengesetzt sind. Die Wahl der Basis B für die interne Darstellung von Gleitkommazahlen auf einem solchen Computer wird diskutiert. Es zeigt sich, dass in gewisser Weise B = r am besten ist."}
{"DOCID": "1844", "TEXT": "Ein modulares Computer-Sharing-System: Ein alternativer Ansatz für den Entwurf und die Organisation eines interaktiven Multiterminal-Computersystems für allgemeine Zwecke wird vorgestellt. Die beschriebene Systemorganisation ist eine konzeptionell einfache Anordnung einer Bank aus austauschbaren Computern, von denen jeder ein Speicher/Prozessor-Paar ist, die dazu bestimmt sind, Terminaljobs zu verarbeiten, wenn sie ankommen. Einer der Computer dient als Master- oder Steuercomputer und überwacht die Sammlung und Verteilung von Nachrichten von und zu den entfernten Terminals. In der einfachsten Form gibt es für jedes angeschlossene Terminal ein Laufwerk. Ein Koppelpunkt-Umschaltnetzwerk ermöglicht es, jedes derartige Plattenlaufwerk mit jedem Computer zu verbinden. Während also jeder aktive Terminalbenutzer ein dediziertes Plattenlaufwerk \"belegt\", kann er den Computer auf einfache Weise mit vielen anderen Terminalbenutzern teilen. Das Verhältnis von Benutzern zu Computern hängt sowohl von der Größe und Leistung der verwendeten Maschinen als auch von den Rechenanforderungen der jeweiligen Benutzermischung ab. Diese Systemorganisation ist von Natur aus ein einfacherer und daher zuverlässigerer Ansatz für Time-Sharing-Computer und hat das Potenzial eines hochverfügbaren Systems zu relativ geringen Kosten. Wirtschaftliche Konfigurationen sind für eine Reihe von Systemgrößen möglich, die mindestens eine Größenordnung umfassen. Schließlich können problematische Programme, die von Remote-Terminal-Benutzern entwickelt wurden, auf einem dedizierten Batch-System ausgeführt werden, wenn kompatible Computer verwendet werden."}
{"DOCID": "1845", "TEXT": "Loader-Standardisierung für Overlay-Programme: Die Overlay-Fähigkeit wird für vier Computersysteme der dritten Generation beschrieben: CDC-6000, GE-635, IBM-360 und UNIVAC-1108. Eine Kritik der ersten drei Systeme basiert auf tatsächlichen Erfahrungen mit einem großen überlagerten Flugbahnsimulationsprogramm; Eine kurze Geschichte und Beschreibung dieses Programms wird vorgestellt. Eine Standardisierung der Mindestfähigkeiten für Lader wird empfohlen, damit Programme, die auf mehr als einem Computersystem laufen müssen, leicht konvertiert und gewartet werden können. Ein Vorschlag, dass Überlagerungssoftware ein Speicherbelegungsspezifikationskonzept anstelle der bedingten Baumstruktur enthält, wird skizziert. Dieses Konzept bietet eine effizientere und kostengünstigere Nutzung des Speichers sowie eine erhöhte Flexibilität in der Programmstruktur."}
{"DOCID": "1846", "TEXT": "Über das Simulieren von Netzwerken paralleler Prozesse, in denen gleichzeitige Ereignisse auftreten können: Einige der Probleme beim Simulieren diskreter Ereignissysteme, insbesondere von Computersystemen, auf einem herkömmlichen digitalen Computer werden behandelt. Es wird angenommen, dass die Systeme als Netzwerk miteinander verbundener sequentieller Prozesse beschrieben werden. Kurz werden die üblichen Techniken beschrieben, die verwendet werden, um solche Simulationen zu handhaben, wenn gleichzeitige Ereignisse nicht auftreten, ignoriert werden können oder durch einfache Prioritätsregeln gehandhabt werden können. Anschließend wird das Problem des Umgangs mit gleichzeitigen Ereignissen in getrennten Prozessen eingeführt. Es wird eine Abstraktion dieses Problems entwickelt, die eine Lösung für die Mehrzahl der häufig auftretenden Probleme zulässt. Die Technik findet entweder ein Verfahren zum Simulieren der parallelen Ereignisse oder meldet, dass keines gefunden werden kann. In einigen der letzteren Fälle ist es möglich, eine Lösung zu finden, indem die für die Lösungstechnik verfügbare Information erweitert wird, aber in vielen Fällen wird die Technik rechnerisch nicht durchführbar, wenn die zusätzlichen Informationen bereitgestellt werden."}
{"DOCID": "1847", "TEXT": "Ein Algorithmus zum Finden eines fundamentalen Satzes von Zyklen eines Graphen: Es wird ein schnelles Verfahren zum Finden eines fundamentalen Satzes von Zyklen für einen ungerichteten endlichen Graphen vorgestellt. Ein aufspannender Baum wird gezüchtet und die Eckpunkte der Reihe nach untersucht, wobei ungeprüfte Eckpunkte in einer Kellerspeicherliste gespeichert werden, um auf die Untersuchung zu warten. Eine Stufe in dem Prozess besteht darin, das oberste Element v der Kellerliste zu nehmen und es zu untersuchen, d. h. alle jene Kanten (v, z) des Graphen zu untersuchen, für die z noch nicht untersucht wurde. Wenn z bereits im Baum vorhanden ist, wird ein fundamentaler Zyklus hinzugefügt; wenn nicht, wird die Kante (v,z) in den Baum gelegt. Für jede der n Ecken des Graphen gibt es genau eine solche Stufe. Für große n erhöht sich der erforderliche Speicher um n^2 und die Zeit um n^g, wobei g von der Art des beteiligten Graphen abhängt. g ist unten durch 2 und oben durch 3 begrenzt, und es wird gezeigt, dass beide Schranken erreicht werden. In Bezug auf die Speicherung ähnelt unser Algorithmus dem von Gotlieb und Corneil und ist dem von Welch überlegen; in Bezug auf die Geschwindigkeit ist es dem von Welch ähnlich und dem von Gotlieb und Corneil überlegen. Tests zeigen, dass unser Algorithmus bei zufälligen Graphen bemerkenswert effizient ist (g=2)."}
{"DOCID": "1848", "TEXT": "Die gedämpfte Taylor-Reihenmethode zur Minimierung einer Summe von Quadraten und zum Lösen von Systemen nichtlinearer Gleichungen (Algorithmus 315 [E4, C5])"}
{"DOCID": "1849", "TEXT": "Funktionsminimierung (Algorithmus 251 [E4])"}
{"DOCID": "1850", "TEXT": "Generierung von Permutationen in lexikografischer Reihenfolge (Algorithmus 323 [G6])"}
{"DOCID": "1851", "TEXT": "Generator von Spanning Trees (Algorithmen 354 [H])"}
{"DOCID": "1852", "TEXT": "Eine Basis für ein mobiles Programmiersystem: Ein Algorithmus für einen Makroprozessor, der als Basis einer Implementierung von Prozessoren für Programmiersprachen durch Bootstrapping verwendet wurde, wird beschrieben. Dieser Algorithmus kann leicht auf modernen Rechenmaschinen implementiert werden. Erfahrungen mit Programmiersprachen, deren Implementierung auf diesem Algorithmus basiert, zeigen, dass eine solche Sprache in weniger als einer Mannwoche auf eine neue Maschine übertragen werden kann, ohne die alte Maschine zu verwenden."}
{"DOCID": "1853", "TEXT": "Kompakte Listendarstellung: Definition, Garbage Collection und Systemimplementierung: Kompakte Listen werden sequentiell im Speicher gespeichert und nicht mit Zeigern verkettet. Da dies nicht immer bequem ist, erlaubt das Swym-System, dass eine Liste verkettet, kompakt oder jede Kombination der beiden ist. Es wird eine Beschreibung dieser Listendarstellung und der implementierten Operatoren gegeben (die meisten ähneln denen von LISP 1.5). Der System-Garbage Collector versucht, alle Listen kompakt zu machen; Es verschiebt und ordnet den gesamten Listenspeicher unter Verwendung des temporären Speichers neu. Dieser einzigartige Listen-Komprimierungs-Garbage-Collection-Algorithmus wird im Detail vorgestellt. Es werden mehrere Klassen von Makros beschrieben, die zum Implementieren des Systems verwendet werden. Schließlich werden jene Entwurfsfaktoren berücksichtigt, die für den Erfolg einer Implementierung eines Plex-Verarbeitungssystems wesentlich sind."}
{"DOCID": "1854", "TEXT": "Zu Multiprogramming, Machine Coding und Computer Organization: Der Autor ist der Ansicht, dass die Interrupt-Funktion, die in den meisten modernen Computern verfügbar ist, eine starke Quelle für Programmierfallen und -fehler ist und dass sie daher stark zur Unzuverlässigkeit von Programmen beitragen kann, die sie verwenden . Es wird ein Programmierschema vorgestellt, das das Konzept des Interrupts vermeidet und die Spezifikation gleichzeitiger (oder pseudo-gleichzeitiger) Aktivitäten auf eine vermeintlich durchsichtigere Weise erlaubt. Es soll als Grundlage für die Konstruktion von Betriebssystemen dienen, die Paradebeispiele für Programme mit gleichzeitigen Aktivitäten sind. Das Schema enthält einen Satz grundlegender Anweisungen für die Generierung, Beendigung und Synchronisierung paralleler Prozesse. Ein Satz von Routinen, die diese Anweisungen darstellen und dadurch eine hypothetische Maschinenorganisation simulieren, wurde implementiert und auf dem IBM System/360 getestet. Zwei Programme, die diese in PL360 geschriebenen Anweisungen verwenden, werden vorgestellt."}
{"DOCID": "1855", "TEXT": "Ein Programm zur syntaktischen Analyse englischer Sätze: Es wird ein Programm beschrieben, das syntaktische Analysen englischer Sätze im Hinblick auf eine Transformationsgrammatik erstellt. Die Hauptmerkmale des Analysators bestehen darin, dass er nur ein begrenztes Wörterbuch englischer Wörter verwendet und alle Analysepfade gleichzeitig verfolgt, während er den Satz von links nach rechts verarbeitet. Die für das Wörterbuch und die Grammatik verwendete Darstellungsform wird angegeben und das Analyseverfahren skizziert. Es werden Techniken beschrieben, um die Größe des Analysedatensatzes innerhalb angemessener Grenzen zu halten und um die Notwendigkeit einer dynamischen Anwendung bestimmter Transformationsregeln zu vermeiden. Es wird eine Reihe von Beispielen für die vom Programm erzeugten Ausgaben gegeben. Die Ausgabe enthält Zeitinformationen."}
{"DOCID": "1856", "TEXT": "The Teachable Language Comprehender: Ein Simulationsprogramm und Sprachtheorie: Der Teachable Language Comprehender (TLC) ist ein Programm, das so konzipiert ist, dass es gelehrt werden kann, englischen Text zu „verstehen“. Wenn Text eingegeben wird, den das Programm vorher nicht gesehen hat, versteht es diesen Text, indem es jede (explizite oder implizite) Aussage des neuen Textes korrekt mit einem großen Speicher in Beziehung setzt. Dieses Gedächtnis ist ein \"semantisches Netz\", das Tatsachenaussagen über die Welt darstellt. Das Programm erstellt auch Kopien der Teile seines Gedächtnisses, die sich auf den neuen Text beziehen, und passt diese Kopien an und kombiniert sie, um die Bedeutung des neuen Textes darzustellen. Auf diese Weise wird die Bedeutung des gesamten Textes, den das Programm erfolgreich versteht, in dasselbe Format wie das des Speichers codiert. In dieser Form kann es dem Speicher hinzugefügt werden. Sowohl Tatsachenbehauptungen für das Gedächtnis als auch die Fähigkeiten, Text korrekt auf den vorherigen Inhalt des Gedächtnisses zu beziehen, sind dem Programm bei Bedarf beizubringen. TLC enthält derzeit eine relativ kleine Anzahl von Beispielen für solche Behauptungen und Fähigkeiten, aber innerhalb des Systems werden Notationen zum Ausdrücken einer dieser beiden bereitgestellt. Somit entspricht das Programm nun einem allgemeinen Prozess zum Verstehen von Sprache und stellt eine Methodik bereit, um die zusätzlichen Informationen hinzuzufügen, die dieser Prozess erfordert, um Text irgendeiner bestimmten Art tatsächlich zu verstehen. Die Speicherstruktur und der Verständnisprozess von TLC ermöglichen neue Tatsachenbehauptungen und Fähigkeiten zum automatischen Verallgemeinern von Text mit solchen gespeicherten Behauptungen. Das heißt, sobald eine solche Behauptung oder Fähigkeit in das System aufgenommen wird, wird sie verfügbar, um in Zukunft beim Verständnis vieler anderer Sätze zu helfen. Daher wird die Hinzufügung einer einzigen Tatsachenbehauptung oder sprachlichen Fähigkeit oft einen großen Zuwachs an TLCs effektivem Wissen über die Welt und an seiner Gesamtfähigkeit, Text zu verstehen, liefern. Die Strategie des Programms wird als allgemeine Theorie des Sprachverständnisses vorgestellt."}
{"DOCID": "1857", "TEXT": "Filon-Quadratur (Algorithmus [D1])"}
{"DOCID": "1858", "TEXT": "Ein Algorithmus für die Filon-Quadratur: Ein Algorithmus für die Filon-Quadratur wird beschrieben. Erhebliche Aufmerksamkeit wurde einer Analyse der Rundungs- und Trunkierungsfehler gewidmet. Der Algorithmus enthält eine automatische Fehlerkontrollfunktion."}
{"DOCID": "1859", "TEXT": "Fehlergrenzen für periodische quintische Splines: Es werden explizite Fehlergrenzen für die periodische quintische Spline-Interpolation entwickelt. Die erste (dritte) Ableitung des periodischen Splines ist als Annäherung sechster (vierter) Ordnung an den Eingriffspunkten an die erste (dritte) Ableitung der zu interpolierenden Funktion gezeigt."}
{"DOCID": "1860", "TEXT": "Eine Algol-basierte assoziative Sprache: Eine höhere Programmiersprache für große, komplexe assoziative Strukturen wurde entworfen und implementiert. Die zugrunde liegende Datenstruktur wurde unter Verwendung einer Hash-Codierungstechnik implementiert. Die Diskussion beinhaltet einen Vergleich mit anderen Arbeiten und Anwendungsbeispiele der Sprache."}
{"DOCID": "1861", "TEXT": "Die MAD Definition Facility: Eine der ersten Definitionseinrichtungen für höhere Sprachen wird beschrieben. Benutzer der Sprache können neue Operatoren und/oder Datentypen in der MAD-Sprache definieren, sodass ihre Verwendung so aussieht, als ob sie vordefiniert wäre. Es werden Informationen darüber gegeben, wie man Definitionen schreibt, sowie zu einem Großteil der Motivation hinter der Form, in der Definitionen geschrieben werden. Es werden einige Schlussfolgerungen über zukünftige Definitionsmöglichkeiten gezogen."}
{"DOCID": "1862", "TEXT": "Computerkapazitäten an argentinischen und chilenischen Universitäten: Der Autor berichtet über eine Reise zu Universitäten in Argentinien und Chile im November 1968 und beschreibt die Universitätsbedingungen und Computeraktivitäten. Wie anderswo erleben diese Universitäten die Unzufriedenheit der Studenten mit dem Status quo und den Lösungsversuchen, die sie dagegen versuchen: Argentinien schließt Studenten von der Teilnahme an der Universitätsregierung aus; Chile erlaubt eine solche Teilnahme. Der universitäre Rechendienst und die akademischen Aktivitäten sind eingeschränkt. Die Anzahl der Computer ist gering, ebenso die Kapazität, keine größer als ein IBM 360/40; Mit einigen Ausnahmen sind akademische Informatikprogramme selten. Diese Situation ist keineswegs den nach Exzellenz strebenden Verantwortlichen für Computerentwicklungen zuzuschreiben; vielmehr ist das \"system\" schwer zu überwinden. Universitäten, insbesondere solche mit starker europäischer Tradition, passen sich langsam an neue akademische Ressourcen und Disziplinen an; überlagert sind die strengen technologischen und wirtschaftlichen Zwänge der Entwicklungsländer. Infolgedessen kann der künftige Fortschritt verzögert werden, wenn die Regierung keinen bewussten Schwerpunkt auf die Stärkung der Computerkapazitäten legt."}
{"DOCID": "1863", "TEXT": "Minit-Algorithmus für lineare Programmierung (Algorithmus 333 [H])"}
{"DOCID": "1864", "TEXT": "Generierung einer von Hilbert abgeleiteten Testmatrix (Algorithmus 274 [F1])"}
{"DOCID": "1865", "TEXT": "Algol 60 Reference Language Editor (Algorithmus 268 [R2])"}
{"DOCID": "1866", "TEXT": "Charakteristische Werte und zugehörige Lösungen der Differentialgleichung von Mathieu (Algorithmus 352 [S22])"}
{"DOCID": "1867", "TEXT": "Über die erwarteten Längen von Sequenzen, die beim Sortieren durch Ersetzungsauswahl erzeugt werden: Bei der Ersetzungsauswahltechnik des Sortierens interessiert das Verhältnis L(j) der erwarteten Länge der j-ten Sequenz, die durch die Technik erzeugt wird, zur Anzahl von Speicherzellen verwendet. Unter Verwendung der Theorie komplexer Variablen wird gezeigt, dass L(j) -> 2 und dass asymptotisch das durchschnittliche Intervall zwischen Vorzeichenänderungen von L(j)-2 2,6662 beträgt."}
{"DOCID": "1868", "TEXT": "Zur Beschaffung korrekter Eingaben: Ein neuer Ansatz: Die meisten Informationen, die in maschinenlesbare Form gebracht werden, ob wissenschaftlicher oder geschäftlicher Herkunft, werden immer noch per Tastatur gestanzt. Dieses Papier befasst sich mit der Schwierigkeit, korrekt gelochte und schlüsselgeprüfte Daten zu erhalten, und es wird ein alternatives Verfahren vorgeschlagen, bei dem der Computer selbst verwendet wird, um die Möglichkeit von Eingabefehlern auszuschließen. Diese Technik wird anhand eines Arbeitsprogramms erläutert und veranschaulicht, das im Wesentlichen aus zwei Phasen besteht: In der ersten Phase werden Fehler von der Maschine erkannt und anschließend in der zweiten Phase von ihr korrigiert."}
{"DOCID": "1869", "TEXT": "Blockstrukturen, indirekte Adressierung und Garbage Collection: Programmiersprachen enthalten explizite oder implizite Blockstrukturen, um dem Programmierer eine bequemere Benennung zu ermöglichen. Wenn jedoch indirekte Adressierung verwendet wird, wie in SNOBOL, können Namensbeschränkungen eingeführt werden. Es werden zwei Modifikationen an SNOBOL beschrieben, die zu zwei wünschenswerten Konsequenzen führen: (1) Namensbeschränkungen verschwinden, selbst wenn es eine indirekte Adressierung innerhalb von Funktionsdefinitionen gibt; und (2) es gibt eine signifikante Einsparung bei der Anzahl der Aufrufe an den Garbage Collector, da jedes Mal, wenn eine Funktion zu ihrem aufrufenden Programm zurückkehrt, mit geringem Aufwand etwas Garbage Collection gesammelt wird. Diese Modifikationen wurden als Erweiterung eines SNOBOL-Dialekts implementiert."}
{"DOCID": "1870", "TEXT": "Einige Techniken zur Verwendung von Pseudozufallszahlen in der Computersimulation: Es wird ein Algorithmus beschrieben, durch den einheitliche pseudozufällige ganze Zahlen verwendet werden können, um binäre \"Zahlen\" zu konstruieren, bei denen die Wahrscheinlichkeit, dass jedes Bit im Wort ein 1-Bit ist und jeden gewünschten Parameterwert annehmen kann . Techniken zur Verwendung solcher \"Zahlen\" bei der Simulationsprogrammierung werden beschrieben."}
{"DOCID": "1871", "TEXT": "Automatische Konturabbildung: Einige Methoden zur Konturabbildung mittels eines digitalen Plotters werden diskutiert, und eine neue Methode wird vorgestellt, die einfach genug ist, um von Programmen mit einer ziemlich kleinen Anzahl von Befehlen implementiert zu werden (ungefähr 120 FORTRAN IV-Befehle sind erforderlich). Es werden auch Vergleiche mit einigen von anderen Autoren vorgeschlagenen Methoden durchgeführt. Ein FORTRAN IV-Programm, das die vorgeschlagene Methode implementiert, ist beim Istituto di Elettrotecnica ed Elettronica, Politencnico di Milano erhältlich."}
{"DOCID": "1872", "TEXT": "Tschebyscheff-Interpolation und Quadraturformeln sehr hohen Grades (Errata)"}
{"DOCID": "1873", "TEXT": "Beschleunigung von LP-Algorithmen: Es wird gezeigt, wie eine neuartige Methode zur Berechnung (verwandter) innerer Produkte die Preisfindungsphase von LP-Algorithmen beschleunigen kann. Andere LP-Anwendungen sind angegeben."}
{"DOCID": "1874", "TEXT": "Generieren von Pseudozufallszahlen auf einer Zweierkomplementmaschine wie der IBM 360: Der bekannte multiplikative Kongruenzgenerator wird im Zusammenhang mit der Art der Zweierkomplementarithmetik untersucht, die in der IBM 360-Serie verwendet wird. Unterschiedliche Sequenzen von Resten werden betrachtet und Beziehungen zwischen ihnen hergestellt. Es wird gezeigt, dass eine Folge positiver und negativer Reste einfacher und wirtschaftlicher als mit dem herkömmlichen Ansatz hergestellt werden kann und dennoch die doppelte Periode des letzteren ohne Verlust wünschenswerter statistischer Eigenschaften aufweist. Eine andere leicht zu erzeugende Sequenz mit absoluten Werten hat ebenfalls die doppelte Periode, aber weniger attraktive statistische Eigenschaften. Die statistischen Eigenschaften dieser Sequenzen werden angegeben und mit zuvor festgelegten Kriterien in Beziehung gesetzt."}
{"DOCID": "1875", "TEXT": "Polynom- und Spline-Approximation durch quadratische Programmierung: Das Problem der Approximation an eine gegebene Funktion oder das Anpassen eines gegebenen Datensatzes, wobei die Approximationsfunktion bestimmte Ableitungen bestimmter Vorzeichen über den gesamten Approximationsbereich haben muss, wird untersucht . Es werden zwei Ansätze vorgestellt, bei denen jeweils eine quadratische Programmierung verwendet wird, um sowohl die Beschränkungen für die Ableitungen als auch die Auswahl der Funktion bereitzustellen, die die beste Anpassung ergibt. Das erste ist ein modifiziertes Bernstein-Polynomschema, und das zweite ist ein Spline-Fit."}
{"DOCID": "1876", "TEXT": "Erzeugung von Testmatrizen mit bestimmten Vorzeichenmustern und vorgeschriebenen positiven Spektren: Es wird eine Klasse orthogonaler Transformationen vorgestellt, deren Mitglieder eine gegebene positive Diagonalmatrix in eine Matrix mit einem von vier speziellen Vorzeichenmustern transformieren."}
{"DOCID": "1877", "TEXT": "Verhinderung von System-Deadlocks: Ein wohlbekanntes Problem beim Entwurf von Betriebssystemen ist die Auswahl einer Ressourcenzuweisungsrichtlinie, die Deadlocks verhindert. Deadlock ist die Situation, in der Ressourcen verschiedenen Aufgaben so zugewiesen wurden, dass keine der Aufgaben fortgesetzt werden kann. Die verschiedenen veröffentlichten Lösungen waren etwas restriktiv: Entweder behandeln sie das Problem nicht in ausreichender Allgemeinheit oder sie schlagen Richtlinien vor, die gelegentlich eine Anfrage ablehnen, der sicher hätte stattgegeben werden können. Es werden Algorithmen vorgestellt, die eine Anfrage im Lichte der aktuellen Ressourcenzuweisung prüfen und bestimmen, ob die Gewährung der Anfrage die Möglichkeit einer Blockierung einführt oder nicht. Beweise in den Anhängen zeigen, dass die von den Algorithmen auferlegten Bedingungen sowohl notwendig als auch ausreichend sind, um Deadlocks zu verhindern. Die Algorithmen wurden im THE-System erfolgreich eingesetzt."}
{"DOCID": "1878", "TEXT": "Wiederherstellung von wiedereintretenden Listenstrukturen in SLIP: Eine Konsequenz des von SLIP verwendeten referenzanzahlbasierten Raumwiederherstellungssystems besteht darin, dass wiedereintretende Listenstrukturen nicht wiederhergestellt werden, selbst wenn sie explizit gelöscht werden. LISP-ähnliche Garbage-Collection-Schemata sind frei von diesem Hindernis. Sie hängen jedoch davon ab, Knoten zu finden und zu markieren, die von Programmvariablen aus erreichbar sind. Durch Verfolgen können dann alle Nachkommen von Programmvariablen identifiziert und gesammelt werden. Die Listenerstellungsfunktion LIST von SLIP kann ergänzt werden, um diejenigen Listen zu markieren, für die der Programmierer die Verantwortung übernehmen möchte. Angesichts dieser Modifikation kann dann ein LISP-ähnlicher Garbage Collector, der aufgegebene Wiedereintrittslistenstrukturen wiederherstellt, an das SLIP-System angehängt werden."}
{"DOCID": "1879", "TEXT": "Eine Anmerkung zur Speicherfragmentierung und Programmsegmentierung: Der Hauptzweck dieses Dokuments ist die Präsentation einiger Ergebnisse einer Reihe von Simulationsexperimenten, die das Phänomen der Speicherfragmentierung untersuchen. Es werden zwei verschiedene Arten der Speicherfragmentierung unterschieden: (1) externe Fragmentierung, nämlich der Verlust der Speichernutzung, der dadurch verursacht wird, dass nicht der gesamte verfügbare Speicher verwendet werden kann, nachdem er in eine große Anzahl separater Blöcke fragmentiert wurde; und (2) interne Fragmentierung, der Nutzungsverlust, der durch das Aufrunden einer Speicheranforderung verursacht wird, anstatt nur die genaue Anzahl der erforderlichen Wörter zuzuweisen. Das auffallendste Ergebnis ist die scheinbar allgemeine Regel, dass das Aufrunden von Speicheranforderungen, um die Anzahl unterschiedlicher Blockgrößen zu reduzieren, die im Speicher koexistieren, mehr Speicherverlust durch erhöhte interne Fragmentierung verursacht, als durch verringerte externe Fragmentierung eingespart wird. Beschrieben sind auch ein Verfahren zur Segmentzuweisung und eine begleitende Technik zur Segmentadressierung, die das obige Ergebnis ausnutzen. Es werden Beweise für mögliche Vorteile des Verfahrens gegenüber herkömmlichen Paging-Techniken präsentiert."}
{"DOCID": "1880", "TEXT": "Tschebyscheff-Lösung für ein überbestimmtes lineares System (Algorithmus 328 [F4])"}
{"DOCID": "1881", "TEXT": "Vektor gespeichertes Array transponieren (Algorithmus 302 [K2])"}
{"DOCID": "1882", "TEXT": "Bestimmung der Quadratwurzel einer positiv bestimmten Matrix (Algorithmus 298 [F1])"}
{"DOCID": "1883", "TEXT": "Modifizierte Romberg-Quadratur (Algorithmus [D1])"}
{"DOCID": "1884", "TEXT": "Eine Anomalie in den Raum-Zeit-Eigenschaften bestimmter Programme, die in einer Paging-Maschine laufen: Die Laufzeit von Programmen in einer Paging-Maschine nimmt im Allgemeinen zu, wenn der Speicher, in dem Programme zum Laufen gezwungen sind, abnimmt. Experimente haben jedoch Fälle ergeben, in denen das Gegenteil zutrifft: Eine Verringerung der Größe des Speichers geht mit einer Verringerung der Laufzeit einher. Eine informelle Diskussion des anomalen Verhaltens wird gegeben, und für den Fall des FIFO-Ersetzungsalgorithmus wird eine formelle Behandlung präsentiert."}
{"DOCID": "1885", "TEXT": "Ein Computersystem für Transformationsgrammatik: Ein umfassendes System für Transformationsgrammatik wurde entworfen und auf dem IBM 360/67-Computer implementiert. Das System befasst sich mit dem Transformationsmodell der Syntax, in Anlehnung an Chomskys Aspekte der Syntaxtheorie. Zu den wichtigsten Neuerungen gehören eine vollständige, formale Beschreibung der Syntax einer Transformationsgrammatik, ein Generator für gerichtete Zufallsphrasenstrukturen, ein lexikalischer Einfügungsalgorithmus, eine erweiterte Definition der Analyse und eine einfache problemorientierte Programmiersprache, in der der Algorithmus zur Anwendung kommt Transformationen ausgedrückt werden können. In diesem Beitrag stellen wir das System als Ganzes vor, indem wir zunächst die allgemeinen Einstellungen diskutieren, die der Entwicklung des Systems zugrunde liegen, dann das System skizzieren und seine wichtigeren Besonderheiten diskutieren. Es werden Verweise auf Artikel gegeben, die einen bestimmten Aspekt des Systems im Detail betrachten."}
{"DOCID": "1886", "TEXT": "Generierung von optimalem Code für Ausdrücke durch Faktorisierung: Bei einem gegebenen Satz von Ausdrücken, die kompiliert werden sollen, werden Verfahren vorgestellt, um die Effizienz des erzeugten Objektcodes zu erhöhen, indem zuerst die Ausdrücke faktorisiert werden, d. h. ein Satz von Unterausdrücken gefunden wird, von denen jeder in zwei auftritt oder mehr andere Ausdrücke oder Teilausdrücke. Sobald alle Faktoren ermittelt wurden, wird ein Sequenzierungsverfahren angewendet, das die Faktoren und Ausdrücke so ordnet, dass alle Informationen in der richtigen Reihenfolge berechnet werden und die Faktoren für eine minimale Zeitdauer im Speicher gehalten werden müssen. Dann wird ein Zuweisungsalgorithmus ausgeführt, um die Gesamtzahl von temporären Speicherzellen zu minimieren, die erforderlich sind, um die Ergebnisse der Bewertung der Faktoren zu halten. Um diese Techniken rechnerisch durchführbar zu machen, werden heuristische Prozeduren angewendet, und daher werden nicht notwendigerweise globale optimale Ergebnisse erzeugt. Die Faktorisierungsalgorithmen sind auch auf das Problem des Faktorisierens von Booleschen Umschaltausdrücken und des Faktorisierens von Polynomen anwendbar, die in Symbolmanipulationssystemen angetroffen werden."}
{"DOCID": "1887", "TEXT": "Eine rekursive Relation für die Determinante einer Pentadiagonalmatrix: Für die Determinante einer Pentadiagonalmatrix wird eine rekursive Relation entwickelt, die führende Hauptminoren in Beziehung setzt. Ein numerisches Beispiel ist enthalten, um seine Verwendung bei der Berechnung von Eigenwerten anzuzeigen."}
{"DOCID": "1888", "TEXT": "Spline-Funktionsverfahren für nichtlineare Randwertprobleme: Die Lösung der nichtlinearen Differentialgleichung Y\"=F(x,Y,Y') mit Zweipunkt-Randbedingungen wird durch eine quintische oder kubische Spline-Funktion y(x) angenähert Die Methode eignet sich gut für ungleichmäßige Netzgrößen und dynamische Netzgrößenzuweisung. Für eine gleichmäßige Netzgröße h beträgt der Fehler im quintischen Spline y(x) O(h^4), wobei der typische Fehler ein Drittel des Fehlers bei der Methode von Numerov beträgt Die an den Gitterpunkten zu erfüllende Differentialgleichung führt zu einem Satz von Differenzgleichungen, die blocktridiagonal sind und daher leicht durch Relaxation oder andere Standardverfahren gelöst werden können."}
{"DOCID": "1889", "TEXT": "Einführung des Computerwesens an kleineren Colleges und Universitäten -- Ein Fortschrittsbericht: Durch technische Mittel, die heute Routine sind, können Computerdienste für kleinere Colleges und Universitäten durch entfernte Terminals einer zentralen Einrichtung bereitgestellt werden. Zugang ist jedoch nicht genug – wirksame organisatorische und pädagogische Methoden für die Einführung von Computern an solchen Institutionen müssen ebenfalls entwickelt werden. Die Erfahrungen aus zwei Jahren mit einem landesweiten Netzwerk von 41 Institutionen werden diskutiert. Zu den Lektionen gehören die Bedeutung einer separaten Organisation, die die kleinen Colleges vertritt, die Notwendigkeit einer Ausbildung auf dem Campus für die Institutionen, die Notwendigkeit einer speziellen Programmierung und Dokumentation zur Unterstützung solcher Benutzer und die Entwicklung des Lehrplans mit evolutionären Mitteln."}
{"DOCID": "1890", "TEXT": "Simulation von Verkehrsflüssen in einem Netzwerk: Ein Computersimulationsprogramm, das sich mit Verkehrsflüssen in einem Netzwerk eines großen Bereichs befasst, wird beschrieben. Jede Straße ist in Blöcke von mehreren zehn Metern Länge segmentiert und wird durch eine bidirektionale Liste im Computerspeicher dargestellt. Die Bewegung von Autos, d. h. der Transfer von Autos von einem Block zum nächsten, wird durch eine eigene Formel ausgedrückt. Diese Formel basiert auf der Annahme, dass die Geschwindigkeit von Autos in einem Block nur durch die Dichte von Autos in dem Block bestimmt wird, und dieser Geschwindigkeits-gegen-Dichte-Kurve werden empirisch die numerischen Werte gegeben. Dieses Simulationsschema hat seinen herausragenden Punkt darin, dass es ermöglicht, das dynamische Verhalten von Verkehrsströmen in einer Vielzahl von Situationen zu verfolgen, von denen einige Beispiele für ein reales Gebiet der Stadt Kyoto, Japan, gegeben werden."}
{"DOCID": "1891", "TEXT": "Dreidimensionale Computeranzeige: Ein stereografisches Anzeigeterminal wurde unter Verwendung der kürzlich in Brookhaven entwickelten Rasteranzeige (BRAD) hergestellt. Das System verwendet einen rotierenden Auffrischungsspeicher, um standardmäßige Fernsehmonitore zu speisen. Um eine stereografische Anzeige zu erzeugen, berechnet der Computer die projizierten Videobilder eines Objekts, betrachtet von zwei getrennten Punkten. Die resultierenden Videokarten werden auf getrennten Refresh-Bändern des rotierenden Speichers gespeichert. Die beiden Ausgangssignale werden mit getrennten Farbkanonen eines Farbfernsehmonitors verbunden, wodurch ein überlagertes Bild auf dem Bildschirm erzeugt wird. Die optische Trennung wird erreicht, indem das Bild durch Farbfilter betrachtet wird. Die Anzeige ist interaktiv und kann von einer großen Gruppe von Personen gleichzeitig betrachtet werden."}
{"DOCID": "1892", "TEXT": "Grad der Mehrfachprogrammierung in Page-on-Demand-Systemen: Es wird ein einfaches stochastisches Modell beschrieben, das eine Basis zum Verständnis der Beziehung zwischen der Anzahl von Programmen bietet, die Speicher gemeinsam nutzen dürfen (der Grad der Mehrfachprogrammierung), Trommelverkehrsraten und Auslastung der zentralen Verarbeitungseinheit in mehrprogrammierten, zeitgeteilten Computersystemen mit Page-on-Demand. Das Modell bewahrt als Schlüsselmerkmal die Eigenschaft der Seitenanforderungsstatistik, die einen \"Burst\" von Seitenanforderungen zu Beginn jeder Job- oder Quantenausführung impliziert. Das Modell, eine Markov-Kette, wird numerisch analysiert und die Ergebnisse werden grafisch für eine Vielzahl wichtiger umweltbeschreibender Parameter dargestellt. Die Auswirkungen der Ergebnisse auf den Entwurf und die Programmierung von Time-Sharing-Systemen werden diskutiert, und eine Berechnung des optimalen Grads an Multiprogramming für eine breite Palette von Parametern wird grafisch dargestellt."}
{"DOCID": "1893", "TEXT": "Wurzeln von Polynomen durch eine Root-Squaring- und Resultant-Routine (Algorithmus 340 [C2])"}
{"DOCID": "1894", "TEXT": "Normale zufällige Abweichungen (Algorithmus 334 [G5])"}
{"DOCID": "1895", "TEXT": "Gaußsche Quadraturformeln (Algorithmus 331 [D1])"}
{"DOCID": "1896", "TEXT": "Reguläre Coulomb-Wellenfunktionen (Algorithmus 292 S22])"}
{"DOCID": "1897", "TEXT": "Coulomb-Wellenfunktionen (Algorithmus 300 [S22])"}
{"DOCID": "1898", "TEXT": "Reguläre Coulomb-Wellenfunktionen (Algorithmus 292 [S22])"}
{"DOCID": "1899", "TEXT": "Simplex-Methodenverfahren unter Verwendung der Lu-Zerlegung (Algorithmus 350 [H])"}
{"DOCID": "1900", "TEXT": "Klärung der Fortran-Standards – Anfängliche Fortschritte: 1966 wurde FORTRAN nach vierjähriger Anstrengung zur ersten standardisierten Programmiersprache in den Vereinigten Staaten. Seit dieser ersten Errungenschaft haben das Studium und die Anwendung der Standardspezifikationen die Notwendigkeit der Aufrechterhaltung der Standards aufgezeigt. Als Ergebnis der 1967 begonnenen Arbeit wurde eine erste Reihe klarstellender Interpretationen vorbereitet. Über die Art der Wartung, Korrekturen an den Standardspezifikationen und abgeschlossene Interpretationen wird berichtet."}
{"DOCID": "1901", "TEXT": "Dynamisches Space-Sharing in Computersystemen: Es wird eine Formalisierung der Beziehungen zwischen dem Space-Shading-Programmverhalten und der Prozessoreffizienz in Computersystemen vorgestellt. Konzepte von Wert und Kosten der Platzzuweisung pro Aufgabe werden definiert und dann werden Wert und Kosten kombiniert, um einen einzigen Parameter zu entwickeln, der als Wert pro Kosteneinheit bezeichnet wird. Ziel ist es, einen möglichen analytischen Ansatz zur Untersuchung der Raumteilungsproblematik aufzuzeigen und die Methode an Stichprobenproblemen zu demonstrieren."}
{"DOCID": "1902", "TEXT": "Ein automatisches Bewertungsschema für einfache Programmierübungen: Es werden Änderungen diskutiert, die an einem typischen Universitätsbetriebssystem vorgenommen wurden, um die Ergebnisse von Programmierübungen in drei verschiedenen Sprachen, einschließlich Assemblersprache, aufzuzeichnen. Bei diesem computergesteuerten Bewertungsschema sind Tests mit vom Programmierer gelieferten Daten und Endläufe mit vom System gelieferten Daten vorgesehen. Übungen, die im Rahmen des Programms durchgeführt werden, können mit anderen Programmen gemischt werden, und es ist keine besondere Anerkennung von Übungen durch die Betreiber erforderlich."}
{"DOCID": "1903", "TEXT": "Tschebyscheff-Interpolation und Quadraturformeln sehr hohen Grades"}
{"DOCID": "1904", "TEXT": "Grobe Fehlerschätzungen bei der Gaußschen Integration analytischer Funktionen"}
{"DOCID": "1905", "TEXT": "Das Simplex-Verfahren der linearen Programmierung unter Verwendung der LU-Zerlegung: Standardcomputerimplementierungen des Simplex-Verfahrens von Dantzig für die lineare Programmierung basieren auf der Bildung des Inversen der Basismatrix und dem Aktualisieren des Inversen nach jedem Schritt des Verfahrens. Diese Implementierungen haben schlechte Rundungsfehlereigenschaften. Dieses Papier liefert den theoretischen Hintergrund für eine Implementierung, die auf der LU-Zerlegung basiert, die mit Reihenaustauschen der Grundmatrix berechnet wird. Die Implementierung ist langsam, hat aber ein gutes Rundungsfehlerverhalten. Die Implementierung erscheint als CACM-Algorithmus 350."}
{"DOCID": "1906", "TEXT": "Automatisiertes Routing von gedruckten Schaltungen mit einer Stepping Aperture: Ein Computerprogramm zum Routing von Verbindungen auf einer zweiseitigen gedruckten Schaltungsplatine mit einem regelmäßigen Muster von Leitungen, Stiften (Anschlüssen) und Vias (Durchgangslöchern) wird beschrieben. In diesem Programm erhält jede Verbindung ein geplantes Routing – typischerweise vom oberen Pin nach unten durch ein Via und horizontal zum unteren Pin. Von oben wird eine virtuelle Öffnung (d. h. ein langer horizontaler Schlitz) die Platine nach unten geführt. Das geplante Routing ist die Basis für das Umleiten von Verbindungen innerhalb der Apertur, um Konflikte für Leitungen und Vias unterhalb der Apertur zu lösen und die effektive Leitungsnutzung zu maximieren. Wenn ein Konflikt nicht gelöst wurde, bevor die Öffnung am unteren Stift ankommt, werden Verbindungen gelöscht, um den Konflikt zu lösen. Erweiterungen dieser Technik auf die Kontrolle des Übersprechens zwischen gerouteten Verbindungen und auf das Problem, eine 100-prozentige Verbindung zu erhalten, werden ebenfalls diskutiert."}
{"DOCID": "1907", "TEXT": "Eine Anmerkung zur zuverlässigen Vollduplex-Übertragung über Halbduplex-Verbindungen: Es wird ein einfaches Verfahren zum Erzielen einer zuverlässigen Vollduplex-Übertragung über Halbduplex-Verbindungen vorgeschlagen. Das Schema wird mit einem anderen des gleichen Typs verglichen, der kürzlich in der Literatur beschrieben wurde. Abschließend werden einige Anmerkungen zu einer anderen Gruppe verwandter Übermittlungsverfahren gemacht, die sich unter bestimmten Umständen als unzuverlässig erwiesen haben."}
{"DOCID": "1908", "TEXT": "Time-Sharing und Stapelverarbeitung: Ein experimenteller Vergleich ihrer Werte in einer Problemlösungssituation: Ein experimenteller Vergleich der Problemlösung unter Verwendung von Time-Sharing- und Stapelverarbeitungs-Computersystemen, der am MIT durchgeführt wurde, wird in diesem Artikel beschrieben. Diese Studie ist der erste bekannte Versuch, zwei solcher Systeme für die möglicherweise vorherrschende Benutzerpopulation innerhalb des nächsten Jahrzehnts zu bewerten - die Fachleute, die als Nicht-Programmierer den Computer eher als Hilfsmittel bei der Entscheidungsfindung und Problemlösung verwenden als als Selbstzweck der Programmierung. Statistisch und logisch signifikante Ergebnisse weisen auf gleiche Kosten für die Nutzung der beiden Computersysteme hin; ein viel höheres Leistungsniveau wird jedoch von Time-Sharing-Benutzern erreicht. Es gibt Hinweise darauf, dass deutlich geringere Kosten entstanden wären, wenn die Time-Sharing-Nutzer ihre Arbeit eingestellt hätten, wenn sie ein Leistungsniveau erreicht hätten, das dem der Batch-Nutzer entspricht. Die Problemlösungsgeschwindigkeit der Nutzer und ihre Einstellung machten Time-Sharing zum günstigeren System."}
{"DOCID": "1909", "TEXT": "Berechnung von Jn(x) durch numerische Integration: Es hat sich als praktisch erwiesen, Jn(x) durch numerische Integration seiner Integraldarstellung unter Verwendung der Trapezregel zu berechnen. Der Fehler in dieser Annäherung wurde empirisch untersucht."}
{"DOCID": "1910", "TEXT": "Ein Algorithmus zum Lösen einer speziellen Klasse tridiagonaler Systeme linearer Gleichungen: Es wird ein Algorithmus zum Lösen eines Systems linearer Gleichungen Bu = k vorgestellt, wobei B tridiagonal und von einer speziellen Form ist. Es wird gezeigt, dass dieser Algorithmus fast doppelt so schnell ist wie das Gaußsche Eliminationsverfahren, das üblicherweise zur Lösung solcher Systeme vorgeschlagen wird. Außerdem werden explizite Formeln für die Inverse und Determinante der Matrix B angegeben."}
{"DOCID": "1911", "TEXT": "Zur Koordinationsreduktion und Satzanalyse: Im Rahmen der Transformationstheorie wird eine Klasse von Koordinationsphänomenen in natürlichen Sprachen betrachtet. Um diesen Phänomenen Rechnung zu tragen, wird vorgeschlagen, der syntaktischen Komponente einer Transformationsgrammatik bestimmte Mechanismen hinzuzufügen. Diese Maschinerie enthält bestimmte Regelschemata, die Bedingungen, unter denen sie anzuwenden sind, und Bedingungen, die die Folge von Unterbäumen bestimmen, an denen sie ausgeführt werden sollen. Eine Lösung des syntaktischen Analyseproblems für diese Klasse von Grammatiken wird skizziert. Eine genaue Spezifikation sowohl des generativen Verfahrens dieses Papiers als auch seiner Umkehrung wird in Form von LISP-Funktionsdefinitionen gegeben."}
{"DOCID": "1912", "TEXT": "Simulation von ambulanten Terminsystemen: Es wird ein experimentelles Computerprogramm beschrieben, das Terminsysteme simuliert, die von Ambulanzabteilungen von Krankenhäusern verwendet werden. Beide Hauptarten von Terminsystemen – individuell und blockweise – können simuliert werden. Der Zweck des Simulators besteht darin, den Benutzer in die Lage zu versetzen, die Wirksamkeit alternativer Terminsysteme in einer bestimmten klinischen Umgebung zu bewerten."}
{"DOCID": "1913", "TEXT": "Polygamma-Funktionen mit beliebiger Genauigkeit (Algorithmus 349 [S14])"}
{"DOCID": "1914", "TEXT": "Matrixskalierung durch ganzzahlige Programmierung (Algorithmus 348 [F1])"}
{"DOCID": "1915", "TEXT": "Ein Algorithmus zur Eliminierung verdeckter Linien: Der vorgestellte Algorithmus bewirkt die Eliminierung verdeckter Linien in der Darstellung einer perspektivischen Ansicht von konkaven und konvexen Objekten mit ebener Fläche auf der Bildebene. Alle Kanten der Objekte werden sequentiell betrachtet, und alle Ebenen, die jeden Punkt einer Kante verdecken, werden gefunden. Die Rechenzeit wächst ungefähr quadratisch mit der Anzahl der Kanten. Der Algorithmus nutzt eine reduzierte Anzahl konkaver Punkte und erkennt automatisch, wenn nur ein Objekt ohne konkave Punkte betrachtet wird. In diesem letzten Fall erhält man das Ergebnis auf viel einfachere Weise."}
{"DOCID": "1916", "TEXT": "Analyse boolescher Programmmodelle für zeitgeteilte, ausgelagerte Umgebungen: Gerichtete Graphen oder ihre zugeordneten Matrizen werden häufig verwendet, um die logische Struktur von Sequenzen von Computerbefehlen darzustellen. Solche Techniken werden verwendet und zusätzlich werden Datenreferenzen in einem ungerichteten Modell dargestellt. Die vollständige strukturelle Spezifikation eines Programms wird durch ein kombiniertes Modell dargestellt. Eine Transformation des kombinierten Modells ergibt ein neues Modell, in dem auch zusätzliche Zeitinformationen enthalten sind. Die Analyse dieser Modelle vor der Ausführung liefert Informationen, die beim Bestimmen der Segmentierung von Anweisungen und Daten für eine zeitgeteilte Umgebung sowie für das anfängliche Laden von Seiten wertvoll sind; während der Ausführung kann die Analyse zur \"vorausschauenden\" Steuerung des Seitenumblätterns verwendet werden."}
{"DOCID": "1917", "TEXT": "Ein Algol-Verfahren für die schnelle Fourier-Transformation mit beliebigen Faktoren (Algorithmus 339 [C6])"}
{"DOCID": "1918", "TEXT": "Verteilung nicht unterscheidbarer Objekte in unterscheidbare Slots (Algorithmus 329 [G6])"}
{"DOCID": "1919", "TEXT": "Ein effizienter Algorithmus zum Sortieren mit minimalem Speicherplatz (Algorithmus 347 [M1])"}
{"DOCID": "1920", "TEXT": "F-Test-Wahrscheinlichkeiten (Algorithmus 346 [S14])"}
{"DOCID": "1921", "TEXT": "Ein Algol-Faltungsverfahren basierend auf der schnellen Fourier-Transformation (Algorithmus 345 [C6])"}
{"DOCID": "1922", "TEXT": "Vorgeschlagener USA-Standard (Data Communication Control Procedures for the USA Standard Code for Information Interchange)"}
{"DOCID": "1923", "TEXT": "Pseudodateien: Es wird ein Ansatz für Systemschnittstellen für Hochsprachen unter Verwendung grundlegender Eingabe/Ausgabe-Unterstützungseinrichtungen beschrieben. Es wird gezeigt, dass diese Technik potenziell kostengünstige Methoden für Programme bereitstellen kann, um mit tief eingebetteten Einrichtungen wie Befehlssprachenprozessoren zu kommunizieren."}
{"DOCID": "1924", "TEXT": "Organisieren von Matrizen und Matrixoperationen für ausgelagerte Speichersysteme: Matrixdarstellungen und -operationen werden zum Zweck des Minimierens von Seitenfehlern untersucht, die in einem ausgelagerten Speichersystem auftreten. Es wird gezeigt, dass sorgfältig entworfene Matrixalgorithmen zu enormen Einsparungen bei der Anzahl von Seitenfehlern führen können, die auftreten, wenn nur ein kleiner Teil der Gesamtmatrix gleichzeitig im Hauptspeicher sein kann. Die Untersuchung von Additions-, Multiplikations- und Inversionsalgorithmen zeigt, dass eine unterteilte Matrixdarstellung (d. h. eine Untermatrix oder Partition pro Seite) in den meisten Fällen weniger Seitenfehler hervorrief als eine zeilenweise Darstellung. Die Anzahl der für diese Matrixmanipulationsalgorithmen erforderlichen Seitenzugriffe wird auch als Funktion der Anzahl der für den Algorithmus verfügbaren Seiten des Hauptspeichers untersucht."}
{"DOCID": "1925", "TEXT": "Nutzungskonzepte bei der Konturkartenverarbeitung: Verallgemeinerte Techniken, deren Einsatz die Lösung von Problemen im Zusammenhang mit Konturkarten vereinfachen kann. Eine dieser Techniken nutzt die topologischen Eigenschaften von Höhenlinienkarten. Die Topologie wird durch eine grafische Struktur dargestellt, in der benachbarte Höhenlinien als verbundene Knoten erscheinen. Eine andere verallgemeinerte Technik besteht darin, geometrische Eigenschaften zu verwenden, um die Eigenschaften von geraden Linien zu bestimmen, die auf der Konturkarte gezeichnet sind. Beide dieser Techniken wurden auf das Problem des Lokalisierens des Bodenkurses eines Flugzeugs aus während eines Flugs erhaltenen Höhenablesungen angewendet."}
{"DOCID": "1926", "TEXT": "Beschreibung von FORMAT, einem Textverarbeitungsprogramm: FORMAT ist ein Produktionsprogramm, das das Bearbeiten und Drucken \"fertiger\" Dokumente direkt auf dem Drucker eines relativ kleinen (64k) Computersystems ermöglicht. Es zeichnet sich durch gute Leistung, völlig freie Eingaben, sehr flexible Formatierungsmöglichkeiten mit bis zu acht Spalten pro Seite, automatische Großschreibung, Hilfen für die Indexerstellung und ein Minimum an Nicht-Text-Elementen aus. Es ist vollständig in FORTRAN IV geschrieben."}
{"DOCID": "1927", "TEXT": "Informationswissenschaft in einem Ph.D. Informatikprogramm: Dieser Bericht enthält Empfehlungen zu einem beispielhaften Lehrplan im allgemeinen Bereich Informationsorganisation und Informationssystemdesign in einem Ph.D. Informatikprogramm. Das Fachgebiet wird zunächst kurz beschrieben, gefolgt von einer Auflistung einiger wünschenswerter Studiengänge auf Graduiertenebene. Passende Bibliographien sind beigefügt."}
{"DOCID": "1928", "TEXT": "Exklusive Simulation der Aktivität in digitalen Netzwerken: Eine Technik zur Simulation der detaillierten logischen Netzwerke großer und aktiver digitaler Systeme wird beschrieben. Wesentliche angestrebte Ziele sind eine verbesserte Leichtigkeit und Wirtschaftlichkeit bei der Modellerzeugung, Wirtschaftlichkeit bei Ausführungszeit und -platz und eine Möglichkeit zur Handhabung gleichzeitiger Aktivitäten. Die erhaltenen Hauptergebnisse sind eine klare und nützliche Trennung von Struktur- und Verhaltensmodellbeschreibung, eine Reduzierung manueller Aufgaben bei der Umwandlung der Booleschen Logik in ein Strukturmodell, die Eliminierung manueller Prozesse bei der Erzielung einer ausschließlichen Simulation von Aktivitäten, einer Ereignisplanungstechnik, die dies tut sich nicht in der Wirtschaftlichkeit verschlechtern, wenn die Ereigniswarteschlange in der Länge zunimmt, und eine Simulationsprozedur, die jede Mischung aus seriellen und gleichzeitigen Aktivitäten effektiv handhabt. Der Zeitverlauf wird auf präzise quantitative Weise simuliert und zu simulierende Systeme können Kombinationen aus synchroner und asynchroner Logik sein. Bestimmte Aspekte der beschriebenen Techniken können für die Simulation von anderen Netzwerkstrukturen als digitalen Netzwerken verwendet werden."}
{"DOCID": "1929", "TEXT": "Bilder von Computern und Mikrofilmplottern: Digitale Computer werden in großem Umfang für die Verarbeitung von Informationen und Daten aller Art verwendet, einschließlich der in Fotografien und anderen grafischen Darstellungen enthaltenen Bildinformationen. Effiziente Konvertierungseinrichtungen zum Eingeben graphischer Informationen in den Computer und Abrufen derselben in graphischer Form werden daher dringend benötigt. Eines der am häufigsten verwendeten Geräte zum Erzielen einer permanenten grafischen Ausgabe von Digitalcomputern ist der Mikrofilmplotter. Bedauerlicherweise haben derzeitige Modelle keine Vorkehrungen zum Erzeugen von Bildern mit einer kontinuierlichen Grauskala oder \"Halbtönen\". In dieser Anmerkung werden mehrere Programmiertechniken zum Erhalten von Halbtonbildern von einem Mikrofilmplotter unter der Steuerung eines digitalen Computers beschrieben. Veranschaulichende Beispiele für mehrere Methoden werden gegeben."}
{"DOCID": "1930", "TEXT": "Extrem portabler Zufallszahlengenerator: Manchmal werden extrem portable Subroutinen benötigt, für die mäßige Qualität und Effizienz ausreichen. Typischerweise tritt dies für Bibliotheksfunktionen (wie Zufallszahlengenerierung und Kernsortierung) auf, die nicht vollständig universell sind oder nicht standardisiert verwendet werden. Die Literatur zu Zufallszahlengeneratoren scheint keinen Algorithmus zu enthalten, der derartige Anforderungen erfüllt. Es wird ein äußerst portables 8-Zeilen-FORTRAN-Programm bereitgestellt, das auf einem wichtigen Artikel von Coveyou und MacPherson (1967) basiert. Unter Verwendung ihrer Methoden wird die Fourier-Analyse auf die Wahrscheinlichkeitsfunktion für die aufeinanderfolgenden n-Tupel angewendet, die von unserem Generator bereitgestellt werden (mit n weniger als oder gleich 4). Während der kleine Modul, der verwendet werden muss, um die Tragbarkeit aufrechtzuerhalten, verhindert, dass die Qualität des Generators hoch ist, lässt sich der Generator gut mit den in der oben erwähnten Veröffentlichung aufgestellten Grenzen vergleichen."}
{"DOCID": "1931", "TEXT": "Interval Arithmetic Determinant Evaluation and Its Use in Testing for a Chebyshev System: Zwei neuere Arbeiten, eine von Hansen und eine von Hansen und R. R. Smith, haben gezeigt, wie Intervallarithmetik (I.A.) effektiv verwendet werden kann, um Fehler in Matrizenberechnungen einzugrenzen. In der vorliegenden Arbeit wird eine von Hasen und R. R. Smith vorgeschlagene Methode mit der direkten Verwendung von I.A. bei der Determinantenbewertung. Berechnungsergebnisse zeigen die Genauigkeit und Laufzeiten, die bei der Verwendung von I.A. zur bestimmenden Bewertung. Eine Anwendung mit I.A. Determinanten in einem Programm zum Testen einer Reihe von Funktionen, um zu sehen, ob sie ein Tschebyscheff-System bilden, werden dann dargestellt."}
{"DOCID": "1932", "TEXT": "Der logarithmische Fehler und das Newton-Verfahren für die Quadratwurzel: Es wird das Problem betrachtet, optimale Startwerte für die Berechnung der Quadratwurzel mit dem Newton-Verfahren zu erhalten. An anderer Stelle wurde darauf hingewiesen, dass bei Verwendung des relativen Fehlers als Maß für die Anpassungsgüte keine optimalen Ergebnisse erzielt werden, wenn die anfängliche Annäherung eine beste Anpassung ist. Hier zeigt sich, dass wenn stattdessen der sogenannte logarithmische Fehler verwendet wird, ein bester Anfangsfit für beide Fehlerarten optimal ist. Darüber hinaus scheint die Verwendung des logarithmischen Fehlers das Problem der Bestimmung der optimalen Anfangsnäherung zu vereinfachen."}
{"DOCID": "1933", "TEXT": "Kodierung des Lehmer Pseudo-Zufallszahlengenerators: Es wird ein Algorithmus und eine Kodierungstechnik zur schnellen Auswertung des Lehmer Pseudo-Zufallszahlengenerators Modulo 2**31 – 1, eine Mersenne-Primzahl mit 2**31 – 2 Zahlen, vorgestellt ein p-Bit-Computer (größer als 31). Das Berechnungsverfahren ist auf begrenzte Probleme in der modularen Arithmetik erweiterbar. Primfaktorzerlegung für 2**61 - 2 und eine Primitivwurzel für 2**61 - 1, die nächstgrößte Mersenne-Primzahl, werden für die mögliche Konstruktion eines Pseudo-Zufallszahlengenerators mit erhöhter Zykluslänge angegeben."}
{"DOCID": "1934", "TEXT": "Zu arithmetischen Ausdrücken und Bäumen: Es wird beschrieben, wie ein Baum, der die Auswertung eines arithmetischen Ausdrucks darstellt, so gezeichnet werden kann, dass die Anzahl der für die Berechnung benötigten Akkumulatoren auf einfache Weise dargestellt werden kann. Diese Darstellung reduziert die Wahl der besten Berechnungsordnung auf ein spezifisches Problem der Graphentheorie. Ein Algorithmus zur Lösung dieses Problems wird vorgestellt."}
{"DOCID": "1935", "TEXT": "Randomisierte binäre Suchtechnik: Es wird ein mathematisches Modell für den Mittelwert und die Varianz der Anzahl von Versuchen entwickelt, um ein bestimmtes Dokument in einer zufällig erhaltenen Liste von Dateien wiederherzustellen. Das beschriebene Suchverfahren ist binärer Natur und bietet ein neues Potential für Informationsabrufsysteme."}
{"DOCID": "1936", "TEXT": "Baumstrukturen variabler Länge mit minimaler durchschnittlicher Suchzeit: Sussenguth schlägt in einem Artikel (1963) vor, dass eine Datei als eine doppelt verkettete Baumstruktur organisiert werden sollte, wenn es notwendig ist, häufig sowohl zu suchen als auch zu aktualisieren. Eine derartige Struktur stellt einen Kompromiß zwischen den Merkmalen der schnellen Suche/langsamen Aktualisierung der binären Suche und den Merkmalen der langsamen Suche/schnellen Aktualisierung der seriellen Suche bereit. Sein Verfahren enthält jedoch die einschränkende Einschränkung, dass alle Endknoten auf der gleichen Ebene des Baums liegen. Dieses Papier befasst sich mit der Auswirkung einer Lockerung dieser Beschränkung. Zuerst werden Bäume untersucht, die die Eigenschaft haben, dass a priori die Filialmenge jedes Knotens wohldefiniert ist. Es ist bewiesen, dass das Codieren der Knoten innerhalb jeder untergeordneten Menge in Bezug auf die Anzahl der erreichbaren Endknoten notwendig und ausreichend ist, um eine minimale durchschnittliche Suchzeit zu garantieren. Dann wird der allgemeinere Fall (das heißt, wo die gesamte Struktur des Baums veränderbar ist) behandelt. Es wird ein Verfahren entwickelt, um einen Baum mit einer minimalen durchschnittlichen Suchzeit zu konstruieren. Als Funktion der Anzahl der Endknoten erhält man einen einfachen geschlossenen Ausdruck für diese minimale mittlere Suchzeit. Außerdem wird die zur Implementierung der doppelt verketteten Baumstruktur auf einem Digitalrechner erforderliche Speicherkapazität bestimmt. Schließlich werden die Gesamtkosten der Struktur unter Verwendung des Kostenkriteriums von Süßenguth berechnet. Es wird gezeigt, dass signifikante Verbesserungen sowohl in der durchschnittlichen Suchzeit als auch in den Gesamtkosten erzielt werden können, indem man Sussenguths Einschränkung lockert, dass alle Endknoten auf der gleichen Ebene des Baums liegen."}
{"DOCID": "1937", "TEXT": "CODAS: Ein Datenanzeigesystem: CODAS, ein kundenorientiertes Datensystem, ist ein benutzerorientiertes Datenabruf- und -anzeigesystem. Die Befehlssprache des Systems bietet dem Benutzer ein einfaches Mittel zum Spezifizieren von Datenabruf- und Anzeigeanforderungen. Die Daten werden als Tabellen und Grafiken angezeigt, die in einem zur Veröffentlichung bereiten Format erstellt wurden. In diesem Papier werden die Aussagen der Anforderungssprache und das allgemeine Systemdesign beschrieben."}
{"DOCID": "1938", "TEXT": "Einige Kriterien für die Leistungsfähigkeit von Time-Sharing-Systemen: Time-Sharing-Systeme, wie sie in diesem Artikel definiert sind, sind solche Vielfachzugriffssysteme, die es einem Terminalbenutzer ermöglichen, im Wesentlichen die vollen Ressourcen des Systems zu nutzen, während er seine Zeit mit anderen Terminalbenutzern teilt. Es ist die Fähigkeit jedes Terminalbenutzers, die vollen Ressourcen des Systems zu nutzen, die eine quantitative Bewertung von Time-Sharing-Systemen besonders schwierig macht. Es werden sechs Kriterien beschrieben, die erfolgreich verwendet wurden, um eine erste quantitative Leistungsbewertung von Time-Sharing-Systemen durchzuführen."}
{"DOCID": "1939", "TEXT": "Gezielte Zufallsgenerierung von Sätzen: Das Problem der Erzeugung von Sätzen einer Transformationsgrammatik durch Verwendung eines Zufallsgenerators zur Erzeugung von Phrasenstrukturbäumen zur Eingabe in die lexikalische Einfügungs- und Transformationsphase wird diskutiert. Ein reiner Zufallsgenerator erzeugt Basisbäume, die durch die Transformationen blockiert werden und die häufig zu lang sind, um von praktischem Interesse zu sein. Eine Lösung wird in Form eines Computerprogramms angeboten, das es dem Benutzer ermöglicht, die Generierung durch das einfache, aber leistungsstarke Gerät eingeschränkter Teilbäume einzuschränken und zu lenken. Das Programm ist ein gerichteter Zufallsgenerator, der als Eingabe einen Teilbaum mit Beschränkungen akzeptiert und um ihn herum einen Baum erzeugt, der die Beschränkungen erfüllt und für die nächste Phase der Grammatik bereit ist. Das zugrunde liegende linguistische Modell ist das von Noam Chomsky, wie es in Aspekte der Syntaxtheorie vorgestellt wird. Das Programm ist in FORTRAN IV für IBM 360/67 geschrieben und Teil eines einheitlichen Computersystems für Transformationsgrammatik. Es wird derzeit mit mehreren Teilgrammatiken des Englischen verwendet."}
{"DOCID": "1940", "TEXT": "Berechnung eines Polynoms und seiner Ableitungswerte nach dem Horner-Schema (Algorithmus 337 [C1])"}
{"DOCID": "1941", "TEXT": "F-Verteilung (Algorithmus 322 [S14])"}
{"DOCID": "1942", "TEXT": "Finden einer Lösung von N Funktionsgleichungen in N Unbekannten (Algorithmus 314 [C5])"}
{"DOCID": "1943", "TEXT": "Vollständige elliptische Integrale (Algorithmus 165 [S21])"}
{"DOCID": "1944", "TEXT": "Studentische t-Verteilung (Algorithmus 344 [S14])"}
{"DOCID": "1945", "TEXT": "Die Rolle der Programmierung in einem Ph.D. Informatikprogramm: In diesem allgemeinen Beitrag wird die Rolle der Programmierung in der weiterführenden Graduiertenausbildung diskutiert. Berücksichtigt werden sowohl programmierbezogene Themen als auch das Programmieren an sich. Die Bedeutung und Anwendung des Formalismus werden ebenso berücksichtigt wie die Notwendigkeit guter empirischer Experimente. Eine kurze Gliederung für eine Abfolge von Lehrveranstaltungen ist enthalten, und Schlagworte, die einer umfangreichen Bibliographie entnommen wurden, werden angegeben. Eine Bibliographie der Programmierreferenzen ist enthalten."}
{"DOCID": "1946", "TEXT": "Berechnen von Polynomresultaten: Bezouts Determinante vs. Collins' reduzierte P.R.S. Algorithmus: Algorithmen zur Berechnung der Resultierenden zweier Polynome in mehreren Variablen, ein wichtiger, sich wiederholender Berechnungsschritt beim Lösen von Systemen polynomischer Gleichungen durch Elimination, werden untersucht. Die Bestimmung des besten Algorithmus für die Computerimplementierung hängt von dem Ausmaß ab, in dem äußere Faktoren eingeführt werden, dem Ausmaß der Ausbreitung von Fehlern, die durch das Abschneiden realer Koeffizienten verursacht werden, den Speicheranforderungen und der Rechengeschwindigkeit. Vorüberlegungen grenzen die Wahl des besten Algorithmus auf Bezouts Determinanten- und Collins' Algorithmus der reduzierten Polynomrestfolge (p.r.s.) ein. Detaillierte Tests, die an Beispielproblemen durchgeführt wurden, zeigen schlüssig, dass die Determinante von Bezout in jeder Hinsicht überlegen ist, mit Ausnahme von univariaten Polynomen, in welchem ​​​​Fall Collins reduzierte p.r.s. Algorithmus ist etwas schneller. Insbesondere die Determinante von Bezout erweist sich als auffallend überlegen in der numerischen Genauigkeit und zeigt eine hervorragende Stabilität in Bezug auf Rundungsfehler. Die Ergebnisse der Tests werden im Detail berichtet."}
{"DOCID": "1947", "TEXT": "Objektcode-Optimierung: Methoden zur Analyse des Kontrollflusses und des Datenflusses von Programmen während der Kompilierung werden auf die Transformation des Programms angewendet, um die Objektzeiteffizienz zu verbessern. Dominanzbeziehungen, die angeben, welche Anweisungen notwendigerweise vor anderen ausgeführt werden, werden verwendet, um eine globale Eliminierung gemeinsamer Ausdrücke und eine Schleifenidentifikation durchzuführen. Die Implementierung dieser und anderer Optimierungen in OS/360 FORTRAN H wird beschrieben."}
{"DOCID": "1948", "TEXT": "Computer in der Gruppentheorie: eine Übersicht: Computer werden für eine zunehmend vielfältige Palette von Problemen in der Gruppentheorie eingesetzt. Die derzeit wichtigsten Anwendungsgebiete sind Nebenklassenaufzählung, Untergruppenverbände, Automorphismengruppen endlicher Gruppen, Zeichentafeln und Kommutatorrechnung. Gruppentheorieprogramme reichen von einfachen kombinatorischen oder numerischen Programmen bis hin zu großen Symbolmanipulationssystemen. In dieser Übersicht werden die wichtigsten verwendeten Algorithmen beschrieben und gegenübergestellt, und Ergebnisse, die mit bestehenden Programmen erzielt wurden, werden angegeben. Eine umfangreiche Bibliographie ist enthalten."}
{"DOCID": "1949", "TEXT": "Endlichkeitsannahmen und intellektuelle Isolation von Informatikern"}
{"DOCID": "1950", "TEXT": "Effizienter Umgang mit binären Daten"}
{"DOCID": "1951", "TEXT": "Abschätzungen von Verteilungen von Zufallsvariablen für bestimmte Computerkommunikations-Verkehrsmodelle: Eine Studie über Computerkommunikation mit Mehrfachzugriff hat die Verteilungen charakterisiert, die einem elementaren Modell des Benutzer-Computer-Interaktionsprozesses zugrunde liegen. Das verwendete Modell ist insofern elementar, als viele der Zufallsvariablen, die im Allgemeinen für Computerkommunikationsstudien von Interesse sind, in die Elemente dieses Modells zerlegt werden können. Es wurden Daten von vier in Betrieb befindlichen Mehrfachzugriffssystemen untersucht, und das Modell erweist sich als robust; das heißt, jede der Variablen des Modells hat die gleiche Verteilung, unabhängig davon, welches der vier Systeme untersucht wird. Es wird gezeigt, dass die Gammaverteilung zur Beschreibung der diskreten Variablen verwendet werden kann. Annäherungen an die Gamma-Verteilung durch die Exponentialverteilung werden für die untersuchten Systeme diskutiert."}
{"DOCID": "1952", "TEXT": "Index nach Thema Algorithmen, 1970"}
{"DOCID": "1953", "TEXT": "Exponentialintegral Ei(x) (Algorithmen 385 $S13))"}
{"DOCID": "1954", "TEXT": "Eigenwerte und Eigenvektoren einer reellen symmetrischen Matrix (Algorithmus 384 $F2))"}
{"DOCID": "1955", "TEXT": "Charakteristische Werte und zugehörige Lösungen der Differentialgleichung von Mathieu (Algorithmus 352 $S22))"}
{"DOCID": "1956", "TEXT": "Optimale Zusammenführung aus Massenspeicher: Es wird ein Algorithmus angezeigt, der die Zusammenführungsbefehle so liefert, dass die gesamte Lesezeit, definiert als die Summe aus Suchzeit plus Datenübertragungszeit, für eine Sortierung unter Verwendung von Massenspeicher minimiert wird. Die Analyse wird hinsichtlich des Verhältnisses der Suchzeit zu der Zeit, die benötigt wird, um den verfügbaren Kern mit Datensätzen zu füllen, und der Dateigröße in Einheiten von Kernlängen parametrisiert; und somit kann es auf jede herkömmliche CPU/Massenspeicher-Kombination angewendet werden. Es wird eine explizite Formel für die gesamte Lesezeit bezüglich der Parameter hergeleitet, die sehr gut mit der berechneten gesamten Lesezeit korreliert, die unter Verwendung der vom Algorithmus gelieferten optimalen Zusammenführungsreihenfolgen verwendet wird. Die Formel beinhaltet die Wurzeln einer einfachen transzendentalen Gleichung. Eine kurze Tabelle dieser Wurzeln ist enthalten. Numerische Ergebnisse werden für eine Vielzahl von Parametern grafisch angezeigt. Es zeigt sich, dass die normalisierte Lesezeit für optimales Zusammenführen bei einer gegebenen Hardwarekonfiguration proportional zu der Dateilänge mal dem Logarithmus der Dateilänge ist."}
{"DOCID": "1957", "TEXT": "Der Listenmengengenerator: Ein Konstrukt zur Auswertung von Mengenausdrücken: Der Listenmengengenerator wird definiert und Algorithmen für seine Verwendung werden angegeben. Der Listensatzgenerator ist ein Konstrukt, das zu einem Listenverarbeitungssystem oder irgendeinem System, das Sätze handhabt, hinzugefügt werden kann. Es erzeugt effizient die Menge, die sich aus jedem Ausdruck ergibt, der Mengen und Mengenoperatoren enthält. Die Effizienz ergibt sich aus der Auswertung des Ausdrucks als Ganzes und parallel, anstatt Teilausdrücke auszuwerten und dann diese Sätze zu verwenden, um zum Endergebnis zu gelangen."}
{"DOCID": "1958", "TEXT": "Verbesserung der Rundung in Runge-Kutta-Berechnungen mit dem Gill-Verfahren: Ein allgemein verwendetes Runge-Kutta-Gill-Schema basiert auf einer unvollständigen Anpassung des Gill-Verfahrens für Gleitkommaoperationen. Eine verbesserte Version reduziert Rundungsfehler erheblich. In dieser Notiz wird das Herzstück des Schemas in Fortran-Sprache dargestellt. Anschließend wird gezeigt, wie durch Hinzufügen von zwei Fortran-Anweisungen eine verbesserte Version des Verfahrens erhalten werden kann. Die Zwei-Version ist eine deutliche Verbesserung. Ein Zahlenbeispiel zum Vergleich der beiden ist enthalten."}
{"DOCID": "1959", "TEXT": "Eine unterbrechungsbasierte Organisation für Verwaltungsinformationssysteme: Eine Programmierstruktur, Sprachkonstrukte und eine Überwachungssystemorganisation werden für den Entwurf und die Codierung großer gemeinsam genutzter Datenbanksysteme vorgeschlagen. Die Grundlagen für diese Organisation sind eine verallgemeinerte Unterbrechungsstruktur und das neu eingeführte Konzept der \"Dateikennzeichnung\", bei der es sich um den Vorgang des Zuordnens von Programmstrukturen und Unterbrechungserzeugungsbedingungen zu Elementen in der Datenbank handelt. Ein Algorithmus zum Auflösen von Konflikten, die beim Planen der Interrupt-Verarbeitungsroutinen entstehen, wird vorgestellt. DPL, eine Programmiersprache und ein Überwachungssystem, in dem diese Konzepte implementiert sind, wird verwendet, um die neue Organisation zu veranschaulichen, die für Management-Informationssysteme vorgeschlagen wird."}
{"DOCID": "1960", "TEXT": "Prozessmanagement und gemeinsame Nutzung von Ressourcen im Vielfachzugriffssystem ESOPE: Die wichtigsten Gestaltungsprinzipien des Vielfachzugriffssystems ESOPE werden beschrieben. Der Schwerpunkt liegt auf den grundlegenden Ideen, die dem Design zugrunde liegen, und nicht auf Implementierungsdetails. Zu den Hauptmerkmalen des Systems gehören die jedem Benutzer gegebene Fähigkeit, seine eigenen parallelen Prozesse unter Verwendung von Systemprimitiven zu planen, die Datei-Speicher-Beziehung und die Zuordnungsplanungsrichtlinie, die dynamisch aktuelle Informationen über das Benutzerverhalten berücksichtigt."}
{"DOCID": "1961", "TEXT": "An Efficient Search Algorithm to Find the Elementary Circuits of a Graph: Ein theoretisch effizientester Suchalgorithmus wird vorgestellt, der eine erschöpfende Suche verwendet, um alle elementaren Schaltkreise eines Graphen zu finden. Der Algorithmus kann leicht modifiziert werden, um alle elementaren Schaltungen mit einem bestimmten Attribut, wie beispielsweise Länge, zu finden. Ein rigoroser Beweis des Algorithmus wird ebenso gegeben wie ein Beispiel seiner Anwendung. Es werden empirische Grenzen dargestellt, die die Geschwindigkeit des Algorithmus mit der Anzahl der Scheitelpunkte und der Anzahl der Bögen in Beziehung setzen. Die Geschwindigkeit hängt auch mit der Anzahl der Schaltungen im Diagramm zusammen, um eine Beziehung zwischen Geschwindigkeit und Komplexität herzustellen. Erweiterungen auf ungerichtete und S-Graphen werden diskutiert."}
{"DOCID": "1962", "TEXT": "GROOVE-A-Programm zum Zusammenstellen, Speichern und Bearbeiten von Zeitfunktionen: Es wird ein Programm beschrieben, das das Erstellen, Speichern, Reproduzieren und Bearbeiten von Zeitfunktionen ermöglicht. Die Funktionen sind typisch für die von Menschen erzeugten. Mehrere Funktionen (bis zu 14) werden über lange Zeiträume (bis zu mehreren Stunden) mit ausreichend hohen Abtastraten erzeugt, um schnelle menschliche Reaktionen zu beschreiben (bis zu 200 Abtastungen pro Sekunde). Die Funktionen können für eine Vielzahl von Zwecken verwendet werden, wie z. B. die Steuerung von Werkzeugmaschinen oder Klangsynthesizern oder alles, was eine Person normalerweise steuert. Das Programm läuft auf einem kleinen Computer (DDP-224). Funktionen werden in einer Plattendatei gespeichert. Funktionen können durch menschliche Eingaben in Echtzeit in den Computer erzeugt werden, die mit bereits gespeicherten Funktionen und berechneten Funktionen interagieren können. Echtzeit-Feedback vom zu steuernden Prozess ist ein wichtiges Bindeglied im System. Die Umgebung für eine effektive Mensch-Maschine-Interaktion wurde sorgfältig gepflegt."}
{"DOCID": "1963", "TEXT": "Zustandsnummern von PEI-Matrizen"}
{"DOCID": "1964", "TEXT": "Kommentar zum Arbeitssatzmodell für Programmverhalten"}
{"DOCID": "1965", "TEXT": "Korrektur der \"logischen\" Arithmetik auf Computern mit Zweierkomplement-Binärarithmetik"}
{"DOCID": "1966", "TEXT": "Eine verallgemeinerte Methode zum Generieren von Argument-/Funktionswerten"}
{"DOCID": "1967", "TEXT": "Ein verbesserter Algorithmus zur Erzeugung komplexer Primzahlen (Algorithmus 401 $A1))"}
{"DOCID": "1968", "TEXT": "Eigenwerte und Eigenvektoren einer reellen allgemeinen Matrix (Algorithmus 343 $F1))"}
{"DOCID": "1969", "TEXT": "Steigerung der Effizienz von Quicksort (Algorithmus 402 $M1))"}
{"DOCID": "1970", "TEXT": "Unbespieltes Magnetband für den Informationsaustausch (9 Spuren-200 und 800 CPI, NRZI und 1600 CPI, PE)* (vorgeschlagener amerikanischer nationaler Standard)"}
{"DOCID": "1971", "TEXT": "Bespieltes Magnetband für den Informationsaustausch (1600 CPI, phasenkodiert)* (vorgeschlagener amerikanischer nationaler Standard)"}
{"DOCID": "1972", "TEXT": "Ein nichtrekursiver Listenkomprimierungsalgorithmus: Ein einfaches nichtrekursives Listenstrukturkomprimierungsschema oder Garbage Collector, das sowohl für kompakte als auch für LISP-ähnliche Listenstrukturen geeignet ist, wird vorgestellt. Der Algorithmus vermeidet die Notwendigkeit einer Rekursion, indem er die partielle Struktur verwendet, während sie aufgebaut ist, um jene Listen zu verfolgen, die kopiert wurden."}
{"DOCID": "1973", "TEXT": "Der lineare Quotient-Hash-Code: Eine neue Methode der Hash-Codierung wird vorgestellt und es wird gezeigt, dass sie wünschenswerte Attribute besitzt. Insbesondere ist der Algorithmus einfach, effizient und erschöpfend, während er wenig Zeit pro Sonde benötigt und wenige Sonden pro Suche verwendet. Leistungsdaten und Implementierungshinweise werden ebenfalls gegeben."}
{"DOCID": "1974", "TEXT": "NEATER2: Ein PL/I Source Statement Reformatierer: NEATER2 akzeptiert ein PL/I Source Programm und verarbeitet es, um eine neu formatierte Version zu erzeugen. Im LOGICAL-Modus zeigt NEATER2 die logische Struktur des Quellenprogramms im Einrückungsmuster seiner Ausgabe an. Logikfehler, die durch die logische Analyse von NEATER2 entdeckt werden, werden viel wirtschaftlicher entdeckt, als dies durch Kompilieren und Probeläufe möglich ist. Eine Reihe von Optionen stehen zur Verfügung, um dem Benutzer die volle Kontrolle über das Ausgabeformat zu geben und den Nutzen von NEATER2 als Hilfsmittel in den frühen Phasen der Entwicklung eines PL/I-Quelldecks zu maximieren. Eine Option, VERWENDUNG, bewirkt, dass NEATER2 in jede logische Codiereinheit eine Anweisung einfügt, die die Anzahl der Ausführungsvorgänge während der Ausführung aufzeichnet. Von diesem Merkmal wird erwartet, dass es eine große Hilfe bei der Optimierung von PL/I-Programmen darstellt."}
{"DOCID": "1975", "TEXT": "Ein Divisionsalgorithmus mit mehrfacher Genauigkeit: Ein verallgemeinerter Divisionsalgorithmus zur Verwendung mit positiven ganzzahligen Operanden wird vorgestellt. Abhängig von der algebraischen Beziehung der ersten beiden Chiffren des Divisors müssen eine oder höchstens zwei Anpassungen des ursprünglichen Divisors und Dividenden durchgeführt werden, bevor die Divisionsoperation eingeleitet werden kann. Die Einzigartigkeit dieses Verfahrens führt dazu, dass jede Testchiffre im Quotienten entweder gleich oder um eins größer als ihr endgültiger Ersatz ist."}
{"DOCID": "1976", "TEXT": "Mehrattribut-Abruf mit kombinierten Indizes: In diesem Dokument wird ein Dateiorganisationsschema beschrieben, das die Verwendung des beliebten sekundären Index-Ablageschemas (oder invertierter Dateien auf sekundären Schlüsselfeldern) ersetzen soll. Durch die Verwendung von Redundanz und Speichern von Schlüsseln (oder Zugriffsnummern der Datensätze), die verschiedene Kombinationen von sekundären Indexwerten in \"Buckets\" erfüllen, ist es möglich, alle Schlüssel abzurufen, die jede Eingabeabfrage erfüllen, die von einer Teilmenge von Feldern durch einen einzigen Zugriff abgeleitet wurde in eine Indexdatei, obwohl jeder Bucket für viele Kombinationen von Werten verwendet werden kann und eine Kombination von Buckets für eine bestimmte Abfrage erforderlich sein kann. Das Verfahren, das in seinem degenerierten Fall zum herkömmlichen Sekundärindex-Ablageschema wird, funktioniert ähnlich, hat aber die folgenden Vorteile: (1) die Eliminierung von Mehrfachzugriffen in vielen Fällen; (2) die Eliminierung falscher Tropfen; (3) die Eliminierung von Computerzeit zum Durchführen einer Überschneidung von Schlüsselsätzen, die jeweils nur für ein sekundäres Indexfeld qualifiziert sind; und (4) die Vermeidung langer Schlüsselfolgen, wenn ein Indexfeld, das in einer Abfrage erscheint, sehr wenige mögliche Werte hat. Redundanz ist in einigen Fällen dasselbe wie die sekundäre Indizierungsmethode. Im allgemeinen Fall besteht ein Kompromiss zwischen der Anzahl der Zugriffe für die Abfrage und der Redundanz."}
{"DOCID": "1977", "TEXT": "Eine interaktive Anzeige zur Annäherung durch lineare Programmierung: Ein interaktives Programm mit einer grafischen Anzeige wurde für die Annäherung von Daten mittels einer vom Benutzer ausgewählten linearen Kombination von Funktionen (einschließlich Splines) entwickelt. Die Koeffizienten der Annäherung werden durch lineare Programmierung bestimmt, um den Fehler entweder in der L1- oder der L-unendlich-Norm zu minimieren. Auch Nebenbedingungen wie Monotonie oder Konvexität der Approximation können auferlegt werden. Dieses interaktive System wird beschrieben und es werden mehrere Beispiele seiner Verwendung gegeben."}
{"DOCID": "1978", "TEXT": "Die Verwendung interaktiver Graphiken zum Lösen numerischer Probleme: Mit dem Aufkommen von Online-(Time-Sharing)-Computersystemen und Graphikterminals steht uns eine neue Dimension der numerischen Problemlösungsfähigkeiten zur Verfügung. Anstatt die neue Leistung einfach zu nutzen, um eine schnelle Abwicklung zu erreichen, können wir interaktive Routinen entwickeln, die einfach zu bedienen sind und auch die Einblicke und visuellen Fähigkeiten des menschlichen Problemlösers nutzen. Mehrere Online-Systeme zum Lösen mathematischer Probleme für allgemeine Zwecke wurden bereits implementiert, ebenso wie einige Systeme für spezielle Zwecke zum Lösen von Problemen auf einem bestimmten Gebiet, wie zum Beispiel gewöhnliche Differentialgleichungen. Der Vorteil der Einschränkung des Problembereichs besteht darin, dass die Schnittstelle mit einem Benutzer stark vereinfacht werden kann. In diesem Papier diskutieren wir einige der Vorteile, die durch solche Systeme entstehen, und Designüberlegungen für interaktive Routinen. Darüber hinaus wird eine Implementierung eines Online-Datenanpassungsprogramms der kleinsten Quadrate, PEG, mit Ergebnissen vorgestellt, die aus empirischen Daten erhalten wurden. Abschließend werden Bereiche für zukünftige Arbeiten auf diesem Gebiet diskutiert."}
{"DOCID": "1979", "TEXT": "Numerische Inversion von Laplace-Transformationen (Algorithmus 368 $D5))"}
{"DOCID": "1980", "TEXT": "Ein effizienter Algorithmus zum Sortieren mit minimalem Speicherplatz (Algorithmus 347 $M1))"}
{"DOCID": "1981", "TEXT": "Normalkurvenintegral (Algorithmus 304 $S15))"}
{"DOCID": "1982", "TEXT": "Modifizierte Havie-Integration (Algorithmus 400 $D1))"}
{"DOCID": "1983", "TEXT": "Spanning Tree $H) (Algorithmus 399)"}
{"DOCID": "1984", "TEXT": "Tabellenlose Datumsumwandlung $Z) (Algorithmus 398)"}
{"DOCID": "1985", "TEXT": "Ein ganzzahliges Programmierproblem $H) (Algorithmus 397)"}
{"DOCID": "1986", "TEXT": "Student's t-Quantile $S14) (Algorithmus 396)"}
{"DOCID": "1987", "TEXT": "Studentische t-Verteilung $S14) (Algorithmus 395)"}
{"DOCID": "1988", "TEXT": "Ein Formalismus für Übersetzer-Interaktionen: Es wird ein Formalismus vorgestellt, um die Aktionen von Prozessoren für Programmiersprachen – Compiler, Interpreter, Assembler – und ihre Interaktionen in komplexen Systemen wie Compiler-Compiler oder erweiterbaren Sprachen zu beschreiben. Der Formalismus hier könnte verwendet werden, um eine Frage wie \"Kann man Bootstrapping mit einem Meta-Compiler durchführen, dessen Metaphase interpretierend ist?\" zu definieren und zu beantworten. Zusätzlich wird ein Algorithmus vorgestellt, um zu entscheiden, ob ein gegebenes System aus einem gegebenen Satz von Komponentenprozessoren hergestellt werden kann oder nicht."}
{"DOCID": "1989", "TEXT": "Übergangsnetzwerk-Grammatiken für die Analyse natürlicher Sprache: Die Verwendung von erweiterten Übergangsnetzwerk-Grammatiken für die Analyse von Sätzen natürlicher Sprache wird beschrieben. Strukturbildende Aktionen, die mit den Bögen des Grammatiknetzwerks verbunden sind, ermöglichen das Neuordnen, Umstrukturieren und Kopieren von Bestandteilen, die erforderlich sind, um Tiefenstrukturdarstellungen des Typs zu erzeugen, der normalerweise aus einer Transformationsanalyse erhalten wird, und Bedingungen an den Bögen ermöglichen eine starke Selektivität die bedeutungslose Analysen ausschließen und semantische Informationen nutzen können, um das Parsing zu leiten. Die Vorteile dieses Modells für die Analyse natürlicher Sprache werden ausführlich diskutiert und anhand von Beispielen veranschaulicht. Eine Implementierung eines experimentellen Analysesystems für Übergangsnetzwerkgrammatiken wird kurz beschrieben."}
{"DOCID": "1990", "TEXT": "Numerische Konstanten (Algorithmus)"}
{"DOCID": "1991", "TEXT": "Über die Anzahl der Automorphismen eines einzeln erzeugten Automaten"}
{"DOCID": "1992", "TEXT": "Kommentar zur quadratischen Quotientenmethode von Bell für die Hash-Code-Suche"}
{"DOCID": "1993", "TEXT": "Reguläre Coulomb-Wellenfunktionen (Algorithmus 292 $S22))"}
{"DOCID": "1994", "TEXT": "Entscheidungstabellenübersetzung $H) (Algorithmus 394)"}
{"DOCID": "1995", "TEXT": "Spezielle Reihensummierung mit beliebiger Genauigkeit $C6) (Algorithmus 393)"}
{"DOCID": "1996", "TEXT": "Systeme hyperbolischer PDE $D3) (Algorithmus 392)"}
{"DOCID": "1997", "TEXT": "Steigerung der Effizienz von Quicksort: Es wird eine Methode zur Analyse verschiedener Verallgemeinerungen von Quicksort vorgestellt. Die durchschnittliche asymptotische Anzahl benötigter Vergleiche wird als log^2(n) angegeben. Es wird eine Formel abgeleitet, die a als Wahrscheinlichkeitsverteilung der \"Grenze\" einer Partition ausdrückt. Diese Formel nimmt eine besonders einfache Form für eine bereits von Hoare betrachtete Verallgemeinerung an, nämlich die Wahl der Schranke als Median einer Zufallsstichprobe. Der Hauptbeitrag dieses Papiers ist eine weitere Verallgemeinerung von Quicksort, die ein Begrenzungsintervall anstelle eines einzelnen Elements als Begrenzung verwendet. Diese Verallgemeinerung erweist sich als einfach in einem Computerprogramm zu implementieren. Eine numerische Näherung zeigt, dass a = 1,140 für diese Version von Quicksort im Vergleich zu 1,386 für das Original. Dies impliziert einen Rückgang der Vergleichszahlen um 18 Prozent; Tatsächliche Tests zeigten etwa 15 Prozent Einsparung an Rechenzeit."}
{"DOCID": "1998", "TEXT": "Komplexe Matrixinversion versus Real: Es wird ein Vergleich der komplexen Matrix mit der reellen Matrixinversion durchgeführt. Es wird gezeigt, dass die komplexe Inversion bis zu doppelt so schnell sein kann wie die reale Inversion. Ferner beträgt der für die komplexe Inversion gebundene Rundungsfehler etwa ein Achtel des reellen Fehlers für die Gaußsche Eliminierung. Unter Verwendung der erweiterten inneren Produktakkumulation ist die Schranke die Hälfte des realen Systems."}
{"DOCID": "1999", "TEXT": "Optimale Startnäherungen zum Erzeugen der Quadratwurzel für langsame oder keine Division: Auf Maschinen mit langsamer oder keiner Division ist es vorzuziehen, ein iteratives Schema für die Quadratwurzel zu verwenden, das sich von dem klassischen Heron-Schema unterscheidet. Das Problem optimaler anfänglicher Näherungen wird betrachtet, und einige optimale polynomische anfängliche Näherungen werden tabelliert."}
{"DOCID": "2000", "TEXT": "Eine Variation der Goodman-Lance-Methode zur Lösung von Zweipunkt-Grenzwertproblemen: Eine kürzlich veröffentlichte Methode zur interpolativen Lösung nichtlinearer Gleichungen wird verbessert und angewendet, um eine signifikante Variation der Goodman-Lance-Methode zur Lösung von zu erhalten Zweipunkt-Randwertprobleme. Das resultierende Verfahren gilt insbesondere für die numerische Lösung von Optimalsteuerungsproblemen in der Euler-Lagrange-Formulierung. Es werden quantitative Schätzungen vorgelegt, die darauf hindeuten, dass die Variation bei einigen Problemen im letzteren Kontext fast doppelt so schnell ist."}
{"DOCID": "2001", "TEXT": "Integrieren von Quadratwurzeln: Differentialgleichungen von (y')^2 = f(y) sind aufgrund der Singularität an Punkten, an denen f(y) verschwindet, numerisch schwer zu integrieren. Ein einfacher Trick beseitigt die Singularität."}
{"DOCID": "2002", "TEXT": "AMESPLOT-A Higher Level Data Plotting Software System: AMESPLOT ist ein erweiterbares Softwaresystem, das entwickelt wurde, um die Anzeige von Daten so einfach, schmerzlos und ordentlich wie möglich zu machen. Das beschriebene System ist Hardware-unabhängig und wurde auf einer Vielzahl von Installationen unterschiedlicher Hersteller mit unterschiedlichen Konfigurationen implementiert. Die Elemente, die allen Arten von Datenplots gemeinsam sind, werden umrissen und die Art und Weise gezeigt, wie diese Elemente zu einem System kombiniert werden können, das auf einfachen Modulen basiert. Diese Module werden unabhängig spezifiziert und sind unabhängig von den Achsensystemen oder anderen Attributen des Diagramms. Dadurch können beliebig komplexe Plots durch Hinzufügen oder Ersetzen von Modulen erstellt werden. Die grundlegende Syntax von AMESPLOT wird skizziert, und es wird eine kurze Beschreibung seiner aktuellen Hilfssoftware gegeben, die aus \"Makros\" zum Erzeugen von selbstskalierten Plots, formellen Texttafeln mit durchsetzten Subplots, Kartenküsten und 3-D-Plots besteht. Das System wurde so formuliert, dass der Benutzer ein Minimum an Informationen bereitstellen konnte, und es sollte vollständig in das Benutzerprogramm integrierbar sein, das in den meisten herkömmlichen höheren Sprachen geschrieben ist. Die Funktionen des Positionierens, Lokalisierens und Skalierens (im Layout mehrerer Teilplots) von Achsen, Beschriftungen und allen anderen Elementen des Plots werden automatisch vom Softwaresystem gehandhabt, sofern der Benutzer nichts anderes angibt. Die Strukturierung von Parzellen aus mehreren unabhängigen, in sich geschlossenen Teilparzellen wird beschrieben. Transformation, Projektion, Skalierung, Rotation oder Verschiebung ganzer Plots oder Subplots durch die Wirkung eines oder mehrerer einfacher Module ist möglich. Der Benutzer kann auf drei Ebenen frei mit AMESPLOT interagieren, was es ihm ermöglicht, seine eigenen Datenmarkierungen, Buchstaben und Transformationen zu konstruieren und eine Vielzahl von künstlerischen und anderen Effekten zu erzeugen."}
{"DOCID": "2003", "TEXT": "Ein interaktives Softwaresystem für computergestütztes Design: Eine Anwendung für das Schaltungsprojekt: Die Eigenschaften eines interaktiven Softwaresystems, das während verschiedener Schritte des Designprozesses eine Schnittstelle zwischen Designer und Computer darstellen soll, werden vorgestellt. Der Schwerpunkt liegt auf der Beschreibung der Merkmale der beiden benutzerorientierten Hochsprachen, die auf unterschiedlichen Ebenen operieren und auf denen die Interaktion basiert. Die erste ist IMOL, eine interaktive Monitorsprache, die entwickelt wurde, um die Gesamt- und Steuerfunktionen des Softwaresystems auszuführen; Seine Entwurfskriterien liefern dem Benutzer Befehle, die sowohl einfach als auch effizient sind, um alle Funktionen auszuführen, die beim computergestützten Schaltungsentwurf benötigt werden. Die zweite ist COIF, eine schaltungsorientierte Grafiksprache, die entwickelt wurde, um grafische Problemspezifikationen zu beschreiben, zu erzeugen und zu manipulieren; es ist eine Erweiterung von Fortran mit grafikartigen Variablen, so dass der Designer, der mit Fortran vertraut ist, keine neue Sprache lernen muss. Insbesondere wird die Anwendung auf den computergestützten Schaltungsentwurf untersucht; Andererseits bieten die angenommenen Entwurfskriterien eine ausreichende Allgemeingültigkeit, um die Verwendung der beiden Sprachen auf verschiedene computergestützte Anwendungen auszudehnen."}
{"DOCID": "2004", "TEXT": "Ein Verfahren zur Erzeugung von dreidimensionalen Halbton-Computergraphikdarstellungen: Es wird eine Beschreibung eines Algorithmus zur Erzeugung von computererzeugten Halbtondarstellungen von dreidimensionalen polygonalen Oberflächenstrukturen gegeben. Dieser Algorithmus erzielt gegenüber dem Warnock-Algorithmus, der an der University of Utah entwickelt und auch auf dem Computersystem CDC 1604 des Coordinated Science Laboratory an der University of Illinois implementiert wurde, eine signifikante Steigerung der Rechengeschwindigkeit. Die Geschichte, die zur Algorithmusentwicklung führte, und dann der Algorithmus selbst werden beschrieben. Die Ergebnisse werden präsentiert und mit Computerläufen verglichen, die durch den Warnock-Ansatz erreicht wurden. Eine Erweiterung des Verfahrens auf ortsveränderliche Beleuchtungsquellen ist ebenfalls gegeben."}
{"DOCID": "2005", "TEXT": "Vorgeschlagene Überarbeitung des American National Standard X3.21-1967, „Rechteckige Löcher in zwölfreihigen Lochkarten“*"}
{"DOCID": "2006", "TEXT": "Vorgeschlagener amerikanischer Nationalstandard"}
{"DOCID": "2007", "TEXT": "Algorithmenrichtlinie/überarbeitet August 1970"}
{"DOCID": "2008", "TEXT": "Gaußsche Quadraturformeln (Algorithmus 331 $D1))"}
{"DOCID": "2009", "TEXT": "Simpson-Regel für multiple Integration (Algorithmus 233 $D1))"}
{"DOCID": "2010", "TEXT": "Unitäre symmetrische Polynome $Z) (Algorithmus 391)"}
{"DOCID": "2011", "TEXT": "Sequenzgeordnete Walsh-Funktionen $S22) (Algorithmus 390)"}
{"DOCID": "2012", "TEXT": "Binär geordnete Walsh-Funktionen $S22) (Algorithmus 389)"}
{"DOCID": "2013", "TEXT": "Rademacher-Funktion $S22) (Algorithmus 388)"}
{"DOCID": "2014", "TEXT": "Funktionsminimierung und lineare Suche $E4) (Algorithmus 387)"}
{"DOCID": "2015", "TEXT": "Eine Technik zum Erzeugen fast optimaler Floyd-Evans-Produktionen für Präzedenzgrammatiken: Es wird eine Technik entwickelt zum Erzeugen nahezu optimaler Floyd-Evans-Produktionen, wenn eine Präzedenzgrammatik gegeben ist. Für das Problem der Zusammenführung von Produktionen wird eine Graphenformulierung verwendet. Die erzeugten Produktionen entsprechen der inversen Arboreszenz der minimalen Kosten dieses Graphen. Die Gültigkeit der Technik wird für hier definierte Grammatiken mit schwacher Präzedenz demonstriert, aber die für jede Präzedenzgrammatik mechanisch erzeugten Produktionen können oft so modifiziert werden, dass korrekte, fast optimale Parser erhalten werden."}
{"DOCID": "2016", "TEXT": "Die Instrumentierung von Multics: Eine Reihe von Messwerkzeugen, die entwickelt wurden, um bei der Implementierung eines Prototyp-Computerdienstprogramms zu helfen, wird diskutiert. Zu diesen Werkzeugen gehören spezielle Hardwareuhren und Datenkanäle, für allgemeine Zwecke programmierte Prüf- und Aufzeichnungswerkzeuge und spezialisierte Messeinrichtungen. Einige besondere interessierende Messungen in einem System, das Bedarfsruf mit Mehrfachprogrammierung kombiniert, werden im Detail beschrieben. Gegebenenfalls wird ein Einblick in die Wirksamkeit (oder deren Fehlen) einzelner Instrumente gegeben."}
{"DOCID": "2017", "TEXT": "Sortieren in einer Paging-Umgebung: Diese Sortierstudie war Teil eines umfangreichen Messprojekts, das am M44/44X durchgeführt wurde, einem experimentellen Paging-System, das bei IBM Research konzipiert und implementiert wurde, um das Konzept der virtuellen Maschine zu untersuchen. Die Studie befasste sich mit der Implementierung von Sortierverfahren im Kontext der für virtuelle Speichermaschinen charakteristischen dynamischen Paging-Umgebung. Es werden Beschreibungen der experimentellen Sortierprogramme und die Analyse der für sie erhaltenen Ergebnisse der Leistungsmessung vorgestellt. Die aus den experimentellen Bemühungen gewonnenen Erkenntnisse werden verwendet, um zu einer Reihe allgemeiner Richtlinien zum Schreiben von Sortierprogrammen für eine Paging-Umgebung zu gelangen."}
{"DOCID": "2018", "TEXT": "Quadratische Volltabellensuche für Streuspeicherung: Das quadratische Restsuchverfahren für Hash-Tabellen vermeidet einen Großteil der Clusterbildung, die bei einem linearen Suchverfahren auftritt. Die einfache quadratische Suche greift nur auf die halbe Tabelle zu. Es wurde gezeigt, dass, wenn die Länge der Tabelle eine Primzahl der Form 4n+3 ist, wobei n eine ganze Zahl ist, auf die gesamte Tabelle durch zwei quadratische Suchen plus einem separaten Zugriff für den ursprünglichen Einstiegspunkt zugegriffen werden kann. Es wird ein Suchverfahren vorgestellt, das rechnerisch einfach ist, alle Vorteile der quadratischen Suche hat und dennoch auf die gesamte Tabelle in einem Durchlauf zugreift."}
{"DOCID": "2019", "TEXT": "Normalisierungstechniken für handgedruckte Ziffern: Eine Familie von Musterstandardisierungstechniken, die auf geometrischer Projektion basieren, wird auf eine Datei von digitalisierten handgedruckten Ziffern angewendet, die von Verkäufern erhalten werden. Das Prinzip besteht darin, ein durch die konvexe Hülle jedes Musters spezifiziertes Viereck in ein Quadrat umzuwandeln. Der Betrag der Überlappung innerhalb jeder Klasse von Zeichen gegenüber dem Betrag zwischen den Klassen wird verwendet, um den Grad der Normalisierung zu bewerten, der in Bezug auf andere veröffentlichte Verfahren erreicht wird, einschließlich Größen- und Schernormalisierung durch Momente."}
{"DOCID": "2020", "TEXT": "Die Zuweisung von Computerressourcen – ist die Preisgestaltung die Antwort?: Die weit verbreitete Verwendung komplexer Computersysteme der dritten Generation hat zu einer viel breiteren Besorgnis über die Mittel geführt, mit denen die Ressourcen dieser Systeme in der Benutzergemeinschaft zugewiesen werden. Ein Mittel, das immer häufiger vorgeschlagen wird, ist ein Preisfindungsverfahren. In diesem Beitrag wird die Art und Weise betrachtet, wie man Computerressourcen zuweisen möchte, und dann wird diskutiert, inwieweit ein Preismechanismus in diese Form passt. Da die Preisgestaltung zeitweise als Rationierungsmechanismus dienen muss, wird überlegt, wie Preise flexibel angepasst werden können, um eine dynamische Ressourcenallokation vorzunehmen. Es wird auch überlegt, wie die Benutzer von den schädlichen Auswirkungen häufiger Preisschwankungen isoliert werden können. Obwohl dem Thema Preisgestaltung in letzter Zeit viel Aufmerksamkeit geschenkt wurde, bestehen weiterhin eine Reihe von Missverständnissen über seinen Zweck und seine Funktionsweise. Es wird versucht, einige dieser Missverständnisse aufzuklären und die Vor- und Nachteile aufzuzeigen sowie die Vor- und Nachteile der Preisgestaltung herauszustellen. Zwei beispielhafte Preissysteme werden ebenfalls diskutiert, um die Anwendbarkeit der Preisbildung in ganz unterschiedlichen Umgebungen zu demonstrieren."}
{"DOCID": "2021", "TEXT": "Ein Kommentar zu Axiomatischen Ansätzen zur Programmierung"}
{"DOCID": "2022", "TEXT": "Hinweis zu einer Anomalie beim Paging"}
{"DOCID": "2023", "TEXT": "Eine Anmerkung zu Datenbank-Deadlocks"}
{"DOCID": "2024", "TEXT": "Kommentare zu einem Papier von Lowe"}
{"DOCID": "2025", "TEXT": "Student's t-Verteilung; Jacobi-Polynome; Modifizierte Romberg-Quadratur; Faktorielle Varianzanalyse; (Algorithmen 332.344.351.359)"}
{"DOCID": "2026", "TEXT": "Exponentialintegral (Algorithmus 385 $S13))"}
{"DOCID": "2027", "TEXT": "Ricatti-Bessel-Funktionen erster und zweiter Art (Algorithmus 22 $S17))"}
{"DOCID": "2028", "TEXT": "Größter gemeinsamer Teiler von n ganzen Zahlen und Multiplikatoren $A1) (Algorithmus 386)"}
{"DOCID": "2029", "TEXT": "Exponentialintegral $S13) (Algorithmus 385)"}
{"DOCID": "2030", "TEXT": "Kontextsensitives Parsing: Dieses Papier stellt eine kanonische Form für kontextsensitive Ableitungen und einen Parsing-Algorithmus vor, der jede kontextsensitive Analyse einmal und nur einmal findet. Die vom Algorithmus benötigte Speichermenge ist im Wesentlichen nicht größer als die zum Speichern einer einzelnen vollständigen Ableitung erforderliche. Außerdem wird eine modifizierte Version des Basisalgorithmus vorgestellt, die unendliche Analysen für Grammatiken blockiert, die Schleifen enthalten. Der Algorithmus wird auch mit mehreren früheren Parsern für kontextsensitive Grammatiken und allgemeine Umschreibungssysteme verglichen, und der Unterschied zwischen den beiden Arten von Analysen wird diskutiert. Der Algorithmus scheint in mehrfacher Hinsicht komplementär zu einem Algorithmus von S. Kuno zu sein, einschließlich des Raum-Zeit-Kompromisses und des Ausmaßes der beteiligten Kontextabhängigkeit."}
{"DOCID": "2031", "TEXT": "Algorithmus und Schranke für den größten gemeinsamen Teiler von n ganzen Zahlen: Eine neue Version des euklidischen Algorithmus zum Finden des größten gemeinsamen Teilers von n ganzen Zahlen a(i) und Multiplikatoren x(i), so dass ggT = x(1)a(1) + ... + x(n)a(n) wird präsentiert. Die Anzahl der Rechenoperationen und die Anzahl der Speicherplätze sind linear in n. Ein Satz von Lame, der eine Grenze für die Anzahl der Iterationen des euklidischen Algorithmus für zwei ganze Zahlen angibt, wird auf den Fall von n ganzen Zahlen erweitert. Ein Algorithmus zum Konstruieren eines minimalen Satzes von Multiplikatoren wird vorgestellt. Ein Fortran-Programm für den Algorithmus erscheint als Comm. ACM-Algorithmus 386."}
{"DOCID": "2032", "TEXT": "Dateistrukturen unter Verwendung von Hash-Funktionen: Es wird ein allgemeines Verfahren zur Dateistrukturierung vorgeschlagen, das eine Hash-Funktion verwendet, um eine Baumstruktur zu definieren. Zwei Arten solcher Bäume werden untersucht und ihre Beziehung zu früher untersuchten Bäumen erläutert. Ergebnisse für die Wahrscheinlichkeitsverteilungen von Weglängen werden hergeleitet und dargestellt."}
{"DOCID": "2033", "TEXT": "Platz/Zeit-Kompromisse bei der Hash-Codierung mit zulässigen Fehlern: In diesem Artikel werden Kompromisse zwischen bestimmten Berechnungsfaktoren und einem bestimmten Satz von Nachrichten gemacht. Zwei neue Hash-Codierungsverfahren werden untersucht und mit einem bestimmten herkömmlichen Hash-Codierungsverfahren verglichen. Die berücksichtigten Berechnungsfaktoren sind die Größe des Hash-Bereichs (Raum), die Zeit, die erforderlich ist, um eine Nachricht als kein Mitglied der gegebenen Menge zu identifizieren (Zurückweisungszeit) und eine zulässige Fehlerhäufigkeit. Die neuen Verfahren sollen den Platzbedarf für die hashcodierten Informationen gegenüber herkömmlichen Verfahren verringern. Die Reduzierung des Speicherplatzes wird erreicht, indem die Möglichkeit ausgenutzt wird, dass ein kleiner Bruchteil von Kommissionsfehlern in einigen Anwendungen tolerierbar sein kann, insbesondere in Anwendungen, in denen eine große Datenmenge involviert ist und ein kernresidenter Hash-Bereich folglich bei herkömmlicher Verwendung nicht realisierbar ist Methoden. Bei solchen Anwendungen wird in Betracht gezogen, dass die Gesamtleistung verbessert werden könnte, indem ein kleinerer kernresidenter Hash-Bereich in Verbindung mit den neuen Verfahren verwendet wird und, falls erforderlich, ein sekundärer und möglicherweise zeitaufwändiger Test verwendet wird, um den kleinen Bruchteil davon zu \"fangen\". Fehler im Zusammenhang mit neuen Methoden. Es wird ein Beispiel diskutiert, das mögliche Anwendungsgebiete der neuen Methoden verdeutlicht. Die Analyse des Paradigmenproblems zeigt, dass es ermöglicht wird, dass eine kleine Anzahl von Testnachrichten fälschlicherweise als Mitglieder des gegebenen Satzes identifiziert werden, dass ein viel kleinerer Hash-Bereich verwendet werden kann, ohne die Zurückweisungszeit zu erhöhen."}
{"DOCID": "2034", "TEXT": "Das mobile Programmiersystem: STAGE2: STAGE2 ist die zweite Ebene einer Bootstrap-Sequenz, die einfach auf jedem Computer implementiert werden kann. Es ist eine flexible, von STAGE2 bereitgestellte Lösung, die zusammengefasst wird, und die Implementierungstechniken, die es möglich gemacht haben, STAGE2 auf einer neuen Maschine mit weniger als einer Arbeitswoche zum Laufen zu bringen, werden diskutiert. Der Ansatz war auf über 15 Maschinen mit sehr unterschiedlichen Eigenschaften erfolgreich."}
{"DOCID": "2035", "TEXT": "Konversationszugriff auf eine 2048-Wörter-Maschine: LAP6 ist ein Online-System, das auf einem 2048-Wörter-LINC läuft und vollständige Einrichtungen für die Textbearbeitung, die automatische Ablage und Dateipflege sowie die Programmvorbereitung und -zusammenstellung bietet. Es konzentriert sich auf die Vorbereitung und Bearbeitung von fortlaufend angezeigten Textfolgen (Manuskripten) mit 23.040 Zeichen, die vom Benutzer beliebig positioniert und durch einfaches Hinzufügen und Löschen von Zeilen bearbeitet werden können, als würde man direkt auf einer elastischen Schriftrolle arbeiten. Weitere Funktionen sind über einen einheitlichen Befehlssatz verfügbar, der selbst vom Benutzer erweitert werden kann. Obwohl die Maschine klein ist, unterstützt sie das Programmdesign, indem sie einen Anzeigebereich und vormarkierte wahlfrei adressierbare LINC-Bänder als Standardelemente in einer Umgebung bereitstellt, die der eines hochentwickelten Terminals ähnelt. Die Bänder sind logisch einer Platte ähnlich. Priorität wurde dem Entwurf effizienter Bandalgorithmen eingeräumt, um die Beschränkungen des kleinen Speichers zu minimieren. Techniken, die für den Umgang mit Scroll-Editierung, Archivierung und der geschichteten Systemstruktur entwickelt wurden, werden skizziert. LAP6 wird von etwa 2000 Personen in 11 Ländern verwendet. Sein Design wurde stark von Leistungskriterien beeinflusst, die in Interviews mit LINC-Benutzern selbst während des Spezifikationszeitraums festgelegt wurden."}
{"DOCID": "2036", "TEXT": "Eine Einrichtung zur Generierung interaktiver Befehle: Es wird eine Einrichtung vorgeschlagen, um zu ermöglichen, dass konversationsgesteuerte Aufgaben in einer nicht interaktiven Umgebung ausgeführt werden. Es wird ein Mittel vorgestellt, mit dem Programme interaktive Timesharing-Befehle erzeugen und die entsprechende Ausgangsantwort empfangen können. Die Befehle werden so aufgerufen, als ob sie auf einer Konsolentastatur eingegeben worden wären. Es wird argumentiert, dass diese Einrichtung dazu beitragen wird, einige der derzeitigen Beschränkungen in der Mensch-Computer-Kommunikation zu überwinden. Es wird ein Satz von Funktionen vorgeschlagen, um das Obige zu erreichen, die in jede Zeichenketten-Verarbeitungssprache eingebettet werden könnten, und es werden notwendige Informationen gegeben, die für die Implementierung der Einrichtung in bestehenden Time-Sharing-Systemen relevant sind."}
{"DOCID": "2037", "TEXT": "Permutationen einer Menge mit Wiederholungen (Algorithmus 383 $G6))"}
{"DOCID": "2038", "TEXT": "Kombinationen von M aus N Objekten (Algorithmus 382 $G6))"}
{"DOCID": "2039", "TEXT": "Permanente Funktion einer quadratischen Matrix I und II (Algorithmus 361 $G6))"}
{"DOCID": "2040", "TEXT": "Modifizierte Romberg-Quadratur (Algorithmus 351 $D1))"}
{"DOCID": "2041", "TEXT": "Shellsort (Algorithmus 201 $M1))"}
{"DOCID": "2042", "TEXT": "Treesort 3 (Algorithmus 245 $M1)): Die Zertifizierung eines Algorithmus kann in Form eines Beweises erfolgen, dass der Algorithmus korrekt ist. Als veranschaulichendes, aber praktisches Beispiel hat sich der Algorithmus 245, TREESORT 3 zum Sortieren eines Arrays als richtig erwiesen."}
{"DOCID": "2043", "TEXT": "Eigenwerte und Eigenvektoren einer reellen symmetrischen Matrix $F2) (Algorithmus 384)"}
{"DOCID": "2044", "TEXT": "Permutationen einer Menge mit Wiederholungen (Algorithmus 383 $G6))"}
{"DOCID": "2045", "TEXT": "Kombinationen von M aus N Objekten (Algorithmus 382 $G6))"}
{"DOCID": "2046", "TEXT": "Ein relationales Datenmodell für große gemeinsam genutzte Datenbanken: Zukünftige Benutzer großer Datenbanken müssen davor geschützt werden, wissen zu müssen, wie die Daten in der Maschine organisiert sind (die interne Repräsentation). Ein Aufforderungsdienst, der solche Informationen liefert, ist keine zufriedenstellende Lösung. Aktivitäten von Benutzern an Endgeräten und den meisten Anwendungsprogrammen sollten unberührt bleiben, wenn die interne Darstellung von Daten geändert wird und selbst wenn einige Aspekte der externen Darstellung geändert werden. Änderungen in der Datendarstellung werden oft als Folge von Änderungen im Abfrage-, Aktualisierungs- und Berichtsverkehr und natürlichem Wachstum der Arten gespeicherter Informationen erforderlich sein. Existierende nicht-inferentielle, formatierte Datensysteme stellen Benutzern baumstrukturierte Dateien oder etwas allgemeinere Netzwerkmodelle der Daten bereit. In Abschnitt 1 werden Unzulänglichkeiten dieser Modelle diskutiert. Ein auf n-stelligen Beziehungen basierendes Modell, eine Normalform für Datenbankbeziehungen und das Konzept einer universellen Form für Datenbankbeziehungen und das Konzept einer universellen Datenuntersprache werden eingeführt. In Abschnitt 2 werden bestimmte Operationen auf Beziehungen (außer logischer Inferenz) diskutiert und auf die Probleme der Redundanz und Konsistenz im Benutzermodell angewendet."}
{"DOCID": "2047", "TEXT": "Einbau von Ursprungsverschiebungen in den QR-Algorithmus für symmetrische tridiagonale Matrizen: Die QR-Iteration für die Eigenwerte einer symmetrischen tridiagonalen Matrix kann beschleunigt werden, indem eine Folge von Ursprungsverschiebungen eingebaut wird. Die Ursprungsverschiebung kann entweder direkt von den Diagonalelementen der Matrix subtrahiert oder mittels eines impliziten Algorithmus eingebaut werden. Beide Verfahren haben Nachteile: Das direkte Verfahren kann kleine Eigenwerte unnötig verschlechtern, während das implizite Verfahren die Verschiebung effektiv verlieren und dadurch die Konvergenz verzögern kann. Dieses Papier stellt eine neue Methode vor, die keine Nachteile hat."}
{"DOCID": "2048", "TEXT": "Vergleich mehrerer adaptiver Newton-Cotes-Quadraturroutinen bei der Bewertung bestimmter Integrale mit Spitzen-Integranden: Dieser Bericht vergleicht die Leistung von fünf verschiedenen adaptiven Quadraturschemata, basierend auf Newton-Cotes (2N + 1)-Punktregeln (N = 1, 2, 3, 4, 5), bei der Approximation der Menge bestimmter Integrale INTEGRAL$1/(x^2 + p^2)) dx mit relativer Genauigkeit e."}
{"DOCID": "2049", "TEXT": "Genaue Fließkomma-Summierung: Dieses Dokument beschreibt eine alternative Methode zum Summieren einer Reihe von Fließkommazahlen. Ein Vergleich der Fehlergrenze für dieses Verfahren mit dem des Standard-Summierungsverfahrens zeigt, dass es erheblich weniger empfindlich gegenüber der Ausbreitung von Rundungsfehlern ist."}
{"DOCID": "2050", "TEXT": "Automatisches Parsing für die Inhaltsanalyse: Obwohl eine automatische syntaktische und semantische Analyse noch nicht für den gesamten uneingeschränkten Text in natürlicher Sprache möglich ist, haben einige Anwendungen, zu denen die Inhaltsanalyse gehört, keine so strenge Abdeckungsanforderung. Vorläufige Studien zeigen, dass der Harvard Syntactic Analyzer für ungefähr die Hälfte der relevanten Vorkommen eine korrekte und eindeutige Identifizierung von Subjekt und Objekt bestimmter Verben liefern kann. Dies bietet einen Abdeckungsgrad für Variablen der Inhaltsanalyse, die im Vergleich zu manuellen Methoden günstig sind, bei Variablen, die im Vergleich zu manuellen Methoden günstig sind, bei denen normalerweise nur eine Stichprobe des gesamten verfügbaren Textes verarbeitet wird."}
{"DOCID": "2051", "TEXT": "Ein PL/I-Programm zur Unterstützung des Komparativlinguisten: Es wird ein praktisches PL/I-Programm beschrieben, das Komparativlinguisten dabei unterstützen kann, die regulären Lautkorrespondenzen zwischen genetisch verwandten Sprachen zu bestimmen. Der Ermittler muss die Daten für die Eingabe arrangieren, indem er Paare mutmaßlicher Verwandter aneinanderreiht. Das Programm tabelliert die Korrespondenzen und verwendet Listenverarbeitungstechniken, um sie zu sortieren und zu zählen. Jedem Wortpaar wird dann ein relativer Wert zugewiesen, der eine Funktion der Gesamthäufigkeit in den Daten jeder Korrespondenz ist, die in diesem Wortpaar gefunden wird. Die Ausgabe ist eine Liste aller Entsprechungstypen mit ihrer Häufigkeit des Auftretens in den Daten und eine separate Auflistung jeder Entsprechung mit allen Wortpaaren, die diese Entsprechung zeigen (es sei denn, ihr relativer Wert liegt unter einem willkürlich gewählten Grenzwert). Der Artikel erläutert die Nützlichkeit sowie die Einschränkungen der Programme und veranschaulicht ihre Verwendung anhand eines kleinen Teils hypothetischer Daten."}
{"DOCID": "2052", "TEXT": "Planung zur Reduzierung von Konflikten in Besprechungen: Konflikte bei der Planung können so behandelt werden, als würden sie einen ungerichteten linearen Graphen definieren, unabhängig von der Beziehung der konfliktbehafteten Aktivitäten zu zusätzlichen zeitlichen und räumlichen Beschränkungen. Jede verbundene Komponente eines solchen Graphen, die durch einen von Gotlieb und Corneil beschriebenen Algorithmus gefunden werden kann, entspricht einer Reihe von Ereignissen, die zu unterschiedlichen Zeiten geplant werden müssen."}
{"DOCID": "2053", "TEXT": "Über die Umwandlung von Entscheidungstabellen in Computerprogramme: Die Verwendung von Ausführungszeitdiagnosen zum Auffinden von Mehrdeutigkeiten in Entscheidungstabellen wird diskutiert. Es wird darauf hingewiesen, dass jeder Versuch, Mehrdeutigkeiten zur Kompilierzeit aufzulösen, im Allgemeinen unmöglich sein wird. Es wird gezeigt, dass folglich Baumverfahren zum Konvertieren von Entscheidungstabellen in Programme hinsichtlich der Mehrdeutigkeitserkennung unzureichend sind. Es werden zwei Algorithmen zum Programmieren von Entscheidungstabellen vorgestellt, deren Vorzüge die Einfachheit der Implementierung und die Erkennung von Mehrdeutigkeiten zur Ausführungszeit sind. Der erste Algorithmus gilt für Entscheidungstabellen mit begrenztem Eintrag und verdeutlicht die Wichtigkeit der richtigen Codierung der Informationen in der Entscheidungstabelle. Der zweite Algorithmus programmiert eine Entscheidungstabelle für gemischte Einträge direkt, ohne den Zwischenschritt der Umwandlung in eine begrenzte Eintragsform zu durchlaufen, was zu einer Einsparung von Speicherplatz führt. Es wird ein Vergleich der Algorithmen und anderer in der Literatur vorgeschlagener durchgeführt. Einige Merkmale einer von den Autoren entwickelten Entscheidungstabelle zum Fortran IV-Übersetzer für den IBM 7044 werden angegeben."}
{"DOCID": "2054", "TEXT": "Über die Machbarkeit der Spracheingabe in ein Online-Computerverarbeitungssystem: Es wird ein digitales Online-Computerverarbeitungssystem betrachtet, bei dem ein gewöhnliches Telefon das vollständige Endgerät ist, wobei die Eingabe in den Computer als Folge gesprochener Wörter bereitgestellt wird, und Ausgabe an den Benutzer in Form von Audioantworten von der Maschine. Die Durchführbarkeit der Implementierung eines solchen Systems mit einem FORTRAN-ähnlichen algebraischen Compiler als Objektprozessor wird in Betracht gezogen. Details eines bestimmten Worterkennungsprogramms werden angegeben. Diese Technik hängt von drei vereinfachenden Beschränkungen ab, nämlich einem \"kleinen\" Vokabularsatz, \"bekannten\" Sprechern und einem \"Moment der Stille\" zwischen jedem eingegebenen Wort. Es werden experimentelle Ergebnisse präsentiert, die Fehlerraten für verschiedene experimentelle Bedingungen sowie die Maschinenressourcen angeben, die erforderlich sind, um mehreren Benutzern gleichzeitig gerecht zu werden. Die Ergebnisse zeigen, dass es derzeit sowohl wirtschaftlich als auch logisch machbar ist, mindestens 40 Benutzer gleichzeitig mit einem IBM 360/65-Computer zu bedienen."}
{"DOCID": "2055", "TEXT": "Subroutine zum Durchführen einer In-situ-Transposition einer rechteckigen Matrix (Algorithmus 380)"}
{"DOCID": "2056", "TEXT": "Gomory (Algorithmus 263A $H))"}
{"DOCID": "2057", "TEXT": "Im Raumwinkel einheitliche Zufallsvektoren (Algorithmus 381 $G5))"}
{"DOCID": "2058", "TEXT": "In-situ-Transposition einer Rechteckmatrix (Algorithmus 380 $F1))"}
{"DOCID": "2059", "TEXT": "Eine Sprache zur Behandlung von Graphen: Eine Sprache zur Darstellung von Graphen wird beschrieben, und die Formulierung von Graphoperationen, wie z. B. Knoten- und/oder Verknüpfungslöschung oder -einfügung, Vereinigung, Schnittmenge, Vergleich und Traversierung von Graphen, wird angegeben. Diagramme werden durch verknüpfte Listen dargestellt. Die Sprache ist syntaktisch als Erweiterung von ALGOL 60 definiert und wird mit Hilfe eines syntaxgesteuerten Compilers in ALGOL übersetzt. Anwendungsgebiete für diese Sprache sind Betriebsforschung, Netzwerkprobleme, Steuerungstheorie, Verkehrsprobleme usw."}
{"DOCID": "2060", "TEXT": "GEDANKEN-Eine einfache typlose Sprache basierend auf dem Prinzip der Vollständigkeit und dem Referenzkonzept: GEDANKEN ist eine experimentelle Programmiersprache mit den folgenden Merkmalen. (1) Jeder Wert, der in irgendeinem Kontext der Sprache erlaubt ist, ist in jedem anderen sinnvollen Kontext erlaubt. Zulässige Ergebnisse von Funktionen und Werten von Variablen sind insbesondere Funktionen und Labels. (2) Zuweisung und indirekte Adressierung werden formalisiert, indem Werte eingeführt werden, Referenz genannt, die wiederum andere Werte besitzen. Die Zuweisungsoperation wirkt sich immer auf die Beziehung zwischen einer Referenz und ihrem Wert aus. (3) Alle zusammengesetzten Datenstrukturen werden als Funktionen behandelt. (4) Typdeklarationen sind nicht zulässig. Der funktionale Ansatz für Datenstrukturen und die Verwendung von Referenzen stellen sicher, dass jeder Prozess, der irgendeine Datenstruktur akzeptiert, jede logisch äquivalente Struktur akzeptiert, unabhängig von ihrer internen Darstellung. Allgemeiner kann jede Datenstruktur implizit sein; d.h. es kann spezifiziert werden, indem ein willkürlicher Algorithmus zum Berechnen oder Zugreifen auf seine Komponenten angegeben wird. Die Existenz von Label-Variablen erlaubt die Konstruktion von Coroutinen, quasi-parallelen Prozessen und anderen unorthodoxen Kontrollmechanismen. Eine Vielzahl von Programmierbeispielen veranschaulicht die Allgemeingültigkeit der Sprache. Einschränkungen und mögliche Erweiterungen werden kurz besprochen."}
{"DOCID": "2061", "TEXT": "Ein Algorithmus für die Konstruktion von Parsern mit begrenztem Kontext: Es wird ein Algorithmus beschrieben, der eine beliebige kontextfreie Grammatik akzeptiert und einen Parser mit begrenztem Kontext dafür konstruiert, wann immer ein solcher Parser existiert. Im ersten Teil der Arbeit wird an die Definition einer kontextfreien Grammatik und die Arbeitsweise eines Bounded-Context-Parsers erinnert. Anschließend wird der Begriff der Reduktionsklasse für eine kontextfreie Grammatik eingeführt und ihr Zusammenhang mit der Struktur eines Parsers mit begrenztem Kontext aufgezeigt. Als nächstes werden Kellerautomaten definiert, die die verschiedenen Reduktionsklassen einer kontextfreien Grammatik erzeugen. Abschließend wird der Algorithmus beschrieben; es führt im Wesentlichen eine erschöpfende Untersuchung aller möglichen Läufe der Kellerautomaten durch, die die Reduktionsklassen erzeugen. Im zweiten Teil wird die Nützlichkeit des Algorithmus im Lichte der Erfahrungen aus seinem Einsatz im Compiler-Design diskutiert. Der Algorithmus gilt als besonders nützlich beim gleichzeitigen Entwurf einer Sprache und eines Compilers dafür."}
{"DOCID": "2062", "TEXT": "Die Anwendung der sequentiellen Stichprobennahme auf die Simulation: Ein beispielhaftes Bestandsmodell: Vier verschiedene sequenzielle Stichprobenverfahren werden auf die Analyse von Daten angewendet, die durch ein Computersimulationsexperiment mit einem Bestandsmodell mit mehreren Artikeln erzeugt wurden. Für jedes Verfahren wird der Rechenzeitaufwand berechnet, der erforderlich ist, um ein bestimmtes Maß an statistischer Genauigkeit zu erreichen. Auch die Kosten für Computerzeit unter Verwendung vergleichbarer Verfahren mit festem Stichprobenumfang werden berechnet. Die Computerkosten von Verfahren mit fester Stichprobengröße und sequentiellen Stichprobenverfahren werden verglichen."}
{"DOCID": "2063", "TEXT": "Übersetzungsgleichungen (Errata)"}
{"DOCID": "2064", "TEXT": "Operationen auf verallgemeinerten Arrays mit dem Genie-Compiler: Operationen auf Vektoren, Matrizen und höherdimensionalen Speicher-Arrays sind heute Standardfunktionen der meisten Compiler. Die Elemente solcher Strukturen sind normalerweise auf Skalare beschränkt. Für viele anspruchsvolle Anwendungen kann diese Einschränkung umständliche Datendarstellungen auferlegen. Es wurde ein effizientes System entwickelt und implementiert, das es den Elementen mehrdimensionaler Arrays ermöglicht, selbst mehrdimensionale Arrays zu sein. Dieses System wurde aus einer Speicherstruktur entwickelt, in der der Ort, die Länge und der Inhalt jedes Arrays durch ein Codewort beschrieben wird, das vom System interpretiert werden kann. Codewörter können Arrays beschreiben, die mehr Codewörter enthalten, wodurch alle erforderlichen beschreibenden Informationen für Hyperstrukturen jeglicher Form bereitgestellt werden."}
{"DOCID": "2065", "TEXT": "Ein Programmiersystem für die Online-Analyse biomedizinischer Bilder: Es wird eine vorläufige Beschreibung der Software für ein Computeranzeigesystem mit besonderem Schwerpunkt auf der Mensch-Maschine-Interaktion gegeben. Dieses System ist für eine Vielzahl von biomedizinischen Anwendungen bestimmt. Beispielsweise werden die Methoden auf die Karyotypisierung von Chromosomen angewendet. Das System ist in vier Programmieraufgaben unterteilt: Bildtransformationen, Dateiverwaltung, Bildstrukturierung und Anzeigeverwaltung. Die Bildstrukturierung gilt als Vehikel der Mensch-Maschine-Kommunikation. Ein Prototyp-Datenformat für Bilder, Bildform genannt, wird entwickelt. Es werden Strukturoperatoren definiert, die Bildformen manipulieren, um neue Bildformen zu erzeugen. Viele der Ideen stammen aus dem symbolischen mathematischen Labor am MIT, das von Marvin Minsky konzipiert wurde."}
{"DOCID": "2066", "TEXT": "Eine Algol-Konstruktion für Prozeduren als Parameter von Prozeduren"}
{"DOCID": "2067", "TEXT": "Kommentar zu Lawlers mehrstufiger boolescher Minimierung"}
{"DOCID": "2068", "TEXT": "Kommentar zu Multiprogramming unter einer Page-on-Demand-Strategie"}
{"DOCID": "2069", "TEXT": "Kommentare zu einem Artikel von Wallace und Mason"}
{"DOCID": "2070", "TEXT": "Ein formelles System zum Abrufen von Informationen aus Dateien"}
{"DOCID": "2071", "TEXT": "Filon-Quadratur (Algorithmus 353 $D1))"}
{"DOCID": "2072", "TEXT": "Modifizierte Romberg-Quadratur (Algorithmus 351 $D1))"}
{"DOCID": "2073", "TEXT": "Lösung linearer Programme in 0-1 Variablen durch implizite Aufzählung (Algorithmus 341 $H))"}
{"DOCID": "2074", "TEXT": "Sqank (Algorithmus 379 $D1))"}
{"DOCID": "2075", "TEXT": "Diskretisiertes Newton-ähnliches Verfahren zum Lösen eines Systems simultaner nichtlinearer Gleichungen (Algorithmus 378 $C5))"}
{"DOCID": "2076", "TEXT": "Kubische Splines auf gleichmäßigen Netzen: Es wird ein sehr einfaches Verfahren zum Konstruieren kubischer Splines, periodisch oder nichtperiodisch, auf gleichmäßigen Netzen vorgestellt. Bögen von zwei Kubikzentimetern genügen, um eine Basis von kardinalen Splines zu konstruieren. Es wird ein Algorithmus angegeben, der nur minimale Speicherung und Berechnung erfordert und ein leichtes Abwägen des einen gegen den anderen ermöglicht."}
{"DOCID": "2077", "TEXT": "Das Problem der zyklischen Mehrheit: Das Problem der zyklischen Mehrheit wird vorgestellt und einige neue, simulierte Ergebnisse für 3, 4, 5, ..., 40 Ausgaben ad 3, 5, 7, ..., 37 Richter werden berichtet."}
{"DOCID": "2078", "TEXT": "Darstellungen für die Raumplanung: Probleme der Anordnung von Objekten im Zwei- oder Dreiraum, bei denen die Zielfunktion hauptsächlich aus Ableitungen der Entfernung zwischen Objekten oder ihrer Anordnung besteht, werden als Raumplanungsprobleme bezeichnet. Die Darstellungsanforderungen für dieses Problemfeld werden definiert und mit aktuellen Computergrafiksprachen verglichen. Vier alternative Datenstrukturen, die eine automatisierte Raumplanung ermöglichen, werden beschrieben und verglichen."}
{"DOCID": "2079", "TEXT": "Über Multiprogramming, Maschinencodierung und Computerorganisation"}
{"DOCID": "2080", "TEXT": "Der Kern eines Multiprogramming-Systems: Dieses Dokument beschreibt die Philosophie und Struktur eines Multiprogramming-Systems, das um eine Hierarchie von Betriebssystemen erweitert werden kann, um verschiedenen Anforderungen der Programmplanung und Ressourcenzuweisung gerecht zu werden. Der Systemkern simuliert eine Umgebung, in der Programmausführung und Ein-/Ausgabe einheitlich als parallele, kooperierende Prozesse behandelt werden. Ein grundlegender Satz von Primitiven ermöglicht die dynamische Erstellung und Steuerung einer Hierarchie von Prozessen sowie die Kommunikation zwischen ihnen."}
{"DOCID": "2081", "TEXT": "Einige vollständige Kalküle für Matrizen: Ein Matrizenkalkül wird mit der Absicht eingeführt, Datenstrukturen zu entwickeln, die für eine höhere algorithmische Sprache für die mathematische Programmierung geeignet sind. Der Beitrag untersucht, wie die spezielle Struktur von Matrizen beschrieben und für effizientes Rechnen genutzt werden kann, indem Speicherplatz und überflüssige Operationen eingespart werden. Folgen von Matrizen (und Folgen von Folgen von Matrizen) werden betrachtet, und Matrixoperatoren werden zu Folgenoperatoren und kumulativen Operatoren erweitert. Es werden Algorithmen angegeben, die eine Symbolmanipulation von Matrixausdrücken verwenden, um die für die Berechnung am besten geeigneten Formen zu finden. Diese Formen werden Normalformen genannt. Mehrere Vollständigkeitsergebnisse werden in dem Sinne erhalten, dass für jeden Ausdruck ein äquivalenter Ausdruck in Normalform innerhalb eines angegebenen Kalküls gefunden werden kann."}
{"DOCID": "2082", "TEXT": "Syntaxgesteuerte Dokumentation für PL 360: Die Sprache PL 360 wird zusammen mit ihrer Phrasenstrukturgrammatik als konkrete Grundlage zur Veranschaulichung einer Idee verwendet, die als syntaxgesteuerte Dokumentation bezeichnet wird. Diese Idee besteht darin, (1) die Phrasenstruktur eines Programms zu verwenden, um die Struktur einer formalen Dokumentation für dieses Programm zu definieren; (2) die syntaktischen Typen und Identifikatoren in der resultierenden Struktur zu verwenden, um die automatische Bildung von Fragen an den Programmierer auszulösen, deren Antworten Teil dieser Dokumentation werden; und (3) automatische Speicher- und Abrufeinrichtungen bereitzustellen, damit andere Programmierer, die das Programm verstehen oder modifizieren möchten, auf die resultierende Dokumentation zugreifen können, die auf verschiedene Weise nach syntaktischen Typen und Objekten querindiziert ist. Als Beispiel wird ein kleines PL 360-Programm herausgearbeitet, das bereits in der Literatur zu finden ist."}
{"DOCID": "2083", "TEXT": "Erzeugung und Steuerung interner Datenbanken unter einer Fortran-Programmierumgebung: Es wird ein Verfahren zur Definition einer COMMON-Struktur eines Benutzers und zur automatischen Erzeugung der erforderlichen COMMON-, DIMENSION-, EQUIVALENCE- und Typdeklarationen für jede der Routinen des Benutzers beschrieben. Die Definition für COMMON ist in einer leicht zu modifizierenden Form enthalten, wodurch die Steuerung allgemeiner Datenkommunikationen zwischen Routinen ermöglicht wird. Das beschriebene System wurde auf dem IBM 7094, der CDC 6000-Serie und dem IBM 360 implementiert. Das Verfahren hat sich als unschätzbar für die Definition und Steuerung von COMMON in vielen großen Programmen erwiesen."}
{"DOCID": "2084", "TEXT": "Eine Anmerkung zur Ergänzung von inhärent mehrdeutigen kontextfreien Sprachen"}
{"DOCID": "2085", "TEXT": "Kommentieren Sie eine Paging-Anomalie"}
{"DOCID": "2086", "TEXT": "Eine andere Methode zur Umwandlung von Hexadezimal in Dezimal"}
{"DOCID": "2087", "TEXT": "Ein Zahlensystem für die Permutationen"}
{"DOCID": "2088", "TEXT": "Netzfluss (ALgorithm 336 $H))"}
{"DOCID": "2089", "TEXT": "Primzahl (Algorithmus 310 $A1))"}
{"DOCID": "2090", "TEXT": "Symbolische Erweiterung algebraischer Ausdrücke (Algorithmus 377 $R2))"}
{"DOCID": "2091", "TEXT": "PDEL-A Language for Partial Differential Equations: Herkömmliche Computermethoden zur Lösung kontinuierlicher Systemprobleme, die durch partielle Differentialgleichungen gekennzeichnet sind, sind sehr zeitaufwändig und umständlich. Eine bequeme, einfach zu erlernende und zu verwendende, problemorientierte Sprache auf hohem Niveau zum Lösen und Studieren von partiellen Differentialgleichungsproblemen wurde entworfen; Ein praktischer Übersetzer für die Sprache wurde ebenfalls entworfen, und eine Arbeitsversion davon wurde für einen erheblichen Teil der Sprache erstellt. Diese partielle Differentialgleichungssprache, PDEL, wird umrissen und die Highlights des Übersetzers werden kurz zusammengefasst."}
{"DOCID": "2092", "TEXT": "Eine deduktive Frage-Antwort für die Inferenz natürlicher Sprache: Die Frage-Antwort-Aspekte des Protosynthex III-Prototyp-Sprachverarbeitungssystems werden im Detail beschrieben und veranschaulicht. Das System ist in LISP 1.5 geschrieben und arbeitet auf dem Time-Sharing-System Q-32. Die Datenstrukturen des Systems und ihre semantische Organisation, der deduktive Frage-Antwort-Formalismus relationaler Eigenschaften und Operatoren, die komplexe Beziehungen bilden, und die Frage-Antwort-Prozeduren, die diese Merkmale in ihrem Betrieb verwenden, werden alle beschrieben und illustriert. Beispiele für die Leistungsfähigkeit des Systems und die Grenzen seiner Frage-Antwort-Fähigkeit werden vorgestellt und diskutiert. Es wird gezeigt, dass die Verwendung semantischer Informationen bei der deduktiven Fragebeantwortung den Prozess erheblich erleichtert und dass ein Top-down-Verfahren, das von der Frage zur Antwort arbeitet, eine effektive Nutzung dieser Informationen ermöglicht. Es wird der Schluss gezogen, dass die Entwicklung von Protosynthex III zu einem praktisch nützlichen System zum Arbeiten mit großen Datenbanken möglich ist, aber Änderungen sowohl in den Datenstrukturen als auch in den Algorithmen erfordern wird, die für die Beantwortung von Fragen verwendet werden."}
{"DOCID": "2093", "TEXT": "Ein Vergleich von Fehlerverbesserungsschätzungen für adaptive Trapezoid-Integration: Verschiedene einfache Wahlmöglichkeiten von Fehlerverbesserungsschätzungen für die Trapezregel werden untersucht, um ein Vergleichsverfahren zu demonstrieren, das relativ unabhängig von der Fülle adaptiver Such- und Stoppstrategien ist. Vergleiche basieren auf x^r, `; die Einbeziehung der nicht ganzzahligen Potenzen macht dies realistischer als der übliche polynombasierte Vergleich. Es wurde festgestellt, dass das Verhalten in der Nähe der Singularität der dominierende Faktor war, und eine neue Schätzung, die auf einer konstanten Krümmungsannahme und parametrischen Unterschieden beruhte, wurde als etwas besser angesehen als die anderen in Betracht gezogenen Optionen."}
{"DOCID": "2094", "TEXT": "Über einen Algorithmus zur nichtlinearen Minimax-Approximation: Bestimmte nichtlineare Minimax-Approximationsprobleme sind durch Eigenschaften gekennzeichnet, die die Anwendung spezieller Algorithmen, hauptsächlich basierend auf den Austauschalgorithmen von Remes (1934, 1935), zu ihrer Lösung erlauben. In dieser Arbeit wird die Anwendung eines allgemeinen nichtlinearen Algorithmus nach Osborne und Watson (1969) auf Probleme dieser Art betrachtet. Es werden Beispiele gegeben, um zu veranschaulichen, dass dieser Algorithmus zufriedenstellende Ergebnisse liefern und insbesondere Probleme erfolgreich lösen kann, die mit dem herkömmlicheren Spezialverfahren zu Schwierigkeiten führen."}
{"DOCID": "2095", "TEXT": "Messungen der Segmentgröße: Verteilungen von Segmentgrößen, die unter routinemäßigen Betriebsbedingungen auf einem Computersystem gemessen wurden, das Segmente variabler Größe verwendet (das Burroughs B5500), werden diskutiert. Auffälligstes Merkmal der Messungen ist die große Anzahl kleiner Segmente – etwa 60 Prozent der verwendeten Segmente enthalten weniger als 40 Wörter. Obwohl die Ergebnisse sicherlich nicht installationsunabhängig sind und insbesondere von Merkmalen des B5500-ALGOL-Systems beeinflusst werden, sollten sie für das Design neuer Computersysteme relevant sein, insbesondere im Hinblick auf die Organisation von Paging-Schemata."}
{"DOCID": "2096", "TEXT": "Experimente mit dem M&N-Baumsuchprogramm: Das M&N-Verfahren ist eine Verbesserung des Mini-Max-Backup-Verfahrens, das in Computerprogrammen zum Spielen und für andere Zwecke weit verbreitet ist. Es basiert auf dem Grundsatz, dass es wünschenswert ist, viele Optionen zu haben, um Entscheidungen angesichts der Unsicherheit zu treffen. Die Mini-Max-Prozedur weist einem MAX (MIN)-Knoten den Wert des höchst (niedrigst) bewerteten Nachfolgers dieses Knotens zu. Die M&N-Prozedur weist einem MAX(MIN)-Knoten eine Funktion der M(N)-Nachfolger mit dem höchsten (niedrigsten) Wert zu. Eine M&N-Prozedur wurde in LISP geschrieben, um das Kalah-Spiel zu spielen, und es wurde gezeigt, dass die M&N-Prozedur der Mini-Max-Prozedur signifikant überlegen ist. Die statistische Signifikanz wichtiger Schlussfolgerungen wird angegeben. Da in Arbeiten zu Computerexperimenten im Bereich der künstlichen Intelligenz oft Angaben zur statistischen Signifikanz gefehlt haben, können diese Experimente vielleicht als Modell für zukünftige Arbeiten dienen."}
{"DOCID": "2097", "TEXT": "Ein Programm zum Lehren des Programmierens: Das TEACH-System wurde am MIT entwickelt, um die Kosten zu senken und die Ergebnisse des elementaren Programmierunterrichts zu verbessern. TEACH bietet dem Schüler eine lose geführte Erfahrung mit einer Konversationssprache, die für das Unterrichten entwickelt wurde. Die Beteiligung der Fakultät ist minimal. Ein Begriff der Erfahrung mit TEACH wird diskutiert. Pädagogisch scheint das System erfolgreich zu sein; eine unkomplizierte Neuimplementierung macht es auch wirtschaftlich erfolgreich. Ähnliche Programme mit profunden Tutorial-Fähigkeiten werden nur als Ergebnisse ausgedehnter Forschung erscheinen. Die Umrisse seiner Forschung beginnen sich abzuzeichnen."}
{"DOCID": "2098", "TEXT": "t-Test-Wahrscheinlichkeiten (Algorithmus 321); Studentische t-Verteilung (Algorithmus 344)"}
{"DOCID": "2099", "TEXT": "Eigenwerte und Eigenvektoren einer reellen allgemeinen Matrix (Algorithmus 343 $F))"}
{"DOCID": "2100", "TEXT": "Ortho (Algorithmus 127 $F5))"}
{"DOCID": "2101", "TEXT": "Least Squares Fit By f(x) = Acos(Bx+C) (Algorithmus 376 $E2))"}
{"DOCID": "2102", "TEXT": "Anpassen von Daten an eine Exponentialfunktion (Algorithmus 375 $E2))"}
{"DOCID": "2103", "TEXT": "Restricted Partition Generator (Algorithmus 374 $A1))"}
{"DOCID": "2104", "TEXT": "Anzahl doppelt eingeschränkter Partitionen (Algorithmus 373 $A1))"}
{"DOCID": "2105", "TEXT": "Ein interaktives Computersystem, das eine grafische Flussdiagrammeingabe verwendet: Ein interaktives Computersystem, das auf einem grafischen Computerterminal betrieben wird, wird beschrieben. Dieses System wurde entwickelt, um ein Programmierverfahren durch Computerinterpretation eines Flussdiagramms zu demonstrieren. Der Benutzer zeichnet eine Beschreibung eines abgetasteten Datensystems und spezifiziert, dass die Beschreibung an einen Großcomputer übertragen wird. Das Design wird simuliert und eine grafische Darstellung des verarbeiteten Signals wird an das Oszilloskop zurückgegeben. Ein erfolgreicher Entwurf kann zahlreiche Modifikationen des ursprünglichen Entwurfs erfordern. Ein grafisches interaktives System stellt eine Umgebung bereit, um diesen iterativen Prozess effizient und effektiv durchzuführen."}
{"DOCID": "2106", "TEXT": "Computerausbildung in einer Graduate School of Management: Mehrere Jahre Erfahrung haben zu der Überzeugung geführt, dass die kreative Gestaltung und Bewertung von Management-Informationssystemen ein gründliches Verständnis der zugehörigen Computertechnologie erfordert. Konzepte wie Paging- und Priority-Interrupt-Systeme lassen sich am besten auf Maschinensprachenebene erklären. Jede Ausstellungsmaschine sollte mehrere Kriterien erfüllen. Es sollte: (1) so wenig Scheinprobleme wie möglich aufwerfen; (2) ohne übermäßigen Aufwand die Lösung interessanter Probleme ermöglichen; (3) in der Lage sein, alle ausstehenden signifikanten Probleme innerhalb der gewählten Maschine aufzudecken; (4) darauf bedacht sein, Themen gegebenenfalls in großer Tiefe zu verfolgen; (5) nicht an die von einem Hersteller bereitgestellte Ausrüstung gebunden sein; (6) in der Lage sein, dem Studenten diagnostische Hilfsmittel in großer Tiefe zur Verfügung zu stellen; (7) dem Schüler einen leichten Zugang zur Maschine gewähren; (8) in der Lage sein, neue Probleme aufzudecken, sobald sie auftreten. Wir haben eine simulierte Maschine und die zugehörige Software konstruiert, die diese Kriterien erfüllt. Dieses PRISM-System genannte System ist durch eine Einführung und ein Referenzhandbuch dokumentiert."}
{"DOCID": "2107", "TEXT": "Die quadratische Quotientenmethode: Ein Hash-Code, der sekundäres Clustering eliminiert: Sekundäres Clustering als Ursache für Hash-Code-Ineffizienz wird diskutiert, und ein neues Hashing-Verfahren, das auf seiner Eliminierung basiert, wird vorgestellt. Vergleiche mit bisherigen Methoden werden sowohl analytisch als auch empirisch angestellt."}
{"DOCID": "2108", "TEXT": "Eine Variation des Sortierens nach Adressberechnung: Die Prinzipien der Adressberechnung und -zusammenführung werden kombiniert, um eine effiziente Sortiertechnik zu ergeben. Detaillierte Flussdiagramme der wichtigsten Programmschritte sind enthalten. Die Eigenschaften der vorgeschlagenen Sorte werden diskutiert."}
{"DOCID": "2109", "TEXT": "Die Verwendung der quadratischen Residuenforschung: Ein quadratisches Residuen-Suchverfahren wurde früher vorgeschlagen, um die Clusterbildung zu vermeiden, die normalerweise angetroffen wird, wenn Hash-Adressenkollisionen auftreten und lineare Suchverfahren verwendet werden. Die Suchgröße ist aufgrund der Eigenschaft quadratischer Reste auf eine Hälfte der Speichertabelle beschränkt. Es wird gezeigt, dass für einige Klassen von Primzahlen das Komplement der Menge der quadratischen Reste leicht bestimmt werden kann und daher die gesamte Tabelle der Größe p, wobei p diese Primzahl ist, durchsucht werden kann."}
{"DOCID": "2110", "TEXT": "Ein effizienter kontextfreier Analysealgorithmus: Ein Analysealgorithmus, der der effizienteste allgemein bekannte kontextfreie Algorithmus zu sein scheint, wird beschrieben. Er ähnelt sowohl dem LR(k)-Algorithmus von Knuth als auch dem bekannten Top-Down-Algorithmus. Es hat im Allgemeinen eine Zeitgrenze, die proportional zu n ^ 3 ist (wobei n die Länge der zu analysierenden Zeichenfolge ist); es hat eine n^2-Grenze für eindeutige Grammatiken; und es läuft in linearer Zeit auf einer großen Klasse von Grammatiken, die die meisten praktischen Grammatiken für kontextfreie Programmiersprachen zu enthalten scheinen. Im empirischen Vergleich scheint es den von Griffiths und Petrick untersuchten Top-Down- und Bottom-Up-Algorithmen überlegen zu sein."}
{"DOCID": "2111", "TEXT": "Rechtschreibkorrektur in Systemprogrammen: Es werden mehrere spezialisierte Techniken zur effizienten Integration von Rechtschreibkorrekturalgorithmen in Compiler und Betriebssysteme gezeigt. Dazu gehören die Verwendung von Syntax- und Semantikinformationen, die Organisation eingeschränkter Schlüsselwort- und Symboltabellen und die Berücksichtigung einer begrenzten Klasse von Rechtschreibfehlern. Es wird eine Beispiel-360-Codierung zum Durchführen einer Rechtschreibkorrektur vorgestellt. Durch die Verwendung von Systemen, die eine Rechtschreibkorrektur durchführen, wurde die Anzahl der Debugging-Durchläufe pro Programm verringert, was sowohl Programmierer- als auch Maschinenzeit spart."}
{"DOCID": "2112", "TEXT": "Übersetzungsgleichungen: Eingabebegrenzte Transduktionsausdrücke oder Übersetzungsgleichungen werden verwendet, um die Syntax und linkskontextabhängige Semantik für kontextfreie Sprachen zu beschreiben. Es wird ein formales Verfahren zum Ableiten der Spezifikationen für einen Kellerübersetzer aus einem Satz von Übersetzungsgleichungen angegeben. Der Übersetzer besteht aus endlichen Automaten in Mealy-Form, die mittels eines Kellerstapels interagieren. Innerhalb des beschriebenen Rahmens können String-Erkennung und Parsing als Spezialfälle des Übersetzungsproblems behandelt werden."}
{"DOCID": "2113", "TEXT": "Der Multistore-Parser für hierarchische syntaktische Strukturen: Ein syntaktischer Parser wird für hierarchische Verkettungsmuster beschrieben, die dem Analysator in Form von linearen Zeichenfolgen präsentiert werden. Besonders hervorzuheben ist das System der \"bedeutenden Adressen\", durch das die Bearbeitungszeiten bei großangelegten Abgleichsverfahren erheblich verkürzt werden können. Die Beschreibung verwendet häufig Beispiele, die aus der voll funktionsfähigen Implementierung des Parsers in einem experimentellen Analysator für englische Sätze entnommen wurden. Indem ein Bereich des zentralen Kernspeichers des Computers so strukturiert wird, dass die einzelnen Orte von Bytes und Bits die Daten darstellen, die am Abgleichvorgang beteiligt sind, wird das Verschieben von Informationen auf ein Minimum reduziert und das Durchsuchen von Listen eliminiert insgesamt. Die Übereinstimmungen werden mittels binärer Masken verfolgt und der Zustand einzelner Bits bestimmt den Ablauf der Prozedur. Das Verfahren könnte mit jeder interpretativen Grammatik implementiert werden, vorausgesetzt, sie kann durch die funktionale Klassifizierung der Elemente ausgedrückt werden, die die hierarchischen Eingabestrukturen bilden."}
{"DOCID": "2114", "TEXT": "Ein formales System zum Abrufen von Informationen aus Dateien: Es wird eine verallgemeinerte Dateistruktur bereitgestellt, durch die die Konzepte von Schlüsselwort, Index, Datensatz, Datei, Verzeichnis, Dateistruktur, Verzeichnisdecodierung und Datensatzabruf definiert werden und aus der einige der häufig verwendeten Dateien hervorgehen Strukturen wie invertierte Dateien, indexsequenzielle Dateien und Multilist-Dateien werden abgeleitet. Es werden zwei Algorithmen vorgestellt, die Datensätze aus der verallgemeinerten Dateistruktur abrufen."}
{"DOCID": "2115", "TEXT": "Fortran Tausworthe Pseudozufallszahlengenerator"}
{"DOCID": "2116", "TEXT": "Austauschrollen mit perforiertem Klebeband für den Informationsaustausch* (vorgeschlagener amerikanischer nationaler Standard)"}
{"DOCID": "2117", "TEXT": "Darstellung für Kalenderdatum für Machine-to-Machine Data Interchange* (vorgeschlagener amerikanischer nationaler Standard)"}
{"DOCID": "2118", "TEXT": "Ein effizienter Algorithmus zum Sortieren mit minimalem Speicherplatz (Algorithmus 347 $M1))"}
{"DOCID": "2119", "TEXT": "Derivate (Algorithmus 282 $S22))"}
{"DOCID": "2120", "TEXT": "An Algorithm to Produce Complex Primes, Csieve (Algorithm 372 $A1))"}
{"DOCID": "2121", "TEXT": "Partitionen in natürlicher Reihenfolge (Algorithmus 371 $A1))"}
{"DOCID": "2122", "TEXT": "Allgemeiner Zufallszahlengenerator (Algorithmus 370 $G5))"}
{"DOCID": "2123", "TEXT": "Zufallszahlengenerator, der die Poisson-Verteilung erfüllt (Algorithmus 369 $G5))"}
{"DOCID": "2124", "TEXT": "Numerische Inversion von Laplace-Transformationen (Algorithmus 368 $D5))"}
{"DOCID": "2125", "TEXT": "Eine Anmerkung zur polygonalen Annäherung minimaler Länge an eine digitalisierte Kontur: Ein Verfahren zum Extrahieren einer glatten polygonalen Kontur aus einem digitalisierten Bild wird veranschaulicht. Die geordnete Folge von Konturpunkten und der Verbindungsgraph des Bildes werden zunächst durch einen modifizierten Ledley-Algorithmus in einem Bildscan erhalten. Als Näherungskontur wird dann ein minimales Umfangspolygon gewählt, das bestimmten Beschränkungen unterliegt. Die Bestimmung des minimalen Polygons kann auf ein nichtlineares Programmierproblem reduziert werden, das durch einen Algorithmus gelöst wird, der die schwachen Bindungen zwischen Variablen berücksichtigt. Es werden einige Beispiele vorgestellt und die entsprechenden Rechenzeiten aufgelistet."}
{"DOCID": "2126", "TEXT": "Erfahrung mit einer erweiterbaren Sprache: Ein funktionsfähiges erweiterbares Sprachsystem wird beschrieben. Das System und seine Basissprache werden im Hinblick auf Effizienz, Flexibilität und Nützlichkeit für verschiedene Benutzerkategorien bewertet."}
{"DOCID": "2127", "TEXT": "Frage-Antwort-Systeme in natürlicher Sprache: 1969: Jüngste Experimente zur Programmierung von Frage-Antwort-Systemen in natürlicher Sprache werden überprüft, um die Methoden zusammenzufassen, die für die syntaktische, semantische und logische Analyse englischer Zeichenfolgen entwickelt wurden. Es wird der Schluss gezogen, dass zumindest minimal effektive Techniken zur Beantwortung von Fragen aus Teilmengen natürlicher Sprache in kleinen experimentellen Systemen entwickelt wurden und dass sich ein nützliches Paradigma entwickelt hat, um die Forschungsbemühungen auf diesem Gebiet zu leiten. Gegenwärtige Ansätze zur semantischen Analyse und logischen Schlussfolgerungen werden als effektive Anfänge angesehen, sind jedoch von fragwürdiger Allgemeingültigkeit in Bezug auf subtile Bedeutungsaspekte oder Anwendungen auf große Teilmengen des Englischen. Die Verallgemeinerung von aktuellen kleinen Experimenten auf sprachverarbeitende Systeme auf der Grundlage von Wörterbüchern mit Tausenden von Einträgen – mit entsprechend großen Grammatiken und semantischen Systemen – kann eine neue Komplexitätsordnung nach sich ziehen und die Erfindung und Entwicklung völlig anderer Ansätze zur semantischen Analyse und zu Fragestellungen erfordern antworten."}
{"DOCID": "2128", "TEXT": "Ein Prozessorzuweisungsverfahren für Time-Sharing: Es wird ein Scheduling-Algorithmus vorgeschlagen, der dazu bestimmt ist, Änderungen von Aufgaben auf Prozessoren zu minimieren und dadurch Overhead zu reduzieren. Der Algorithmus findet auch Anwendung auf allgemeinere Ressourcenzuweisungsprobleme. Es wird mittels eines Verfahrens zum effizienten Handhaben sich dynamisch ändernder segmentierter Listen implementiert."}
{"DOCID": "2129", "TEXT": "Rekursive Berechnung bestimmter Ableitungen – eine Untersuchung der Fehlerfortpflanzung: Es wird eine kurze Untersuchung der Fortpflanzung von Fehlern in linearen Differenzgleichungen erster Ordnung durchgeführt. Zur Veranschaulichung sei die rekursive Berechnung aufeinanderfolgender Ableitungen von (e^x)/x und (cos x)/x betrachtet."}
{"DOCID": "2130", "TEXT": "Automatische Segmentierung zyklischer Programmstrukturen auf der Grundlage von Konnektivität und Prozessortaktung: Zeitgeteilte, mehrfach programmierte und überlagerte Batch-Systeme erfordern häufig eine Segmentierung von Computerprogrammen in diskrete Teile. Diese Programmteile werden bei Bedarf zwischen ausführbarem und peripherem Speicher übertragen; Die Segmentierung von Programmen in einer Weise, die die Häufigkeit solcher Übertragungen reduziert, ist das Thema dieses Papiers. Von C. V. Ramamoorthy vorgeschlagene Segmentierungstechniken unterliegen Beschränkungen, die auftreten, wenn die bevorzugte Segmentgröße nicht mit den physikalischen Beschränkungen kompatibel ist, die durch die verfügbare Computerausrüstung auferlegt werden. Eine Verallgemeinerung von Ramamoorthys Vorschlägen wird gemacht, um ihre Anwendung zu ermöglichen, wenn die Umstände nicht ideal sind."}
{"DOCID": "2131", "TEXT": "Schnelle Berechnung von Gewichten interpolatorischer Quadraturregeln [D1] (Algorithmus 417)"}
{"DOCID": "2132", "TEXT": "Schnelle Berechnung von Koeffizienten von Interpolationsformeln [E1] (Algorithmus 416)"}
{"DOCID": "2133", "TEXT": "Algorithmus für das Zuordnungsproblem (rechteckige Matrizen) [H] (Algorithmus 415)"}
{"DOCID": "2134", "TEXT": "Eine Erweiterung des Munkres-Algorithmus für das Zuordnungsproblem auf rechteckige Matrizen: Das Zuordnungsproblem wird zusammen mit dem von Munkres vorgeschlagenen Algorithmus für seine Lösung in quadratischen Matrizen zuerst vorgestellt. Anschließend entwickeln die Autoren eine Erweiterung dieses Algorithmus, die eine Lösung für rechteckige Matrizen erlaubt. Zeitmessungsergebnisse, die mit einer angepassten Version des Algol-Verfahrens von Silver erzielt wurden, werden diskutiert, und es wird eine Beziehung zwischen Lösungszeit und Problemgröße angegeben."}
{"DOCID": "2135", "TEXT": "Schnelle Berechnung allgemeiner Interpolationsformeln und mechanischer Quadraturregeln: Sei f n stetig auf einem geschlossenen Intervall [a,b] und sei L eine lineare Funktion. Es wird versucht, L (f) mit L (Q) zu approximieren, wobei Q ein Polynom ist, das f approximiert. Es werden Algorithmen zur schnellen Berechnung von L(Q) für eine breite Klasse von Auswahlen von Q entwickelt, die die Lagrange- und die Hermite-Regel als Spezialfälle einschließt."}
{"DOCID": "2136", "TEXT": "Eine Anmerkung zu \"Eine Modifikation der Nordsieck-Methode unter Verwendung eines 'Off-Step'-Punktes\""}
{"DOCID": "2137", "TEXT": "Neue LISP-Techniken für eine Paging-Umgebung: Das hier beschriebene System verwendet das Blockkonzept und das von globalen und lokalen Variablen zusätzlich zu den Verfahren, die in den meisten LISP-Systemen angewendet werden. Außerdem wird ein neues Mittel zur Listendarstellung verwendet: \"lokal sequentiell\" für Listen, die während der Kompilierung erstellt werden, und \"block level sequentiell\" für dynamisch erstellte Listen. Ein neuer Garbage-Collection-Algorithmus wurde eingeführt, um Listen so kompakt wie möglich zu machen; eine teilweise Garbage-Collection wird nach jedem Blockausgang anstelle einer totalen Garbage-Collection durchgeführt, wenn der Speicher erschöpft ist. Der Algorithmus verzichtet auf das übliche Flagging-Verfahren. Diese Kombination von Funktionen macht eine kostenlose Liste überflüssig und minimiert effektiv die Anzahl der zu jedem Zeitpunkt verwendeten Seiten."}
{"DOCID": "2138", "TEXT": "BLISS: Eine Sprache für die Systemprogrammierung: Eine Sprache, BLISS, wird beschrieben. Diese Sprache ist so konzipiert, dass sie besonders geeignet für die Verwendung beim Schreiben von Produktionssoftwaresystemen für eine bestimmte Maschine (den PDP-10) ist: Compiler, Betriebssysteme usw. Hauptdesignziele des Designs sind die Fähigkeit, hocheffizienten Objektcode zu erzeugen , um den Zugriff auf alle relevanten Hardwaremerkmale der Hostmaschine zu ermöglichen und um ein rationales Mittel bereitzustellen, mit dem die evolutionäre Natur von Systemprogrammen bewältigt werden kann. Ein wesentliches Merkmal, das zur Verwirklichung dieser Ziele beiträgt, ist ein Mechanismus, der die Definition der Darstellung aller Datenstrukturen im Sinne des Zugriffsalgorithmus für Elemente der Struktur erlaubt."}
{"DOCID": "2139", "TEXT": "Implementierung des Teilkettentests durch Hashing: Es wird eine Technik zum Implementieren des Tests beschrieben, der feststellt, ob eine Kette eine Teilkette einer anderen ist. Wenn die Wahrscheinlichkeit gering ist, dass der Test bestanden wird, wird gezeigt, wie die Operation erheblich beschleunigt werden kann, wenn ihr ein Test auf geeignet gewählte Hash-Codes der Zeichenketten vorangeht."}
{"DOCID": "2140", "TEXT": "Kompromisse bei der Abruf- und Aktualisierungsgeschwindigkeit unter Verwendung kombinierter Indizes: In einem Artikel in den Communications of the ACM vom November 1970 stellte V. Y. Lum eine Technik der Dateiindizierung mit dem Namen „combined indices“ vor. Diese Technik ermöglichte eine verkürzte Abrufzeit auf Kosten von mehr Speicherplatz. Dieser Beitrag untersucht kombinierte Indizes unter Bedingungen der Dateinutzung mit unterschiedlichen Abruf- und Aktualisierungsanteilen. Kompromisskurven werden entwickelt, um die minimalen Kosten der Dateinutzung durch Gruppieren verschiedener teilweise kombinierter Indizes zu zeigen."}
{"DOCID": "2141", "TEXT": "Algorithmische Auswahl des besten Verfahrens zum Komprimieren von Kartendatenfolgen: Das beste von einem Dutzend verschiedener Verfahren zum Komprimieren von Kartendaten wird veranschaulicht. Die Wahlmöglichkeiten werden durch Codieren von Datenketten – Folge gleicher Codes – durch drei Verfahren und in vier Richtungen erzeugt. Zwischen Komprimierungsalternativen werden Beziehungen entwickelt, um zu vermeiden, dass sie alle verglichen werden. Die Technik wurde verwendet, um Daten aus Waldressourcenkarten zu komprimieren, ist jedoch weithin für die Reduzierung von Karten- und fotografischen Daten anwendbar."}
{"DOCID": "2142", "TEXT": "Rekonstruktion von Bildern aus ihren Projektionen: Es gibt Situationen in den Naturwissenschaften und der Medizin (z. B. in der Elektronenmikroskopie und Röntgenfotografie), in denen es wünschenswert ist, die Graustufen eines digitalen Bildes an den einzelnen Punkten aus den Summen der zu schätzen Graustufen entlang gerader Linien (Projektionen) in einigen Winkeln. Normalerweise ist das Bild in solchen Situationen alles andere als bestimmt, und das Problem besteht darin, das \"repräsentativste\" Bild zu finden. Es werden drei Algorithmen beschrieben (die alle Monte-Carlo-Verfahren verwenden), die entwickelt wurden, um dieses Problem zu lösen. Die Algorithmen sind in einer großen und vielfältigen Anzahl von Gebieten anwendbar. Die wichtigsten Anwendungen können die Rekonstruktion von möglicherweise asymmetrischen Partikeln aus elektronenmikroskopischen Aufnahmen und dreidimensionaler Röntgenanalyse sein."}
{"DOCID": "2143", "TEXT": "Tschebyscheff-Approximation stetiger Funktionen durch ein Tschebyscheff-Funktionssystem [E2] (Algorithmus 414)"}
{"DOCID": "2144", "TEXT": "Zur genauen Gleitkomma-Summierung: Die Akkumulation von Gleitkomma-Summen wird auf einem Computer betrachtet, der eine t-stellige Gleitkomma-Addition zur Basis B mit Exponenten im Bereich von -m bis M durchführt. Es wird ein Algorithmus zum genauen Summieren von N t- angegeben. einstellige Gleitkommazahlen. Jede dieser N Zahlen wird in q Teile zerlegt, wodurch qN t-stellige Gleitkommazahlen entstehen. Jeder von diesen wird dann zu dem geeigneten von n zusätzlichen t-Ziffern-Akkumulatoren addiert. Schließlich werden die Akkumulatoren zusammengezählt, um die berechnete Summe zu ergeben. Insgesamt werden qN+n-1 t-stellige Gleitkommaadditionen durchgeführt. Unter normalen Bedingungen beträgt der relative Fehler in der berechneten Summe höchstens [(t+1)/v]B^(1-t) für einige v. Ferner, mit zusätzlichen q+n-1 t-stelligen Additionen, die berechnete Summe kann auf volle t-Stellengenauigkeit korrigiert werden. Beispielsweise sind für IBM/360 (B=16, t=14, M=63, m=64) typische Werte für q und n q=2 und n=32. In diesem Fall wird (*) zu N <= 32.768, und wir haben [(t+1)/v]B^(1-t) = 4x16^-13."}
{"DOCID": "2145", "TEXT": "Automatisierung des Ätzmuster-Layouts: HELP (Heuristic Etching-Pattern Layout Program) ist ein Anwendungsprogramm, das entwickelt wurde, um das mühsame und fehleranfällige, wenn auch lebenswichtige Verdrahtungsdesign von Leiterplatten zu computerisieren. HELP hilft bei der Automatisierung einer Designphase, die der Produktion einen Schritt näher kommt als das logische Design. Es kann verwendet werden, um Verdrahtungsmuster von zweischichtigen Leiterplatten zu entwerfen, auf denen ICs in Dual-in-Line-Gehäusen sowie diskrete Komponenten wie Transistoren und Widerstände platziert wurden. HELP verwendet zwei Verdrahtungsmethoden. Die eine ist die heuristische Methode, die menschliche Herangehensweisen an das Verdrahtungsdesign simuliert, und die andere ist die theoretisch interessante, aber zeitaufwändige Methode des Labyrinthlaufs, die auf dem Lee-Algorithmus basiert. HELP führt mehr als 90 Prozent der erforderlichen Verdrahtung durch den heuristischen Pfad in Bezug auf eine Leistungsfunktion für jede Punkt-zu-Punkt- und Punkt-zu-Leitung-Verbindung durch. Es kann die Anzahl erfolgreicher Verdrahtungsverbindungen sehr nahe an 100 Prozent bringen."}
{"DOCID": "2146", "TEXT": "Optimieren der Polyphasensortierung: Verschiedene Dispersionsalgorithmen für das Polyphasensortierungsverfahren werden untersucht. Der optimale Algorithmus basierend auf der Minimierung der Gesamtzahl der gelesenen Einheitsketten wird angezeigt. Die Logik dieses Algorithmus ist ziemlich kompliziert; daher werden mehrere andere neue Dispersionsalgorithmen mit einfacherer Logik vorgestellt. Von den diskutierten einfachen Dispersionsalgorithmen ist der horizontale am besten. Er benötigt etwa ein Viertel bis eineinhalb Prozent weniger Lese- und Schreibvorgänge als die meisten heute verwendeten Algorithmen. Eine zusätzliche Verbesserung um zwei und ein Viertel bis drei Prozent kann durch die Verwendung des modifizierten optimalen Algorithmus erreicht werden. Dieser Algorithmus ist relativ einfach, aber er erfordert eine ziemlich genaue Schätzung der Gesamtzahl von Einheitsketten, bevor die Dispersion beginnt."}
{"DOCID": "2147", "TEXT": "Using Computers in Higher Education: Past Recommendations, Status, and Needs: Daten aus einer Umfrage, die mit Unterstützung der National Science Foundation durchgeführt und im Dezember 1970 veröffentlicht wurde, werden überprüft, und es wird darauf hingewiesen, dass in Bezug auf Computer in der Hochschulbildung Die in den Berichten von Rosser und Pierce genannten nationalen Ziele wurden nicht erreicht. In fast der Hälfte der 1966-67 angebotenen Associate- und Bachelor-Studiengänge in Datenverarbeitung, Informatik usw. mangelte es an Hardware oder Kursen an Qualität. Es wird für weiterführende Studien zu Status und Zielen der Informatik in der Hochschulbildung, zur Verbesserung von Studiengängen und für ein nationales Testlabor für Bildungstechnologie plädiert."}
{"DOCID": "2148", "TEXT": "Die Zusammensetzung der Semantik in Algol 68: Die Hauptmerkmale von Algol 68 werden aus semantischer Sicht erklärt. Es wird gezeigt, wie die Sprache die Komposition von Werten und Handlungen, also letztendlich von Programmen, aus einer minimalen Menge von Primitiven mit wenigen grundlegenden rekursiven Kompositionsregeln erlaubt. Die zugehörige Syntax wird kurz wiederholt. Es wurde versucht, eine strukturierte und einfache Einführung sowohl in Algol 68 als auch in sein orthogonales Design zu erhalten."}
{"DOCID": "2149", "TEXT": "ENTCAF und ENTCRE: Auswertung normalisierter Taylor-Koeffizienten einer analytischen Funktion [C5] (Algorithmus 413)"}
{"DOCID": "2150", "TEXT": "Concurrent Control with „Readers“ und „Writers“: Das Problem des gegenseitigen Ausschlusses mehrerer unabhängiger Prozesse vom gleichzeitigen Zugriff auf einen „critical section“ wird für den Fall diskutiert, dass es zwei unterschiedliche Klassen von Prozessen gibt, die als „readers“ und „writers“ bekannt sind. Schriftsteller.\" Die „Leser“ dürfen den Abschnitt untereinander teilen, aber die „Schreiber“ müssen exklusiven Zugriff haben. Zwei Lösungen werden vorgestellt: eine für den Fall, wo wir eine minimale Verzögerung für die Leser wünschen; das andere für den Fall, dass wir so früh wie möglich schreiben möchten."}
{"DOCID": "2151", "TEXT": "Messung von Benutzerprogrammen in einer Time-Shared-Umgebung: Einer allgemeinen Erörterung der Messung von Softwaresystemen folgt eine Beschreibung eines Hardware- und Software-Schemas zum Messen von Benutzerprogrammen in einer Time-Shared-Umgebung. Der TX-2-Computer am MIT Lincoln Laboratory wurde für die Implementierung eines solchen Systems verwendet, und die Eigenschaften dieser Implementierung werden berichtet. Ein Szenario, das das verwendete System zeigt, wird vorgestellt. Abschließend wird gezeigt, wie andere Time-Sharing-Systeme ähnliche Messeinrichtungen bereitstellen können."}
{"DOCID": "2152", "TEXT": "Anzeigeprozeduren: Obwohl die Verwendung von strukturierten Anzeigedateien in interaktiven Computergraphiken weit verbreitet ist, stellen diese Strukturen eine Reihe von Problemen dar, die dazu neigen, ihre Allgemeingültigkeit und Nützlichkeit einzuschränken. Diese Abhandlung diskutiert einige dieser Probleme und schlägt einen alternativen Ansatz für den Entwurf von Anzeigesystemen vor, der die Verwendung von strukturierten Anzeigedateien vermeidet. Diese Technik verwendet Anzeigeprozeduren, um Informationen zur Anzeige zu erzeugen. Durch Einfügen von Transformationen in Aufrufe dieser Prozeduren ist es möglich, sowohl die Spezifikation von Bildern zu vereinfachen als auch ihre Generierung zu beschleunigen. Anzeigeverfahren erlauben eine bedingte Definition von Bildelementen und erleichtern auch die Verarbeitung von Eingaben von Zeigegeräten. Der Beitrag wird durch Beispiele aus der Abneigung gegen die EULER-Sprache illustriert, in denen Anzeigeverfahren implementiert wurden."}
{"DOCID": "2153", "TEXT": "Experimente mit einem automatisierten Unterrichtssystem für numerische Methoden: An der Purdue University wurde ein Computersystem entwickelt, um Teile eines Grundstudiums in numerischen Methoden zu unterrichten. Jede Unterrichtseinheit oder Unterrichtsstunde ist in drei Unterrichtsmodi unterteilt, die es dem Schüler ermöglichen, von einer computergesteuerten Präsentation zu einer schülergesteuerten Untersuchung überzugehen. Das System ist als klassenzimmerunabhängiger Studiengang konzipiert und wird seit zwei Semestern von den Studierenden anstelle des klassischen Präsenzunterrichts genutzt. Anfängliche Messungen der Effektivität, der Akzeptanz durch die Schüler und der Betriebskosten sind das Ergebnis des Testens des Systems unabhängig vom Eingreifen des Lehrers. Das System ist auf einem CDC 6500 mit Fernschreibterminals betriebsbereit."}
{"DOCID": "2154", "TEXT": "Klärung der Fortran-Standards – Zweiter Bericht: 1966 wurde Fortran nach vierjähriger Anstrengung zur ersten in den Vereinigten Staaten standardisierten Programmiersprache. Seit dieser ersten Errungenschaft haben die Untersuchung und Anwendung der Standardspezifikationen die Notwendigkeit der Aufrechterhaltung der Standards aufgezeigt. Als Ergebnis der 1967 begonnenen Arbeit wurde eine erste Reihe klarstellender Interpretationen vorbereitet und diese Klarstellung im Mai 1969 in den Mitteilungen der ACM veröffentlicht. Diese Arbeit wurde fortgesetzt und führte zur Vorbereitung dieser zweiten Reihe klarstellender Interpretationen. Über die Art der Wartung und die neuen Korrekturen und Interpretationen der Standardspezifikationen wird berichtet."}
{"DOCID": "2155", "TEXT": "Toward an Understanding of Data Structures: Dieses Papier stellt eine Notation und einen Formalismus zur Beschreibung der Semantik von Datenstrukturen vor. Dies basiert auf gerichteten Graphen mit benannten Kanten und Transformationen auf diesen Graphen. Außerdem wird eine Implementierungseinrichtung beschrieben, die Teil einer Programmiersprache sein könnte, die es einem Programmierer, der die Semantik eines Algorithmus in Form von Graphen ausgedrückt hat, ermöglicht, dann die Implementierung einiger seiner Datenstrukturen zu spezifizieren, um an Effizienz zu gewinnen ."}
{"DOCID": "2156", "TEXT": "Kommentar zu Cheneys List-Compaction-Algorithmus"}
{"DOCID": "2157", "TEXT": "Durchschnittliche binäre Suchlänge für dicht geordnete Listen"}
{"DOCID": "2158", "TEXT": "Ein Stoppkriterium für die Newton-Raphson-Methode in impliziten Mehrschrittintegrationsalgorithmen für nichtlineare Systeme gewöhnlicher Differentialgleichungen"}
{"DOCID": "2159", "TEXT": "Eine Anmerkung zu den besten einseitigen Annäherungen"}
{"DOCID": "2160", "TEXT": "Kanonische Struktur in der attributbasierten Dateiorganisation: In diesem Dokument wird eine neue Dateistruktur für den attributbasierten Abruf vorgeschlagen. Es ermöglicht die Verarbeitung von Abfragen mit beliebigen Booleschen Funktionen der Attribut-Wert-Paare, ohne Schnittmengen von Listen zu nehmen. Der Aufbau ist stark abhängig von der Art und Weise, wie die Datei verwendet werden soll, und wird eindeutig durch die Angabe der erlaubten Abfragen bestimmt. So wäre beispielsweise die Struktur für den Abruf auf der Grundlage von Wertebereichen eines gegebenen Attributs sehr verschieden von einer Struktur, bei der nur der Abruf auf der Grundlage eines einzelnen Werts zulässig ist. Die vorgeschlagene Dateiorganisation basiert auf den Atomen einer Booleschen Algebra, die durch die Abfragen erzeugt wird. Die wünschenswerten Eigenschaften, die für diese Struktur beansprucht werden, werden bewiesen, und Fragen der Dateiverwaltung werden diskutiert."}
{"DOCID": "2161", "TEXT": "Ein Algorithmus für die Blöcke und Cutnodes eines Graphen (Korrigendum)"}
{"DOCID": "2162", "TEXT": "Eine effiziente Bittabellentechnik für die dynamische Speicherzuweisung von 2^n-Wort-Blöcken: Es wird eine effiziente Bittabellentechnik für die dynamische Speicherzuweisung von 2^n-Wort-Blöcken beschrieben, die eine minimierte Speichermenge für Buchhaltungszwecke erfordert. Die Technik wurde in einer Implementierung der Listenverarbeitungssprache L^6 getestet. Eine Reihe von Ideen, die in den Prozessor integriert sind, werden ebenfalls beschrieben."}
{"DOCID": "2163", "TEXT": "Bildung im Zusammenhang mit der Verwendung von Computern in Organisationen: Das ACM Curriculum Committee on Computer Education for Management hat im Rahmen eines Stipendiums der National Science Foundation eine Studie zur „Curriculum Development in Management Information Systems Education in Colleges and Universities“ durchgeführt. Dieses Positionspapier gibt einen Rahmen für die Studie vor. Es werden vorläufige Schlussfolgerungen zum Ausbildungsbedarf in Verwaltungsinformationssystemen gezogen und geeignete Lehrpläne und Studiengänge für Hochschulen vorgeschlagen. Außerdem wird die Rolle von Berufsverbänden und Organisationen diskutiert, die Computer verwenden, und die Pläne des Komitees werden skizziert. Der anfängliche Ansatz des Komitees bestand darin, die Ausbildung zu beschreiben, die für den effektiven Einsatz von Computern in Organisationen erforderlich ist, die Positionen zu klassifizieren, für die Ausbildung erforderlich ist, und die jetzt verfügbaren Ausbildungsprogramme zu untersuchen."}
{"DOCID": "2164", "TEXT": "Symbolische Integration: Das stürmische Jahrzehnt: Drei Ansätze zur symbolischen Integration in den 1960er Jahren werden beschrieben. Die erste, von künstlicher Intelligenz, führte zu Slagles SAINT und zu einem großen Teil zu Moses' SIN. Die zweite, von der algebraischen Manipulation, führte zu Manoves Implementierung und zu Horowitz' und Tobeys erneuter Untersuchung des Hermite-Algorithmus zur Integration rationaler Funktionen. Die dritte, aus der Mathematik, führte zu Richardsons Beweis der Unlösbarkeit des Problems für eine Klasse von Funktionen und zu Rischs Entscheidungsverfahren für die elementaren Funktionen das bestimmte Integral werden ebenfalls beschrieben."}
{"DOCID": "2165", "TEXT": "Allgemeine Relativitätstheorie und die Anwendung algebraischer Manipulationssysteme: Der Artikel beschreibt einige Anwendungen symbolischer Algebrasysteme auf Probleme der allgemeinen Relativitätstheorie, einschließlich der Ableitung der Feldgleichungen, der Petrov-Klassifizierung einer Metrik und der Lösung der Feldgleichungen in Anwesenheit von Angelegenheit in einem einfachen Fall. Es wird auf die streng algebraischen Schwierigkeiten hingewiesen, denen diese Arbeit begegnet."}
{"DOCID": "2166", "TEXT": "Automatisierte algebraische Manipulation in der Himmelsmechanik: In diesem Artikel betrachten wir einige der Anwendungen der automatisierten algebraischen Manipulation, die in der Himmelsmechanik gemacht wurden. Besonderes Augenmerk wird auf die Verwendung von Poisson-Reihen gelegt und ein typisches Problem der Störungstheorie beschrieben. Die Anforderungen an Prozessoren für den Einsatz in der Himmelsmechanik werden betrachtet und mit denen für allgemeine Manipulationspakete verglichen. Einige zukünftige Richtungen für die Forschung unter Verwendung dieser Systeme werden kurz skizziert. Um die relative Einfachheit des in der Himmelsmechanik erforderlichen Algorithmus zu veranschaulichen, wird in einem Anhang ein typisches Integrationsproblem betrachtet."}
{"DOCID": "2167", "TEXT": "Algebraische Vereinfachung: Ein Leitfaden für Verwirrte: Die algebraische Vereinfachung wird erstens aus der Sicht eines Benutzers untersucht, der einen großen Ausdruck verstehen muss, und zweitens aus der Sicht eines Designers, der ein nützliches und effizientes System konstruieren möchte. Zuerst beschreiben wir verschiedene Techniken, die der Substitution ähneln. Diese Techniken können verwendet werden, um die Größe eines Ausdrucks zu verringern und ihn für einen Benutzer verständlicher zu machen. Dann skizzieren wir das Spektrum von Ansätzen zum Entwurf automatischer Vereinfachungsfähigkeiten in einem algebraischen Manipulationssystem. Systeme werden in fünf Typen unterteilt. Jeder Typ bietet unterschiedliche Möglichkeiten zur Bearbeitung und Vereinfachung von Ausdrücken. Abschließend diskutieren wir einige der theoretischen Ergebnisse im Zusammenhang mit der algebraischen Vereinfachung. Wir beschreiben mehrere positive Ergebnisse über die Existenz leistungsfähiger Vereinfachungsalgorithmen und die zahlentheoretischen Vermutungen, auf denen sie beruhen. Ergebnisse über die Nichtexistenz von Algorithmen für bestimmte Klassen von Ausdrücken sind enthalten."}
{"DOCID": "2168", "TEXT": "Listenverfolgung in Systemen, die mehrere Zelltypen zulassen: Listenverarbeitungssysteme haben jeweils die Verwendung nur einer einzigen Größe und Konfiguration von Listenzellen zugelassen. In dieser Arbeit wird ein System beschrieben, das die Verwendung beliebig vieler unterschiedlicher Größen und Konfigurationen von Listenzellen erlaubt, die möglicherweise erst zur Laufzeit spezifiziert werden."}
{"DOCID": "2169", "TEXT": "Das Altran-System zur Manipulation rationaler Funktionen – eine Übersicht: Altran ist ein vollständiges System zur symbolischen Berechnung mit rationalen Funktionen in mehreren Variablen mit ganzzahligen Koeffizienten. Es wurde entwickelt und implementiert, um große Probleme einfach und effizient zu bewältigen. Beträchtliche Anstrengungen wurden unternommen, um eine minimale Maschinenabhängigkeit bei der Implementierung sicherzustellen, wodurch ermöglicht wird, dass das System schnell und einfach auf einer Vielzahl von Rechenmaschinen installiert werden kann. In diesem Dokument wird eine kurze Beschreibung der Sprache, der Laufzeitdatenstrukturen und der Implementierung gegeben."}
{"DOCID": "2170", "TEXT": "Anwendungen der Symbolmanipulation in der Theoretischen Physik: Dieser Beitrag untersucht die Anwendungen symbolischer Rechentechniken auf Probleme in der Theoretischen Physik. Besonderes Augenmerk wird auf Anwendungen in der Quantenelektrodynamik gelegt, wo die meisten Aktivitäten aufgetreten sind."}
{"DOCID": "2171", "TEXT": "Lösung simultaner nichtlinearer Gleichungen"}
{"DOCID": "2172", "TEXT": "Graphplotter [J6] (Algorithmus 412)"}
{"DOCID": "2173", "TEXT": "Drei Prozeduren für das Problem der stabilen Ehe [H] (Algorithmus 411)"}
{"DOCID": "2174", "TEXT": "Das Problem der stabilen Ehe: Die ursprüngliche Arbeit von Gale und Shapley über eine Zuordnungsmethode unter Verwendung des Kriteriums der stabilen Ehe wurde erweitert, um alle Zuordnungen der stabilen Ehe zu finden. Es wurde bewiesen, dass der Algorithmus, der zum Auffinden aller stabilen Ehezuordnungen abgeleitet wurde, alle Bedingungen des Problems erfüllt. Algorithmus 411 gilt für dieses Papier."}
{"DOCID": "2175", "TEXT": "Reihenfolge der Teilausdrücke bei der Ausführung von arithmetischen Ausdrücken: Ein arithmetischer Ausdruck kann oft in seine Teilausdrücke zerlegt werden. Abhängig von der Hardwareumgebung, in der der Ausdruck ausgeführt werden soll, können diese Unterausdrücke seriell, parallel oder in einer Kombination dieser Modi ausgewertet werden. Dieses Papier zeigt, dass die Ausführungszeit von Ausdrücken nur minimiert werden kann, wenn die Reihenfolge der Teilausdrücke berücksichtigt wird. Insbesondere sollten Teilausdrücke in der Reihenfolge abnehmender Speicher- und Prozessorzeitanforderungen ausgeführt werden. Diese Beobachtung gilt für Konfigurationen, die von einem Einprozessor mit einem ungepufferten Hauptspeicher bis zu einem Mehrprozessor mit einem \"Cache\"-Pufferspeicher reichen. Wenn die Anzahl der parallel ausführbaren Unterausdrücke die Anzahl der verfügbaren Prozessoren übersteigt, muss die Ausführung einiger dieser Unterausdrücke verschoben werden. Es wird ein Verfahren angegeben, das diese Anforderung mit den früheren Ordnungsüberlegungen kombiniert, um eine optimale Ausführungsreihenfolge bereitzustellen."}
{"DOCID": "2176", "TEXT": "Pufferzuordnung beim Zusammenführungssortieren: Hier wird eine feste Pufferzuordnung zum Zusammenführungssortieren vorgestellt, die die Anzahl der Eingabe-Ausgabe-Operationen für eine gegebene Zusammenführungsreihenfolge minimiert. Beim Sortieren auf beweglichen Armscheiben ist die Anzahl der Suchvorgänge gleich der Anzahl der Eingabe-Ausgabe-Operationen, und die Suchzeit steuert normalerweise die Sortierzeit. Zuerst wird einige Standardterminologie eingeführt. Dann wird das Zuweisungsverfahren für den Eingangspuffer beschrieben, gefolgt von einer Analyse der zu erwartenden Verbesserung gegenüber einer konventionelleren Zuweisung. Diese Analyse macht sich eine bestimmte Verteilungsfunktion zunutze. Es wird eine Analyse einer völlig anderen Verteilung gegeben, die zu ähnlichen Ergebnissen führt. Dies deutet darauf hin, dass die Ergebnisse nicht von einer bestimmten Verteilungsfunktion abhängen. Eine optimale Ausgangspuffergröße wird ebenfalls bestimmt. Es wird geschlussfolgert, dass diese Pufferzuweisung die Zeit des Mischsortierens auf Platten mit beweglichem Arm erheblich reduzieren kann, wenn die Eingangsdaten nicht zufällig sind, und dass diese Ausgangspufferzuweisung unabhängig davon verwendet werden sollte, ob die Daten zufällig sind oder nicht."}
{"DOCID": "2177", "TEXT": "An Algorithm for the Blocks and Cutnodes of a Graph: Es wird ein effizientes Verfahren zum Auffinden von Blöcken und Cutnodes eines beliebigen ungerichteten Graphen vorgestellt. Der Graph kann entweder (i) als eine geordnete Liste von Kanten oder (ii) als eine gepackte Adjazenzmatrix dargestellt werden. Wenn w die Wortlänge der verwendeten Maschine bezeichnet, erhöht sich der Speicherbedarf (in Maschinenworten) für einen Graphen mit n Knoten und m Kanten im Wesentlichen um 2(m+n) im Fall (i), oder (n^2)/ Fall gewinnen (ii). Es entsteht ein aufspannender Baum mit beschrifteten Kanten, wobei zwei Kanten schließlich unterschiedliche Beschriftungen tragen, wenn und nur wenn sie zu unterschiedlichen Blöcken gehören. Für beide Darstellungen steigt die Zeit, die benötigt wird, um einen Graphen auf n Knoten zu analysieren, mit n^G, wobei G von der Art des Graphen abhängt, 1 <= G <= 2, und beide Schranken erreicht werden. Werte von G werden für jede von mehreren geeigneten Familien von Testgraphen abgeleitet, die durch eine Erweiterung des Web-Grammatik-Ansatzes erzeugt werden. Der Algorithmus wird im Detail mit dem von Read vorgeschlagenen verglichen, für den 1 <= G <= 3 gilt."}
{"DOCID": "2178", "TEXT": "Eine Spracherweiterung für die Graphverarbeitung und ihre formale Semantik: Eine einfache Programmiersprachen-\"Erweiterung\" Graspe zur Verarbeitung von gerichteten Graphen wird definiert. Graspe besteht aus einer Art gerichteter Graphen-Datenstruktur und einem Satz primitiver Operationen zum Manipulieren dieser Strukturen. Graspe kann am einfachsten implementiert werden, indem es in eine Wirtssprache eingebettet wird. Der Schwerpunkt liegt sowohl auf Graspe selbst als auch auf seiner Definitionsmethode. Üblicherweise umfasst die Definition einer Sprache die Definition der syntaktischen Elemente und die Erklärung der ihnen zuzuweisenden Bedeutung (der Semantik). Die Definition von Graspe bezieht sich hier ausschließlich auf seine Semantik; das heißt, die Datenstrukturen und Operationen sind genau definiert, aber ohne Zuweisung einer bestimmten syntaktischen Darstellung. Erst bei der Implementierung der Sprache ist die Zuweisung einer expliziten Syntax notwendig. Zur Veranschaulichung wird ein Beispiel einer in Lisp eingebetteten Implementierung von Graspe gegeben. Die Vor- und Nachteile der semantischen Definition einer Sprache werden diskutiert."}
{"DOCID": "2179", "TEXT": "Einfache LR(k)-Grammatiken: Eine Klasse von kontextfreien Grammatiken, die als \"einfache LR(k)\"- oder SLR(k)-Grammatiken bezeichnet werden, wird definiert. Es hat sich gezeigt, dass diese Klasse Grammatiken mit schwacher Präzedenz und einfacher Präzedenz als geeignete Teilmengen enthält. Es wird auch gezeigt, wie man Parser für die SLR(k)-Grammatiken konstruiert. Diese Parser-Konstruktionstechniken sind erweiterbar, um alle LR(k)-Grammatiken von Knuth abzudecken; Sie wurden implementiert und erwiesen sich im direkten Vergleich den Präzedenztechniken als überlegen, nicht nur im Bereich der abgedeckten Grammatiken, sondern auch in der Geschwindigkeit der Parserkonstruktion und in der Größe und Geschwindigkeit der resultierenden Parser."}
{"DOCID": "2180", "TEXT": "Ein Programmierer-Ausbildungsprojekt: Es wird ein Projekt beschrieben, dessen Zweck darin besteht, ausgewählte schwarze Einwohner des Albany-Schenectady-Gebiets in Computerprogrammierung auszubilden und ihnen Jobs im Computerbereich zu vermitteln. Sowohl die Organisation als auch das Curriculum des Kurses werden besprochen."}
{"DOCID": "2181", "TEXT": "The State of Computer Oriented Curricula in Business Schools 1970: Das ACM Committee on Computer Education for Management, unterstützt durch ein Stipendium der National Science Foundation, wird gegründet, um den Stand der Technik zu bewerten und eine Reihe von Empfehlungen zur Verbesserung der Computerausbildung für das Management zu entwickeln . Um das Komitee mit Material für seine Untersuchung des Curriculumbedarfs zu versorgen, wurden 1970 fünf Regionaltreffen in den Vereinigten Staaten abgehalten, bei denen jeweils ein breiter Querschnitt geladener Akademiker und Praktiker den Stand der Curricula an Business Schools erörterte. Drei Themen wurden behandelt: Lehrpläne für den Geschäftsführer; computerbezogenes Material in Pflicht- und Funktionskursen; und Curricula für Studenten, die sich auf computergestützte Informationssysteme konzentrieren. Eine Analyse der Sitzungsprotokolle ergab eine Reihe gemeinsamer Erfahrungen, die ähnliche pädagogische und wirtschaftliche Fragen aufwarfen. Diese Präsentation gibt eine Zusammenfassung der Diskussionen; eine Zusammenfassung der geäußerten pädagogischen und inhaltlichen Bedenken; und Berücksichtigung der damit verbundenen Ressourcenzuweisungsfragen. Vor den Empfehlungen des Komitees zur Verbesserung der Computerausbildung für das Management wurde dieser Bericht erstellt, um den Teilnehmern und den Administratoren ihrer Institutionen Hintergrundinformationen für die laufende Aufgabe der Kursentwicklung zu liefern. Vorsitzender des zehnköpfigen Komitees ist Daniel Teichroew (The University of Michigan)."}
{"DOCID": "2182", "TEXT": "Interruptgesteuerte Programmierung"}
{"DOCID": "2183", "TEXT": "Binäre Summierung"}
{"DOCID": "2184", "TEXT": "Zur Bedeutung von Namen in Programmiersystemen: Es wird angenommen, dass zwischen den Datennamen einer Programmiersprache und den Dateinamen eines Betriebssystems eine Funktionsähnlichkeit besteht. Die beiden Funktionen werden im Hinblick auf die gleichen Grundkonzepte diskutiert, um das Ausmaß ihrer Überschneidung zu identifizieren. Es wird vermutet, dass es eine gewisse Ähnlichkeit zwischen der Idee eines Dateiverzeichnisses und einem speicherbaren Objekt vom Typ Kontext gibt. Manipulationen mit Kontexten werden dann ausführlich diskutiert. Es wird darauf hingewiesen, dass es eine einfache Erweiterung der Lambda-Notation von Church gibt, die sich gut mit diesen Ideen der Kontextmanipulation befasst. Während eine Funktion als Abstraktion basierend auf den ersten beiden Begriffen des Ausdrucks Lambda(Namensliste)(Ausdruck)(Werteliste) betrachtet werden kann, stellt sich heraus, dass ein Kontext als Abstraktion basierend auf den ersten beiden Begriffen in angesehen werden kann der äquivalente Ausdruck Mu(Namensliste)(Werteliste)(Ausdruck)."}
{"DOCID": "2185", "TEXT": "Eine Anmerkung zum Kompilieren binärer Festkommamultiplikationen: Es wurde ein Algorithmus zum Kompilieren vieler binärer Festkommamultiplikationen mit einer Konstanten als Folge von Verschiebungen, Additionen und Subtraktionen entwickelt. Die wichtigsten Eigenschaften des Algorithmus sind die Einfachheit des Tests, der bestimmt, ob der Algorithmus angewendet werden sollte, und inwieweit er effizienten Objektcode \"vorschlägt\"."}
{"DOCID": "2186", "TEXT": "Numerische Eigenschaften des Ritz-Trefftz-Algorithmus zur optimalen Steuerung: In diesem Artikel wird der Ritz-Trefftz-Algorithmus auf die Computerlösung des Zustandsreglerproblems angewendet. Der Algorithmus stellt eine Modifikation des direkten Ritz-Verfahrens dar und ist darauf ausgelegt, die Lösungsgeschwindigkeit und die Speicheranforderungen bis zu dem Punkt zu verbessern, an dem eine Echtzeitimplementierung machbar wird. Es wird gezeigt, dass die Modifikation rechnerisch stabiler ist als der traditionelle Ritz-Ansatz. Das erste Anliegen der Arbeit ist es, den Algorithmus zu beschreiben und seine Eigenschaften als gültiges und nützliches numerisches Verfahren zu etablieren. Insbesondere werden für das Verfahren solche nützlichen Eigenschaften wie Eindeutigkeit und Angemessenheit der Bedingung festgestellt. Der zweite Teil der Arbeit widmet sich einem Vergleich der neuen Techniken mit dem Standardverfahren der numerischen Integration einer Matrix-Riccati-Gleichung zur Bestimmung einer Rückkopplungsmatrix. Die neue Technik ist bei vergleichbarer Genauigkeit deutlich schneller."}
{"DOCID": "2187", "TEXT": "Informatik: Ein konzeptioneller Rahmen für die Lehrplanplanung: Es werden zwei Sichtweisen der Informatik betrachtet: eine globale Sichtweise, die versucht, breite Merkmale des Fachgebiets und seine Beziehungen zu anderen Fachgebieten zu erfassen, und eine lokale Sichtweise, die sich auf die innere Struktur des Fachgebiets konzentriert . Diese Struktur wird in Bezug auf die Arten von Wissen, Problemen und Aktivitäten, die innerhalb der Disziplin existieren, sowie die Beziehungen zwischen ihnen dargestellt. Es wird ein Ansatz zur Curriculumplanung in der Informatik vorgestellt, der sich an der Struktur des Faches orientiert, an der Tatsache, dass Wandel ein wichtiges Merkmal der Situation ist, und an der Erwartung, dass die Informatik ihre Arbeitskontakte mit anderen Disziplinen weiter ausbauen wird ."}
{"DOCID": "2188", "TEXT": "Ein Ansatz für das optimale Design von Computergrafiksystemen: Entwickler von Anzeigesystemen stehen vor der schwierigen Aufgabe, wichtige Subsysteme auf intelligente Weise auszuwählen. Jedes Teilsystem wird aus einer großen Anzahl von Alternativen ausgewählt; die Auswahl basiert auf Erwägungen wie Systemreaktionszeit, Systemkosten und der Verteilung der Datenspeicherung und -verarbeitung zwischen dem Grafikprozessor und seinem unterstützenden Datenverarbeitungssystem. Die hier berichtete Arbeit entwickelt ein objektives, quantitatives Entwurfsverfahren und trägt zu einem besseren Verständnis der Konfiguration von Anzeigesystemen bei. Dies wird mittels eines mathematischen Modells eines computergesteuerten Graphiksystems erreicht. Die Parameter des Modells sind Funktionen der Fähigkeiten der Grafikhardware und der Rechenanforderungen der Grafikanwendung. Das Modell kann unter Verwendung einer numerischen Warteschlangenanalyse oder Simulation analysiert werden, um eine durchschnittliche Antwortzeitvorhersage zu erhalten. Durch Kombinieren des Modells mit einer Optimierung wird die beste Grafiksystemkonfiguration unter Kostenbeschränkung für mehrere Anwendungen gefunden. Die optimalen Konfigurationen werden wiederum verwendet, um allgemeine Designrichtlinien für Anzeigesysteme zu finden."}
{"DOCID": "2189", "TEXT": "Generierung von Rosenkranz-Permutationen, ausgedrückt in Hamiltonkreisen: Es wird die systematische Generierung einer bestimmten Klasse von Permutationen beschrieben, die grundlegend für Scheduling-Probleme sind. In einem nicht orientierten vollständigen Graphen mit n Eckpunkten sind Hamitonsche Kreise äquivalent zu 0,5 (n - 1)! spezifische Permutationen von n Elementen, Rosenkranzpermutationen genannt, können definiert werden. Jede von ihnen entspricht zwei kreisförmigen Permutationen, die einander spiegelbildlich sind, und wird sukzessive von einem Zahlensystem erzeugt, das 3*4*...*(n-1) Kantensätze umfasst. Jede Kantenmenge {E[k]}, 1 <= E[k] <= k, 3 <= k <= (n-1) wird rekursiv bestimmt, indem aus einem Hamiltonkreis mit k ein Hamiltonkreis mit k Knoten konstruiert wird -1 Knoten, beginnend mit dem Hamilton-Kreis von 3 Knoten. Die Grundoperation besteht aus der Transposition eines Paares benachbarter Eckpunkte, wobei die Position des Paares in der Permutation durch {E[k]} bestimmt wird. Zwei Algorithmen, die dasselbe Beispiel für fünf Scheitelpunkte behandeln, werden vorgestellt. Es ist sehr einfach, alle möglichen n abzuleiten! Permutationen von .5(n - 1 )! Rosenkranz-Permutationen bestehen darin, die Permutationen zu durchlaufen und sie in umgekehrter Reihenfolge durchzuführen - Verfahren, die ziemlich effizient vom Computer durchgeführt werden können."}
{"DOCID": "2190", "TEXT": "Funktionsminimierung"}
{"DOCID": "2191", "TEXT": "ALGORITHMUS 410 Partielles Sortieren [M1]"}
{"DOCID": "2192", "TEXT": "Ein weiteres Prinzip der Rekursionsinduktion: Eine induktive Methode zum Beweisen von Dingen über rekursiv definierte Funktionen wird beschrieben. Es hat sich als nützlich erwiesen, um die Äquivalenz von Teilfunktionen zu beweisen, und ist daher in Beweisen über Interpreter für Programmiersprachen anwendbar."}
{"DOCID": "2193", "TEXT": "Über die Implementierung von Label-Variablen: Variablen des Label-Modus werden herkömmlicherweise mit einer Technik implementiert, die bestimmte Programmierfehler nicht abfangen kann. Feinkörnige Kalenderuhren sind seit kurzem verfügbar; diese ermöglichen die Implementierung von Label-Variablen über eine neue Technik, die alle Programmierfehler dieser Art abfängt."}
{"DOCID": "2194", "TEXT": "Wie man die Adressen kurz hält: Es wird ein Algorithmus vorgestellt, um die Summe der Längen der von einem Assembler oder Compiler erzeugten Codierblöcke zu minimieren, wenn (1) angenommen wird, dass die Länge jeder Computeranweisung entweder \"lang\" oder \"kurz\" ist \" (\"lang\", wenn die adressierte Speicherstelle mehr als eine vorbestimmte Entfernung von der aktuellen Stelle entfernt ist; andernfalls \"kurz\"), und (2) es gibt Befehlsblöcke, deren Anfänge (Ursprünge) durch vorbestimmte Beträge getrennt sind. Beispielsweise erlauben einige Computer entweder eine 8-Bit-Adressierung (interpretiert relativ zum Positionszähler) oder eine vollständige 16-Bit-Adressierung des gesamten Speichers. Beim Zusammenstellen oder Kompilieren von zwei oder mehr Befehlsblöcken, die viele gegenseitige Referenzen in einem solchen Computer haben, gibt es kein einfaches iteratives Verfahren, um so viele der Adressen wie möglich kurz zu halten. Diese Arbeit zeigt, dass eine breite Klasse von Problemen dieser Art formuliert werden kann, indem sie Probleme abdeckt, die mittels elementarer arithmetischer Operationen an den Spaltenvektoren einer ternären Matrix lösbar sind."}
{"DOCID": "2195", "TEXT": "Zur optimalen Erkennung von Kurven in verrauschten Bildern: Es wird eine Technik zur Erkennung von Liniensystemen vorgestellt. Bei dieser Technik ist die Heuristik des Problems nicht in den Erkennungsalgorithmus eingebettet, sondern wird in einer Gütezahl ausgedrückt. Ein mehrstufiger Entscheidungsprozess ist dann in der Lage, im Eingangsbild das optimale Liniensystem gemäß der vorgegebenen Gütezahl zu erkennen. Durch den globalen Ansatz wird eine größere Flexibilität und Angemessenheit in der jeweiligen Problemstellung erreicht. Anschließend wird der Zusammenhang zwischen der Struktur der Gütezahl und der Komplexität des Optimierungsprozesses diskutiert. Das beschriebene Verfahren ist für eine parallele Verarbeitung geeignet, da die Operationen bezüglich jedes Zustands parallel berechnet werden können und die Anzahl der Stufen gleich der Länge N der Kurven ist (oder log 2 N, wenn das Näherungsverfahren verwendet wird)."}
{"DOCID": "2196", "TEXT": "Ein Mensch-Maschine-Ansatz zur Lösung des Problems des Handlungsreisenden: Das Problem des Handlungsreisenden gehört zu einer wichtigen Klasse von Planungs- und Routingproblemen. Es ist auch ein Unterproblem bei der Lösung anderer, wie beispielsweise des Lagerverteilungsproblems. Es wurde von vielen mathematischen Methoden angegriffen, aber mit mäßigem Erfolg. Nur für spezielle Formen des Problems oder für Probleme mit einer moderaten Anzahl von Punkten kann es exakt gelöst werden, selbst wenn sehr viel Rechenzeit verwendet wird. Heuristische Verfahren wurden vorgeschlagen und mit nur geringfügig besseren Ergebnissen getestet. Dieses Papier beschreibt eine computergestützte heuristische Technik, die nur eine bescheidene Menge an Computerzeit in Echtzeit verwendet, um große (100–200) Punkteprobleme zu lösen. Diese Technik nutzt sowohl die Problemlösungsfähigkeiten des Computers als auch die des Menschen. Der Computer soll das Problem nicht wie in vielen heutigen Heuristiken auf brutale Weise lösen, sondern er soll die Daten für den Menschen so organisieren, dass der Mensch das Problem leicht lösen kann. Die in diesem Beitrag verwendete Technik scheint neue Richtungen im Bereich der Mensch-Maschine-Interaktion und im Bereich der künstlichen Intelligenz aufzuzeigen."}
{"DOCID": "2197", "TEXT": "Der Vorteil regionaler Computernetzwerke: Eines der vorgeschlagenen Mittel zur Stimulierung der Verbreitung von Computerkapazitäten in Hochschulen ist der Aufbau regionaler Computernetzwerke. Ein solches Netzwerk wurde in der San Francisco Bay Area von der Stanford University aufgebaut. Dieses Papier berichtet über die Erfahrungen aus dem Betrieb des Netzwerks in den letzten zwei Jahren. Eine wesentliche Auswirkung des Netzwerks war weniger die an die Schulen gelieferte Computerleistung als vielmehr das Erwachen des Computerbewusstseins und die Förderung der Fähigkeitsentwicklung an diesen Schulen. Das Fachwissen und die Unterstützung durch die zentrale Einrichtung sowie der Ideenaustausch unter den Teilnehmern waren weitere wichtige Vorteile. Es wurde festgestellt, dass sowohl die Qualität als auch die Vielfalt der von der zentralen Einrichtung bereitgestellten Dienste eine Schlüsselrolle für die Effektivität des Netzwerks spielen. Ein regionales Netzwerk bringt viele Vorteile mit sich und sollte nicht nur als Lieferant roher Computerleistung beurteilt werden."}
{"DOCID": "2198", "TEXT": "Introduction to \"Feature Analysis of Generalized Database Management Systems\": Dieses Papier ist eine separat veröffentlichte Einführung zu einem Hauptbericht, der die Merkmale von generalisierten Datenbankverwaltungssystemen analysiert. Diese Einführung gibt einen Überblick über den aktuellen Stand der Technik in diesen Systemen und diskutiert die Unterschiede und Ähnlichkeiten zwischen Fähigkeiten, die in Wirtssprachensystemen gefunden werden, und denen, die in eigenständigen Systemen gefunden werden. Nach einer Diskussion der Probleme der Datenunabhängigkeit und -bindung werden die vier Benutzerebenen identifiziert und beschrieben. Technische Probleme, mit denen zukünftige Designer konfrontiert sind, werden beschrieben. Die erste besteht darin, vorhandene gespeicherte Daten zu handhaben, und die nächste darin, komplexere Datenstrukturen als die bereits in herkömmlichen Programmiersprachen verfügbaren bereitzustellen. Das Problem von Abfrage- und Aktualisierungsfunktionen auf hoher Ebene, die auf Netzwerkstrukturen einwirken, wird erwähnt, gefolgt von einer Erörterung des Problems der Bewältigung eines großen Volumens von Transaktionen, die von Endgeräten durch parametrische Benutzer – der niedrigsten Ebene von Benutzern – initiiert werden. Die Verwendung von Cobol als Grundlage für weitere Entwicklungsarbeiten wird in Bezug auf Datenstrukturen, Hostsprachenfähigkeiten und eigenständige Fähigkeiten ausführlich betrachtet. Dieser Abschnitt bewertet auch die Wirkung der Vorschläge der Datenbank-Arbeitsgruppe. Der letzte Abschnitt umreißt die zehn Hauptthemen im Hauptteil des vollständigen Berichts."}
{"DOCID": "2199", "TEXT": "Ein Sparse-Matrix-Paket (Teil I) [F4] (Algorithmus 408)"}
{"DOCID": "2200", "TEXT": "Über die Komplementdivision: Das Theorem des Divisionsalgorithmus wird in einer Form ausgedrückt, die es ihm ermöglicht, als Grundlage für die Entwicklung von Divisionsoperationen zu dienen, die sowohl den Quotienten als auch den Rest in Komplementform erzeugen. Algorithmen zur Division, die Komplementergebnisse liefern, werden für Zahlen abgeleitet, die in einer beliebigen Basis größer als eins dargestellt werden. Es werden sowohl Radix- als auch Radix-weniger-eins-Komplementierungsschemata betrachtet. Die binäre Form der Algorithmen beinhaltet somit sowohl die Zweier- als auch die Einerkomplement-Implementierung. Das Problem des Quotientenüberlaufs für Komplementergebnisse wird ebenso behandelt wie das der Auswahl einer geeigneten Form der Restbedingung für die Komplementdivision."}
{"DOCID": "2201", "TEXT": "Animator: Ein zweidimensionales Online-Filmanimationssystem: Animator ist ein Computeranimationssystem, das entwickelt wurde, um einige der inhärenten Nachteile herkömmlicher Computeranimationstechniken zu überwinden die Trial-and-Error-Gestaltung von Bildsequenzen im Gesprächsmodus. Während aller Phasen des Systems bleiben die Eingabeelemente (Lichtgriffel, Drucktasten und Fernschreiber) erhalten. Auf Anforderung des Benutzers wird dieser Datensatz an IBM 360/75 gesendet, wo die S-D 4020-Anweisungen erzeugt werden können, die zum Erzeugen derselben Bildfolge erforderlich sind. Es wird erwartet, dass einer der Hauptbeiträge von Animator die Bereitstellung einer Einrichtung sein wird, die es jedem Professor ermöglicht, seine eigenen erklärenden Filmstreifen zu produzieren."}
{"DOCID": "2202", "TEXT": "Dynamische Mikroprogrammierung: Prozessororganisation und -programmierung: Ein dynamisch mikroprogrammierter Prozessor ist durch einen kleinen (4^k 64-Bit-Wort) Lese-Schreib-„Mikro“-Speicher gekennzeichnet. Die Zugriffszeit dieses Speichers ist ähnlich der Zykluszeit der Maschine (50–100 nsec). Dieser Mikrospeicher wird verwendet, um sowohl Daten als auch Subroutinen zu enthalten. Die (Mikro-)Befehle in einem solchen Prozessor unterscheiden sich von den herkömmlichen darin, dass sie nur rein kombinatorische Operationen ausführen; die Sequenzierung steht unter der Kontrolle des Mikrobefehls. Das Vorhandensein des Lese-Schreib-Mikrospeichers ermöglicht eine flexiblere Zuweisung von Ressourcen als der Nur-Lese-Speicher. Insbesondere betont der in dieser Veröffentlichung entwickelte Prozessor den gleichzeitigen Betrieb (innerhalb des Mikrobefehls) des Addierers, Verschiebers, Maskierers und der Testeinrichtungen des Prozessors. Eine Mikroassemblierungssprache wird entwickelt und der mit Unterroutinenverknüpfungen verbundene Overhead wird analysiert. Die Effizienz eines flexiblen Software-Verknüpfungsschemas wird hinsichtlich seines Overheads für verschiedene Subroutinen-Eigenschaften untersucht. Abschließend werden drei Beispiele problemorientierter Programmierung betrachtet und die resultierende Codierung mit einer System/360-Version in Assemblersprache verglichen, wobei die Technologie normalisiert wurde."}
{"DOCID": "2203", "TEXT": "Schlüssel-zu-Adresse-Umwandlungstechniken: Eine grundlegende Leistungsstudie zu großen vorhandenen formatierten Dateien: Die Ergebnisse einer Studie von acht verschiedenen Schlüssel-zu-Adresse-Umwandlungsmethoden, die auf eine Reihe bestehender Dateien angewendet wurden, werden vorgestellt. Da jede Methode auf eine bestimmte Datei angewendet wird, variieren Lastfaktor und Bucket-Größe über einen weiten Bereich. Außerdem nehmen geeignete Variablen, die nur für ein bestimmtes Verfahren relevant sind, unterschiedliche Werte an. Die Leistung jeder Methode wird in Form der Anzahl der Zugriffe zusammengefasst, die erforderlich sind, um zu einem Datensatz zu gelangen, und der Anzahl der Überlaufdatensätze, die durch eine Umwandlung erstellt werden. Besonderheiten der einzelnen Methoden werden diskutiert. Aus den Ergebnissen abgeleitete praktische Richtlinien werden angegeben. Abschließend wird ein Vorschlag für eine weitere quantitative Grundlagenstudie skizziert."}
{"DOCID": "2204", "TEXT": "Programmentwicklung durch schrittweise Verfeinerung: Die kreative Tätigkeit des Programmierens – zu unterscheiden vom Codieren – wird üblicherweise anhand von Beispielen vermittelt, die der Demonstration bestimmter Techniken dienen. Es wird hier als eine Folge von Entwurfsentscheidungen betrachtet, die die Zerlegung von Aufgaben in Teilaufgaben und von Daten in Datenstrukturen betreffen. Der Prozess der sukzessiven Verfeinerung von Spezifikationen wird durch ein kurzes, aber nicht triviales Beispiel illustriert, aus dem einige Rückschlüsse auf die Kunst und den Unterricht des Programmierens gezogen werden."}
{"DOCID": "2205", "TEXT": "DIFSUB zur Lösung gewöhnlicher Differentialgleichungen [D2] (Algorithmus 407)"}
{"DOCID": "2206", "TEXT": "Exakte Lösung linearer Gleichungen unter Verwendung von Restarithmetik [F4] (Algorithmus 406)"}
{"DOCID": "2207", "TEXT": "Die automatische Integration gewöhnlicher Differentialgleichungen: Es wird ein Integrationsverfahren zur automatischen Lösung eines Anfangswertproblems für einen Satz gewöhnlicher Differentialgleichungen beschrieben. Es wird ein Kriterium für die Auswahl der Approximationsordnung vorgeschlagen. Das Ziel des Kriteriums besteht darin, die Schrittweite zu erhöhen, um die Lösungszeit zu verkürzen. Eine Option erlaubt die Lösung \"steifer\" Differentialgleichungen. Ein Programm, das die diskutierten Techniken verkörpert, erscheint im Algorithmus 407."}
{"DOCID": "2208", "TEXT": "Speichernutzung in einer Speicherhierarchie, wenn die Speicherzuweisung durch einen Hashing-Algorithmus durchgeführt wird: Die Speichernutzung wird in einer zweistufigen Speicherhierarchie untersucht. Die erste Lagerebene, das Schnelllager, ist in mehrere Lagerbereiche unterteilt. Wenn ein Eintrag in der Hierarchie abgelegt werden soll, versucht ein Hash-Algorithmus, den Eintrag in einem dieser Bereiche zu platzieren. Wenn dieser bestimmte Bereich voll ist, dann wird der Eintrag in dem langsameren Speicher der zweiten Ebene angeordnet, selbst wenn andere Bereiche im Speicher der ersten Ebene möglicherweise Platz zur Verfügung haben. Unter der Voraussetzung, dass N Einträge in der gesamten Hierarchie abgelegt wurden, wird ein Ausdruck für die erwartete Anzahl von Einträgen abgeleitet, die im Speicher der ersten Ebene abgelegt wurden. Dieser Ausdruck gibt an, wie effektiv der Speicher der ersten Ebene verwendet wird. Anhand von Beispielen wird dann die Speicherauslastung in Abhängigkeit vom Hashalgorithmus, der Anzahl der Speicherbereiche, in die der First-Level-Speicher aufgeteilt ist, und der Gesamtgröße des First-Level-Speichers untersucht."}
{"DOCID": "2209", "TEXT": "Ein Planungsalgorithmus für ein computergestütztes Registrierungssystem: Dieses Papier stellt den Planungsalgorithmus vor, der im computergestützten Registrierungssystem an der Universität von Tennessee verwendet wird. Die Notation wird definiert und die Logik des Algorithmus beschrieben, der zur Umsetzung der Bildungspolitik erforderlich ist. Ergebnisse aus der Umsetzung des ersten Semesters werden vorgestellt."}
{"DOCID": "2210", "TEXT": "Auf dem Weg zur automatischen Programmsynthese: Es wird ein elementarer Überblick über den theorembeweisenden Ansatz zur automatischen Programmsynthese gegeben, ohne auf technische Details einzugehen. Das Verfahren wird durch die automatische Konstruktion sowohl rekursiver als auch iterativer Programme veranschaulicht, die mit natürlichen Zahlen, Listen und Bäumen arbeiten. Um ein Programm zu konstruieren, das bestimmte Spezifikationen erfüllt, wird ein durch diese Spezifikationen induziertes Theorem bewiesen, und das gewünschte Programm wird daraus extrahiert nachweisen. Die gleiche Technik wird angewendet, um rekursiv definierte Funktionen in iterative Programme umzuwandeln, häufig mit einer großen Verstärkungsineffizienz. Es wird betont, dass zur Konstruktion eines Programms mit Schleifen oder mit Rekursion das Prinzip der mathematischen Induktion angewendet werden muss. Die Beziehung zwischen der verwendeten Version der Induktionsregel und der Form des konstruierten Programms wird ausführlich untersucht."}
{"DOCID": "2211", "TEXT": "Computergrafik mit gescannter Anzeige: Ein fernsehähnliches System mit gescannter Anzeige wurde erfolgreich auf einer Honeywell DDP-224-Computerinstallation implementiert. Das abgetastete Bild wird im Kernspeicher des Computers gespeichert, und eine Software-Abtastumwandlung wird verwendet, um die rechtwinkligen Koordinaten eines Punktes in das entsprechende Wort und Bit in einem Ausgabeanzeigearray im Kernspeicher umzuwandeln. Die bisherigen Ergebnisse zeigen, dass flimmerfreie Anzeigen großer Datenmengen mit einigermaßen schneller grafischer Interaktion möglich sind. Ein gescanntes Bild der Größe 240 x 254 Punkte wird mit einer Rate von 30 Bildern pro Sekunde angezeigt."}
{"DOCID": "2212", "TEXT": "F-VERTEILUNG"}
{"DOCID": "2213", "TEXT": "Wurzeln von Matrixstiften: Das verallgemeinerte Eigenwertproblem [F2] (Algorithmus 405)"}
{"DOCID": "2214", "TEXT": "Komplexe Intervallarithmetik: Die komplexe Intervallarithmetik wird unter Verwendung der reellen Intervallarithmetik definiert. Komplexe Intervalleinteilung wird definiert, um kleinstmögliche resultierende Intervalle sicherzustellen."}
{"DOCID": "2215", "TEXT": "Anwendung von Spielbaum-Suchtechniken auf die sequentielle Mustererkennung: Ein sequentielles Mustererkennungsverfahren (SPR) testet nicht alle Merkmale eines Musters auf einmal. Stattdessen wählt es ein zu testendes Merkmal aus. Nach Erhalt des Ergebnisses dieses Tests klassifiziert das Verfahren entweder das unbekannte Muster oder wählt ein anderes zu testendes Merkmal aus usw. Die medizinische Diagnose ist ein Beispiel für SPR. In diesem Beitrag schlagen die Autoren vor, SPR als ein Ein-Personen-Spiel gegen die Natur (den Zufall) zu betrachten. Nahezu alle leistungsstarken Techniken, die zum Durchsuchen von streng konkurrierenden Zwei-Personen-Spielbäumen entwickelt wurden, können leicht entweder direkt oder analog in SPR-Verfahren integriert werden. Insbesondere kann man das \"Mini-Average-Backup-Verfahren\" und das \"Gamma-Verfahren\" einbeziehen, die die Analoga des \"Minimax-Backup-Verfahrens\" bzw. des \"Alpha-Beta-Verfahrens\" sind. Einige computersimulierte Experimente zur Zeichenerkennung werden vorgestellt. Die Ergebnisse zeigen, dass der Ansatz vielversprechend ist."}
{"DOCID": "2216", "TEXT": "Zur Wahrscheinlichkeitsverteilung der Werte von Binärbäumen: Für die Erzeugungsfunktion für Binärbaumwerte wird eine Integralgleichung hergeleitet, wobei die Werte den Sortieraufwand widerspiegeln. Die Analyse geht nicht von gleichmäßig verteilten Verzweigungsverhältnissen aus und ist daher auf eine Familie von Sortieralgorithmen anwendbar, die von Hoare, Singleton und van Emden diskutiert werden. Die Lösung der Integralgleichung zeigt, dass die Verwendung fortschrittlicherer Algorithmen in der Familie den erwarteten Sortieraufwand nur geringfügig reduziert, aber die Varianz des Sortieraufwands erheblich reduziert. Statistische Tests der Werte mehrerer tausend Bäume mit bis zu 10.000 Punkten haben erste, zweite und dritte Momente der Wertverteilungsfunktion in zufriedenstellender Übereinstimmung mit den aus der Erzeugungsfunktion berechneten Momenten ergeben. Sowohl die empirischen Tests als auch die analytischen Ergebnisse stimmen im ersten Moment für die Fälle von gleichmäßiger und ungleichmäßiger Verteilung des Verzweigungsverhältnisses und im zweiten Moment für den Fall von gleichmäßiger Verteilung des Verzweigungsverhältnisses mit zuvor veröffentlichten Ergebnissen überein."}
{"DOCID": "2217", "TEXT": "Experimente zum automatischen Lernen für ein heuristisches Mehrzweckprogramm: Eine automatische Lernfähigkeit wurde zur Verwendung mit dem heuristischen Baumsuchprogramm MULTIPLE (MULTIpurpose Program that LEArns) entwickelt und implementiert, das derzeit auf den Beweis von Auflösungstheoremen im Prädikatenkalkül angewendet wird. Das Prüfprogramm (PP) von MULTIPLE verwendet zwei Bewertungsfunktionen, um seine Suche nach einem Beweis dafür zu leiten, ob ein bestimmtes Ziel erreichbar ist oder nicht. Dreizehn allgemeine Merkmale von Prädikatenkalkülklauseln wurden zur Verwendung beim automatischen Lernen besserer Bewertungsfunktionen für PP geschaffen. Ein multiples Regressionsprogramm wurde verwendet, um hinsichtlich der Merkmale optimale Koeffizienten für lineare Polynomfunktionen zu erzeugen. Außerdem wurden automatische Datenverarbeitungsroutinen geschrieben, um Daten zwischen dem Lernprogramm und dem Prüfungsprogramm auszutauschen und die Ergebnisse zu analysieren und zusammenzufassen. Die Daten wurden im Allgemeinen zum Lernen (Regressionsanalyse) aus der Erfahrung mit PP erhoben. Eine Reihe von Experimenten wurde durchgeführt, um die Wirksamkeit und Allgemeingültigkeit des Lernprogramms zu testen. Die Ergebnisse zeigten, dass das Lernen dramatische Verbesserungen bei der Lösung von Problemen hervorrief, die in derselben Domäne lagen wie diejenigen, die für die Sammlung von Lerndaten verwendet wurden. Es wurde auch gezeigt, dass sich das Lernen erfolgreich auf andere Bereiche als die für die Datenerfassung verwendeten verallgemeinern lässt. Ein weiteres Experiment zeigte, dass das Lernprogramm gleichzeitig die Leistung bei Problemen in einem bestimmten Bereich und bei Problemen in einer Vielzahl von Bereichen verbessern konnte. Einige Variationen des Lernprogramms wurden ebenfalls getestet."}
{"DOCID": "2218", "TEXT": "Eine Analyse einiger Time-Sharing-Techniken: Die Wirksamkeit bestimmter Time-Sharing-Techniken wie Programmieren, Verschieben, Minimierung der Plattenrotationsverzögerung und Minimierung des Austauschvolumens wird untersucht. Zusammenfassende Daten werden präsentiert, und die Ergebnisse werden diskutiert. Das Vehikel für diese Untersuchung war ein SIMULA-basiertes Simulationsmodell, das einen frühen Rahmen für ein geplantes Time-Sharing-System Burroughs B6500 widerspiegelt. Da das B6500-System auf der Verwendung von Segmenten mit variabler Größe und einem dynamischen Overlay-Verfahren basiert, werden auch Daten präsentiert, die einen gewissen Hinweis auf die Effektivität dieser Art von Organisation in einer Time-Sharing-Umgebung liefern. Die Konstruktionsmerkmale und Betriebsfähigkeiten des Simulationsmodells werden ebenfalls beschrieben."}
{"DOCID": "2219", "TEXT": "Ein richtliniengesteuerter Scheduler für ein Time-Sharing-System: Der Dienst, der von einem Prozess von einem Time-Sharing-Betriebssystem empfangen wird, kann durch eine Ressourcenzählung SUM{w[i]R[ij]} gekennzeichnet werden, wobei R[ij] die ist Anzahl der Diensteinheiten, die der Prozess i von der Ressource i erhält, und w[i] die Kosten pro Diensteinheit sind. Jede Klasse von Benutzern kann durch eine Richtlinienfunktion charakterisiert werden, die die Servicemenge angibt, die ein Benutzer, der zu dieser Klasse gehört, als Funktion der Zeit erhalten sollte. Die Priorität ändert sich dynamisch als Funktion der Differenz zwischen dem Dienst, der dem Benutzer von der Richtlinienfunktion zugesagt wird, und dem Dienst, den er tatsächlich erhält. Ein Scheduling- und Swapping-Algorithmus, der die Ressourcenanzahl jedes Prozesses über seiner Richtlinienfunktion hält, stellt das angegebene Serviceniveau bereit. Overhead kann reduziert werden, indem Austauschvorgänge von Prozessen vermieden werden, die mindestens sein Dienstniveau erhalten haben. Der Algorithmus wurde in einem Allzweck-Betriebssystem implementiert und hat für interaktive und Batch-Jobs einen wesentlich besseren Service bereitgestellt als der vorherige Scheduler."}
{"DOCID": "2220", "TEXT": "Umwandlung von Entscheidungstabellen mit begrenztem Eintrag in Computerprogramme – eine vorgeschlagene Modifikation des Pollack-Algorithmus: Pollack hat einen Algorithmus zum Umwandeln von Entscheidungstabellen in Flussdiagramme vorgeschlagen, der die nachfolgende Ausführungszeit minimiert, wenn er in ein Computerprogramm kompiliert wird. Zwei Modifikationen dieses Algorithmus werden vorgeschlagen. Die erste stützt sich auf Shannons geräuschloses Codierungstheorem und das Kommunikationskonzept der Entropie, testet aber die ELSE-Regel nicht vollständig. Die zweite Modifikation testet die ELSE-Regel vollständig, führt aber zu mehr Ausführungen als die erste Modifikation. Beide Modifikationen ergeben eine Modifikation, die eine global optimale Lösung garantiert."}
{"DOCID": "2221", "TEXT": "Kommentar zur Umwandlung von Entscheidungstabellen in Computerprogramme"}
{"DOCID": "2222", "TEXT": "Kommentar zu Londons Zertifizierung des Algorithmus 245"}
{"DOCID": "2223", "TEXT": "Minit-Algorithmus für lineare Programmierung (Algorithmus 222 [H])"}
{"DOCID": "2224", "TEXT": "Komplexe Gammafunktion [S14] (Algorithmus 404)"}
{"DOCID": "2225", "TEXT": "Zirkuläre ganzzahlige Partitionierung [A1] (Algorithmus 403)"}
{"DOCID": "2226", "TEXT": "Weitere Beweise für die Analyse von Algorithmen für das Null-Eins-Programmierproblem: Der Zweck dieser Anmerkung ist es, zusätzlich zu den kürzlich von Gue et al. zusammengefassten Rechenerfahrungen mit zwei Algorithmen für das Null-Eins-Programmierproblem zu berichten. Ein Fehler in Gues Artikel wurde korrigiert. Die Nützlichkeit eines der Algorithmen als Suboptimierer wird angezeigt."}
{"DOCID": "2227", "TEXT": "Beweis eines Programms: FIND: Es wird ein Beweis für die Korrektheit des Algorithmus \"Find\" erbracht. Zunächst erfolgt eine informelle Beschreibung des Zwecks des Programms und der verwendeten Methode. Es wird eine systematische Technik beschrieben, um den Programmbeweis während des Prozesses seiner Codierung so zu konstruieren, dass das Eindringen von logischen Fehlern verhindert wird. Der Kündigungsnachweis wird als gesonderte Übung behandelt. Abschließend werden einige Schlussfolgerungen zur allgemeinen Programmiermethodik gezogen."}
{"DOCID": "2228", "TEXT": "Anmerkungen zur Verhinderung von System-Deadlocks: Es wird die Methode von Habermann zur Verhinderung von Deadlocks besprochen, bei der Deadlock als ein Systemzustand definiert wird, von dem aus Ressourcenzuweisungen an bestimmte Prozesse nicht möglich sind. Es wird gezeigt, dass der Scheduler \"künstliche\" Deadlocks einführen kann, die das Verfahren von Habermann nicht verhindert. Permanentes Blockieren ist die Situation, in der bestimmte Prozesse ihre Ressourcenanforderungen nie erhalten. Es wird gezeigt, dass Deadlock-Prävention nicht zwangsläufig dauerhafte Blockierungen beseitigt. Es wird ein Verfahren zum Verhindern einer dauerhaften Blockierung angegeben."}
{"DOCID": "2229", "TEXT": "Konstruktion rationaler und negativer Potenzen einer formalen Reihe: Es werden einige Verfahren zur Erzeugung gebrochener und negativer Potenzen beliebiger formaler Reihen, wie z. B. Poisson-Reihen oder Tschebyscheff-Reihen, beschrieben. Es wird gezeigt, dass mit Hilfe der drei elementaren Operationen Addition, Subtraktion und Multiplikation alle rationalen (positiven und negativen) Potenzen einer Reihe konstruiert werden können. Grundsätzlich gibt es zwei Ansätze: das Binomialtheorem und die Iterationsverfahren. Beide Methoden werden hier beschrieben und die Beziehung zwischen ihnen aufgezeigt. Einige wohlbekannte klassische Formeln werden als Sonderfälle erhalten, und es wird gezeigt, wie die Konvergenzeigenschaften dieser Formeln mit sehr wenig zusätzlichen Berechnungen verbessert werden können. Abschließend werden am Ende des Artikels einige numerische Experimente mit Tschebyscheff-Reihen und mit Fourier-Reihen beschrieben."}
{"DOCID": "2230", "TEXT": "Eine Sprache zur Behandlung geometrischer Muster in einem zweidimensionalen Raum: In diesem Artikel wird CADEP, eine problemorientierte Sprache zur Positionierung geometrischer Muster in einem zweidimensionalen Raum, vorgestellt. Obwohl die Sprache speziell für die automatische Generierung von Masken für integrierte Schaltungen entwickelt wurde, erweist sie sich auch für andere Platzierungsprobleme wie Architekturdesign, Stadtplanung, logische und Blockdiagrammdarstellung als gut geeignet. Dargestellt werden die Gestaltungskriterien, der Aufbau und die Besonderheiten von CADEP."}
{"DOCID": "2231", "TEXT": "Die Rekonstruktion binärer Muster aus ihren Projektionen: Können wir angesichts der horizontalen und vertikalen Projektionen eines endlichen binären Musters f das ursprüngliche Muster f konstruieren? In diesem Beitrag geben wir eine Charakterisierung von Mustern, die aus ihrer Projektion rekonstruierbar sind. Drei Algorithmen werden entwickelt, um sowohl eindeutige als auch mehrdeutige Muster zu rekonstruieren. Es wird gezeigt, dass ein eindeutiges Muster in der Zeit m x n perfekt rekonstruiert werden kann und dass ein einem mehrdeutigen Muster ähnliches Muster auch in der Zeit m x n konstruiert werden kann, wobei m, n die Abmessungen des Musterrahmens sind."}
{"DOCID": "2232", "TEXT": "Musterbreite bei einem gegebenen Winkel: Dass das Mustermerkmal „Breite als Funktion des Winkels“ mehrere mögliche Interpretationen besitzt, wird in diesem Artikel demonstriert, der einen Überblick über das Breitenkonzept bei der Mustererkennung und das geometrische Konzept selbst gibt. Das Ziel der Arbeit besteht darin, zu klären, wie die Wortbeschreibung präzisiert werden kann, damit Computeralgorithmen für die Merkmalsextraktion erhalten werden können; Der Schwerpunkt liegt auf den theoretischen Inhalten. Die Ergebnisse bestehen aus einer mengentheoretischen Definition der Breite im Winkel, einem Satz, der sie mit dem Radiusvektor der Mustergrenze in Beziehung setzt, und Beschreibungen alternativer Breiten. Alle Breiten sind für ein anschauliches Beispiel berechnet; grafische und tabellarische Vergleiche werden gegeben. Es wird eine erhebliche Schwankung in der Breite-im-Winkel-Größe festgestellt. Die Hauptschlussfolgerung ist, dass die mengentheoretische Winkelbreite ein nützliches Mustermerkmal ist, wenn sie leicht berechnet werden kann. Eine weitere Untersuchung der Informationen, die nur in einem Teil einer Breitenfunktion enthalten sind, wird für Fälle empfohlen, in denen die Berechnung der Breite im Winkel schwierig ist."}
{"DOCID": "2233", "TEXT": "Signatursimulation und bestimmte kryptografische Codes: Drei Chiffren, die angeblich von Thomas Jefferson Beale im Jahr 1822 verfasst wurden, sind seit über 100 Jahren Gegenstand intensiver Studien. Generationen von Kryptoanalytikern haben bisher erfolglos unzählige Mannjahre damit verbracht, sie zu kodieren; Riesige Armeen von Glücksrittern und Schatzsuchern haben Herkulesarbeit darauf verwendet, die sanften Hügel von Virginia aufzugraben, um die versprochene Goldgrube zu finden. Die Geschichte einschlägiger Aktivitäten würde Bände füllen, doch ernsthafte Studenten der Kryptographie hatten schon immer nagende Zweifel an der Echtheit der Chiffren. Es wurde behauptet, dass die „bekannte Lösung“ für Chiffre Nummer Zwei: 115, 73, 24, 818, 37, 52, 49, … („Ich habe in der Grafschaft Bedford, etwa vier Meilen von Buford entfernt, bei einer Ausgrabung deponiert or vault...\") mit Hilfe einer unsauberen Version der Unabhängigkeitserklärung war lediglich ein hervorragender, phantasievoller und grandioser Schwindel, der vor Ewigkeiten aus welchen Gründen auch immer begangen wurde. Moderne Computertechnik könnte offensichtlich Signaturanalysen am Verschlüsselungsprozess selbst vornehmen, um neue Hinweise und tiefere Einblicke in deren Aufbau zu gewinnen. Zum Nutzen des Uneingeweihten verwendet das in der zweiten Chiffre verwendete Codierungsverfahren ein bestimmtes Dokument, dessen Wörter einfach fortlaufend nummeriert sind, und die Anfangsbuchstaben dieser Wörter werden zufällig gesucht, um mit den Buchstaben dieser Wörter zufällig zusammenzupassen mit den Buchstaben des Klartextes oder der Nachricht übereinstimmen. Die diesen Übereinstimmungen entsprechende Zahlenfolge wird dann als endgültiger Code aufgeschrieben. Obwohl primitiv, hat der Prozess den Vorteil relativer Sicherheit, bis das Quelldokument bekannt wird; In diesem Moment kann die Chiffre sogar von Zweitklässlern entschlüsselt werden. Die jetzt mit Hilfe unseres UNIVAC 1108 abgeschlossene Arbeit umfasst zahlreiche analytische Studien der Beale-Chiffren und verschiedene Arten von Simulationen. Zum Beispiel haben wir den gesamten Prozess der simulierten Codierung durch verschiedene Schemata auf die Maschine übertragen und die Signaturen dieser synthetischen Codes analysiert; Wir haben auch verschiedene Nachrichten von Hand codiert, indem wir verschiedene Texte und eine Vielzahl von Methoden verwendet haben, um ihre Signaturen zu erhalten. Diese Simulationen liefern überzeugende Beweise dafür, dass die Signaturen sowohl prozess- als auch datenabhängig sind; sie weisen auch sehr stark darauf hin, dass Mr. Beales Chiffren echt sind und dass es nur eine Frage der Zeit ist, bis jemand das richtige Quelldokument findet und den richtigen Tresor im Commonwealth von Virginia ausfindig macht."}
{"DOCID": "2234", "TEXT": "Wurzeln von Matrixstiften (Algorithmus R405)"}
{"DOCID": "2235", "TEXT": "Übersetzung der Entscheidungstabelle (Algorithmus R394)"}
{"DOCID": "2236", "TEXT": "Bemerkungen zu charakteristischen Werten und zugehörigen Lösungen der Mathieus-Differentialgleichung, des Exponentialintegrals und der Systeme der hyperbolischen P.D.E. (Algorithmen R352, R385, R392)"}
{"DOCID": "2237", "TEXT": "BANDSOLVE (Algorithmus R195)"}
{"DOCID": "2238", "TEXT": "Kleinste-Quadrate-Oberflächenanpassung (Algorithmus R176)"}
{"DOCID": "2239", "TEXT": "Squank (Algorithmus C379)"}
{"DOCID": "2240", "TEXT": "Pseudo-Zufallszahlen [G5] (Algorithmus C266)"}
{"DOCID": "2241", "TEXT": "Produkttyp Dreipunkt-Gauß-Legendre-Simpson-Integration [D1] (Algorithmus A439)"}
{"DOCID": "2242", "TEXT": "Produkttyp Zweipunkt-Gauss-Legendre-Simpson-Integration [D1] (Algorithmus A438)"}
{"DOCID": "2243", "TEXT": "Produkttyp Simpson-Integration [D1] (Algorithmus A437)"}
{"DOCID": "2244", "TEXT": "Produkttyp Trapezintegration (Algorithmus A436)"}
{"DOCID": "2245", "TEXT": "Trace-gesteuerte Modellierung und Analyse der CPU-Planung in einem Multiprogramming-System: Jobstream-Daten auf mikroskopischer Ebene, die in einer Produktionsumgebung durch eine ereignisgesteuerte Softwaresonde erhalten werden, werden verwendet, um ein Modell eines Multiprogramming-Computersystems zu steuern. Der CPU-Scheduling-Algorithmus des Modells wird systematisch variiert. Diese Technik, die als Trace-gesteuerte Modellierung bezeichnet wird, bietet eine genaue Nachbildung einer Produktionsumgebung zum Testen von Variationen im System. Gleichzeitig können Änderungen in Scheduling-Methoden einfach und kontrolliert durchgeführt werden, wobei Ursache-Wirkungs-Beziehungen isoliert werden. Die getesteten Scheduling-Methoden umfassten die bestmöglichen und schlechtestmöglichen Methoden, die traditionellen Methoden der Multiprogramming-Theorie, Round-Robin, Wer zuerst kommt, mahlt zuerst usw. und dynamische Prädiktoren. Die relativen und absoluten Leistungen dieser Scheduling-Verfahren sind angegeben. Es wird geschlussfolgert, dass ein erfolgreiches CPU-Scheduling-Verfahren präventiv sein muss und verhindern muss, dass ein gegebener Job die CPU für einen zu langen Zeitraum hält."}
{"DOCID": "2246", "TEXT": "Sprachniveaus für portable Software: Immer mehr Software wird in portabler Form implementiert. Ein beliebter Weg, dies zu erreichen, besteht darin, die Software in einer speziell entworfenen maschinenunabhängigen Sprache zu codieren und diese Sprache dann, häufig unter Verwendung eines Makroprozessors, in die Assemblersprache jeder gewünschten Objektmaschine abzubilden. Das Design der maschinenunabhängigen Sprache ist der Schlüsselfaktor bei dieser Operation. Dieses Papier diskutiert die relativen Vorzüge, diese Sprache auf einem hohen oder niedrigen Niveau zu platzieren, und präsentiert einige Vergleichsergebnisse."}
{"DOCID": "2247", "TEXT": "Über die zu verwendenden Kriterien bei der Zerlegung von Systemen in Module: Dieser Beitrag diskutiert Modularisierung als einen Mechanismus zur Verbesserung der Flexibilität und Verständlichkeit eines Systems bei gleichzeitiger Verkürzung seiner Entwicklungszeit. Die Wirksamkeit einer \"Modularisierung\" hängt von den Kriterien ab, die bei der Aufteilung des Systems in Module verwendet werden. Ein Systementwurfsproblem wird dargestellt und sowohl eine herkömmliche als auch eine unkonventionelle Zerlegung werden beschrieben. Es wird gezeigt, dass die unkonventionellen Zerlegungen deutliche Vorteile für die skizzierten Ziele haben. Die Kriterien, die beim Erreichen der Zerlegungen verwendet werden, werden diskutiert. Die unkonventionelle Dekomposition wird in den meisten Fällen weniger effizient sein, wenn sie mit der konventionellen Annahme implementiert wird, dass ein Modul aus einer oder mehreren Subroutinen besteht. Ein alternativer Umsetzungsansatz, der diesen Effekt nicht hat, wird skizziert."}
{"DOCID": "2248", "TEXT": "Eine neue Methode zur Lösung des Cauchy-Problems für parabolische Gleichungen: Für parabolische partielle Differentialgleichungen wird eine Integralgleichungsdarstellung angegeben. Wenn die Gleichungen in unbeschränkten Bereichen definiert sind, wie beim Anfangswert-(Cauchy-)Problem, hat die Lösung der Integralgleichung durch das Verfahren der sukzessiven Approximation inhärente Vorteile gegenüber anderen Verfahren. Fehlergrenzen für die Methoden sind von der Ordnung h^(3/2) und h^(7/2) (das ist die Inkrementgröße), abhängig von den beteiligten Finite-Differenzen-Approximationen."}
{"DOCID": "2249", "TEXT": "Ein Vergleich multivariater Normalgeneratoren: Drei Methoden zur Generierung von Ergebnissen auf multivariaten normalen Zufallsvektoren mit einer angegebenen Varianz-Kovarianz-Matrix werden vorgestellt. Es wird ein Vergleich durchgeführt, um zu bestimmen, welches Verfahren die geringste Computerausführungszeit und den geringsten Speicherplatz erfordert, wenn IBM 360/67 verwendet wird. Alle Verfahren verwenden als Basis einen Standard-Gaußschen Zufallszahlengenerator. Die Ergebnisse des Vergleichs zeigen, dass das auf Dreiecksfaktorisierung der Kovarianzmatrix basierende Verfahren im Allgemeinen weniger Speicherplatz und Rechenzeit benötigt als die beiden anderen Verfahren."}
{"DOCID": "2250", "TEXT": "Computermethoden zur Stichprobenziehung aus der Exponential- und Normalverteilung (Korrigendum)"}
{"DOCID": "2251", "TEXT": "Weighted Increment Linear Search for Scatter Tables: Eine neue lineare Suche nach Hash-Tabellen, deren Inkrementschritt eine Funktion des adressierten Schlüssels ist, wird vorgestellt. Es werden Vergleiche mit bekannten Verfahren im Hinblick auf Effizienz und Berechnungskomplexität gegeben. Insbesondere gilt das neue Verfahren für Tabellen der Größe n = 2^r. Es ermöglicht eine vollständige Tabellensuche und eliminiert praktisch das primäre Clustering zu sehr geringen Kosten."}
{"DOCID": "2252", "TEXT": "Ein Verfahren zum inkrementellen Kompilieren von Sprachen mit verschachtelter Anweisungsstruktur: Es wird ein Verfahren zum inkrementellen Kompilieren vorgestellt, das insbesondere für Programmiersprachen gilt, in denen Anweisungen verschachtelt werden können (wie Algol und PL/I). Das Verfahren ermöglicht das Editieren der Quellsprache unter Verwendung eines Allzweck-Texteditors und die inkrementelle Verarbeitung von Änderungen ohne häufiges Neukompilieren ganzer Routinen. Die wesentlichen Punkte des Verfahrens sind: (1) die Syntax der Sprache ist dahingehend eingeschränkt, welche Konstrukte auf Zeilen vorkommen dürfen; (2) eine interne Datenstruktur (als Skeleton bezeichnet) wird aufrechterhalten, um die Anweisungsstruktur darzustellen; (3) die Neukompilierung erfolgt teilweise stapelweise in dem Sinne, dass die Neukompilierung von modifizierten Zeilen nicht auftritt, bis der letzte eines Satzes von Editierbefehlen empfangen wurde; und (4) das Analysieren und Kompilieren werden in zwei Teile zerlegt, denjenigen, der auf einzelnen Zeilen ausgeführt wird, und denjenigen, der global ausgeführt wird, um die Beziehungen zwischen den Zeilen zu handhaben."}
{"DOCID": "2253", "TEXT": "Indexbereiche für Matrixkalküle: Der Artikel beschreibt ein Schema zur symbolischen Manipulation von Indexausdrücken, die als Nebenprodukt der symbolischen Manipulation von Ausdrücken in den Matrixkalkülen entstehen, die von den Autoren in einem früheren Artikel beschrieben wurden. Dieses Schema versucht eine Programmoptimierung durch Transformieren des ursprünglichen Algorithmus anstelle des Maschinencodes. Ziel ist es, automatisch Code zu generieren, um die mühsamen Adressberechnungen zu handhaben, die durch komplizierte Datenstrukturen erforderlich sind. Das Papier beschäftigt sich daher mit der \"Indexierung nach Position\". Die Beziehung zwischen \"Indizierung nach Namen\" und \"Indizierung nach Position\" wird diskutiert."}
{"DOCID": "2254", "TEXT": "Dynamische Partitionierung für Array-Sprachen: Der klassische Prozess der Partitionierung eines Arrays in Subarrays wird auf eine nützlichere Array-Sprachoperation erweitert. Für verschiedene Arten von Arrays sind verschiedene Partitionierungsmodi definiert, so dass Subarrays gegenüber dem ursprünglichen Array auf nahezu willkürliche Weise variieren können. Diese Definitionen sind mit mehreren realistischen Beispielen motiviert, um den Wert der Partitionierung für Array-Sprachen zu veranschaulichen. Von allgemeinem Interesse ist die Datenstruktur für die Partitionierung. Diese besteht aus dynamischen Baumstrukturen, die verwendet werden, um die Array-Steuerinformationen abzuleiten und zu verwalten. Diese werden ausreichend detailliert beschrieben, um beim Entwurf anderer Array-Sprachen von Wert zu sein. Die in diesem Dokument vorgestellte Beschreibung ist in einer neuen Array-Sprache, OL/2, implementiert, die derzeit an der University of Illinois entwickelt wird."}
{"DOCID": "2255", "TEXT": "Kommentare zu Moorers Musik und Computerkomposition"}
{"DOCID": "2256", "TEXT": "Weitere Kommentare zu Dijkstras Concurrent Programming Control Problem"}
{"DOCID": "2257", "TEXT": "Eine Anmerkung zu optimalen doppelt verketteten Bäumen"}
{"DOCID": "2258", "TEXT": "Zusätzliche Ergebnisse zu Key-to-Address-Transformationstechniken: Eine grundlegende Leistungsstudie zu großen vorhandenen formatierten Dateien"}
{"DOCID": "2259", "TEXT": "Modifizierte unvollständige Gammafunktion [S14] (Algorithmus A435)"}
{"DOCID": "2260", "TEXT": "Exakte Wahrscheinlichkeiten für R x C-Kontingenztabellen [G2] (Algorithmus A434)"}
{"DOCID": "2261", "TEXT": "Ein ungefähres Verfahren zum Erzeugen symmetrischer Zufallsvariablen: Ein Verfahren zum Erzeugen von Werten kontinuierlicher symmetrischer Zufallsvariablen, das relativ schnell ist, im Wesentlichen keinen Computerspeicher erfordert und einfach zu verwenden ist, wird entwickelt. Das Verfahren, das eine einheitliche Null-Eins-Zufallszahlenquelle verwendet, basiert auf der Umkehrfunktion der Lambda-Verteilung der Türkei. Da es viele der kontinuierlichen theoretischen Verteilungen und empirischen Verteilungen annähert, die häufig in Simulationen verwendet werden, sollte das Verfahren für Simulationspraktiker nützlich sein."}
{"DOCID": "2262", "TEXT": "Garbage Collection für Computersysteme mit virtuellem Speicher: Bei der Listenverarbeitung besteht typischerweise ein wachsender Platzbedarf während der Programmausführung. Dieser Aufsatz untersucht die praktischen Implikationen dieses Wachstums innerhalb eines Computersystems mit virtuellem Speicher, schlägt zwei neue Garbage-Collection-Techniken für virtuelle Speichersysteme vor und vergleicht sie mit traditionellen Methoden durch Diskussion und durch Simulation."}
{"DOCID": "2263", "TEXT": "Die Umwandlung von Entscheidungstabellen mit begrenztem Eintrag in optimale und nahezu optimale Flussdiagramme: Zwei neue Algorithmen: Zwei neue Algorithmen zum Ableiten optimaler und nahezu optimaler Flussdiagramme aus Entscheidungstabellen mit begrenztem Eintrag werden vorgestellt. Beide berücksichtigen Regelhäufigkeiten und die Zeit, die zum Testen der Bedingungen benötigt wird. Einer der Algorithmen, der als Optimalfindungsalgorithmus bezeichnet wird, führt zu einem Flussdiagramm, das die Ausführungszeit für eine Entscheidungstabelle, in der einfache Regeln bereits zu komplexen Regeln zusammengefasst sind, wirklich minimiert. Der andere, Optimalannäherungsalgorithmus genannt, erfordert viel weniger Berechnungen, erzeugt aber nicht unbedingt das optimale Flussdiagramm. Die Algorithmen werden zunächst zum Behandeln von Entscheidungstabellen hergeleitet, die keine ELSE-Regel enthalten, aber es wird gezeigt, dass der sich dem Optimum nähernde Algorithmus gleichermaßen für Tabellen gültig ist, die eine solche Regel enthalten. Beide Algorithmen werden mit bestehenden verglichen und auf eine ziemlich große Entscheidungstabelle angewendet, die von einem realen Fall abgeleitet wurde. Aus diesem Vergleich werden zwei Schlussfolgerungen gezogen. (1) Der Optimum-Annäherungsalgorithmus wird in der Regel zu besseren Ergebnissen führen als vergleichbare existierende und wird nicht mehr, aber in der Regel weniger Rechenzeit benötigen. (2) Im Allgemeinen wird der größere Rechenaufwand für die Anwendung des Optimal-Finding-Algorithmus erforderlich sein nicht durch die erzielte geringfügige Verkürzung der Ausführungszeit gerechtfertigt werden."}
{"DOCID": "2264", "TEXT": "Abgeleitete Semantik für einige Programmiersprachenkonstrukte: Die Konstrukte einer einfachen Programmiersprache werden eingeführt und informell in Bezug auf Werte und Nebenwirkungen beschrieben. Es wird ein Übersetzer definiert, der die Sprache in Flussdiagramme für eine einfache Maschine übersetzt. Die Aktion der Maschine beim Ausführen eines Flussdiagramms wird definiert. Es wird ein Beweis dafür konstruiert, dass die Wirkung des Übersetzens und Ausführens eines beliebigen Programms ausschließlich in Bezug auf den Wert und die Nebenwirkung des Programms ausgedrückt werden kann. Im Zuge der Beweiskonstruktion werden formale Definitionen der Begriffe Wert und Nebenwirkung hergeleitet, um den Beweis streng zu machen. Die Korrektheit der Implementierung beinhaltet die Überprüfung, ob die im obigen Schritt abgeleiteten Definitionen eine akzeptable Formalisierung der im ersten Schritt gegebenen informellen Beschreibung sind."}
{"DOCID": "2265", "TEXT": "Ein Modell zur Typprüfung: Die meisten aktuellen Programmiersprachen behandeln Berechnungen über verschiedene Klassen von Objekten (z. B. Zahlen, Zeichenfolgen, Labels und Funktionen). Für die korrekte Kompilierung und Ausführung stellt sich dann folgende Frage: Ist ein Programm richtig aufgebaut, so dass seine Operationen und Operanden kompatibel sind? Die Aktivität zur Beantwortung dieser Frage wird normalerweise als Typprüfung bezeichnet. Dieses Papier versucht, den Begriff der Typprüfung zu isolieren, und präsentiert eine teilweise Lösung des Typprüfungsproblems, die auf den Begriffen der Abstraktion und der Anwendung von Funktionen basiert. Insbesondere wird ein Programm in einen Ausdruck innerhalb einer entscheidbaren Teilmenge des Lambda-Kalküls abgebildet, der die Typbeziehungen innerhalb des Programms charakterisiert und alle anderen Informationen eliminiert. Die Bestimmung der typmäßigen Korrektheit oder Unrichtigkeit des Programms wird gelöst, indem sein entsprechender Lambda-Kalkül-Ausdruck auf eine von zwei Normalformen reduziert wird, die Konstante \"richtig\" für ein typmäßig korrektes Programm oder die Konstante \"Fehler\". Es wird ein Antrag auf Typprüfung in Algol 60 gestellt, und die begleitenden Probleme, die bei jedem Begriff der Typprüfung auftreten, werden diskutiert."}
{"DOCID": "2266", "TEXT": "A Highly Parallel Algorithm for Approximating All Zeros of a Polynomial with Only Real Zeros: Basierend auf dem Newton-Verfahren wird ein Algorithmus beschrieben, der gleichzeitig alle Nullstellen eines Polynoms mit nur echten Nullstellen approximiert. Der konzeptionell für parallele Berechnungen geeignete Algorithmus bestimmt seine Startwerte selbst, so dass eine Konvergenz zu den Nullstellen gewährleistet ist. Mehrere Nullstellen und ihre Multiplizität werden leicht bestimmt. An keiner Stelle des Verfahrens wird eine polynomiale Deflation verwendet."}
{"DOCID": "2267", "TEXT": "Algorithmen zur Darstellung von Eigenschaften der Fließkommaarithmetik: Zwei Algorithmen werden in Form von Fortran-Unterroutinen vorgestellt. Jede Subroutine berechnet die Basis und die Anzahl der Ziffern der Gleitkommazahlen und ob Rundung oder Zerhacken von der Maschine durchgeführt wird, auf der sie ausgeführt wird. Es wird gezeigt, dass die Methoden auf jedem \"vernünftigen\" Gleitkommacomputer funktionieren."}
{"DOCID": "2268", "TEXT": "Eine vergleichende Studie von Computerprogrammen zum Integrieren von Differentialgleichungen: Es wird über eine Studie berichtet, die die Leistung mehrerer Computerprogramme zum Integrieren von Systemen gewöhnlicher Differentialgleichungen vergleicht. Als Integrationsverfahren sind Mehrschrittverfahren (Prädiktor-Korrektoren), Einschrittverfahren (Runge-Kutta) und Extrapolationsverfahren (sowohl polynomial als auch rational) vertreten. Das Prüfverfahren wird zusammen mit den angewandten Bewertungskriterien beschrieben. Eine Reihe von Testproblemen, an denen die Programme getestet wurden, ist in einem Anhang enthalten. Für die speziellen Probleme und Kriterien, die in der Untersuchung verwendet wurden, wurde festgestellt, dass ein Programm, das auf rationaler Extrapolation basiert, die beste Leistung zeigte."}
{"DOCID": "2269", "TEXT": "Tabellenlose Datumskonvertierung (Algorithmus R398)"}
{"DOCID": "2270", "TEXT": "Interpolation und glatte Kurvenanpassung basierend auf lokalen Prozeduren [E2] (Algorithmus A433)"}
{"DOCID": "2271", "TEXT": "Ästhetik und der menschliche Faktor in der Programmierung (Korrigendum)"}
{"DOCID": "2272", "TEXT": "Sortieren durch natürliche Selektion: Es wird eine Familie von Sortieralgorithmen vorgeschlagen, deren Mitglieder den Speicherplatz vollständiger ausnutzen und somit längere sortierte Zeichenfolgen liefern. Umfangreiche Simulationsergebnisse werden vorgestellt und verschiedene Implikationen und weitere Anwendungen diskutiert."}
{"DOCID": "2273", "TEXT": "Konvertierung von Entscheidungstabellen durch Regelmaskenverfahren ohne Regelmaske: Es werden zwei Algorithmen zum Erzeugen von Computerprogrammen aus Entscheidungstabellen beschrieben. Die Algorithmen ermöglichen die Handhabung von Tabellen mit eingeschränkter Eingabe, erweiterter Eingabe und gemischter Eingabe. Die Algorithmen basieren auf dem Regelmaskenverfahren, müssen aber die Masken zur Ausführungszeit nicht haben. Sie führen die logischen Operationen sofort und nicht erst am Ende des Dolmetschprozesses durch. Die Ausführungszeit kann erheblich verkürzt werden, indem nicht anwendbare Regeln (Algorithmen 1 und 2) oder bereits getestete Bedingungen (Algorithmus 2) sofort markiert werden. Die neuen Algorithmen vereinen gewissermaßen die Vorteile von Maskenverfahren mit denen von Baumverfahren."}
{"DOCID": "2274", "TEXT": "Generieren des englischen Diskurses aus semantischen Netzen: Es wird ein System zum Generieren englischer Sätze aus einer Form von semantischen Netzen beschrieben, in denen die Knoten Wort-Sinn-Bedeutungen und die Pfade hauptsächlich tiefe Fallbeziehungen sind. Die vom System verwendete Grammatik hat die Form eines Netzwerks, das einem Satz syntaktischer Transformationen, die als LISP-Funktionen ausgedrückt werden, eine Ordnung auferlegt. Der Generierungsalgorithmus verwendet die Informationen im semantischen Netz, um geeignete Generierungspfade durch die Grammatik auszuwählen. Das System ist für die Verwendung als Rechenwerkzeug ausgelegt, das es einem Linguisten ermöglicht, Methoden zum Erzeugen von Oberflächenketten aus einer zugrunde liegenden semantischen Struktur zu entwickeln und zu studieren. Erste Ergebnisse in Bezug auf Formbestimmende wie Stimme, Form, Tempus und Stimmung, einige Regeln für das Einbetten von Sätzen und einige Aufmerksamkeit für die pronominale Substitution werden berichtet. Das System ist in LISP 1.5 programmiert und bei den Autoren erhältlich."}
{"DOCID": "2275", "TEXT": "Integralgleichungen der Immunologie: Die Umkehrung einer bestimmten Integralgleichung der ersten (Fredholm) Art ist das betrachtete Grundproblem. Die erfolgreiche Strategie bestand aus drei wesentlichen Punkten: (1) Anpassen der bekannten experimentellen Daten durch eine Kurve mit Eigenschaften, die sich von Eigenschaften der (noch unbekannten) Funktion ableiten; (2) Stabilisierung der Berechnung für die unbekannte Funktion durch Verwendung der Singulärwertzerlegung; (3) beschränke die Approximation der unbekannten Funktion (da sie eine Wahrscheinlichkeitsverteilung darstellt) auf nichtnegativ. Eine Reihe von Testfällen wird vorgestellt. Ein Satz tatsächlicher experimenteller Daten wird mit den vorgestellten Verfahren analysiert."}
{"DOCID": "2276", "TEXT": "Computerverfahren zur Abtastung der Exponential- und Normalverteilung: Es sind verschiedene Verfahren bekannt, um gleichverteilte Zufallszahlen in exponentiell und normalverteilte Größen umzuwandeln. Die effizientesten werden in Bezug auf Speicherbedarf und Geschwindigkeit mit einigen neuen Algorithmen verglichen. Eine Reihe von Verfahren wandeln Taylor-Reihenentwicklungen direkt in Stichprobenschritte um, ein Ansatz, der für Stichproben aus jeder kontinuierlichen Verteilung verwendet werden kann. Für die Exponentialverteilung kann eine klare Empfehlung ausgesprochen werden, während bei der Normalverteilung die Wahl zwischen langsameren und kürzeren Algorithmen und schnelleren, aber platzraubenden Verfahren bleibt."}
{"DOCID": "2277", "TEXT": "Demand Paging Through Utilization of Working Sets on the MANIAC II: Eine Hardwareimplementierung auf dem Maniac II-Computer des Working Set-Modells für Demand Paging, wie es von Denning eingeführt wurde, wird diskutiert. Eigenschaften des Maniac II werden zusammen mit einer Beschreibung des grundlegenden Demand-Paging-Schemas und des zugeordneten Speichers, der der Maniac II-Hardware hinzugefügt wurde, angegeben. Abschließend wird eine Beschreibung des Hardwaredesigns zur Implementierung des Working-Set-Modells diskutiert und eine Spezifikation der Aktionen gegeben, die unter verschiedenen Bedingungen durchgeführt werden, die während des Betriebs des vollständigen Working-Set-Modells, des Anforderungs-Paging-Systems, auftreten können."}
{"DOCID": "2278", "TEXT": "Über Fosters Informationsspeicherung und -abruf unter Verwendung von AVL-Bäumen"}
{"DOCID": "2279", "TEXT": "Ein Controller für ein Braille-Terminal"}
{"DOCID": "2280", "TEXT": "Kommentar zur Deadlock-Präventionsmethode"}
{"DOCID": "2281", "TEXT": "Das Eigenproblem von Block-Tridiagonalmatrizen"}
{"DOCID": "2282", "TEXT": "Ein Vergleich von Fließkomma-Summierungsmethoden"}
{"DOCID": "2283", "TEXT": "Ausdünnungsalgorithmen für rechteckige, sechseckige und dreieckige Arrays: In diesem Bericht werden drei Ausdünnungsalgorithmen entwickelt: jeweils einer für die Verwendung mit rechteckigen, hexagonalen und dreieckigen Arrays. Der Ansatz zur Entwicklung jedes Algorithmus ist derselbe. Bildliche Ergebnisse, die von jedem der Algorithmen erzeugt werden, werden präsentiert und die relativen Leistungen der Algorithmen werden verglichen. Es hat sich herausgestellt, dass der Algorithmus, der mit dem dreieckigen Array arbeitet, am empfindlichsten gegenüber Bildunregelmäßigkeiten und Rauschen ist, dennoch ergibt er ein ausgedünntes Bild mit einer insgesamt reduzierten Anzahl von Punkten. Es wird geschlussfolgert, dass der Algorithmus, der in Verbindung mit dem hexagonalen Array arbeitet, Merkmale aufweist, die ein Gleichgewicht zwischen denen der anderen zwei Arrays herstellen."}
{"DOCID": "2284", "TEXT": "Lösung der Matrixgleichung AX+XB=C [F4] (Algorithmus A432)"}
{"DOCID": "2285", "TEXT": "Computerroutine für quadratische und lineare Programmierprobleme [H] (Algorithmus A431): Ein Computerprogramm, das auf dem komplementären Pivot-Algorithmus von Lemke basiert, wird vorgestellt. Dies kann verwendet werden, um lineare und quadratische Programmierprobleme zu lösen. Das Programm wurde ausgiebig mit einer Vielzahl von Problemen getestet und die Ergebnisse waren äußerst zufriedenstellend."}
{"DOCID": "2286", "TEXT": "Automatische Fehleranalyse zum Bestimmen der Genauigkeit: Das betrachtete Problem besteht darin, einen rationalen Ausdruck innerhalb jeder gewünschten Toleranz auf einem Computer auszuwerten, der Gleitkomma-Arithmetikoperationen mit variabler Genauigkeit ausführt. Eine automatische Fehleranalysetechnik wird angegeben, um direkt aus den Ergebnissen einer arithmetischen Berechnung mit einem Intervall mit niedriger Genauigkeit zu bestimmen, wie viel Genauigkeit und Datengenauigkeit erforderlich sind, um eine gewünschte endgültige Genauigkeit zu erreichen. Die angegebene Technik lässt sich leicht auf die Auswertung vieler nichtrationaler Ausdrücke verallgemeinern."}
{"DOCID": "2287", "TEXT": "Ein neuer Ansatz zum automatischen Scannen von Höhenlinienkarten: Das Problem der automatischen Digitalisierung von Höhenlinienkarten wird diskutiert. Die Struktur einer allgemeinen Konturkarte wird analysiert, und ihre topologischen Eigenschaften werden zur Entwicklung eines neuen Abtastalgorithmus verwendet. Das Problem der Erfassung und Erkennung von Konturlinien wird durch ein Zweifarben-Kennzeichnungsverfahren gelöst. Es wird gezeigt, dass es für Karten, die nur normale Konturlinien enthalten, ausreicht, zwischen sogenannten \"geraden\" und \"ungeraden\" Linien zu unterscheiden. Das mit dem praktischen Scannen verbundene \"Tangentialproblem\" wird diskutiert, und es wird eine Lösung vorgeschlagen, die auf der Minimierung des Computerspeicherplatzes und der Vereinfachung des Steuerprogramms basiert."}
{"DOCID": "2288", "TEXT": "Dateiorganisation: Die konsekutive Abrufeigenschaft: Die konsekutive Abrufeigenschaft ist eine wichtige Beziehung zwischen einem Abfragesatz und einem Datensatz. Seine Existenz ermöglicht den Entwurf eines Informationsabrufsystems mit minimaler Suchzeit und ohne redundante Speicherung. Einige wichtige Theoreme über die konsekutive Retrieval-Eigenschaft werden in dieser Arbeit bewiesen. Es wurden Bedingungen aufgestellt, unter denen die konsekutive Abrufeigenschaft besteht und unveränderlich bleibt. Ein Entwurf zum Entwerfen eines Informationswiedergewinnungssystems basierend auf der konsekutiven Wiedergewinnungseigenschaft wird ebenfalls diskutiert."}
{"DOCID": "2289", "TEXT": "Zelluläre Arrays zur Lösung von Graphenproblemen: Ein zellulares Array ist eine zweidimensionale, schachbrettartige Verbindung identischer Module (oder Zellen), wobei jede Zelle ein paar Speicherbits und eine kleine Menge kombinatorischer Logik enthält und hauptsächlich mit kommuniziert seine unmittelbaren Nachbarn im Array. Der hauptsächliche Rechenvorteil, den zellulare Arrays bieten, ist die Verbesserung der Geschwindigkeit, die aufgrund der Möglichkeiten zur parallelen Verarbeitung erreicht wird. In diesem Beitrag wird gezeigt, dass zellulare Arrays von Natur aus gut für die Lösung vieler Graphenprobleme geeignet sind. Beispielsweise lässt sich die Adjazenzmatrix eines Graphen leicht auf ein Array abbilden; jedes Matrixelement wird in einer Zelle des Arrays gespeichert, und typische Zeilen- und Spaltenoperationen werden leicht durch einfache Zellenlogik implementiert. Eine große Herausforderung bei der effektiven Verwendung von zellulären Arrays zur Lösung von Graphenproblemen ist die Bestimmung von Algorithmen, die die Möglichkeiten der Parallelität ausnutzen, insbesondere für Probleme, deren Lösungen inhärent seriell zu sein scheinen. Insbesondere werden mehrere parallelisierte Algorithmen zur Lösung bestimmter Spanning-Tree-, Entfernungs- und Pfadprobleme vorgestellt, mit direkter Anwendung auf Drahtführung, PERT-Diagrammanalyse und die Analyse vieler Arten von Netzwerken. Diese Algorithmen weisen eine Rechenzeit auf, die in vielen Fällen mit einer Rate wächst, die log2 n nicht übersteigt, wobei n die Anzahl der Knoten im Graphen ist. Unkomplizierte zellulare Implementierungen der wohlbekannten seriellen Algorithmen für diese Probleme erfordern etwa n Schritte, und nichtzellulare Implementierungen erfordern n^2 bis n^3 Schritte."}
{"DOCID": "2290", "TEXT": "Unmittelbare Vorherrscher in einem gerichteten Graphen [H] (Algorithmus A430)"}
{"DOCID": "2291", "TEXT": "Lokalisierung der Nullstellen eines Polynoms [C2] (Algorithmus A429)"}
{"DOCID": "2292", "TEXT": "Eine Anmerkung zur Generierung von Rosenkranz-Permutationen"}
{"DOCID": "2293", "TEXT": "Kommentar zur durchschnittlichen binären Suchlänge"}
{"DOCID": "2294", "TEXT": "Ein Bonus von van Wijngaardens Gerät"}
{"DOCID": "2295", "TEXT": "Kommentar zur Zusammensetzung der Semantik in Algol 68"}
{"DOCID": "2296", "TEXT": "Kompilieren von Festkommamultiplikationen"}
{"DOCID": "2297", "TEXT": "Ein Modell der Speicherkonkurrenz in einer Paging-Maschine: Diese Abhandlung befasst sich mit bestimmten Aspekten der Konkurrenz um Hauptspeicherressourcen in einem Computersystem mit mehreren Programmen, das unter Bedarfs-Paging arbeitet. In dem vorgestellten Modell variiert die Anzahl von Seitenrahmen des Hauptspeichers, die einem Problemprogramm zugeordnet sind, mit der Zeit. Diese Änderungen in der Speicherkonfiguration werden explizit im Modell dargestellt, CPU-Anforderungen und Seitenausnahmeeigenschaften von Programmmaterial werden statistisch beschrieben. Es werden Ausdrücke für die Verteilung der Anzahl von einem ausführenden Programm zugewiesenen Seitenrahmen, den langfristig erwarteten Bruchteil der Ausführungszeit eines Programms in einer gegebenen Anzahl von Seitenrahmen und das durchschnittliche Ausführungsintervall der mehrfach programmierten Last erhalten. Es wird heuristisch darauf hingewiesen und numerisch demonstriert, dass eine Erhöhung des durchschnittlichen Ausführungsintervalls der mehrfach programmierten Last über diejenige hinaus erhältlich ist, die sich aus einer gleichen festen Aufteilung des Hauptspeichers ergibt."}
{"DOCID": "2298", "TEXT": "Eine Umgebung für die Forschung in Mikroprogrammierung und Emulation: Die Entwicklung des Forschungsprojekts in Mikroprogrammierung und Emulation an der State University of New York in Buffalo bestand aus drei Phasen: der Bewertung verschiedener möglicher Maschinen zur Unterstützung dieser Forschung; die Entscheidung, eine solche Maschine zu kaufen, die den anderen überlegen erscheint; und die Organisation und Definition von Zielen für jede Gruppe im Projekt. Über jede dieser Phasen wird berichtet, wobei der Schwerpunkt auf den frühen Ergebnissen dieser Forschung liegt."}
{"DOCID": "2299", "TEXT": "Ein erweiterbarer Editor für eine kleine Maschine mit Plattenspeicher: Eine Entwurfsphilosophie zum Entwickeln eines ausgeklügelten Dienstprogramms wird durch den tatsächlichen Entwurf und die Implementierung eines Texteditors veranschaulicht. Es wird eine vielseitige Datenstruktur verwendet, so dass nur eine kleine Anzahl von programmierten Unterroutinen für alle Arten von Datenmanipulationen notwendig sind. Eine solche Datenstruktur wird beschrieben, und ihre Vorzüge werden durch die Leichtigkeit veranschaulicht, mit der leistungsstarke Erweiterungen hinsichtlich einiger weniger grundlegender Bearbeitungsfunktionen implementiert werden können."}
{"DOCID": "2300", "TEXT": "Politische Umverteilung per Computer: Die Probleme der politischen Umverteilung werden betrachtet und eine Computermethode zur Umverteilung vorgestellt. Kriterien für eine akzeptable Umverteilung werden diskutiert, einschließlich Bevölkerungsgleichheit, Kompaktheit, Nachbarschaft und Bewahrung natürlicher und/oder politischer Grenzen. Es werden nur unparteiische Kriterien berücksichtigt. Unter Verwendung der Bevölkerungsdaten des Bureau of Census von 1970 werden spezifische Ergebnisse für die zehn Kongressbezirke im Bundesstaat Missouri und für die sieben Sitze des St. Louis County Council angegeben. Ergebnisse aus der Verwendung des Algorithmus weisen auf die Machbarkeit einer politischen Umverteilung mit Hilfe eines Computers hin."}
{"DOCID": "2301", "TEXT": "Generieren von Parsern für Affix-Grammatiken: Affix-Grammatiken sind zweistufige Grammatiken, die den zweistufigen Grammatiken von van Wijngaarden ähneln, die in der Definition von Algol 68 verwendet werden. Von Koster wird gezeigt, dass Affix-Grammatiken dieselbe Leistung wie van Wijngaarden-Grammatiken haben. Sie eignen sich jedoch viel besser zum Parsen als letztere. Köster, dem Erfinder des Affixes auf Basis rekursiver Verfahren. Dieses Papier stellt ein Bottom-up-Schema für deren Analyse vor, das auf einer Erweiterung der Floyd Production Language (FPL) basiert. Eingeschlossen ist ein Algorithmus, ähnlich dem von DeRemer, zum Konvertieren einer großen Klasse von Affixgrammatiken in FPL. Der Beitrag schließt mit einer kurzen Erörterung der Anwendbarkeit des Konvertierungsalgorithmus und von Affixgrammatiken im Allgemeinen sowie einiger möglicher Erweiterungen von Kosters Definition von Affixgrammatiken."}
{"DOCID": "2302", "TEXT": "Computer und Beschäftigung: Das Verhältnis von Computern und Automatisierung zur Beschäftigung ist Teil der allgemeineren Beziehung zwischen technologischem Wandel und Beschäftigung. Der offensichtlichste Effekt ist, dass die Produktivitätssteigerung durch Technologie Arbeitsplätze vernichten kann. Technologie beeinflusst den einzelnen Arbeiter in Art und Umfang seiner Arbeit und in seiner Einstellung zu dieser Arbeit. Der technologische Wandel wirkt sich auf die Berufsstruktur der gesamten Erwerbsbevölkerung aus. Aufgrund der zentralen Bedeutung dieser Effekte waren die Auswirkungen der Technologie Gegenstand umfangreicher Studien von Wirtschaftswissenschaftlern, Soziologen, Politikwissenschaftlern und Psychologen. Selbst innerhalb einer Disziplin sind Studien oft widersprüchlich, und Schlussfolgerungen sind von politischen Obertönen geprägt. Wir möchten einige der Probleme skizzieren und Argumente präsentieren, die gegeben werden, um unterschiedliche Standpunkte zu unterstützen."}
{"DOCID": "2303", "TEXT": "Computerarchäologie - Erinnerungen, 1945-1947: Die Zeit vor der Gründung von ACM war geprägt vom ersten Großcomputer ENIAC. Seine hier beschriebenen Eigenschaften weisen auf spätere Entwicklungen hin."}
{"DOCID": "2304", "TEXT": "Ein westlicher Blick auf die Computergeschichte: Viele US-Geschichten im Bereich der digitalen Computer waren eher unpersönlich und legten großen Wert auf östliche Universitäten und kommerzielle Entwicklungen. Dieser Artikel hält die Ereignisse der frühen Jahre auf persönliche Weise fest. Die Menschen, Organisationen, Technologien und Computer der Zeit von 1945 bis 1955 im Westen der Vereinigten Staaten werden so beschrieben, wie sie geschahen."}
{"DOCID": "2305", "TEXT": "Der \"Plankalkul\" von Konrad Zuse: Ein Vorläufer heutiger Programmiersprachen: Plankalkul war ein Versuch von Korrad Zuse in den 1940er Jahren, ein Notations- und Konzeptsystem zum Schreiben dessen zu entwickeln, was heute als Programm bezeichnet wird. Obwohl dieser frühe Ansatz einer Programmiersprache nicht zu einer praktischen Anwendung führte, wird der Plan hier beschrieben, da er Funktionen enthält, die in heutigen Programmiersprachen Standard sind. Die Untersuchung ist von historischem Interesse; außerdem kann es Erkenntnisse liefern, die zu Fortschritten im Stand der Technik führen würden. Unter Verwendung moderner Programmierterminologie wird der Plankalkul so weit dargestellt, wie er aus der veröffentlichten Literatur rekonstruiert werden kann."}
{"DOCID": "2306", "TEXT": "Ancient Babylonian Algorithms: Die frühen Anfänge der Mathematik werden diskutiert, wobei diejenigen Aspekte hervorgehoben werden, die aus Sicht der Informatik von größtem Interesse zu sein scheinen. Eine Reihe alter babylonischer Tafeln, von denen viele noch nie zuvor ins Englische übersetzt worden sind, werden zitiert."}
{"DOCID": "2307", "TEXT": "Dynamische Dokumentenverarbeitung: Die derzeitige Rolle von Computern in der automatischen Dokumentenverarbeitung wird kurz skizziert, und es werden einige Gründe genannt, warum das frühe Versprechen der Bibliotheksautomatisierung und der Mechanisierung von Dokumentationsprozessen nicht erfüllt wurde. Dann wird eine neue dynamische Dokumentenumgebung skizziert, in der geclusterte Dateien durchsucht werden und Informationen nach einem interaktiven benutzergesteuerten Suchprozess abgerufen werden. Es werden Methoden für eine automatische Abfragemodifikation basierend auf Benutzerbedürfnissen und für eine kontinuierliche Reorganisation der gespeicherten Informationen in Abhängigkeit von früherer Dateiverarbeitung und normalem Sammlungswachstum beschrieben. Die vorgeschlagenen Verfahren stellen leistungsstarke Werkzeuge für die Informationssuche und für die Kontrolle dynamischer Bibliothekssammlungen bereit, in denen ständig neue Elemente hinzugefügt und alte entfernt werden."}
{"DOCID": "2308", "TEXT": "Computer und Stadtgesellschaft: Dieser kurze Überblick über die Nutzung von Computern in der Stadtgesellschaft deckt das breite Spektrum an Aktivitäten ab, die in jeder Stadt zu finden sind. Der zukünftige Anwendungsbereich wird nur durch die Vorstellungskraft und den Erfindungsreichtum zukünftiger Systemdesigner, Programmierer, Analysten und Entscheidungsträger begrenzt. Der Computer kann, wenn er richtig eingesetzt wird, im Hinblick auf die Achtung der Menschenwürde und der bürgerlichen Freiheit ein bedeutender Faktor bei der Verbesserung der Effizienz des städtischen Prozesses sein. Es wird erwartet, dass die Vorteile einer solchen Computernutzung die Kosten überwiegen und dass wir uns auf eine Ausweitung dieser Nutzung freuen können."}
{"DOCID": "2309", "TEXT": "Computer im Unterrichtsprozess: Richtungen für Forschung und Entwicklung: Es wird eine Übersicht über Computeranwendungen im Unterrichtsprozess gegeben, die darauf hindeutet, wie der Computerfachmann zu effektiven Bildungssystemen beitragen kann."}
{"DOCID": "2310", "TEXT": "Sprachanalyse in den Geisteswissenschaften: Der Einsatz des Computers in den sprachorientierten Geisteswissenschaften zur erschöpfenden Detailauflistung (zB in Verzeichnissen und Konkordanzen) ist weit verbreitet und als wünschenswert akzeptiert. Die Implikationen des Computers für eine „Wissenschaft“ der Geisteswissenschaften – eine Wissenschaft, die das Sammeln von Daten für die Konstruktion und das Testen von Modellen umfasst – werden weder allgemein anerkannt noch akzeptiert. Dieses Papier argumentiert, dass die Hauptrolle des Computers in Bezug auf die Sprachanalyse in den Geisteswissenschaften darin bestehen wird, eine solche Wissenschaft zu etablieren Komposition) kann der Computer ein äußerst wichtiger Vermittler sein."}
{"DOCID": "2311", "TEXT": "Eine Generationenperspektive der Entwicklung von Informationssystemen: Die Systementwicklung wird aus einer Generationensicht kategorisiert, die parallel zu den allgemein beschriebenen Generationen von Computersystemen verläuft. Für jede Generation werden der Umfang der Entwicklungsprojekte und das technologische Weltbild des Systementwicklers untersucht."}
{"DOCID": "2312", "TEXT": "Zur Gegenwart und Zukunft des wissenschaftlichen Rechnens: Es wird eine pessimistische Prognose abgegeben, was bei der Anwendung von Computern in den Naturwissenschaften zu erwarten ist."}
{"DOCID": "2313", "TEXT": "Die Evolution von Speicherstrukturen: Datenbankverwaltungssysteme haben in der 15-jährigen Geschichte der Datenverarbeitung auf handelsüblichen Computern schnell an Leistung und Komplexität zugenommen. Die ursprünglichen Konzepte haben sich aufgespalten, und neue Begriffe wurden übernommen, um diese Konzepte zu benennen und sich darauf zu beziehen. Die grafische Technik des Datenstrukturdiagramms wird verwendet, um die Aufspaltung der Konzepte und die strukturellen Beziehungen zu veranschaulichen, die zwischen diesen Konzepten an jedem Punkt der Evolution bestehen."}
{"DOCID": "2314", "TEXT": "Anforderungen an fortgeschrittene Programmiersysteme für die Listenverarbeitung: Listenverarbeitungssysteme sollten so ausgelegt sein, dass sie die Produktion großer Programme erleichtern, um große komplexe symbolische Datenspeicher zu manipulieren. Dieses Papier gibt einen Überblick über eine Reihe von Systemmerkmalen, die der Autor für wichtig hält, um die Produktivität von Programmierern zu verbessern, die in solchen Bereichen arbeiten. Es wurde eine Systemsicht eingenommen, anstatt sich nur auf Sprachmerkmale zu konzentrieren, da Algorithmen nicht nur in einer Sprachform codiert, sondern auch debuggt, modifiziert, effizient gemacht und auf Daten ausgeführt werden müssen. Aufgrund dieses allgemeinen Rahmens sind die angegebenen Anforderungen auf das Design fortgeschrittener Programmiersysteme für eine breite Palette von Anwendungen anwendbar. Drei Aspekte von Programmiersystemen werden hervorgehoben: gute interaktive Möglichkeiten, programmierbare Steuerstrukturen und ausgefeilte Datenkommunikationsmechanismen. Interaktive Merkmale werden beschrieben, um Programmzusammenstellung, -eingabe, -test, -debugging, -editierung, -optimierung und -paketierung zu erleichtern. Die Implementierung eines spezifizierten verallgemeinerten Umgebungsstrukturmodells würde die Programmierung verschiedener Steuerregime einschließlich Multiprozessen, Coroutinen und Backtracking ermöglichen. Alternative Methoden des erforderlichen Verfahrensaufrufs umfassen den Aufruf nach Muster und nach Überwachungsbedingung. Der Bedarf an erweiterten Datenformen, Speicherverwaltung und Erweiterbarkeit wird betont, ebenso wie die Dualität von Datenabruf und Funktionsauswertung. Die syntaktisch gesteuerte Eingabe und Ausgabe von Daten würde die Verwendung komplexer Datenspeicher erleichtern."}
{"DOCID": "2315", "TEXT": "Die Herstellung besserer mathematischer Software: Es werden einige Beobachtungen zu Schritten gemacht, die zur Schaffung besserer mathematischer Software unternommen werden müssen. Diese Schritte deuten auf die Notwendigkeit einer koordinierten Anstrengung und der Schaffung eines Zentrums hin, um die Aktivitäten in diesem Bereich zu konzentrieren."}
{"DOCID": "2316", "TEXT": "Programmiersprachen: Geschichte und Zukunft: Dieser Beitrag behandelt sowohl die Geschichte als auch die Zukunft von Programmiersprachen (= höhere Programmiersprachen). Einige der Schwierigkeiten beim Schreiben einer solchen Geschichte werden angedeutet. Zentraler Bestandteil der Arbeit ist ein Baum, der die chronologische Entwicklung der Sprachen und ihre Wechselbeziehungen aufzeigt. Gründe für die Verbreitung von Sprachen werden angegeben. Die wichtigsten Sprachen sind mit den Gründen für ihre Bedeutung aufgelistet. Ein Abschnitt über Chronologie zeigt die Ereignisse der bedeutenden früheren Zeitperioden und die Hauptthemen von 1972 auf. Neben bestimmten Sprachen werden auch andere Schlüsselkonzepte diskutiert."}
{"DOCID": "2317", "TEXT": "Programmiersysteme und -sprachen 1965-1975: Trotz beeindruckender Fortschritte durch PL/I bleiben Fortran und Cobol die Sprachen, in denen die meisten Produktionsprogramme der Welt geschrieben werden, und werden dies auch in absehbarer Zukunft bleiben. Es gibt viel theoretisches Interesse an Algol 68 und an erweiterbaren Sprachen, aber zumindest bisher hatten sie wenig praktische Auswirkungen. Problemorientierte Sprachen könnten in den nächsten fünf bis zehn Jahren zum wichtigsten Sprachentwicklungsbereich werden. Auf dem Gebiet der Betriebssysteme wollten alle großen Computerhersteller sehr ehrgeizige Multiprogramming-Systeme produzieren, und sie alle stießen auf ähnliche Probleme. Eine Reihe von Universitätsprojekten, die zwar nicht direkt mit denen der Hersteller vergleichbar sind, haben jedoch wesentlich zu einem besseren Verständnis der Betriebssystemprinzipien beigetragen. Wichtige Trends umfassen das gesteigerte Interesse an der Entwicklung von Systemmeß- und Bewertungstechniken und die verstärkte Verwendung von Mikroprogrammierung für einige Programmiersystemfunktionen."}
{"DOCID": "2318", "TEXT": "Die Rolle von Computersystemmodellen bei der Leistungsbewertung: Modelle bilden ein nützliches Mittel zur Untersuchung der Computersystemleistung. Dieses Papier untersucht die Wechselbeziehungen zwischen Modellen und anderen Methoden zur Bewertung der Leistung von Computersystemen und stellt Umstände fest, unter denen die Verwendung eines Modells angemessen ist."}
{"DOCID": "2319", "TEXT": "Betriebssystemleistung: Es wird ein Überblick über die aktuelle und zukünftige Position in Bezug auf die Betriebssystemleistung gegeben. Obwohl viele Informationen und eine große Anzahl von Modellen für Subsysteme entwickelt wurden, bestehen immer noch Wissenslücken. Aufgrund der schwerwiegenden Wechselwirkungen zwischen den verschiedenen Subsystemen eines Betriebssystems muss ein Gesamtmodell des Gesamtsystems entwickelt werden, um die Leistungsaspekte eines Betriebssystems analysieren und entwerfen zu können, obwohl solche Gesamtsystemdesigns heute außergewöhnlich sind, wird projiziert dass sie in naher Zukunft immer häufiger und notwendiger werden. Eine solche Designphilosophie wird eindeutig einen schwerwiegenden Einfluss auf die Art und Weise haben, wie wir Betriebs- und Computersysteme modularisieren."}
{"DOCID": "2320", "TEXT": "Strukturiertes Multiprogramming: Dieses Papier stellt einen Vorschlag für eine strukturierte Darstellung von Multiprogramming in einer Hochsprache vor. Die verwendete Notation ordnet explizit eine Datenstruktur, die von gleichzeitigen Prozessen gemeinsam genutzt wird, Operationen zu, die darauf definiert sind. Dies verdeutlicht die Bedeutung von Programmen und ermöglicht das Abfangen einer großen Klasse von zeitabhängigen Fehlern zur Kompilierzeit. Eine Kombination aus kritischen Regionen und Ereignisvariablen ermöglicht es dem Programmierer, die Planung von Ressourcen zwischen konkurrierenden Prozessen in jedem gewünschten Grad zu steuern. Diese Konzepte sind ausreichend sicher, um sie nicht nur innerhalb von Betriebssystemen, sondern auch innerhalb von Benutzerprogrammen zu verwenden."}
{"DOCID": "2321", "TEXT": "Über die Schnittstelle zwischen Computern und Datenkommunikationssystemen: Zukünftige Systeme, die Computer, digitale Endgeräte und Kommunikationsgeräte kombinieren, stellen Entwurfsoptimierungsprobleme dar, die eine Neubetrachtung der traditionellen funktionalen Verantwortlichkeiten der jeweiligen Teilsysteme erfordern. Es werden mehrere \"Standard\"-Schnittstellen benötigt, über die sich Computer und digitale Endgeräte mit den Kommunikationssystemen verbinden. Bei der Spezifikation dieser Schnittstellen müssen Probleme der Koordination, Synchronisation, Fehlerkontrolle, Signalisierung, Strommultiplexierung und Schaltersteuerung zusätzlich zur Minimierung der technologischen gegenseitigen Abhängigkeit spezifischer Subsystemdesigns berücksichtigt werden. Eine Konzentration auf einige der Probleme wird in einer Erörterung einer detaillierten Spezifikation für eine bestimmte Computer-Kommunikationssystem-Schnittstelle erhalten."}
{"DOCID": "2322", "TEXT": "A View of Computer Architecture: Es wird versucht, die Entwicklungen der nächsten 25 Jahre auf dem Gebiet der Computerarchitektur vorherzusagen. Standardisierte, kostengünstige Mikrocomputer auf einem einzigen Chip werden prognostiziert. Diese werden extensiv verwendet, um logische Funktionen für nicht rechentechnische Geräte und nebenbei für das Design von Superscale-Computern bereitzustellen."}
{"DOCID": "2323", "TEXT": "Auf dem Weg zu einer allgemeinen Theorie spezieller Funktionen: Eine Liste einiger natürlicher Entwicklungen für das Gebiet der algebraischen Manipulation wird gegeben. Anschließend werden die Aussichten für eine allgemeine Theorie der durch gewöhnliche Differentialgleichungen definierten Funktionen diskutiert. Es wird behauptet, dass neuere Entwicklungen in der Mathematik darauf hindeuten, dass es möglich sein sollte, viele Eigenschaften von Lösungen von Differentialgleichungen algorithmisch zu erzeugen. Eine solche Theorie ist einem weniger allgemeinen Versuch vorzuziehen, algebraische Manipulationssysteme mit den üblichen Spezialfunktionen (z. B. Exponential, Hypergeometrie) vertraut zu machen."}
{"DOCID": "2324", "TEXT": "Management Science: A View from Nonlinear Programming: Eine kurze Geschichte der ganzzahligen und kontinuierlichen nichtlinearen Programmierung sowie die aktuellen Hindernisse für die praktische Anwendung dieser mathematischen Programmiertechniken werden vorgestellt. Es wird prognostiziert, dass die nützlichen Beiträge zur nichtlinearen Programmierung, die in den nächsten Jahren tatsächlich geleistet werden, eher Konsolidierungen als theoretische Durchbrüche sein werden. Diese Beiträge sind wahrscheinlich die Dokumentation von Standardtestproblemen, die Konstruktion benutzerorientierter Software und Vergleiche derzeit bekannter Algorithmen, um zu demonstrieren, welche Techniken für bestimmte Probleme am besten geeignet sind."}
{"DOCID": "2325", "TEXT": "Numerische Mathematik und Informatik: Numerische Mathematik wird als Analyse kontinuierlicher Algorithmen betrachtet. Vier der Komponenten der numerischen Mathematik werden diskutiert. Diese sind: Grundlagen (Zahlensysteme endlicher Genauigkeit, Rechenkomplexität), Synthese und Analyse von Algorithmen, Fehleranalyse, Programme und Programmbibliotheken."}
{"DOCID": "2326", "TEXT": "Fixpunkt-Ansatz zur Theory of Computation: In Anlehnung an die Fixpunkt-Theorie von Scott wird die Semantik von Computerprogrammen anhand der kleinsten Fixpunkte rekursiver Programme definiert. Dies erlaubt nicht nur die Begründung aller bestehenden Verifikationstechniken, sondern auch deren Erweiterung auf den einheitlichen Umgang mit verschiedenen Eigenschaften von Computerprogrammen, darunter Korrektheit, Terminierung und Äquivalenz."}
{"DOCID": "2327", "TEXT": "Auf dem Weg zu einer Automatentheorie des Gehirns: Eine Ideenquelle für die Automatentheorie – das Studium des Gehirns – wurde bei der mathematischen Entwicklung der Theorie beiseite geschoben. Dieses Papier schlägt vor, wie sich die Automatentheorie in den nächsten 25 Jahren weiterentwickeln könnte, wenn sie zum Verständnis beitragen soll, wie das Gehirn Informationen verarbeitet."}
{"DOCID": "2328", "TEXT": "Individualisierender Unterricht in einem generativen CAI-Tutor"}
{"DOCID": "2329", "TEXT": "Informatik – ein Teufelskreis"}
{"DOCID": "2330", "TEXT": "Berechnung von Fourier-Integralen (Algorithmus R418)"}
{"DOCID": "2331", "TEXT": "Ein ganzzahliges Programmierproblem (Algorithmus R397)"}
{"DOCID": "2332", "TEXT": "Spezielle Reihensummierung mit beliebiger Genauigkeit (Algorithmus R393)"}
{"DOCID": "2333", "TEXT": "Gleichmäßige Zufallsvektoren sind Raumwinkel (Algorithmus R381)"}
{"DOCID": "2334", "TEXT": "Allgemeiner Zufallszahlengenerator (Algorithmus R370)"}
{"DOCID": "2335", "TEXT": "Eigenwerte und Eigenvektoren einer reellen allgemeinen Matrix (Algorithmus R343)"}
{"DOCID": "2336", "TEXT": "Komplexe Fehlerfunktion (Algorithmus C363)"}
{"DOCID": "2337", "TEXT": "Ein Sortierproblem und seine Komplexität: Eine Technik zum Beweis von Min-Max-Normen von Sortieralgorithmen wird angegeben. Ein neuer Algorithmus zum Finden der minimalen und maximalen Elemente einer Menge mit den wenigsten Vergleichen hat sich mit dieser Technik als optimal erwiesen."}
{"DOCID": "2338", "TEXT": "Ein Startverfahren zum Lösen nichtlinearer Volterra-Integralgleichungen zweiter Art: Für Volterra-Integralgleichungen zweiter Art wird ein Startverfahren vierter Ordnung angegeben und Zahlenbeispiele vorgestellt."}
{"DOCID": "2339", "TEXT": "Vom Computer zugewiesene Codes aus verbalen Antworten: Es ist oft wünschenswert, verbale Antworten in mehrstellige Codes umzuwandeln. Diese Konvertierung wird im Allgemeinen von Clerk-Codierern durchgeführt. Es wurde eine Studie durchgeführt, um die Durchführbarkeit der Übersetzung verbaler Beschreibungen in numerische Codes in einem Computerprogramm zu testen. Die Hauptbetonung wurde auf den computergestützten Aufbau einer Referenzdatei mit verbalen Beschreibungen zur Verwendung durch das Programm gelegt. Die Ergebnisse der Studie zeigen deutlich, dass solche Verfahren machbar sind."}
{"DOCID": "2340", "TEXT": "Ein boolesches Matrixverfahren zur Berechnung linearer Vorrangfunktionen: Eine modifizierte Version des Booleschen Matrixverfahrens von Bell zur Berechnung von linearen Vorrangfunktionen, die einer konfliktfreien Matrix von Vorrangbeziehungen zugeordnet sind, wird angegeben. Dieser Algorithmus erkennt nicht nur, wenn die Vorrangfunktionen nicht vorhanden sind, sondern liefert auch einen Hinweis darauf, warum sie nicht vorhanden sind, sodass nach Möglichkeit eine Korrekturmaßnahme ergriffen werden kann. Notwendige und hinreichende Bedingungen für die Existenz von Vorrangfunktionen sind gegeben. Die Verwendung von booleschen Matrizen zum Beweis der Existenz von Präzedenzfunktionen, die Klassen konfliktfreier Grammatiken zugeordnet sind, wird durch ein Beispiel veranschaulicht."}
{"DOCID": "2341", "TEXT": "Blocks-A Neuer Datentyp für SNOBOL4: Ein neuer Datentyp, Block genannt, wurde für SNOBOL4 implementiert. Ein Block ist eine dreidimensionale Ansammlung von Zeichen in Form eines rechtwinkligen Parallelepipeds, das man sich am besten als dreidimensionale Erweiterung einer Zeichenfolge vorstellen kann. (Die dritte Dimension wird zum Überstreichen verwendet.) Blöcke können gedruckt, in jeder der drei Dimensionen verkettet und auf der Grundlage von programmdefinierten Verbindungspunkten zusammengeführt werden. Manche Blöcke passen sich in Größe und Form ihrer Umgebung an. Blöcke und ihre Operationen werden hauptsächlich zum Erstellen von druckbaren Ausgaben verwendet. Eine Vielzahl grafischer Probleme (darunter Flussdiagramme, Balkendiagramme, logische Diagramme, mathematische Gleichungsbildung und Textausrichtung und -vorbereitung) wurden auf scheinbar einfache und natürliche Weise auf einem Drucker programmiert. Zusätzlich zu diesen etwas spezialisierten Anwendungen scheinen Blöcke ein guter geräteunabhängiger Ausgabebildungsmechanismus für allgemeine Zwecke zu sein, der besonders für nichtnumerische Arbeiten geeignet ist. Das Konzept eines Blocks ist weitgehend sprachunabhängig. Das heißt, Blöcke erfordern wenig spezialisierte Syntax und könnten leicht in die externe Struktur der meisten Programmiersprachen aufgenommen werden."}
{"DOCID": "2342", "TEXT": "Interferenz zwischen der Kommunikation paralleler Prozesse: Verschiedene Arten der Interferenz zwischen der Kommunikation paralleler Prozesse wurden von Dijkstra, Knuth und anderen untersucht. Für das Problem des gegenseitigen Ausschlusses und zugehöriger Teilprobleme wurden Lösungen in Form von Parallelprogrammen gegeben und informelle Korrektheitsbeweise für diese Lösungen gegeben. In dieser Arbeit wird ein System paralleler Prozesse als eine Maschine betrachtet, die von einem Zustand S (d. h. einer Sammlung relevanter Datenwerte und Prozesskonfigurationen) zu einem nächsten Zustand S' gemäß einer Übergangsregel S --> S' fortschreitet. Ein Satz solcher Regeln ergibt Sequenzen von Zuständen, die das Verhalten des Systems diktieren. Das Problem des gegenseitigen Ausschlusses und die damit verbundenen Teilprobleme werden als Fragen der Inklusion zwischen Mengen von Zuständen oder der Existenz bestimmter Sequenzen formuliert. Es wird ein mechanisches Beweisverfahren gezeigt, das eine versuchte Lösung in Bezug auf eine der Interferenzeigenschaften entweder verifiziert (die Korrektheit von beweist) oder diskreditiert (die Unkorrektheit von beweist). Es wird gezeigt, wie aus den \"Teilregeln\", nach denen die einzelnen Prozesse ablaufen, Übergangsregeln berechnet werden. Die Bildung von Teilregeln und die Berechnung von Übergangsregeln sind sowohl auf Hardwareprozesse als auch auf Softwareprozesse anwendbar, und eine Symmetrie zwischen Prozessen ist nicht erforderlich."}
{"DOCID": "2343", "TEXT": "Ein Vorschlag zum Einrichten eines pseudovirtuellen Speichers über beschreibbare Overlays: Viele Computersysteme lösen Probleme mit der Größe des ausführbaren Speichers für große Programme durch die Verwendung von Overlays. Es scheint jedoch, dass kein einzelnes Überlagerungsschema eine wohlausgewogene Kombination der nützlichsten Fähigkeiten enthält, die in verschiedenen existierenden Techniken zu finden sind. Es wird ein Vorschlag präsentiert, der mehrere der besten Fähigkeiten bestehender Schemata nutzt und durch mehrere zusätzliche Merkmale ergänzt wird, z. beschreibbare Overlays. Die beschreibbare Overlay-Fähigkeit stellt einen virtuellen Speichereffekt bereit, obwohl der Programmierer möglicherweise immer noch die Overlay-Konfiguration entwerfen muss. Da die Überlagerungsstrukturierung eine komplexe Aufgabe ist, sind mehrere Werkzeuge (einschließlich einer grafischen Anzeige) in dem Vorschlag enthalten, um den Programmierer bei der Gestaltung zu unterstützen. Der Inhalt von Overlays wird kurz diskutiert, und es wird angemerkt, dass viele der Details der endgültigen Overlay-Konfiguration nachträglich entschieden werden können."}
{"DOCID": "2344", "TEXT": "Zur Leistungsoptimierung von Time-Sharing-Systemen durch Simulation: Ein Simulationsmodell eines Time-Sharing-Systems mit einem endlichen nicht zusammenhängenden Speicher und einem unendlichen Hilfsspeicher wird verwendet, um die Variation von Systemparametern wie Speichergröße, Anzahl der zulässigen Arbeitsplätze zu untersuchen zur gleichzeitigen Ausführung, Jobplanungsalgorithmus usw. Die Auswirkungen dieser Variationen auf ein Maß der Systemleistung werden verwendet, um festzustellen, welche der durch den Jobplanungsalgorithmus steuerbaren Parameter, einschließlich der Planung selbst, einer Optimierung bedürfen und welche der Parameter, die normalerweise nicht durch den Planungsalgorithmus steuerbar sind, haben eine deutliche Auswirkung auf die Systemleistung. Die Systemleistung basiert auf den mittleren Verzögerungskosten für alle verarbeiteten Jobs. Es wird gezeigt, dass signifikante Verbesserungen bei der Messung der Systemleistung erzielt werden können, indem Techniken mit variabler Zeitscheibe verwendet werden und indem die optimale Round-Robin-Zykluszeit ausgewählt wird. Es scheint, dass diese Merkmale von einer Optimierung profitieren würden, wohingegen andere Parameter, die durch den Planungsalgorithmus steuerbar sind, die Systemleistung auf vorhersagbare Weise beeinflussen und nicht von einer Optimierung profitieren würden. Merkmale, die normalerweise nicht unter der Kontrolle des Scheduling-Algorithmus stehen, können ebenfalls eine deutliche Auswirkung auf das Leistungsmaß haben; insbesondere Supervisor-Overheads, die Größe des Speichers und die Geschwindigkeit der CPU. Es wird ein Vergleich zwischen den Ergebnissen des Simulationsmodells und zwei analytischen Gleichungen für quantenorientierte nichtpräemptive Time-Sharing-Systeme durchgeführt. Der Vergleich wird als sehr günstig empfunden."}
{"DOCID": "2345", "TEXT": "Curriculum-Empfehlungen für Graduate Professional Programmes in Information Systems: Der Bedarf an Bildung in Bezug auf Informationssysteme in Organisationen wird diskutiert und ein Curriculum für Graduate Professional Programmes an Universitäten auf Master-Ebene vorgeschlagen. Das für solche Programme notwendige Material wird identifiziert und Kurse, die es beinhalten, werden spezifiziert. Es werden detaillierte Kursbeschreibungen vorgestellt, die Programmorganisation besprochen und Umsetzungsfragen betrachtet."}
{"DOCID": "2346", "TEXT": "Hu-Tucker Minimum Redundancy Alphabetic Coding Method [Z] (Algorithmus A428)"}
{"DOCID": "2347", "TEXT": "Fourier-Cosinus-Integral [D1] (Algorithmus A427)"}
{"DOCID": "2348", "TEXT": "Sortieralgorithmus zusammenführen [M1] (Algorithmus A426)"}
{"DOCID": "2349", "TEXT": "Generierung zufälliger korrelierter Normalvariablen [G5] (Algorithmus A425)"}
{"DOCID": "2350", "TEXT": "Clenshaw-Curtis-Quadratur [D1] (Algorithmus A424)"}
{"DOCID": "2351", "TEXT": "Die Optimalität der Winograd-Formel"}
{"DOCID": "2352", "TEXT": "Minimax Nichtlineare Annäherung durch Annäherung an Teilmengen"}
{"DOCID": "2353", "TEXT": "Schnelle Finite-Differenzen-Lösung biharmonischer Probleme: Das Setzen der Reynolds-Zahl gleich Null in einem Verfahren zum numerischen Lösen der Navier-Strokes-Gleichungen führt zu einem schnellen numerischen Verfahren für biharmonische Probleme. Die Gleichung wird als ein System von zwei Gleichungen zweiter Ordnung behandelt, und ein einfacher Glättungsprozess ist für die Konvergenz wesentlich. Es wird eine Anwendung auf ein rissartiges Problem gemacht."}
{"DOCID": "2354", "TEXT": "Implementierung der Clenshaw-Curtis-Quadratur, II Berechnung der Cosinus-Transformation: In einem Begleitpapier dazu, „I Methodology and Experiences“, wurde das automatische Clenshaw-Curtis-Quadraturschema beschrieben und wie jede in dem Schema verwendete Quadraturformel eine Kosinustransformation erfordert Integrandenwerte wurden angezeigt. Die hohen Kosten dieser Kosinustransformationen waren ein ernster Nachteil bei der Verwendung der Clenshaw-Curtis-Quadratur. Zwei andere Probleme im Zusammenhang mit der Kosinustransformation haben ebenfalls zu Problemen geführt. Erstens ist die herkömmliche Berechnung der Kosinustransformation durch Rekursionsbeziehung numerisch instabil, insbesondere bei niedrigen Frequenzen, die den größten Effekt auf das Integral haben. Zweitens ist für den Fall, dass das automatische Schema eine Verfeinerung der Abtastung erfordern sollte, eine Speicherung erforderlich, um die Integrandenwerte zu speichern, nachdem die Kosinustransformation berechnet wurde. Dieser zweite Teil der Arbeit zeigt, wie die Cosinus-Transformation durch eine Modifikation der schnellen Fourier-Transformation berechnet und alle drei Probleme überwunden werden können. Die Modifikation ist auch unter anderen Umständen anwendbar, die Cosinus- oder Sinustransformationen erfordern, wie z. B. polynomische Interpolation durch die Tschebyscheff-Punkte."}
{"DOCID": "2355", "TEXT": "Implementieren der Clenshaw-Curtis-Quadratur, I Methodik und Erfahrung: Die Clenshaw-Curtis-Quadratur ist aus verschiedenen Gründen ein besonders wichtiges automatisches Quadraturschema, insbesondere wegen der hohen Genauigkeit, die aus relativ wenigen Integrandenwerten erhalten wird. Es hat jedoch wenig Verwendung gefunden, da es die Berechnung einer Kosinustransformation erfordert und die arithmetischen Kosten dafür unerschwinglich waren. Dieses Papier besteht aus zwei Teilen; ein begleitender Artikel, \"II Computing the Cosine Transformation\", zeigt, dass dieser Einwand überwunden werden kann, indem die Cosinus-Transformation durch eine Modifikation des schnellen Fourier-Transformationsalgorithmus berechnet wird. Dieser erste Teil diskutiert die Strategie und verschiedene Fehlerschätzungen und fasst Erfahrungen mit einer bestimmten Implementierung des Schemas zusammen."}
{"DOCID": "2356", "TEXT": "Eine Technik zur Spezifikation von Softwaremodulen mit Beispielen: Dieses Papier stellt einen Ansatz zum Schreiben von Spezifikationen für Teile von Softwaresystemen vor. Das Hauptziel besteht darin, Spezifikationen bereitzustellen, die so genau und vollständig sind, dass andere Softwareteile geschrieben werden können, um ohne zusätzliche Informationen mit dem spezifizierten Teil zu interagieren. Das sekundäre Ziel besteht darin, in die Spezifikation nicht mehr Informationen aufzunehmen, als zum Erreichen des ersten Ziels erforderlich sind. Die Technik wird anhand einer Vielzahl von Beispielen aus einem Tutorial-System veranschaulicht."}
{"DOCID": "2357", "TEXT": "MUX, ein einfacher Ansatz zum Online-Computing: Es wird ein Online-System beschrieben, das als Teil eines normalen Batch-Systems für den CDC 6600-Computer arbeitet. Das System, das ein Mannjahr für die anfängliche Softwareimplementierung erforderte, stellt, obwohl es im Grunde einfach ist, die notwendigen Elemente bereit, um Dateien einzugeben und zu ändern, sie zur Batch-Ausführung zu übermitteln und Ergebnisse auf dem Terminal des Benutzers bereitzustellen. Ein Multiplexer, der im Rahmen des Projekts entworfen und entwickelt wurde, kostete ein Mannjahr für Design und Prüfung sowie 16.000 US-Dollar für Teile und Herstellung. Alle Aspekte des Systems werden beschrieben, einschließlich Entwurfskriterien, Implementierung, Kosten, Overhead und Benutzerreaktionen."}
{"DOCID": "2358", "TEXT": "Der virtuelle Multics-Speicher: Konzepte und Design: Da die Erfahrung mit der Verwendung von Online-Betriebssystemen zugenommen hat, ist die Notwendigkeit, Informationen zwischen Systembenutzern gemeinsam zu nutzen, immer offensichtlicher geworden. Viele moderne Systeme erlauben ein gewisses Maß an gemeinsamer Nutzung. Üblicherweise wird die gemeinsame Nutzung erreicht, indem es mehreren Benutzern ermöglicht wird, Daten über die Eingabe und Ausgabe von Informationen zu teilen, die in Dateien gespeichert sind, die im sekundären Speicher aufbewahrt werden. Durch die Verwendung der Segmentierung bietet Multics jedoch eine direkte Hardware-Adressierung aller Informationen durch Benutzer- und Systemprogramme, unabhängig von ihrem physischen Speicherort. Informationen werden in Segmenten gespeichert, von denen jedes potenziell gemeinsam genutzt werden kann und seine eigenen unabhängigen Attribute hinsichtlich Größe und Zugriffsprivileg trägt. Hier werden zunächst die Design- und Implementierungsüberlegungen zur Segmentierung und gemeinsamen Nutzung in Multics unter der Annahme diskutiert, dass alle Informationen in einem großen, segmentierten Hauptspeicher liegen. Da die Größe des Hauptspeichers auf heutigen Systemen eher begrenzt ist, wird anschließend gezeigt, wie die Multics-Software durch den Einsatz der Segmentierungs- und Paging-Hardware Honeywell 645 den Effekt eines großen segmentierten Hauptspeichers erzielt."}
{"DOCID": "2359", "TEXT": "Eine verbesserte indexsequenzielle Zugriffsmethode unter Verwendung von Hashed Overflow: Die indexsequenzielle Zugriffsmethode (ISAM) ist eines der wichtigsten Dateiverwaltungssysteme, das bei Laufwerken mit beweglichem Kopf verwendet wird. Diese Studie untersucht die Verwendung einer unkonventionellen Methode zur Behandlung von Überlaufaufzeichnungen. Das Verfahren besteht darin, Hashing-Techniken zu verwenden, um Speicherplatz für solche Datensätze zuzuweisen. Wenn bestimmte Bedingungen erfüllt sind, ist dies der konventionellen ISAM-Methode der Verkettung der Überlaufdatensätze über Linked-List-Techniken überlegen. Diese Bedingungen sind: lange Überlaufketten mit erheblichem Überlauf; Mangel an engen Speicherplatzbeschränkungen; Datensatzschlüssel, die im Vergleich zur gesamten Datensatzgröße klein sind; und erhebliche Nutzung der Datei im Index im Gegensatz zum sequentiellen Modus. Bei Verwendung von gehashtem Überlauf hängt die Zeit zum Auffinden eines Datensatzes nicht vom Gesamtvolumen der Überlaufdatensätze wie bei herkömmlichem ISAM ab, sondern von der prozentualen Nutzung des für Überlaufdatensätze reservierten Speicherplatzes."}
{"DOCID": "2360", "TEXT": "Ein Kommentar zum Doppelkettenbaum"}
{"DOCID": "2361", "TEXT": "Eine Anmerkung zu Cheneys nichtrekursivem Listenkomprimierungsalgorithmus"}
{"DOCID": "2362", "TEXT": "Linearer Gleichungslöser [F4] (Algorithmus A423)"}
{"DOCID": "2363", "TEXT": "Minimaler Spannbaum [H] (Algorithmus A422)"}
{"DOCID": "2364", "TEXT": "Komplexe Gammafunktion mit Fehlerkontrolle [S14] (Algorithmus A421)"}
{"DOCID": "2365", "TEXT": "Matrixberechnungen mit Fortran und Paging: Die Effizienz herkömmlicher Fortran-Programme für Matrixberechnungen kann oft verbessert werden, indem die Reihenfolge der verschachtelten Schleifen umgekehrt wird. Solche Modifikationen führen in vielen üblichen Situationen zu bescheidenen Einsparungen und zu sehr bedeutenden Einsparungen bei großen Problemen, die unter einem Betriebssystem ausgeführt werden, das Paging verwendet."}
{"DOCID": "2366", "TEXT": "Komplexe Gamma-Funktion mit Fehlerkontrolle: Ein Algorithmus zur Berechnung der Gamma-Funktion und Log-Gamma-Funktion einer komplexen Variablen wird vorgestellt. Der Standardalgorithmus wird in mehrfacher Hinsicht modifiziert, um die Kontinuität des Funktionswerts sicherzustellen und die Akkumulation von Rundungsfehlern zu verringern. Zusätzlich zur Berechnung von Funktionswerten beinhaltet dieser Algorithmus eine Objektzeitschätzung von Rundungsfehlern. Experimentelle Daten bezüglich der Effektivität dieser Fehlerkontrolle werden präsentiert. Ein Fortran-Programm für den Algorithmus erscheint im Abschnitt über Algorithmen dieser Ausgabe."}
{"DOCID": "2367", "TEXT": "Computer und Gesellschaft: Ein vorgeschlagener Kurs für Informatiker: Der Zweck dieses Papiers ist es, einen Kurs zu beschreiben, der sich sowohl mit den Auswirkungen von Computern auf die Gesellschaft als auch mit der Verantwortung von Informatikern gegenüber der Gesellschaft befasst. Der Einfluss von Computern wird in fünf Komponenten unterteilt: politisch, wirtschaftlich, kulturell, sozial und moralisch; Der Hauptteil des Papiers definiert jede Komponente und präsentiert Beispiele für die relevanten Probleme. In den verbleibenden Teilen werden die möglichen Formate für einen solchen Kurs diskutiert, ein thematischer Überblick gegeben und eine Auswahl an Referenzen aufgelistet. Es ist zu hoffen, dass der Vorschlag die Einrichtung von Kursen zu diesem Thema erleichtern wird."}
{"DOCID": "2368", "TEXT": "Ein implementierter Graphalgorithmus zum Gewinnen von Shannon Switching-Spielen: In diesem Tutorial-Papier wird ein Computerprogramm beschrieben, das Shannon Switching-Spiele gewinnt. Da diese Spiele auf Graphen gespielt werden, ist das Programm ein gutes Beispiel für die Implementierung von Graphalgorithmen. Die beiden Spieler in einem Shannon Switching Game, CONNECT und CUT, haben unterschiedliche Ziele. Entweder CONNECT, CUT oder dem Spieler, der sich zuerst bewegt, ist die Existenz einer Gewinnstrategie garantiert. Die einfache Strategie, die in diesem Papier erklärt wird, ist in allen drei Fällen gültig. Tatsächlich müssen die Hauptroutinen nie wissen, ob der Computer CONNECT oder CUT ist."}
{"DOCID": "2369", "TEXT": "Eliminierung verdeckter Linien für ein rotierendes Objekt: Es wird ein Verfahren vorgestellt, um zu bestimmen, welche Teile von dreidimensionalen Objekten sichtbar und welche unsichtbar sind, wenn die Objekte um eine bestimmte Achse gedreht werden. Dieses Dokument beschreibt ein Polygon-Vergleichsschema, in dem die Beziehungen zweier Polygone in Baumtypen klassifiziert werden können, und erörtert auch, wie die Beziehung für jedes Paar von Polygonen unter Rotation um eine Achse geändert wird. Für jedes Polygonpaar wird eine Rotationstabelle definiert, die fest bleibt, solange die Rotation um eine Achse erfolgt, und ein Mittel zum schnellen Bestimmen der sichtbaren und verdeckten Linienbeziehung zwischen zwei Polygonen bereitstellt. Es muss zusätzliche Arbeit geleistet werden, um diesen Ansatz auf eine gleichzeitige Rotation um mehrere Achsen auszudehnen."}
{"DOCID": "2370", "TEXT": "Ein experimentelles Labor für Mustererkennung und Signalverarbeitung: Am IBM Thomas J. Watson Research Center ist seit drei Jahren ein interaktives computergesteuertes Scan- und Anzeigesystem in Betrieb. Das System umfasst zwei Flugpunkt-Scanner und eine TV-Kamera, die speziell an einen Prozesssteuerungs-Digitalcomputer, Punktmodus- und Vektoranzeigen, analoge Eingabe- und Ausgabeeinrichtungen und eine Vielzahl anderer experimenteller Ausrüstung angeschlossen ist. Das Systemdesign und die Programmierunterstützung werden beschrieben und typische Anwendungen in der Scannersteuerung, der optischen Zeichenerkennung und der Bildverarbeitung werden vorgestellt."}
{"DOCID": "2371", "TEXT": "Ein System zur Kommunikation zwischen Prozessen in einem Computernetzwerk mit gemeinsamer Ressourcennutzung: Ein System zur Kommunikation zwischen Prozessen in einem Time-Sharing-System wird beschrieben und das Kommunikationssystem wird so erweitert, dass es zwischen über ein Computernetzwerk verteilten Prozessen verwendet werden kann. Die hypothetische Anwendung des Systems auf ein bestehendes Netzwerk wird diskutiert."}
{"DOCID": "2372", "TEXT": "Zur Implementierung von Sicherheitsmaßnahmen in Informationssystemen: Die Sicherheit eines Informationssystems kann durch eine Modellmatrix dargestellt werden, deren Elemente Entscheidungsregeln sind und deren Zeilen- und Spaltenindizes Benutzer bzw. Datenelemente sind. Ein Satz von vier Funktionen wird verwendet, um auf diese Matrix zur Übersetzungs- und Ausführungszeit zuzugreifen. Die Unterscheidung zwischen datenabhängigen und datenunabhängigen Entscheidungsregeln ermöglicht es, einen Großteil der Sicherheitsüberprüfung nur einmal zur Übersetzungszeit statt wiederholt zur Ausführungszeit durchzuführen. Das Modell wird verwendet, um Sicherheitsmerkmale mehrerer vorhandener Systeme zu erklären, und dient als Rahmen für einen Vorschlag zur allgemeinen Sicherheitssystemimplementierung in heutigen Sprachen und Betriebssystemen."}
{"DOCID": "2373", "TEXT": "Eigenschaften des Arbeitsmengenmodells: Die Arbeitsmenge W(t, T) eines Programms zum Zeitpunkt t ist die Menge unterschiedlicher Seiten unter den T zuletzt referenzierten Seiten. Beziehungen zwischen der durchschnittlichen Working-Set-Größe, der Rate fehlender Seiten und der Interreferenzintervallverteilung können sowohl aus zeitlichen Durchschnittsdefinitionen als auch aus Ensemble-durchschnittlichen (statistischen) Definitionen abgeleitet werden. Ein effizienter Algorithmus zum Schätzen dieser Größen wird angegeben. Die Beziehung zu LRU (am längsten verwendet) Paging wird charakterisiert. Das Independent-Reference-Modell, bei dem Seitenverweise statistisch unabhängig sind, wird verwendet, um die Auswirkungen auf Interpage-Abhängigkeiten von Working-Set-Größenbeobachtungen zu bewerten. Unter allgemeinen Annahmen wird gezeigt, dass die Working-Set-Größe normalverteilt ist."}
{"DOCID": "2374", "TEXT": "Eine Untersuchung der Speicherpartitionierung unter Verwendung eines mathematischen Lokalitätsmodells: Es werden sowohl feste als auch dynamische Speicherpartitionierungsprozeduren für die Verwendung in Mehrprogrammiersystemen untersucht. Der Speicherbedarf von Programmen wird als stationärer Gaußscher Prozess modelliert. Experimente, die dieses Modell rechtfertigen, werden beschrieben. Mittels dieses Modells wird gezeigt, dass die dynamische Speicherpartitionierung gegenüber der festen Partitionierung eine erhebliche Steigerung der Speicherauslastung und Betriebseffizienz bietet."}
{"DOCID": "2375", "TEXT": "Eine vergleichende Analyse von Disk Scheduling Policies: Fünf wohlbekannte Scheduling Policies für bewegliche Kopfplatten werden unter Verwendung der Leistungskriterien der erwarteten Suchzeit (systemorientiert) und der erwarteten Wartezeit (individuelle E/A-Anforderung orientiert) verglichen. Es werden sowohl Analyse- als auch Simulationsergebnisse erhalten. Als weiteres aussagekräftiges Leistungsmaß wird die Varianz der Wartezeit eingeführt, die eine mögliche Diskriminierung einzelner Anfragen aufzeigt. Anschließend wird die Auswahl einer Nutzenfunktion zur Messung der Gesamtleistung einschließlich systemorientierter und individueller anforderungsorientierter Maßnahmen beschrieben. Eine solche Funktion ermöglicht es, zwischen den Planungsrichtlinien über einen weiten Bereich von Eingabebelastungsbedingungen zu unterscheiden. Die Auswahl und Implementierung eines Zwei-Policy-Algorithmus mit maximaler Leistung werden diskutiert."}
{"DOCID": "2376", "TEXT": "Synchronisation kommunizierender Prozesse: Durch die Formalisierung eines wohldefinierten Synchronisationsmechanismus kann nachgewiesen werden, dass gleichzeitig laufende Prozesse eines Systems korrekt kommunizieren. Dies wird für ein System demonstriert, das aus vielen sendenden Prozessen besteht, die Nachrichten in einem Puffer ablegen, und vielen empfangenden Prozessen, die Nachrichten aus diesem Puffer entfernen. Die formale Beschreibung des Synchronisationsmechanismus macht es sehr einfach zu beweisen, dass der Puffer weder über- noch unterläuft, dass Sender und Empfänger niemals mit dem gleichen Nachrichtenrahmen im Puffer arbeiten oder in einen Deadlock geraten."}
{"DOCID": "2377", "TEXT": "Eine Hardwarearchitektur zum Implementieren von Schutzringen: Der Schutz von Berechnungen und Informationen ist ein wichtiger Aspekt eines Computerdienstprogramms. In einem System, das die Segmentierung als Speicheradressierungsschema verwendet, kann der Schutz teilweise dadurch erreicht werden, dass einer Berechnung konzentrische Ringe mit abnehmendem Zugriffsprivileg zugeordnet werden. Dieses Dokument beschreibt Hardwareprozessormechanismen zum Implementieren dieser Schutzringe. Die Mechanismen zur Implementierung dieser Schutzringe. Die Mechanismen ermöglichen das Auftreten von Querrufen und anschließenden Rücksendungen, ohne dass der Supervisor eingefangen wird. Eine automatische Hardware-Validierung von Referenzen über Ringgrenzen hinweg wird ebenfalls durchgeführt. Somit ist ein Aufruf durch eine Benutzerprozedur an ein geschütztes Subsystem (einschließlich des Supervisors) identisch mit einem Aufruf an eine begleitende Benutzerprozedur. Auch die Mechanismen zum Übergeben und Referenzieren von Argumenten sind in beiden Fällen gleich."}
{"DOCID": "2378", "TEXT": "Ein Betriebssystem, das auf dem Konzept eines Überwachungscomputers basiert: Ein Betriebssystem, das als kleiner Überwachungscomputer organisiert ist, und eine Menge unabhängiger Prozesse werden beschrieben. Der Supervisor handhabt die E/A mit externen Geräten – das Datei- und Verzeichnissystem – plant aktive Prozesse und verwaltet den Speicher, handhabt Fehler und stellt einen kleinen Satz primitiver Funktionen bereit, die er für einen Prozess ausführt. Ein Prozess ist in der Lage, eine Anforderung für eine komplizierte Aktion seitens des Überwachers (normalerweise ein Warten auf das Auftreten eines zusammengesetzten Ereignisses im System) zu spezifizieren, indem er diese Grundelemente zu einem \"überwachenden Computerprogramm\" kombiniert. Der Teil des Supervisors, der diese Programme ausführt, kann als ein softwareimplementierter \"Überwachungscomputer\" betrachtet werden. Das Papier entwickelt diese Konzepte im Detail, skizziert den Rest des Supervisors und diskutiert einige der Vorteile dieses Ansatzes."}
{"DOCID": "2379", "TEXT": "Das Design des Venus-Betriebssystems: Das Venus-Betriebssystem ist ein experimentelles Multiprogramming-System, das fünf oder sechs gleichzeitige Benutzer auf einem kleinen Computer unterstützt. Das System wurde entwickelt, um die Auswirkung der Maschinenarchitektur auf die Komplexität von Software zu testen. Das System wird durch eine Kombination aus Mikroprogrammen und Software definiert. Das Mikroprogramm definiert eine Maschine mit einem ungewöhnlichen architektonischen Merkmal; Die Software nutzt diese Eigenschaften, um das Betriebssystem so einfach wie möglich zu definieren. In diesem Dokument wird die Entwicklung des Systems beschrieben, mit besonderem Schwerpunkt auf den Prinzipien, die das Design leiteten."}
{"DOCID": "2380", "TEXT": "TENEX, ein Paged Time-Sharing-System für den PDP-10: TENEX ist ein neues Time-Sharing-System, das auf DEC PDP-10 implementiert ist und durch spezielle Paging-Hardware erweitert wird, die bei BBN entwickelt wurde. Dieser Bericht legt eine Reihe von Zielen fest, die für jedes Timesharing-System wichtig sind. Es beschreibt, wie das Design und die Implementierung von TENEX diese Ziele erreichen. Dazu gehören Spezifikationen für eine leistungsstarke virtuelle Multiprozess-Maschine mit großem Arbeitsspeicher, enge Terminalinteraktionen, umfassende einheitliche Datei- und E/A-Funktionen und eine saubere, flexible Systemstruktur. Obwohl die hier beschriebene Implementierung einige Kompromisse erforderte, um ein betriebsbereites System innerhalb von sechs Monaten nach dem Hardware-Checkout zu erreichen, hat TENEX seine Hauptziele erreicht und zuverlässigen Service an mehreren Standorten und über das ARPA-Netzwerk bereitgestellt."}
{"DOCID": "2381", "TEXT": "Durchschnittliche binäre Suchlänge für dicht geordnete Listen (Korrigendum)"}
{"DOCID": "2382", "TEXT": "Rekonstruktion von Bildern aus ihren Projektionen (Korrigendum)"}
{"DOCID": "2383", "TEXT": "Musik und Computerkomposition: Das diskutierte Problem besteht darin, die menschliche Komposition westlicher Popmusik durch Computer zu simulieren, und es werden einige relevante Musik- und Harmonietheorien vorgestellt. Probleme mit dieser Art von Programmen und mehreren Schemata, von denen bekannt ist, dass sie nicht funktionieren, werden diskutiert. Mehrere frühere Computerzusammensetzungen werden diskutiert, einschließlich der ILLIAC Suite. Ein Programm zum Generieren kurzer Melodiefragmente wurde geschrieben, um einige der Aspekte der menschlichen Komposition zu simulieren. Fünf Beispiele seiner Ergebnisse werden vorgestellt und diskutiert. Es wurde entdeckt, dass die Fragmente zwar viele Merkmale populärer Melodien aufweisen, aber einen seltsam fremden Klang haben. Es wird angenommen, dass dies darauf zurückzuführen ist, dass die relevanten Wahrscheinlichkeiten, die unbekannte Sequenzen diskriminieren würden, nicht verwendet wurden."}
{"DOCID": "2384", "TEXT": "Programm zum Zeichnen verdeckter Linien [J6] (Algorithmus A420)"}
{"DOCID": "2385", "TEXT": "Nullstellen eines komplexen Polynoms [C2] (Algorithmus A419)"}
{"DOCID": "2386", "TEXT": "Dynamische Mikroprogrammierung: Prozessororganisation und -programmierung (Berichtigung)"}
{"DOCID": "2387", "TEXT": "Maximale Rechenleistung und Kostenfaktoren im Zentralisierungsproblem: Eine einfache Analyse einiger computerökonomischer Faktoren, die beim Vergleich von Mehrmaschineninstallationen mit großen Einzelmaschineninstallationen eine Rolle spielen, wird gegeben, und ein mathematisches Modell wird abgeleitet, um politische Entscheidungen zu unterstützen."}
{"DOCID": "2388", "TEXT": "Optimieren von Binärbäumen, die mit einem Sortieralgorithmus gewachsen sind: Elemente können aus Binärbäumen, die mit einer Form des Algorithmus Quicksort gewachsen sind, in einer durchschnittlichen Zeit abgerufen werden, die proportional zu log n ist, wobei n die Anzahl der Elemente im Baum ist. Die mit diesem Algorithmus erzeugten Binärbäume haben manchmal einige Zweige länger als andere; Daher ist es möglich, die durchschnittliche Abrufzeit zu reduzieren, indem der Baum umstrukturiert wird, um die Äste so einheitlich wie möglich zu machen. Ein Algorithmus, um dies zu tun, wird vorgestellt. Die Verwendung dieses Algorithmus wird diskutiert und mit einem anderen verglichen, der den Baum neu strukturiert, nachdem jedes neue Element hinzugefügt wurde."}
{"DOCID": "2389", "TEXT": "Vorläufiger Bericht über ein System zur allgemeinen Raumplanung: Eine Computersprache und eine Reihe von Programmen innerhalb dieser Sprache werden beschrieben, die das Formulieren und Lösen einer Klasse von Raumplanungsproblemen ermöglichen. Die Sprache ist eine Erweiterung von Algol und beinhaltet Mittel, um Räume und Objekte darzustellen, sie zu manipulieren und die resultierenden Anordnungen gemäß einer Vielzahl von Einschränkungen zu testen. Die Algorithmen zur Lösung von Problemen, die in dieser Sprache ausgedrückt werden, beruhen auf heuristischer Programmierung. Sowohl die Sprache als auch die Suchalgorithmen sind detailliert."}
{"DOCID": "2390", "TEXT": "Ein Vorschlag für eine computergestützte interaktive wissenschaftliche Gemeinschaft: Aufgrund der Probleme, die durch die Explosion von Artikeln in den mathematischen Wissenschaften entstehen, und der Nachteile, die dies für die Forschung mit sich bringt, wird vorgeschlagen, einen Baum aller mathematischen Ergebnisse und Terminologien in a zu führen Multiterminal-Computersystem. Benutzer des Systems können im Computer eine aktualisierte Datei ihres aktuellen Wissens speichern, und beim Auswählen einer zu lesenden Arbeit können sie vom Computer den minimalen Teilbaum von Theoremen erhalten, der erforderlich ist, um sie von dem, was sie bereits wissen, zum Hintergrundwissen zu bringen das Papier geht davon aus. Unter bestimmten Bedingungen werden auch Mittel bereitgestellt, um nützliche Kommentare von den Lesern eines Werkes abzugeben und zwischen Kommentatoren und dem Autor zu interagieren. Dieses Papier beschreibt, wie das System organisiert werden kann und welche Rolle von Lesern, Autoren und Kommentatoren gefordert wird."}
{"DOCID": "2391", "TEXT": "Unitäre symmetrische Polynome [Z] (Algorithmus R391)"}
{"DOCID": "2392", "TEXT": "In-situ-Transposition einer rechteckigen Matrix [F1] (Algorithmus C380)"}
{"DOCID": "2393", "TEXT": "Berechnung von Fourier-Integralen [D1] (Algorithmus A418)"}
{"DOCID": "2394", "TEXT": "Bestellung von +-f(+-f(+-f(...+-f(x)..))) Wenn f(x) positiv monoton ist"}
{"DOCID": "2395", "TEXT": "Quadratische Programmierung für nichtlineare Regression: Es wird ein quadratischer Programmieralgorithmus zur Verwendung mit der vergrößerten diagonalen Methode der nichtlinearen Regression mit linearen Beschränkungen beschrieben. Die Regressionsmethode ist in JACM, Juli 1970, veröffentlicht."}
{"DOCID": "2396", "TEXT": "MUSE: Ein Modell zum Verstehen von einfachem Englisch: MUSE ist ein Computermodell für die Verarbeitung natürlicher Sprache, basierend auf einem semantischen Gedächtnisnetzwerk wie dem von Quillian's TLC. MUSE, from a Model to Understand Simple English, verarbeitet englische Sätze mit uneingeschränktem Inhalt, aber etwas eingeschränktem Format. Das Modell wendet zuerst eine syntaktische Analyse an, um einige Interpretationen zu eliminieren, und verwendet dann ein vereinfachtes semantisches Schnittmengenverfahren, um eine gültige Interpretation der Eingabe zu finden. Während die semantische Verarbeitung ähnlich der von TLC ist, umfasst die syntaktische Komponente die frühe Verwendung von Analysebäumen und Regeln für spezielle Zwecke. Die bei der Interpretation von Eingaben verwendete \"relationale Dreifach\"-Notation ist mit den Speicherstrukturen von MUSE kompatibel und ermöglicht die direkte Überprüfung bekannter Konzepte und das Hinzufügen neuer. MUSE verfügt auch über ein Repertoire an Aktionen, die vom Editieren und Melden der Inhalte des eigenen Gedächtnisses bis hin zu einer indirekten Form der Fragebeantwortung reichen. Es werden Beispiele präsentiert, um zu demonstrieren, wie das Modell Text interpretiert, Mehrdeutigkeiten auflöst, Informationen zum Gedächtnis hinzufügt, aus Beispielen verallgemeinert und verschiedene Aktionen ausführt."}
{"DOCID": "2397", "TEXT": "Optimierung der Polyphasensortierung (Korrigendum)"}
{"DOCID": "2398", "TEXT": "Von Lehrern/Schülern verfasstes CAI unter Verwendung des NEWBASIC-Systems: Die pädagogischen Vorteile eines universellen interaktiven Systems namens NEWBASIC/CATALYST werden diskutiert. NEWBASIC/CATALYST enthält eine erweiterte Implementierung von BASIC, interaktive Funktionen auf Systemebene und eine allgemeine Fähigkeit zur Erweiterung durch benutzerorientierte Funktionszuordnung. Die Anwendung dieser letzten Funktion zur Bereitstellung einer flexiblen CAI-Scan-Fähigkeit wird veranschaulicht. Ein Beispiel für die Interaktion auf Systemebene zeigt, wie Studenten die Vorteile des Rechnens im unabhängigen oder \"Solo\"-Modus mit denen der geführten oder \"dualen\" Modus-Interaktion kombinieren können. Vorläufige Erfahrungen mit dem System in einer städtischen Sekundarschulumgebung werden diskutiert."}
{"DOCID": "2399", "TEXT": "Ein CRT-Editiersystem: Ein Test-Editier- und Manipulationsprogramm wird beschrieben. Das Programm arbeitet mit kostengünstigen Kathodenstrahlröhren-Eingabe- und Anzeigestationen mit Tastatur und 13 Funktionstasten. Anwendungen, potenzielle Wirtschaftlichkeit des Betriebs und einige Aspekte der Implementierung werden diskutiert."}
{"DOCID": "2400", "TEXT": "Verwendung der Hough-Transformation zum Erkennen von Linien und Kurven in Bildern: Hough hat ein interessantes und recheneffizientes Verfahren zum Erkennen von Linien in Bildern vorgeschlagen. Dieses Papier weist darauf hin, dass die Verwendung von Winkelradius- statt Steigungsabschnittsparametern die Berechnung weiter vereinfacht. Es zeigt auch, wie die Methode für eine allgemeinere Kurvenanpassung verwendet werden kann, und gibt alternative Interpretationen, die die Quelle ihrer Effizienz erklären."}
{"DOCID": "2401", "TEXT": "Zum Schrumpfen binärer Bildmuster: Ein paralleler Verarbeitungsalgorithmus zum Schrumpfen binärer Muster, um einzelne isolierte Elemente zu erhalten, eines für jedes Muster, wird vorgestellt. Dieses Verfahren kann zum Zählen von Mustern auf einer Matrix verwendet werden, und es wird eine Hardwareimplementierung des Algorithmus unter Verwendung von hochintegrierter Technologie ins Auge gefasst. Die Hauptmerkmale dieses Verfahrens sind das verwendete sehr kleine Fenster (zwei mal zwei Elemente), die Parallelität des Prozesses und die Möglichkeit, jedes Muster zu verkleinern, unabhängig von der Komplexität seiner Konfiguration. Probleme in Bezug auf das Zusammenführen und Trennen von Mustern während des Prozesses sowie die Bestimmung der maximalen Anzahl von Schritten, die erforderlich sind, um ein einzelnes isoliertes Element aus einem Muster zu erhalten, werden überprüft und diskutiert. Es wird eine Analogie mit einer neuronalen Netzwerkbeschreibung in Begriffen von McCulloch-Pitts \"Neuronen\" präsentiert."}
{"DOCID": "2402", "TEXT": "Bildmustererkennung und das Phasenproblem der Röntgenkristallographie: Die Verfügbarkeit von interaktiven, dreidimensionalen Computergrafiksystemen, die mit leistungsstarken Digitalcomputern gekoppelt sind, fördert die Entwicklung von Algorithmen, die an diese Umgebung angepasst sind. Bildmustererkennungstechniken ermöglichen eine Reihe von Ansätzen zur Röntgenstrukturbestimmung auf der Grundlage des Aufbaus von Molekularmodellen, d. h. die Verwendung chemischer Informationen, um \"Strukturhypothesen\" zu formulieren, die rechnerisch getestet und unter Bezugnahme auf die experimentellen Daten verfeinert werden können. Die Anwendung von Standard-Mustererkennungsalgorithmen wird dadurch erschwert, dass die Kreuzkorrelation zwischen einem Modell und der korrekten Struktur aufgrund einer grundlegenden Unvollständigkeit der gemessenen Daten nicht berechnet werden kann. Es ist jedoch möglich, eine Obergrenze für eine solche Kreuzkorrelation zu berechnen. Ein einfaches Beispiel demonstriert, dass diese Informationen die Grundlage einer Technik zur Strukturbestimmung sein können, die ein interaktives Grafiksystem effektiv nutzen kann. Die Modellbildung durch Kreuzkorrelationen hat intrinsische Vorteile gegenüber üblichen kristallographischen Techniken, die auf der Autokorrelation oder der Patterson-Funktion basieren, insbesondere für große Strukturen. Dies ist von Bedeutung, da die Kristallographie biologischer Makromoleküle ein Gebiet von großem Interesse war und auch weiterhin sein wird."}
{"DOCID": "2403", "TEXT": "Verfahren zur natürlichen Spline-Interpolation [E1] (Algorithmus A472)"}
{"DOCID": "2404", "TEXT": "Exponentialintegrale [S13] (Algorithmus A471)"}
{"DOCID": "2405", "TEXT": "Lineare Systeme mit fast tridiagonaler Matrix [F4] (Algorithmus A470)"}
{"DOCID": "2406", "TEXT": "A Data Definition and Mapping Language: Eine Datendefinitionssprache ist eine deklarative Computersprache zur Spezifikation von Datenstrukturen. Die meisten Datendefinitionssprachen konzentrieren sich auf die Deklaration logischer Datenstrukturen, ohne sich darum zu kümmern, wie diese Strukturen physikalisch auf einem Computersystem realisiert werden. Der Bedarf an Datendefinitionssprachen, die sowohl die logischen als auch die physikalischen Aspekte von Daten beschreiben, wird jedoch zunehmend offensichtlich. Solche Sprachen werden Schlüsselsysteme sein, ebenso wie in fortschrittlichen Datenverwaltungssystemen und verteilten Datenbanken. Dieses Papier gibt einen Überblick über frühere Arbeiten in der Datendefinitionssprache zur Beschreibung sowohl logischer als auch physikalischer Aspekte von Daten. Anwendungen dieser \"verallgemeinerten\" Datendefinitionssprachen werden ebenfalls diskutiert."}
{"DOCID": "2407", "TEXT": "Curriculum-Empfehlungen für Undergraduate-Programme in Informationssystemen: Der Bedarf an Bildung in Bezug auf Informationssysteme in Organisationen wird diskutiert und ein Curriculum für ein Undergraduate-Programm vorgeschlagen. Das für solche Programme erforderliche Material wird identifiziert und Kurse, die es enthalten, werden angegeben. Detaillierte Kursbeschreibungen werden präsentiert. Die Programmorganisation und Probleme der Durchführung werden diskutiert."}
{"DOCID": "2408", "TEXT": "Lösen der biharmonischen Gleichung in einem Quadrat: Eine direkte versus eine halbdirekte Methode: Zwei Methoden zum Lösen der biharmonischen Gleichung werden verglichen. Eine Methode ist direkt und verwendet eine Eigenwert-Eigenvektor-Zerlegung. Die andere Methode ist iterativ und löst eine Poisson-Gleichung direkt bei jeder Iteration."}
{"DOCID": "2409", "TEXT": "Ein Algorithmus zur Näherungslösung von Wiener-Hopf-Integralgleichungen: Für eine Gleichung wird eine explizite Näherungslösung angegeben. Wo angenommen wird, dass die klassische Wiener-Hopf-Technik angewendet werden kann. Weiterhin wird vorausgesetzt, dass Fourier-Transformationen explizit bekannt sind. Die Näherungslösung hängt von zwei positiven Parametern ab."}
{"DOCID": "2410", "TEXT": "Ein Rekursionsschema zum Konvertieren von einer orthogonalen Entwicklung in eine andere: Eine Verallgemeinerung eines Hamming-Schemas zum Konvertieren eines Polynoms Pn(x) in eine Tschebyscheff-Reihe wird mit einem Rekursionsschema von Clenshaw zum Summieren beliebiger endlicher Reihen kombiniert, deren Terme eine Drei- Begriffswiederholungsformel."}
{"DOCID": "2411", "TEXT": "Baumstrukturierte Programme"}
{"DOCID": "2412", "TEXT": "Kommentar zum Scatter-Speicheralgorithmus von Brent"}
{"DOCID": "2413", "TEXT": "Eine Anmerkung zur Unterausdrucksreihenfolge bei der Ausführung von arithmetischen Ausdrücken: Ein Gegenbeispiel zur angenommenen Optimalität eines Algorithmus zum Generieren von Zeitplänen für Bäume von Aufgaben mit ungleichen Ausführungszeiten wird präsentiert. Ein Vergleich mit der „Critical Path“-Heuristik wird diskutiert."}
{"DOCID": "2414", "TEXT": "Arithmetik über einem endlichen Körper [A1] (Algorithmus A469)"}
{"DOCID": "2415", "TEXT": "Algorithmus zur automatischen numerischen Integration über ein endliches Intervall [D1] (Algorithmus A468)"}
{"DOCID": "2416", "TEXT": "Matrixtransposition an Ort und Stelle [F1] (Algorithmus A467)"}
{"DOCID": "2417", "TEXT": "Vier kombinatorische Algorithmen [G6] (Algorithmus A466)"}
{"DOCID": "2418", "TEXT": "Schüler-t-Häufigkeit [S14] (Algorithmus A465)"}
{"DOCID": "2419", "TEXT": "Eigenwerte einer reellen, symmetrischen, tridiagonalen Matrix [F2] (Algorithmus A464)"}
{"DOCID": "2420", "TEXT": "Experimente mit einem automatischen Theorem-Beweiser mit partiellen Ordnungsschlussregeln: Automatische Theorem-Beweiser müssen viel effizienter gemacht werden. Vor diesem Hintergrund hat Slagle gezeigt, wie die Axiome für die partielle Ordnung durch eingebaute Inferenzregeln ersetzt werden können, wenn ein bestimmter Algorithmus zum Beweis von Theoremen verwendet wird, der auf Hyperauflösung und Paramodulation basiert. Die neuen Regeln verkörpern die Transitivität partieller Ordnungen und die enge Beziehung zwischen Prädikaten. Unter Verwendung einer modifizierten Version dieser Regeln wurde ein Programm entwickelt. Dieser neue Theorem-Beweiser hat sich als sehr leistungsfähig erwiesen, um Probleme mit partiellen Ordnungen zu lösen. Dieses Papier enthält eine detaillierte Beschreibung des Programms und einen umfassenden Bericht über die Experimente, die damit durchgeführt wurden."}
{"DOCID": "2421", "TEXT": "Ein Scan-Umwandlungsalgorithmus mit reduzierten Speicheranforderungen: Die meisten Grafiksysteme, die ein Rasterscan-Ausgabegerät (CRT oder Hardcopy) verwenden, unterhalten eine Anzeigedatei im XY- oder Random-Scan-Format. Scankonverter, Hardware oder Software, müssen bereitgestellt werden, um die Bildbeschreibung vom XY-Format in das Rasterformat zu übersetzen. Veröffentlichte Scan-Umwandlungsalgorithmen, die schnell sind, reservieren einen Pufferbereich, der groß genug ist, um den gesamten Bildschirm aufzunehmen. Andererseits sind diejenigen, die einen kleinen Pufferbereich verwenden, langsam, da sie mehrere Durchgänge durch die XY-Anzeigedatei erfordern. Der hier beschriebene Abtastumwandlungsalgorithmus verwendet eine verknüpfte Listendatenstruktur, um die Zeilen der Zeichnung in Streifen zu verarbeiten, die Gruppen von Abtastzeilen entsprechen. Ein relativ kleiner Primärspeicherpufferbereich wird verwendet, um das Binärbild für eine Gruppe von Abtastzeilen zu akkumulieren. Wenn dieser Teil der Zeichnung geplottet wurde, wird der Puffer für den nächsten Teil wiederverwendet. Aufgrund der verwendeten Listenverarbeitungsprozeduren ist nur ein einziger Durchlauf durch die XY-Anzeigedatei erforderlich, wenn das Binärbild erzeugt wird, und nur eine geringfügige Erhöhung der Ausführungszeit gegenüber den vollständig gepufferten Kernergebnissen. Die Ergebnisse verlangsamen, dass die Speicheranforderungen um mehr als 80 Prozent reduziert werden können, während die Ausführungszeit um weniger als 10 Prozent erhöht wird."}
{"DOCID": "2422", "TEXT": "Adaptive Korrektur von Programmaussagen (Korrigendum)"}
{"DOCID": "2423", "TEXT": "A Parser-Generating System for Constructing Compressed Compilers: Dieses Dokument beschreibt ein Parser-Generating System (PGS), das derzeit auf dem CDC-6500-Computer an der Purdue University verwendet wird. Der PGS ist ein Fortran-codierter Compiler. In der Eingangsübersetzungsgrammatik entspricht jede syntaktische BNF-Regel einem (möglicherweise leeren) \"Codegenerator\", der als eine Assemblersprachen-, Fortran- oder Algol-Subroutine realisierbar ist, die immer dann aufgerufen wird, wenn diese syntaktische Regel in der Analyse eines Programms angewendet wird. Typische One-Pass-Compiler, die von PGS konstruiert wurden, übersetzen Quellprogramme mit Geschwindigkeiten von annähernd 14.000 Karten pro Minute. Für einen XPL-Compiler belegen das Parser-Programm und seine Tabellen derzeit 288 Wörter eines 60-Bit-Kernspeichers, von denen 140 Wörter Tabelleneinträge parsen und 82 Wörter Verbindungen zu Codegeneratoren sind."}
{"DOCID": "2424", "TEXT": "Dynamische Überprüfung von Betriebssystementscheidungen: Die dynamische Überprüfung einer Entscheidung impliziert, dass jedes Mal, wenn die Entscheidung getroffen wird, eine Konsistenzprüfung an der Entscheidung unter Verwendung unabhängiger Hardware und Software durchgeführt wird. Die dynamische Überprüfung von Betriebssystementscheidungen wird auf dem PRIME-System verwendet, das an der University of California, Berkeley entworfen und gebaut wird. PRIME ist ein experimentelles Timesharing, das die Eigenschaften ständiger Verfügbarkeit, Datenschutz und Kosteneffizienz haben soll. Die Technik der dynamischen Verifizierung ermöglicht den Aufbau eines Betriebssystems, das bestimmte Entscheidungen selbst bei Vorhandensein eines einzigen Hardware- oder Softwarefehlers nicht falsch trifft. Außerdem führen Mehrfachfehler nur dann zu einem unzuverlässigen Betrieb, wenn sich die Fehler gegenseitig verstärken. Bei PRIME wird die dynamische Verifizierung verwendet, um sicherzustellen, dass die Informationen eines Benutzers einem anderen Benutzer nicht unentgeltlich zur Verfügung gestellt werden, selbst wenn nur ein einziger Hardware- oder Softwarefehler vorliegt. Die Menge an zusätzlicher Hardware und Software, die für die dynamische Verifizierung erforderlich ist, kann bescheiden sein."}
{"DOCID": "2425", "TEXT": "Der Programmierer als Navigator"}
{"DOCID": "2426", "TEXT": "Algorithmen SCALE1, SCALE2 und SCALE3 zur Bestimmung von Skalen in computergenerierten Diagrammen [J6] (Algorithmus A463)"}
{"DOCID": "2427", "TEXT": "Bivariate Normalverteilung [S15] (Algorithmus A462)"}
{"DOCID": "2428", "TEXT": "Kubische Spline-Lösungen für eine Klasse funktionaler Differentialgleichungen [D2] (Algorithmus A461)"}
{"DOCID": "2429", "TEXT": "Berechnung optimaler Parameter für implizite Prozeduren mit wechselnder Richtung [D3] (Algorithmus A460)"}
{"DOCID": "2430", "TEXT": "Die Elementarschaltungen eines Graphen [H] (Algorithmus A459)"}
{"DOCID": "2431", "TEXT": "Diskrete lineare L1-Approximation durch Intervall Lineare Programmierung [E2] (Algorithmus A458)"}
{"DOCID": "2432", "TEXT": "Ergänzung zu einem Multiple-Precision-Division-Algorithmus"}
{"DOCID": "2433", "TEXT": "Steuerstrukturen in Illiac IV Fortran: Als Teil der Bemühungen, einen Fortran-Compiler auf dem ILLIAC IV zu entwerfen und zu implementieren, wurde ein erweitertes Fortran namens IVTRAN entwickelt. Diese Sprache bietet ein Mittel zum Ausdrücken von Daten und Steuerstrukturen, die zum Ausnutzen der ILLIAC IV-Parallelität geeignet sind. Dieses Papier gibt einen Überblick über die Hardwareeigenschaften des ILLIAC und hebt unkonventionelle Merkmale hervor, von denen erwartet werden kann, dass sie das Design der Sprache (und des Compilers) beeinflussen. Die Auswirkungen dieser Merkmale auf das Datenlayout und die Algorithmusstruktur werden diskutiert, und es wird die Schlussfolgerung gezogen, dass die Datenzuordnung und nicht die Codestrukturierung das entscheidende ILLIAC-Optimierungsproblem ist. Anschließend wird eine zufriedenstellende Methode der Datenzuordnung vorgestellt. Sprachstrukturen zur Verwendung dieses Speicherverfahrens und zum Ausdrücken paralleler Algorithmen werden beschrieben."}
{"DOCID": "2434", "TEXT": "Verwenden der Seitenresidenz zum Auswählen des Arbeitssatzparameters: Es wird das Verfahren von Denning zum Auswählen des Arbeitssatzparameters untersucht, das Interreferenzintervalle verwendet. Mehrere Auslassungen in seinem Modell werden festgestellt, und neue Annahmen werden eingeführt, um diese Auslassungen zu überwinden. Unter Verwendung dieses modifizierten Modells werden die Ergebnisse von Dening zur Seitenresidenz neu abgeleitet und für die Auswahl des Parameters des Arbeitssatzes erneut betrachtet."}
{"DOCID": "2435", "TEXT": "Eine Klasse dynamischer Speicherzuweisungsalgorithmen: Ein neuer dynamischer Speicherzuweisungsalgorithmus, das Fibonacci-System, wird eingeführt. Dieser Algorithmus ähnelt dem \"Buddy\"-System, scheint aber gewisse Vorteile gegenüber diesem zu haben. Es wird eine Verallgemeinerung erwähnt, die diese beiden Systeme als Spezialfälle einschließt."}
{"DOCID": "2436", "TEXT": "Eine Anmerkung zum Beschränkungsproblem: Diese Anmerkung untersucht das Problem der Beschränkung eines Programms während seiner Ausführung, so dass es keine Informationen an irgendein anderes Programm außer seinem Aufrufer übertragen kann. Eine Reihe von Beispielen versucht, die Grenzen des Problems abzustecken. Notwendige Bedingungen für eine Lösung werden genannt und informell begründet."}
{"DOCID": "2437", "TEXT": "Allgemeine Leistungsanalyse von Schlüssel-zu-Adresse-Umwandlungsverfahren unter Verwendung eines abstrakten Dateikonzepts: Dieses Papier stellt einen neuen Ansatz zur Analyse der Leistung der verschiedenen Schlüssel-zu-Adresse-Umwandlungsverfahren vor. Bei diesem Ansatz wird angenommen, dass die Schlüssel in einer Datei gemäß einem bestimmten probabilistischen Auswahlalgorithmus aus dem Schlüsselraum ausgewählt wurden. Alle aus diesem Schlüsselraum ausgewählten Dateien mit der gleichen Anzahl von Schlüsseln werden gemäß dem Algorithmus geeignet gewichtet und die durchschnittliche Leistung der Transformationsverfahren auf diesen Dateien wird als Potenzial dieser Verfahren verwendet. Anhand dieser Analyse können Methoden mit gleicher Gesamtleistung klassifiziert und Schlüsselverteilungen partiell auf bestimmte Transformationen identifiziert werden. All dies kann analytisch durchgeführt werden. Der Ansatz wird auf eine Gruppe von Transformationsverfahren angewendet, die Dateien verwenden, deren Schlüssel zufällig ausgewählt werden."}
{"DOCID": "2438", "TEXT": "Eine Modell- und Stapelimplementierung mehrerer Umgebungen: Viele Steuerungs- und Zugriffsumgebungsstrukturen erfordern, dass Speicher für eine Prozeduraktivierung zu Zeiten vorhanden sind, wenn die Steuerung nicht innerhalb der aktivierten Prozedur verschachtelt ist. Dies ist einfach durch dynamische Speicherzuweisung mit verknüpften Blöcken für jede Aktivierung zu implementieren, aber ziemlich zeit- und platzaufwändig. Dieses Dokument stellt eine Implementierungstechnik vor, die einen einzigen Stapel verwendet, um den Speicher für die Prozeduraktivierung zu halten, was die Aufbewahrung dieses Speichers für Zeiträume ermöglicht, die nicht notwendigerweise an den Kontrollfluss gebunden sind. Die Technik hat die Eigenschaft, dass sie im einfachen Fall identisch abläuft wie die übliche automatische Stack-Allokation und -Delokation. Anwendungen dieser Technik auf Multitasking, Coroutinen, Backtracking, Label-Wert-Variablen und funktionale Argumente werden diskutiert. Im anfänglichen Modell wird ein einzelner realer Prozessor angenommen, und die Implementierung geht davon aus, dass sich mehrere Prozesse koordinieren, indem sie die Steuerung explizit aneinander übergeben. Eine Multiprozessorimplementierung erfordert nur wenige Änderungen an der grundlegenden Technik, wie beschrieben."}
{"DOCID": "2439", "TEXT": "Mehrere Terminals unter Benutzerprogrammsteuerung in einer Time-Sharing-Umgebung: Benutzergeschriebene Programme auf dem Dartmouth Time-Sharing-System können gleichzeitig mit vielen entfernten Terminals kommunizieren und die Interaktionen zwischen diesen Terminals steuern. Solche Programme können unter Verwendung von standardmäßigen Eingabe- und Ausgabebefehlen in jeder auf dem System verfügbaren Sprache geschrieben werden. Dieses Dokument beschreibt, wie diese Einrichtung für mehrere Terminals implementiert wurde, ohne dass Änderungen in der Systemausführung oder in einem der Compiler oder Interpreter des Systems erforderlich waren."}
{"DOCID": "2440", "TEXT": "Lokalisierung der Nullstellen eines Polynoms (Algorithmus R429)"}
{"DOCID": "2441", "TEXT": "Programm zum Zeichnen verdeckter Linien (Algorithmus R420)"}
{"DOCID": "2442", "TEXT": "Ein Sparse-Matrix-Paket (Algorithmus R408)"}
{"DOCID": "2443", "TEXT": "Generierung von Permutationen in lexikografischer Reihenfolge (Algorithmus R323)"}
{"DOCID": "2444", "TEXT": "Finden aller Cliquen eines ungerichteten Graphen (Algorithmus A457)"}
{"DOCID": "2445", "TEXT": "Routing-Problem (Algorithmus A456)"}
{"DOCID": "2446", "TEXT": "Analyse schiefer Darstellungen der symmetrischen Gruppe (Algorithmus A455)"}
{"DOCID": "2447", "TEXT": "Sard-Kernel für bestimmte bivariate Kubaturen: Eine Fehleranalyse für einige bivariate Kubaturen wird gegeben. Der Rest wird durch die Verwendung von Sardenkernen gewonnen. Numerische Ergebnisse und Computerdiagramme werden für einige der Kernelfunktionen angegeben."}
{"DOCID": "2448", "TEXT": "Reversible Ausführung"}
{"DOCID": "2449", "TEXT": "Eine einfache Technik zum Nachschlagen von strukturierten Variablen: Eine einfache Technik zum Nachschlagen strukturierter Variablen in Symboltabellen auf der Grundlage der Theorie einfacher Automaten wird vorgestellt. Die Technik bietet eine deterministische Lösung für ein Problem, das derzeit in PL/I- und COBOL-Compilern auf nichtdeterministische Weise gehandhabt wird."}
{"DOCID": "2450", "TEXT": "Empirisches Working-Set-Verhalten: Das Working-Set-Modell für das Programmverhalten wurde in den letzten Jahren als Grundlage für den Entwurf von Scheduling- und Paging-Algorithmen vorgeschlagen. Obwohl die Wörter \"Working Set\" heute in der Literatur, die sich mit Ressourcenzuteilung befasst, häufig anzutreffen sind, gibt es einen Mangel an veröffentlichten Daten zu Programmmessungen, in der Hoffnung, dass Fachleute auf diesem Gebiet experimentelle Beweise finden könnten, auf denen sie theoretische Arbeiten untermauern und gründen können ."}
{"DOCID": "2451", "TEXT": "Entwurf von Baumstrukturen für effizientes Abfragen: Eine standardmäßige Informationswiedergewinnungsoperation besteht darin, zu bestimmen, welche Aufzeichnungen in einer Datensammlung eine gegebene Abfrage, ausgedrückt in Form von Datenwerten, erfüllen. Der Prozess des Lokalisierens der gewünschten Antworten kann durch ein Baumsuchmodell dargestellt werden. Dieses Papier wirft ein Optimierungsproblem beim Entwurf solcher Bäume auf, um eine genau spezifizierte Anwendung zu bedienen. Das Problem ist akademisch in dem Sinne, dass der optimale Baum normalerweise nicht durch praktische Techniken implementiert werden kann. Andererseits ist es potenziell nützlich für den Vergleich zwischen der beobachteten Leistung und der eines intuitiv attraktiven idealen Suchverfahrens. Als praktische Anwendung eines solchen Modells betrachtet dieser Beitrag den Entwurf eines neuartigen Baumsuchschemas basierend auf einer Bitvektordarstellung von Daten und zeigt, dass im Wesentlichen derselbe Algorithmus verwendet werden kann, um entweder einen idealen Suchbaum oder einen Bitvektorbaum zu entwerfen . Eine experimentelle Untersuchung einer kleinformatigen Datei veranschaulicht die Konzepte."}
{"DOCID": "2452", "TEXT": "Bewertung und Auswahl der Dateiorganisation – ein Modell und System: Diese Arbeit diskutiert zuerst die Faktoren, die die Leistung der Dateiorganisation (Datenbank) beeinflussen, ein schwer fassbares Thema, und stellt dann eine Methodik, ein Modell und ein programmiertes System vor, um hauptsächlich die Gesamtspeicherkosten zu schätzen und durchschnittliche Zugriffszeit mehrerer Dateiorganisationen bei gegebener spezifischer Datenbank, Abfragecharakterisierung und gerätebezogenen Spezifikationen. Basierend auf diesen Schätzungen kann eine geeignete Dateistruktur für die spezifische Situation ausgewählt werden. Das System ist ein praktisches Werkzeug, um Dateistrukturen zu studieren und den Prozess der Konstruktion und Auswertung von Datenbankstrukturen so weit wie möglich zu erleichtern."}
{"DOCID": "2453", "TEXT": "Angewandte Informationstheorie auf die Umwandlung von Entscheidungstabellen in Computerprogramme: Unter Verwendung von Ideen aus der Informationstheorie entwickelt dieser Aufsatz einen heuristischen Algorithmus, der eine Entscheidungstabelle mit begrenztem Eintrag in ein Computerprogramm mit Baumstruktur mit nahezu minimaler durchschnittlicher Verarbeitungszeit umwandelt. Das Verfahren ist auf jede Entscheidungstabelle mit begrenztem Eintritt anwendbar und erfordert nicht, dass Aktionen einzelne Regeln haben oder dass die Kosten zum Testen von Bedingungen gleich sind. Es ist damit allgemeiner als die bisher veröffentlichten heuristischen Algorithmen. Verglichen mit dem optimalen Algorithmus von Reinwald und Soland ist dieser Algorithmus einfach zu codieren und benötigt eine viel geringere Übersetzungszeit; es wird daher empfunden, dass es in der Praxis nützlicher ist. Der Algorithmus eignet sich gut für die manuelle Umwandlung von Entscheidungstabellen in Flussdiagramme."}
{"DOCID": "2454", "TEXT": "Rechenalgorithmen für geschlossene Warteschlangennetze mit exponentiellen Servern: Es werden Methoden zur Berechnung der Gleichgewichtsverteilung von Kunden in geschlossenen Warteschlangennetzen mit exponentiellen Servern vorgestellt. Ausdrücke für verschiedene Randverteilungen werden ebenfalls abgeleitet. Die Berechnungsalgorithmen basieren auf zweidimensionalen iterativen Techniken, die hocheffizient und recht einfach zu implementieren sind. Implementierungsüberlegungen wie Speicherzuweisungsstrategien und Auswertungsreihenfolge werden ausführlich untersucht."}
{"DOCID": "2455", "TEXT": "Eine Verallgemeinerung von AVL-Bäumen: Es wird eine Verallgemeinerung von AVL-Bäumen vorgeschlagen, bei der Ungleichgewichte bis zu (Dreiecksform) eine kleine ganze Zahl sind. Es wird ein Experiment durchgeführt, um diese Bäume mit Standard-AVL-Bäumen und mit balancierten Bäumen auf der Grundlage der mittleren Suchzeit, des erwarteten Umfangs der Umstrukturierung und der Suchzeit im ungünstigsten Fall zu vergleichen. Es wird gezeigt, dass durch das Zulassen von Ungleichgewichten von bis zu fünf Einheiten die Wiederherstellungszeit um einen kleinen Betrag erhöht wird, während der Umfang der erforderlichen Umstrukturierung um einen Faktor zehn verringert wird. Einige theoretische Ergebnisse werden abgeleitet, einschließlich der Korrektur einer früheren Arbeit, und werden ordnungsgemäß mit den experimentellen Daten verglichen. Es wird eine einigermaßen gute Übereinstimmung gefunden."}
{"DOCID": "2456", "TEXT": "Über die Möglichkeiten von While-, Repeat- und Exit-Anweisungen: Ein wohlgeformtes Programm ist definiert als ein Programm, in dem Schleifen und if-Anweisungen richtig verschachtelt sind und nur an ihrem Anfang eingegeben werden können. Eine entsprechende Definition wird für ein wohlgeformtes Flussdiagramm gegeben. Es wird gezeigt, dass ein Programm genau dann wohlgeformt ist, wenn es mit if-, Repeat- und mehrstufigen Exit-Anweisungen zur Ablaufsteuerung geschrieben werden kann. Es wird auch gezeigt, dass if-, while- und repeat-Anweisungen mit einstufigem Exit nicht ausreichen. Es wird auch gezeigt, dass beliebige Flussdiagramme durch Knotenaufteilung in ein wohlgeformtes Flussdiagramm umgewandelt werden können. Praktische Implikationen werden diskutiert."}
{"DOCID": "2457", "TEXT": "Induktive Methoden zum Beweisen von Eigenschaften von Programmen: Es gibt zwei Hauptzwecke in diesem Artikel: Erstens, Klärung und Erweiterung bekannter Ergebnisse über die Berechnung rekursiver Programme, mit Betonung auf dem Unterschied zwischen theoretischen und praktischen Ansätzen; zweitens Vorstellung und Untersuchung verschiedener bekannter Methoden zum Beweis von Eigenschaften rekursiver Programme. Im Detail diskutiert werden zwei leistungsstarke induktive Methoden, die rechnerische Induktion und die strukturelle Induktion, einschließlich Anwendungsbeispiele."}
{"DOCID": "2458", "TEXT": "Lokalisierung der Nullstellen eines Polynoms (Algorithmus R429)"}
{"DOCID": "2459", "TEXT": "Hu-Tucker Minimum Redundancy Alphabetic Coding Method (Algorithmus R428)"}
{"DOCID": "2460", "TEXT": "Clenshaw-Curtis-Quadratur (Algorithmus R424)"}
{"DOCID": "2461", "TEXT": "Graphenplotter (Algorithmus R412)"}
{"DOCID": "2462", "TEXT": "Ein effizienter Primzahlgenerator (Algorithmus R357)"}
{"DOCID": "2463", "TEXT": "Komplexe Gammafunktion (Algorithmus R404, C404)"}
{"DOCID": "2464", "TEXT": "Die komplexe Methode zur eingeschränkten Optimierung [E4] (Algorithmus A454)"}
{"DOCID": "2465", "TEXT": "Gaußsche Quadraturformeln für Bromwichs Integral [D1] (Algorithmus A453)"}
{"DOCID": "2466", "TEXT": "Aufzählen von Kombinationen von m aus n Objekten [G6] (Algorithmus A452)"}
{"DOCID": "2467", "TEXT": "Chi-Quadrat-Quantile [G1] (Algorithmus A451)"}
{"DOCID": "2468", "TEXT": "Minimierung der Rosenbrock-Funktion [E4] (Algorithmus A450)"}
{"DOCID": "2469", "TEXT": "Petrinetze und geschwindigkeitsunabhängiges Design: Petrinetze werden als eine Methode zur Modellierung geschwindigkeitsunabhängiger asynchroner Schaltungen untersucht. Eine Untersuchung von Schaltungsrealisierungen von Petri-Netzen führt zu einer Demonstration ihrer Nützlichkeit bei der Modellierung eines geschwindigkeitsunabhängigen Betriebs. Diese Nützlichkeit wird durch das Design eines geschwindigkeitsunabhängigen Prozessors aus Modulen betont, die bei der Untersuchung der Petri-Netz-Implementierung entwickelt wurden."}
{"DOCID": "2470", "TEXT": "Fen-An Axiomatic Basis for Program Semantics: Ein formales System wird vorgestellt, das die Begriffe Datenelement, Funktion und Relation abstrahiert. Es wird argumentiert, dass das System für die prägnante und genaue Beschreibung der Programmsemantik besser geeignet ist als die Mengentheorie (oder ihre Ableitungen). Es wird gezeigt, wie das System verwendet werden kann, um zusammengesetzte Datentypen aus einfacheren mit den Operationen des Ruderns, Strukturierens und Vereinigens aufzubauen. Es wird auch demonstriert, dass durch den Mechanismus von Singleton-Datentypen völlig neue primitive Typen in Sprachen eingeführt werden können. Es wird gezeigt, dass sowohl deterministische als auch nichtdeterministische Funktionen im System definierbar sind. Es wird beschrieben, wie die lokale Umgebung als Datenelement modelliert werden kann und wie zwingende Aussagen als Funktionen auf die Umgebung betrachtet werden können. Die Natur rekursiver Funktionen wird kurz diskutiert, und es wird eine Technik vorgestellt, durch die sie in das System eingeführt werden können. Die Technik wird mit der Verwendung des paradoxen Kombinators Y kontrastiert. Die Fragen lokaler und globaler Umgebungen und verschiedener Modi des Funktionsaufrufs und der Parameterübergabe werden berührt. Die Theorie wird auf den Beweis mehrerer elementarer Sätze zur Semantik der Zuweisung, bedingten und iterativen Aussagen angewendet. Ein Anhang ist enthalten, der detailliert das formale System darstellt, das Netze und Fen regelt, die Abstraktionen, die informell im Hauptteil der Arbeit verwendet werden."}
{"DOCID": "2471", "TEXT": "Ein Lernprogramm, das Partnerschaftsdomino spielt: Es wurde ein Lernprogramm geschrieben, das BASIC ist, um Partnerschaftsdomino für vier Spieler zu spielen. Da Domino ein Spiel mit unvollständigen Informationen ist, verwendet das Programm etwas andere Prinzipien der künstlichen Intelligenz als Programme für Spiele mit vollständigen Informationen wie Dame, Schach und Go. Das Programm wurde konstruiert, um eine \"Strategie-Signaturtabelle\" zu verwenden, die Brettsituationen durch die Wechselwirkungen von Spielparametern klassifiziert. Jeder Eintrag in der Tabelle enthält adaptiv ermittelte Gewichte, die die Zweckmäßigkeit verschiedener Strategien angeben. Einmal gewählt, verwendet eine Strategie dann eine Wahrscheinlichkeitsanalyse und eine lineare Polynomauswertung, um einen Zug auszuwählen. Unser Programm gewinnt ungefähr zwei Drittel seiner Spiele in Turniersituationen und hat Meisterschaftsspieler besiegt."}
{"DOCID": "2472", "TEXT": "Minimaler Spannbaum (Algorithmus R422)"}
{"DOCID": "2473", "TEXT": "Programm zum Zeichnen verdeckter Linien (Algorithmus R420)"}
{"DOCID": "2474", "TEXT": "DIFSUB zur Lösung gewöhnlicher Differentialgleichungen (Algorithmus C407)"}
{"DOCID": "2475", "TEXT": "Lösung linearer Programmierprobleme in 0-1 Variablen [H1] (Algorithmus A449)"}
{"DOCID": "2476", "TEXT": "Äquivalenz zwischen UND/ODER-Graphen und kontextfreien Grammatiken"}
{"DOCID": "2477", "TEXT": "Mehrere Exits aus einer Schleife ohne GOTO"}
{"DOCID": "2478", "TEXT": "Informatik-Seminare für Studierende"}
{"DOCID": "2479", "TEXT": "Curriculum-Empfehlungen für Graduate Professional Programs in Information Systems: Empfohlenes Addendum on Information Systems Administration: Ein Addendum zum Bericht des ACM Curriculum Committee on Computer Education for Management wird vorgeschlagen. Der vorgeschlagene Zusatz soll einen Kurs über die Verwaltung von Informationssystemen in den Lehrplan aufnehmen. Dies ist aus zwei Gründen wichtig: (1) Der Systemdesigner muss den administrativen Rahmen verstehen, in dem er arbeiten muss, um effektiv arbeiten zu können, und (2) ein wichtiges Ziel der Lehrplanempfehlungen besteht darin, den zukünftigen Manager auf die Computertätigkeit vorzubereiten. Es wird davon ausgegangen, dass die Bedeutung dieser beiden Gründe die Hinzufügung des empfohlenen Kurses rechtfertigt. Der Kurs ist im Format des Originalberichts beschrieben."}
{"DOCID": "2480", "TEXT": "Lehre „Über das Programmieren“: Dieser Beitrag stellt die Ziele und die Organisation eines Kurses zum Thema Programmieren vor, der darauf ausgelegt ist, Studienanfängern in einem Graduiertenprogramm eine kulturelle Bereicherung in ihrem Berufsleben zu bieten. Von den Studierenden wird erwartet, dass sie zuvor mindestens zwei Programmierkurse besucht haben und daher sowohl als Studierende als auch als Anwender mit mindestens zwei Programmiersprachen vertraut sind. Jemandem das Programmieren beizubringen, ist ähnlich wie ihm das Spielen eines Musikinstruments beizubringen: Keine Fähigkeit kann gelehrt werden – sie muss erlernt werden. Der Lehrer dient jedoch immer noch mehreren wichtigen Zwecken: eine Reihe von Regeln für die Erzeugung wohlgeformter Äußerungen zu präsentieren; zahlreiche Demonstrationen seines eigenen Könnens anzubieten; und als engagierter Kritiker zu fungieren. Schließlich ist der Lehrer die Informationsquelle über den Prozess, an dem der Schüler beteiligt ist."}
{"DOCID": "2481", "TEXT": "Die Verteilung eines Programms im primären und schnellen Pufferspeicher: Es wird ein virtuelles Speicher-Computersystem mit einem schnellen Puffer-(Cache-)Speicher zwischen dem primären Speicher und der zentralen Verarbeitungseinheit betrachtet. Die optimale Verteilung eines Programms zwischen Pufferspeicher und Primärspeicher wird unter Verwendung der Lebensdauerfunktion des Programms untersucht. Ausdrücke für die Verteilung eines Programms, das den nützlichen Bruchteil des Kosten-Zeit-Integrals von primärem und schnellem Pufferspeicher maximiert, werden für Pufferverwaltungsstrategien mit Auslagerung und ohne Auslagerung erhalten."}
{"DOCID": "2482", "TEXT": "Gemischte Lösungen für das Deadlock-Problem: Mischungen aus Erkennung, Vermeidung und Vorbeugung bieten effektivere und praktischere Lösungen für das Deadlock-Problem als jede dieser Lösungen allein. Die einzelnen Techniken können auf Teilprobleme der Ressourcenzuweisung zugeschnitten werden und arbeiten dennoch zusammen, um Deadlocks zu verhindern. Dieser Beitrag stellt eine auf dem Konzept des hierarchischen Betriebssystems basierende Methode zur Konstruktion geeigneter Mischungen vor und schlägt geeignete Subsysteme für die am häufigsten auftretenden Ressourcenallokationsprobleme vor"}
{"DOCID": "2483", "TEXT": "COKO III: Das Cooper-Koz-Schachprogramm: COKO III ist ein vollständig in Fortran geschriebener Schachspieler. Auf dem IBM 360-65 spielt COKO III ein minimales Schachspiel mit einer Rate von 0,2 Sekunden CPU-Zeit pro Zug, mit einem Niveau, das nahe an niedrigerem Schachklubspiel liegt. Ein selektives Baumsuchverfahren, das durch taktische Schachlogistik gesteuert wird, ermöglicht den Einsatz mehrerer minimaler Spielberechnungen, um eine optimale Zugauswahl zu erreichen. Die Baumsuchalgorithmen sind das Herzstück der Effektivität von COKO, aber sie sind konzeptionell einfach. Darüber hinaus hat ein interessantes Phänomen namens Baumsuchkatastrophe die gesamte Entwicklung von COKO geplagt, so wie es einen menschlichen Spieler beunruhigt. Das standardmäßige exponentielle Wachstum wird weitgehend durch die Definition und das Trimmen des Fischer-Sets eingedämmt. Es wird auch klar zwischen Baumschnitt und selektiver Baumsuche unterschieden. Die Darstellung der Schachumgebung wird zusammen mit einem strategischen Voranalyseverfahren beschrieben, das die Lasker-Regionen kartiert. Es werden spezielle Schachalgorithmen beschrieben, die von jedem, der mit Schachprogrammen experimentieren möchte, als Befehlsstruktur verwendet werden könnten. Ein Vergleich einiger mysteriöser Aktionen menschlicher Spieler und COKO III wird angestellt."}
{"DOCID": "2484", "TEXT": "Eine Anmerkung zur Informationsorganisation und -speicherung: Da die logische Struktur einer Datenbank durch einen Baum oder ein Diagramm dargestellt werden kann, ist es für uns ganz natürlich, den Prozess des Entwerfens einer Datenbank als das Konstruieren eines Baums oder eines Diagramms zu betrachten. Es wird ein allgemeines Verfahren zum Konstruieren eines solchen Baums oder eines solchen Graphen bereitgestellt. Es gibt drei wichtige Elemente in dieser allgemeinen Konstruktionsmethode; nämlich ein Satz binärer Beziehungen, ein Algorithmus zum Konstruieren von Teilmengen eines Satzes und ein Algorithmus zum Auswählen eines Elements aus dem gegebenen Satz von Objekten. Die Verwendung unterschiedlicher Relationen und Algorithmen führt zu unterschiedlichen Informationsstrukturen wie Liste, Baum, Ring usw. Somit wird das Problem der Informationsorganisation und -speicherung auf das Definieren von Relationen und das Formulieren von Algorithmen unter einem gegebenen Satz von Randbedingungen reduziert. Die präsentierten Ergebnisse können für Designer als nützliche Designkonzepte wertvoll sein und als Grundlage für die Entwicklung einer formalen Theorie zu diesem Thema dienen."}
{"DOCID": "2485", "TEXT": "Verwaltung der Computerressource: Eine Stufenhypothese: Basierend auf der Untersuchung der Ausgaben für die Datenverarbeitung wird eine deskriptive Stufenhypothese vorgestellt. Es wird vermutet, dass sich die mit der Verwaltung der Computerressourcen verbundenen Planungs-, Organisations- und Kontrollaktivitäten im Laufe der Zeit ändern und sich in Mustern entwickeln werden, die grob mit vier Phasen des Computerbudgets korrelieren: Phase I (Computeranschaffung), Stufe II (intensive Systementwicklung), Stufe III (Vermehrung von Kontrollen) und Stufe IV (Benutzer-/Dienstorientierung). Jede Stufe wird beschrieben und mit einzelnen Aufgaben zur Verwaltung der Computerressource in Beziehung gesetzt."}
{"DOCID": "2486", "TEXT": "Computer-Fotosatz technischer Texte: Beim computergestützten Satz mittels Fotosatz ergeben sich besondere Probleme bei hochtechnischem Material wie mathematischen Formeln. Neue Lösungen für mehrere dieser Probleme wurden im Informationssystem des American Institute of Physics entwickelt. Dazu gehören: die Darstellung von Sonderzeichen (fremde Alphabete, mathematische Symbole usw.), die auf Eingabetastaturen oder auf dem Fotocomposer nicht verfügbar sind; die Generierung solcher Symbole, z.B. durch Überdrucken; die genaue Positionierung von Akzentzeichen (floating diacriticals); Zeilenumbrüche, d. h. Wörter oder Formeln, die teilweise am Ende einer Zeile und teilweise am Anfang der nächsten stehen; und bestimmte Aspekte der Fehlerkorrektur."}
{"DOCID": "2487", "TEXT": "Kubische Spline-Lösungen für Randwertprobleme vierter Ordnung: Die kubische Spline-Näherung der Differentialgleichung vierter Ordnung y''''+p(x)y''+q(x)y'+r(x)y=t Es wird gezeigt, dass (x) auf die Lösung einer Rekursionsbeziehung mit fünf Termen reduziert wird. Für einige Sonderfälle wird gezeigt, dass die Annäherung einfach mit einer Finite-Differenzen-Darstellung mit einem lokalen Abschneidefehler der Ordnung (y/720)delta^8 zusammenhängt."}
{"DOCID": "2488", "TEXT": "Stückweise kubische Kurvenanpassung der kleinsten Quadrate: Die an einer linearen Formulierung der kleinsten Quadrate beteiligten Matrizen werden für das Problem der Anpassung stückweiser kubischer Funktionen, die eine stetige Ableitung besitzen, an Arrays planarer Daten bestimmt."}
{"DOCID": "2489", "TEXT": "Anzahl mehrfach eingeschränkter Partitionen [A1] (Algorithmus A448)"}
{"DOCID": "2490", "TEXT": "Effiziente Algorithmen zur Graphmanipulation [H] (Algorithmus A447): Es werden effiziente Algorithmen zum Partitionieren eines Graphen in verbundene Komponenten, doppelt verbundene Komponenten und einfache Pfade vorgestellt. Der Algorithmus zum Aufteilen eines Graphen in einfache Pfade ist iterativ, und jede Iteration erzeugt einen neuen Pfad zwischen zwei Knoten, die sich bereits auf Pfaden befinden. (Der Startknoten kann dynamisch angegeben werden.) Wenn V die Anzahl der Knoten und E die Anzahl der Kanten ist, benötigt jeder Algorithmus Zeit und Platz proportional zu max (V, E), wenn er auf einem Computer mit wahlfreiem Zugriff ausgeführt wird."}
{"DOCID": "2491", "TEXT": "Threaded Code: Das Konzept des „Threaded Code“ wird als Alternative zum Maschinensprachencode vorgestellt. Hardware- und Softwarerealisierungen davon sind angegeben. In Software wird es als interpretierender Code realisiert, der keinen Interpreter benötigt. Erweiterungen und Optimierungen werden erwähnt."}
{"DOCID": "2492", "TEXT": "Die Entwicklung von Entscheidungstabellen durch Parsing komplexer Entscheidungssituationen: Es wird eine neue Parsing-Technik vorgeschlagen, die ein Parsing nur basierend auf syntaktischen Merkmalen des Entscheidungsproblems erlaubt. Es erfordert eine Beschreibung des Problems im Entscheidungsrasterdiagrammformat und ermöglicht die Entwicklung von Entscheidungstabellen innerhalb definierter Grenzen, indem die Wiederholung von Bedingungen und Aktionen in den resultierenden Tabellen vermieden oder zumindest minimiert wird."}
{"DOCID": "2493", "TEXT": "Optimale Datenbank-Reorganisationspunkte: Bei bestimmten Datenbank-Organisationsschemata können die Kosten pro Zugriff aufgrund struktureller Ineffizienzen, die durch Aktualisierungen verursacht werden, steigen. Durch die Reorganisation der Datenbank können die Kosten pro Zugriff gesenkt werden. Die hohen Kosten einer Reorganisation verbieten jedoch häufige Reorganisationen. Dieses Papier untersucht Strategien zur Auswahl der optimalen Reorganisationspunkte."}
{"DOCID": "2494", "TEXT": "Eine computererzeugte Hilfe für die Clusteranalyse: Ein computererzeugtes Graphikverfahren, das in Verbindung mit jedem hierarchischen Schema der Clusteranalyse verwendet werden kann, wird beschrieben und illustriert. Das verwendete graphische Prinzip ist die Darstellung der Elemente einer Datenmatrix von Ähnlichkeiten oder Unähnlichkeiten durch computergedruckte Symbole (von überstrichenen Zeichen) in verschiedenen Dunkelschattierungen, wobei ein dunkles Symbol einer kleinen Unähnlichkeit entspricht. Die Diagramme, angewendet auf eine Datenmatrix vor dem Clustern und auf die umgeordnete Matrix nach dem Clustern, zeigen auf einen Blick, ob das Clustern charakteristische Cluster hervorgebracht hat. Ein bekannter Datensatz, bestehend aus den Korrelationen von 24 psychologischen Tests, wird verwendet, um den Vergleich von Gruppierungen durch vier Methoden der Faktorenanalyse und zwei Methoden der Clusteranalyse zu veranschaulichen."}
{"DOCID": "2495", "TEXT": "Anpassung der optimalen Codegenerierung für arithmetische Ausdrücke an die auf heutigen Computern verfügbaren Befehlssätze"}
{"DOCID": "2496", "TEXT": "Über die Beinahe-Optimalität der First-Latency-Time-Drum-Scheduling-Disziplin: Für Computersysteme, bei denen es praktisch ist, die augenblickliche Trommelposition zu bestimmen, ist eine beliebte Disziplin zur Bestimmung der Reihenfolge, in der auf die Datensätze zugegriffen werden soll, die sogenannte Shortest-Latency-Time-First, SLTF, Disziplin. Wenn auf eine Sammlung von Aufzeichnungen unterschiedlicher Länge von spezifizierten Trommelpositionen aus zugegriffen werden soll, minimiert die SLTF-Disziplin bekanntlich nicht notwendigerweise die Trommellatenzzeit. Wir zeigen jedoch, dass die Gesamtzeit für den Zugriff auf die gesamte Sammlung für einen beliebigen SLTF-Zeitplan niemals so viel wie eine Trommelumdrehung länger als ein Mindestlatenzzeitplan ist."}
{"DOCID": "2497", "TEXT": "Synchronisieren von Prozessoren mit durch Speicherinhalt erzeugten Unterbrechungen: Implementierungen des \"Lock-Unlock\"-Verfahrens zum Synchronisieren von Prozessoren in einem Mehrprozessorsystem erfordern normalerweise nicht unterbrechbare Anweisungen vom Speicherpausentyp. Für ein Dual-DEC-PDP-10-System mit Echtzeitanforderungen wurde ein Interlock-Schema namens Read-Interlock entwickelt, das keine Speicherpausenbefehle erfordert. Das Lese-Verriegelungsverfahren erfordert einen speziellen \"Lese-Verriegelungs\"-Befehl im Repertoire der Prozessoren und einen speziellen \"Lese-Verriegelungs\"-Zyklus im Repertoire der Speichermodule. Wenn ein Prozessor eine \"Sperre\" (einen Speicherplatz) mit einer Lese-Sperr-Anweisung untersucht, wird er unterbrochen, wenn die Sperre bereits gesetzt war; die Untersuchung einer Sperre setzt diese sofort, falls sie noch nicht gesetzt war (diese Ereignisfolge ist ein Lesesperrzyklus). Das Schreiben in eine Sperre löscht sie. Es ist vorteilhaft, wenn der Prozessor unterbrochen wird, wenn er auf eine gesetzte Sperre stößt, anstatt zu verzweigen, wenn die Verzweigung zu einer effektiven Unterbrechung geführt hätte."}
{"DOCID": "2498", "TEXT": "Minimieren von verschwendetem Speicherplatz bei partitionierter Segmentierung: Ein seitenweises virtuelles Speichersystem, das eine endliche Anzahl von Seitengrößen verwendet, wird betrachtet. Zwei Algorithmen zum Zuordnen von Seiten zu Segmenten werden diskutiert. Beide Algorithmen sind einfach zu implementieren. Das Problem der Wahl der Seitengrößen zur Minimierung des erwarteten Werts des gesamten verschwendeten Platzes bei interner Fragmentierung und in einer Seitentabelle pro Segment wird dann für eine Wahrscheinlichkeitsdichtefunktion der Segmentgröße gelöst, die als konvexe Kombination von Erlang-Dichten ausgedrückt werden kann ."}
{"DOCID": "2499", "TEXT": "Effiziente Multiprogramming-Ressourcenzuweisung und Abrechnung: Obwohl Multiprogramming manchmal nur als eine Komponente des Timesharing-Betriebs angesehen wird, kann es umfassendere Fragen der Ressourcenzuweisung beinhalten, da Fairness nicht erforderlich ist, um ein Antwortkriterium zu erfüllen. In einem multiprogrammierten System kann es dazu dienen, dass die maximale Ressourcennutzung unfair ist, beispielsweise indem ein Eingabe-/Ausgabekanal für ein Programm im Leerlauf gehalten wird, während es eine kleine Menge an Prozessornutzung abschließt, wodurch eine weitere Nutzung des Kanals ermöglicht wird. Es werden mehrere Anwendungen dieses Prinzips angegeben, und es wird vorgeschlagen, dass eine Multiprogramming-Exekutive ihre Zuordnungsalgorithmen dynamisch anpassen könnte, um die Effizienz zu steigern. Die Zuweisung von Ressourcen ist eng mit der Abrechnung dieser Ressourcen verbunden, was die Probleme der Wiederholbarkeit, des minimalen nicht in Rechnung gestellten Overheads und der relativen Gewichtung der Gebühren für abhängige Ressourcen aufwirft. Da Gewichtungen von Zuordnungsalgorithmen abhängen können, handelt es sich nicht um willkürliche Abrechnungsparameter. Oftmals ist die einzige wiederholbare Abrechnung eine, bei der ein umfangreicher Overhead ausgelassen wird, und sollte sich Multiprogramming als effizient erweisen, ergeben sich überhöhte Gebühren. Die Mehrfachprogrammierung schaltet die Zuweisung der Speicherressource ein, die für die Steuerung anderer Ressourcen wesentlich ist. Auf diese Frage werden die allgemeinen Vorschläge zur Zuordnung und Abrechnung angewendet und einige Einzelheiten für den Fall eines Monitors angegeben, der eine Maschine mit virtuellem Speicher steuert."}
{"DOCID": "2500", "TEXT": "Ein praktischer Ansatz zum Verwalten von Ressourcen und Vermeiden von Deadlocks: Die Ressourcenplanung und -zuweisung kann in Bezug auf Zeit und Platz in Multiprogramming- oder Time-Sharing-Umgebungen mit einer großen Anzahl von Aufgaben und Ressourcen mit widersprüchlichen Anforderungen teuer sein. Das Erkennen und/oder Verhindern von Deadlocks kann enorme Mengen an zusätzlichem Overhead erfordern, wenn eine effiziente Nutzung von Ressourcen aufrechterhalten werden soll. Es wird ein Ressourcenverwaltungsprogramm beschrieben, das verknüpfte Listen zusammen mit anderen Techniken verwendet, um einen großen Teil dieses Overheads zu überwinden. Das Programm, das derzeit als Teil eines groß angelegten Allzweckbetriebssystems läuft, hält Ressourcen relativ aktiv, erkennt oder verhindert jedoch nicht alle Deadlocks in seinem implementierten Zustand. Bestimmte Änderungen, die zu zusätzlichen Kosten umfassendere Ebenen der Verhinderung/Erkennung von Deadlocks ermöglichen würden, wurden aufgrund der Seltenheit von Deadlock-Situationen nicht in das laufende System integriert."}
{"DOCID": "2501", "TEXT": "WYLBUR: Ein interaktives Textbearbeitungs- und Ferneingabesystem: WYLBUR ist ein umfassendes System zur Bearbeitung aller Arten von Text, wie Computerprogramme, Briefe und Manuskripte, unter Verwendung von Schreibmaschinenterminals, die mit einem Computer verbunden sind. Es verfügt über Einrichtungen für die Remote-Auftragseingabe und -abrufung sowie Einrichtungen für die Textausrichtung und -ausrichtung. Eine leistungsstarke Methode zum Adressieren von Text nach Inhalt wird bereitgestellt. Dieses Papier beschreibt das äußere Erscheinungsbild von WYLBUR sowie seine interne Struktur. Eine kurze Beschreibung der Hauptmerkmale von ORVYL, einem Allzweck-Time-Sharing-System, das in Verbindung mit WYLBUR betrieben wird, ist ebenfalls enthalten."}
{"DOCID": "2502", "TEXT": "Ein Kommentar zu den praktischen Aspekten der Informatikausbildung"}
{"DOCID": "2503", "TEXT": "Noch ein Kommentar zu Computermusik"}
{"DOCID": "2504", "TEXT": "Über Musik und Computerkomposition in der Computerlinguistik"}
{"DOCID": "2505", "TEXT": "Reflexionsfreie Permutationen, Rosenkranzpermutationen und benachbarte Transpositionsalgorithmen"}
{"DOCID": "2506", "TEXT": "Ein Sparse-Matrix-Paket (Algorithmus R408)"}
{"DOCID": "2507", "TEXT": "Exakte Lösung linearer Gleichungen mit Restarithmetik (Algorithmus R406)"}
{"DOCID": "2508", "TEXT": "Steigerung der Effizienz von Quicksort (Algorithmus R402)"}
{"DOCID": "2509", "TEXT": "Minit-Algorithmus für lineare Programmierung (Algorithmus R333)"}
{"DOCID": "2510", "TEXT": "Minit-Algorithmus für lineare Programmierung (Algorithmus R333)"}
{"DOCID": "2511", "TEXT": "Maxflow (Algorithmus R324)"}
{"DOCID": "2512", "TEXT": "Coulomb-Wellenfunktionen (Algorithmus R300)"}
{"DOCID": "2513", "TEXT": "Ein nichtrekursiver Listenverschiebungsalgorithmus: Ein effizienter, nichtrekursiver Algorithmus wird zum Verschieben einer beliebigen Liste vom LISP-Typ angegeben. Insbesondere erfordert der Algorithmus keinen anderen Speicher als die neuen Knoten, in die die Liste verschoben werden soll, und keine zusätzlichen Bits pro Knoten zum Markieren; der Algorithmus läuft zeitlich proportional zur Anzahl der Knoten in der Liste. Die ursprüngliche Listenstruktur wird beim Verschieben zerstört."}
{"DOCID": "2514", "TEXT": "Ein Array-Grammatik-Programmiersystem: Es wurde ein Paket von Fortran-Programmen entwickelt, das es einem Benutzer ermöglicht, Array-Grammatiken interaktiv zu entwerfen und zu testen. Der Benutzer kann die Regelauswahlprozedur in einer Ableitung oder Analyse unter Verwendung von gewichteten Programmiermatrizen steuern; er hat auch eine Auswahl an Instanzauswahlschemata (Raster, zufällig, parallel). Es werden Beispiele gegeben, die Array-Sprachen beinhalten, die aus einfachen geometrischen Mustern bestehen, sowie eine Sprache von \"Neuronenbildern\"."}
{"DOCID": "2515", "TEXT": "Minimales Ereignis-Knoten-Netzwerk von Projekt-Präzedenz-Beziehungen: Es wird ein Verfahren zum Aufbauen eines minimalen Ereignis-Knoten-Netzwerks zur Darstellung eines Satzes von Präzedenz-Beziehungen ohne parallele Aktivitäten vorgestellt. Ein minimales Netzwerk aus Ereignisknoten ist ein Netzwerk aus Ereignisknoten, in dem sowohl die Anzahl der Knoten als auch die Anzahl der Bögen die Mindestwerte sind, um die gegebenen Vorrangbeziehungen zu bewahren G. L. Nemhauser (1968) produziert Ereignisknotennetzwerke, die nicht minimal sind. Da unser Verfahren das Set-Covering-Problem beinhaltet, kann der Zeitaufwand mit der Anzahl der gegebenen Aktivitäten exponentiell wachsen."}
{"DOCID": "2516", "TEXT": "Hierarchische Speicherung beim Informationsabruf: Eine probabilistische Analyse wird verwendet, um die Auswirkung hierarchischer Speicherorganisationen auf Informationsabrufoperationen zu bestimmen. Es wird angenommen, dass die Datenspeicherhardware aus n Ebenen linear verbundener Speicherhardware mit zunehmenden Datenzugriffszeiten und zunehmenden Datenspeicherfähigkeiten besteht. Ein System könnte beispielsweise aus schnellem Halbleiterspeicher, Computerkernspeicher, erweitertem Kernspeicher, Plattenspeicher und Datenzellen bestehen. Gleichungen werden hergeleitet, um die Wirkung eines solchen Systems auf Datenzugriffszeiten unter Verwendung von sequentiellen Dateien, Dateien mit wahlfreiem Zugriff und strukturierten Dateien, die mehrere hierarchisch verknüpfte Listen verwenden, vorherzusagen."}
{"DOCID": "2517", "TEXT": "Einige Kommentare zur Verwendung mehrdeutiger Entscheidungstabellen und ihrer Umwandlung in Computerprogramme: Dieses Dokument kommentiert kürzlich veröffentlichte Arbeiten zur Übersetzung von Entscheidungstabellen unter Verwendung von Methoden, die der Regelmaskentechnik ähnlich sind. Die Anwendbarkeit dieser Methoden unter verschiedenen möglichen Konventionen zur Gesamtbedeutung von Tabellen wird diskutiert, und es wird argumentiert, dass es sowohl für die Multi-Regel- als auch für die Einzelregel- (oder Aktionssatz-) Konvention einen Platz in der Verwendung von Entscheidungsgeschichten gibt."}
{"DOCID": "2518", "TEXT": "Programmierung per Fragebogen: Ein effektiver Weg zur Verwendung von Entscheidungstabellen: Die Programmierung per Fragebogen kombiniert Aspekte der Entscheidungstabellenprogrammierung und der Programmierung für allgemeine Zwecke, indem Entscheidungstabellen verwendet werden, um ein Anwendungsprogramm durch die Auswahl bestimmter Quellanweisungen aus einer vordefinierten Datei zu erstellen. Es wird vorgeschlagen, dass die Programmierung durch Fragebögen einen nützlichen Kompromiss zwischen allgemeiner und spezieller Programmierung für eine bedeutende Klasse von Problemen großen Maßstabs darstellt. Die Elemente des Ansatzes werden diskutiert und eine bestehende Anwendung wird beschrieben."}
{"DOCID": "2519", "TEXT": "Zum Problem der Übermittlung komplexer Informationen: Es wird die Art der Schwierigkeiten untersucht, die mit der Übermittlung mathematischer Ergebnisse zwischen Wissenschaftlern verbunden sind, die ein computergestütztes Informationsabrufsystem verwenden. Die Problematik wird hinsichtlich psychologischer und informationsverarbeitender Prozesse analysiert und ein Teufelskreis von Wirkungen beschrieben. Dazu gehören Möglichkeiten, die geschriebene natürliche Sprache durch verschiedene Notations- und Sprachmittel zu erweitern, die Darstellung der Struktur, die den von uns kommunizierten Informationen innewohnt, und ein ausgeklügeltes interaktives System, das vom Computer gesteuert wird."}
{"DOCID": "2520", "TEXT": "Größter gemeinsamer Teiler von n ganzen Zahlen und Multiplikatoren (Algorithmus C386)"}
{"DOCID": "2521", "TEXT": "Zehn Subroutinen für die Manipulation der Tschebyscheff-Reihe [C1] (Algorithmus A446)"}
{"DOCID": "2522", "TEXT": "Das Design, die Implementierung und die Bewertung eines Working Set Dispatcher: Das Verhalten eines Computersystems hängt weitgehend von den Algorithmen ab, die verwendet werden, um die Systemressourcen den um sie konkurrierenden Prozessen zuzuweisen. Jüngste Forschungen in Time-Sharing-Paging-Systemen haben das Working-Set-Modell für das Programmverhalten entwickelt, und es wurde eine auf diesem Modell basierende Quellenzuweisungsstrategie vorgeschlagen. Es wurde über zwei Implementierungen nach diesen Prinzipien berichtet, aber es scheint, dass in keinem Fall weitere Ergebnisse bekannt gegeben wurden. Dieser Bericht erörtert den Entwurf und die Implementierung eines Dispatchers auf der Grundlage des Working-Set-Prinzips, präsentiert Daten, um eine Analyse seines Verhaltens zu ermöglichen, und zeigt zukünftige Richtungen der Forschung zu Verfahren zum Steuern eines Computersystems auf."}
{"DOCID": "2523", "TEXT": "Eine Bereichsfärbungstechnik für die Szenenanalyse: Ein Verfahren zum Umwandeln eines Bildes in einen \"Cartoon\" oder eine \"Karte\", deren Bereiche unterschiedlich texturierten Bereichen entsprechen, wird beschrieben. Texturkanten im Bild werden erkannt und von diesen (meist gebrochenen) Kanten umgebene feste Bereiche werden durch einen Ausbreitungsprozess \"eingefärbt\". Die resultierende Karte wird bereinigt, indem die Bereichsfarben mit den Texturen der entsprechenden Bereiche im Bild verglichen werden und auch einige Bereiche mit anderen gemäß Kriterien auf der Grundlage von Topologie und Größe zusammengeführt werden. Das Verfahren wurde auf die Konstruktion von Wolkenbedeckungskarten aus Wolkenbedeckungsbildern angewendet, die von Satelliten erhalten wurden."}
{"DOCID": "2524", "TEXT": "Einige Ansätze zur Dateisuche nach bester Übereinstimmung: Das Problem des Durchsuchens des Satzes von Schlüsseln in einer Datei, um einen Schlüssel zu finden, der einem gegebenen Abfrageschlüssel am nächsten kommt, wird diskutiert. Nachdem \"am nächsten\" im Sinne einer Metrik auf den Schlüsselraum geeignet definiert ist, werden drei Dateistrukturen zusammen mit ihren entsprechenden Suchalgorithmen präsentiert, die die Anzahl der Vergleiche reduzieren sollen, die erforderlich sind, um das gewünschte Ergebnis zu erzielen. Diese Methoden werden unter Verwendung bestimmter Ungleichungen abgeleitet, die durch Metriken und graphentheoretische Konzepte erfüllt werden. Es werden einige empirische Ergebnisse vorgestellt, die die Effizienz der Methoden vergleichen."}
{"DOCID": "2525", "TEXT": "A Statistical Study of the Accuracy of Floating Point Number Systems: Dieses Papier präsentiert die statistischen Ergebnisse von Tests zur Genauigkeit bestimmter arithmetischer Systeme bei der Auswertung von Summen, Produkten und inneren Produkten sowie analytische Fehlerschätzungen für einige der Berechnungen. Die untersuchten arithmetischen Systeme sind 6-stellige hexadezimale und 22-stellige binäre Fließkommazahldarstellungen kombiniert mit den üblichen Chop- und Rundungsmodi der Arithmetik mit einer unterschiedlichen Anzahl von Schutzziffern und mit einem modifizierten Rundungsmodus mit Schutzziffern. In gewissem Sinne erweisen sich arithmetische Systeme, die sich nur in ihrer Verwendung von binären oder hexadezimalen Zahlendarstellungen unterscheiden, als annähernd statistisch äquivalente Ungenauigkeit. Ferner hat sich gezeigt, dass der übliche Rundungsmodus mit Schutzziffern dem üblichen Chop-Modus in allen Fällen bis auf einen hinsichtlich der Genauigkeit statistisch überlegen ist. Der modifizierte Round-Modus erweist sich in allen Fällen als dem Chop-Modus überlegen."}
{"DOCID": "2526", "TEXT": "Asymmetrische Speicherhierarchien: Es wird eine Studie über einige der Systemimplikationen von Speicherhierarchien präsentiert, bei denen der Sicherungs- oder Sekundärspeicher eine sehr kurze Lesezeit hat, sowohl relativ zu der zum Schreiben erforderlichen Zeit als auch zur Lesezeit herkömmlicher Sicherungsspeichergeräte. Es werden mehrere analytische Modelle eingeführt, und es wird gezeigt, dass solche Hierarchien auf eine Weise funktionieren können, die sich von der herkömmlicherer Hierarchien unterscheidet. Insbesondere wird gezeigt, dass es in einer solchen Situation möglicherweise nicht erforderlich ist, mehrfach zu programmieren. In der Vergangenheit waren Backup-Speichergeräte in Bezug auf ihre Lese- und Schreibzeiten ungefähr symmetrisch. Diese Situation wird sich möglicherweise nicht fortsetzen, da derzeit mehrere Geräte entwickelt werden, die möglicherweise ein sehr kleines Lesezeit/Schreibzeit-Verhältnis haben. Diese Studie legt besonderen Wert auf ein solches System – den holografischen optischen RCA-Lese-/Schreibspeicher."}
{"DOCID": "2527", "TEXT": "Implementierung einer Hochsprachenmaschine: In der Vergangenheit wurden Rechenmaschinen vorgeschlagen, die die Anweisungen einer Hochsprache direkt ausführen. Dieser Bericht beschreibt die tatsächliche Implementierung einer solchen Maschine: Es ist ein Computer, dessen \"Maschinensprache\" APL ist. Die Maschine ist voll funktionsfähig und führt fast alle APL-Operationen auf Skalaren, Vektoren und Arrays korrekt aus. Die Maschine weist automatisch Speicher zu, führt Anweisungen aus, ruft Funktionen auf, wandelt Zahlen von einem Typ in einen anderen um, prüft Indizes und erkennt automatisch viele Arten von Programmierfehlern."}
{"DOCID": "2528", "TEXT": "Binäre Musterrekonstruktion aus Projektionen [Z] (Algorithmus R445)"}
{"DOCID": "2529", "TEXT": "Binäre Musterrekonstruktion aus Projektionen [Z] (Algorithmus A445)"}
{"DOCID": "2530", "TEXT": "Ein Algorithmus zum Extrahieren von Phrasen in räumlich optimaler Weise [Z] (Algorithmus A444)"}
{"DOCID": "2531", "TEXT": "Graduiertenausbildung: Der Ph.D. Glut"}
{"DOCID": "2532", "TEXT": "Über Harrisons Substring-Testtechnik"}
{"DOCID": "2533", "TEXT": "Gray-Code und die +- Zeichensequenz, wenn +-f (+-f(+-f(...+-f(x)...))) bestellt wird"}
{"DOCID": "2534", "TEXT": "Entwurf und Implementierung eines Diagnose-Compilers für PL/I: PL/C ist ein Compiler für einen Dialekt für PL/I. Das Designziel bestand darin, ein Höchstmaß an diagnostischer Unterstützung in einer Stapelverarbeitungsumgebung bereitzustellen. Größtenteils ist diese Hilfestellung implizit und wird vom Compiler automatisch bereitgestellt. Das bemerkenswerteste Merkmal von PL/C ist seine Beharrlichkeit – es schließt die Übersetzung jedes eingereichten Programms ab und setzt die Ausführung fort, bis eine vom Benutzer festgelegte Fehlergrenze erreicht ist. Dies erfordert, dass der Compiler Fehler repariert, die sowohl während der Übersetzung als auch der Ausführung auftreten, und das Design von PL/C wird von dieser Überlegung dominiert. PL/C führt auch mehrere explizite benutzergesteuerte Einrichtungen zum Testen von Programmen ein. Um diese Erweiterungen von PL/I aufzunehmen, ohne die Kompatibilität mit dem IBM-Compiler aufzugeben, erlaubt PL/C \"Pseudo-Kommentare\"-Konstruktionen, deren Inhalt wahlweise als Quelltest oder Kommentar betrachtet werden kann. Trotz des Diagnoseaufwandes ist PL/C ein schneller und leistungsfähiger Prozessor. Es demonstriert effektiv, dass Compiler eine bessere Diagnoseunterstützung bieten können, als üblicherweise angeboten wird, selbst wenn eine anspruchsvolle Quellsprache verwendet wird, und dass diese Unterstützung nicht unerschwinglich kostspielig sein muss."}
{"DOCID": "2535", "TEXT": "Die Auswirkungen des Multiplexing auf ein Computer-Kommunikationssystem: Es wird untersucht, wie das asynchrone Zeitmultiplexing die stochastische Natur des Ankunftsprozesses von einem Benutzer zum Computer verändert und folglich die Leistung eines Timesharing-Systems beeinflusst Computer-Kommunikationssystem. Es wird geschlussfolgert, dass es zwar für bestimmte Werte von Systemparametern eine merkliche Verbesserung der Leistung des Computers (Modells) in dem Sinne gibt, dass zeitgeteilte Planungsverzögerungen reduziert werden, diese Verbesserungen jedoch durch die durch das Multiplexen auferlegten Übertragungsverzögerungen aufgehoben werden so dass sich die Leistung des Computerkommunikationssystems nur geringfügig oder gar nicht ändert. Analyse- und Simulationsergebnisse basieren auf dem Modell des Computerkommunikationssystems, das eine M/D/1-Warteschlange (der Multiplexer) im Tandem mit einem einzelnen exponentiellen Server (dem Computer) ist. Analyseergebnisse umfassen eine allgemeine Beschreibung des Ausgabeprozesses einer M/D/1-Warteschlange und der Bedingungen, unter denen dieser Ausgabeprozess ungefähr Poisson ist."}
{"DOCID": "2536", "TEXT": "Telekommunikation unter Verwendung eines Front-End-Minicomputers: Die Verwendung eines Front-End-Minicomputers, um einen vielfältigen entfernten Endgerätezugriff auf einen großen Computer bereitzustellen, wird in Betracht gezogen. Die Probleme der Einbettung von Telekommunikations-E/A in ein Betriebssystem werden diskutiert, und es wird gezeigt, wie die Dezentralisierung der durch die Front-End-Verarbeitung erworbenen Intelligenz das Problem erheblich vereinfacht. Eine spezifische Implementierung wird mit Schwerpunkt auf der Hauptprozessor-Minicomputer-Verbindung, der Hardware-Software-Implementierung, der Wirkung des Hauptprozessor-Betriebssystems und einer Bewertung der Vorteile gegenüber einer festverdrahteten Leitungssteuerung diskutiert."}
{"DOCID": "2537", "TEXT": "Gemeinsame Ausdrücke und Textspeicherung mit minimalem Platzbedarf: Es wird ein Verfahren zum Einsparen von Speicherplatz für Textketten, wie zum Beispiel Compiler-Diagnosemeldungen, beschrieben. Das Verfahren beruht auf der manuellen Auswahl eines Satzes von Textfolgen, die einer oder mehreren Nachrichten gemeinsam sind. Diese Phrasen werden dann nur einmal gespeichert. Die Speichertechnik führt zu einem mathematischen Optimierungsproblem: Bestimmen Sie, wie jede Nachricht die verfügbaren Phrasen verwenden sollte, um ihren Speicherbedarf zu minimieren. Dieses Problem ist nicht trivial, wenn Phrasen existieren, die sich überschneiden. Es wird jedoch ein dynamischer Programmieralgorithmus vorgestellt, der das Problem in der Zeit löst, die linear mit der Anzahl der Zeichen im Text wächst. Algorithmus 444 gilt für dieses Papier."}
{"DOCID": "2538", "TEXT": "Ein Informatik-Kursprogramm für kleine Colleges: Das ACM-Unterkomitee für kleine College-Programme des Komitees für Curriculum in Computer Science (CCCS) wurde 1969 ernannt, um die einzigartigen Probleme kleiner Colleges und Universitäten zu berücksichtigen und Empfehlungen zu Informatikprogrammen abzugeben an solchen Schulen. Dieser Bericht, der sowohl vom Unterausschuss als auch von (CCCS) genehmigt wurde, enthält eine Reihe von Empfehlungen für Kurse und notwendige Ressourcen. Umsetzungsprobleme werden diskutiert, insbesondere im Rahmen begrenzter Kapazitäten und zur Erfüllung einer Vielzahl von Zielen. Eine detaillierte Beschreibung von vier Kursen wird gegeben; es werden Vorschläge für weiterführende Arbeiten gemacht; und eine umfangreiche Bibliotheksliste ist enthalten."}
{"DOCID": "2539", "TEXT": "Lösung der transzendenten Gleichung w*exp(w)=x [C5] (Algorithmus A443)"}
{"DOCID": "2540", "TEXT": "Eigenschaften des Working-Set-Modells (Korrigendum)"}
{"DOCID": "2541", "TEXT": "Ein Überblick über das ISPL-Computersystemdesign: Dieses Papier untersucht die Vorteile des gleichzeitigen Designs von Sprache, Betriebssystem und Maschine (über Mikrocode), um ein interaktives Programmierlabor zu schaffen. Es beschreibt den synergistischen Effekt, den die Freiheit, Merkmale von einer dieser Domänen in eine andere zu verschieben und zu ändern, auf das Design dieses Systems hatte (das nicht implementiert wurde). Diese Freiheit vereinfachte sowohl die inkrementelle Kompilierung als auch die Adressierungsstruktur des Systems und zentralisierte die Kommunikationsmechanismen, die den Aufbau hierarchischer Subsysteme ermöglichten. Es schlug auch ein wichtiges neues Konzept für Betriebssysteme vor: die Trennung der Zeitplanung von den Wartungsfunktionen bei der Ressourcenzuweisung. Diese Trennung ermöglicht die Einbindung neuer Scheduling-Algorithmen (Entscheidung, was zu tun ist), ohne die Systemintegration (korrekte Ausführung der Scheduling-Entscheidungen) zu gefährden."}
{"DOCID": "2542", "TEXT": "Ein Softwaredesign- und Bewertungssystem: Ein kritischer Fehler der aktuellen Softwaresystemdesign- und -implementierungsmethodik besteht darin, dass die Leistung eines vorgeschlagenen Designs nicht bewertet wird, bevor es tatsächlich implementiert wird. In diesem Papier werden die Gründe für dieses Scheitern untersucht und eine neue Methodik vorgeschlagen, die viele der Schwierigkeiten überwindet. Es wird ein System beschrieben, das die Leistungsbewertung mit Design und Implementierung integriert. Dieses System basiert auf einer einfachen Hochsprache, die verwendet wird, um das sich entwickelnde System in allen Stadien seiner Entwicklung zu beschreiben. Die Quellsprachenbeschreibung wird als direkte Eingabe für Leistungsanalyse- und Simulationsroutinen verwendet. Unter Verwendung der von diesen Routinen erhaltenen Leistungsinformationen als Rückmeldung werden die Probleme, die die Leistung nachteilig beeinflussen, früh genug erkannt, so dass sie ohne kostspielige größere Neuimplementierung des vorgeschlagenen Systems korrigiert werden können."}
{"DOCID": "2543", "TEXT": "Reduzierung der Abrufzeit von Scatter-Speichertechniken: Ein neues Verfahren zum Eingeben und Abrufen von Informationen in einer Hash-Tabelle wird beschrieben. Das Verfahren soll effizient sein, wenn die meisten Einträge mehrfach nachgeschlagen werden. Die theoretisch vorhergesagte und durch Monte-Carlo-Experimente verifizierte Anzahl von Sonden zum Nachschlagen eines Eintrags ist bei nahezu voller Tabelle erheblich geringer als bei anderen vergleichbaren Methoden. Ein Beispiel einer möglichen Fortran-Implementierung wird gegeben."}
{"DOCID": "2544", "TEXT": "Automatische Fehlergrenzen für einfache Nullstellen analytischer Funktionen: Das Cauchy-Ostrowski-Theorem über die Konvergenz von Newton-Iterationen für eine analytische Funktion in einer Variablen wird erweitert, um Rechenfehler unter Verwendung komplexer Intervallarithmetik einzubeziehen. Es werden mehrere Zahlenbeispiele für Polynome mit reellen und komplexen Wurzeln und ein Beispiel für die Bessel-Funktion erster Art gegeben."}
{"DOCID": "2545", "TEXT": "Eine Theorie diskreter Muster und ihre Implementierung in SNOBOL4: Der Begriff eines diskreten Musters wird formalisiert und bestimmte Eigenschaften abgeleitet. Es wird gezeigt, dass ein Muster eine Verallgemeinerung einer formalen Sprache ist. Algorithmen zum Implementieren der Arten von Mustern in SNOBOL4 werden angegeben. Der allgemeine Ansatz besteht darin, so weit wie möglich eine Bottom-Up-Analyse aus einer Top-Down-Spezifikation zu erstellen."}
{"DOCID": "2546", "TEXT": "Die Verwendung grammatikalischer Inferenz zum Entwerfen von Programmiersprachen: Sowohl beim Entwerfen einer neuen Programmiersprache als auch beim Erweitern einer bestehenden Sprache steht der Designer vor dem Problem, eine \"natürliche\" Grammatik für die Sprache abzuleiten. Wir schlagen einen interaktiven Ansatz für das Grammatikentwurfsproblem vor, bei dem der Designer eine Stichprobe von Sätzen und Strukturen als Eingabe für einen grammatikalischen Inferenzalgorithmus präsentiert. Der Algorithmus konstruiert dann eine Grammatik, die eine vernünftige Verallgemeinerung der vom Designer vorgelegten Beispiele ist. Die Implementierung ist derzeit auf eine Unterklasse von Grammatiken mit Operatorpräzedenz beschränkt, aber es wird ein zweiter Algorithmus skizziert, der auf eine größere Klasse von kontextfreien Grammatiken anwendbar ist."}
{"DOCID": "2547", "TEXT": "Darstellung von Konturen und Regionen für eine effiziente Computersuche: Eine neuartige computerdurchsuchbare Darstellung für die drei grundlegenden Bildmerkmale, Konturkarten, Bereichsabdeckung und Linienstrukturen, wird beschrieben. Die Darstellung, die praktische Speicheranforderungen hat, bietet ein schnelles Mittel zum Durchsuchen großer Dateien nach Daten, die sowohl mit geometrischen Positionen als auch mit Attributwerten verbunden sind. Eine Anwendung dieser Darstellung auf die Handhabung von Geländeinformationen veranschaulicht ihre Nützlichkeit. Die algebraischen Eigenschaften der Datenstruktur machen es rechnerisch einfach zu bestimmen, ob ein Punkt innerhalb einer geschlossenen Grenze liegt; Berechnen Sie die Fläche, die von einer geschlossenen Grenze umfasst wird; die geschlossene Grenze zu erzeugen, die die Vereinigung oder Schnittmenge zweier geschlossener Grenzen darstellt; und bestimme die Nachbargrenzen zu einem Punkt und die Mindestabstände zwischen ihnen und dem Punkt."}
{"DOCID": "2548", "TEXT": "Normale Abweichung [S14] (Algorithmus A442)"}
{"DOCID": "2549", "TEXT": "Zufällige Abweichungen von der Dipolverteilung [G5] (Algorithmus A441)"}
{"DOCID": "2550", "TEXT": "Eine mehrdimensionale Monte-Carlo-Quadratur mit adaptiver geschichteter Abtastung [D1] (Algorithmus A440)"}
{"DOCID": "2551", "TEXT": "Gegenseitige Rekursion in Algol 60 mit eingeschränkten Compilern"}
{"DOCID": "2552", "TEXT": "Ein Hinweis zum Verketten von Überlaufelementen innerhalb einer Direktzugriffstabelle"}
{"DOCID": "2553", "TEXT": "Der praktische Aspekt der Informatikausbildung-Diskussion"}
{"DOCID": "2554", "TEXT": "Reduktion eines bandsymmetrischen verallgemeinerten Eigenwertproblems: Es wird ein Algorithmus zur Reduktion des verallgemeinerten Eigenwertproblems Ax = Lambda Bx auf ein gewöhnliches Problem beschrieben, falls A und B symmetrische Bandmatrizen mit B positiv definit sind. Wenn n die Ordnung der Matrix und m die Bandbreite ist, werden die Matrizen A und B in m-mal-m-Blöcke unterteilt; und der Algorithmus wird in Bezug auf diese Blöcke beschrieben. Der Algorithmus reduziert das verallgemeinerte Problem auf ein gewöhnliches Eigenwertproblem für eine symmetrische Bandmatrix C, deren Bandbreite dieselbe wie A und B ist. Der Algorithmus ähnelt dem von Rutishauser und Schwartz für die Reduktion symmetrischer Matrizen auf Bandform. Die Berechnung C erfordert eine Operation der Ordnung mn^2. Der Rundungsfehler bei der Berechnung von C liegt in der gleichen Größenordnung wie die Summe der Fehler bei jedem der n/m Schritte des Algorithmus, wobei letztere Fehler weitgehend durch die Bedingung von B bezüglich der Inversion bestimmt werden."}
{"DOCID": "2555", "TEXT": "Exponentiation mit variabler Genauigkeit: Ein früherer Artikel präsentierte einen effizienten Algorithmus, genannt Neuberechnungsalgorithmus, zum Auswerten eines rationalen Ausdrucks innerhalb jeder gewünschten Toleranz auf einem Computer, der arithmetische Operationen mit variabler Genauigkeit ausführt. Der Neuberechnungsalgorithmus kann auf Ausdrücke angewendet werden, die beliebige Operationen mit variabler Genauigkeit mit O(10^(-p) + SUM{|Ei|}) Fehlergrenzen beinhalten, wobei p die Genauigkeit der Operation und Ei den Fehler im i-ten Argument der Operation bezeichnet . Dieses Papier stellt eine effiziente exponentielle Operation mit variabler Genauigkeit mit einer Fehlergrenze der obigen Ordnung vor. Andere Operationen wie log, sin und cos, die einfache Reihenentwicklungen haben, können ähnlich gehandhabt werden."}
{"DOCID": "2556", "TEXT": "Adaptive Korrektur von Programmanweisungen: Es wird ein Verfahren zum Analysieren von Anweisungen in einer Programmiersprache vorgeschlagen, die eine beträchtliche Ungenauigkeit in ihrer Spezifikation tolerieren kann. Diese Methode beinhaltet Prinzipien, die derzeit hauptsächlich auf Studien im Bereich der künstlichen Intelligenz beschränkt sind, wie z. B. Merkmalsextraktion, ungefährer Baumabgleich und Strategieverbesserung durch Feedback aus dem Abgleichsprozess. Ein Pilotprogramm, das die Prinzipien beinhaltet, wird beschrieben und vorläufige Betriebsergebnisse werden präsentiert. Ein abschließender Abschnitt gibt einen Überblick über weitere Prinzipien, die derzeit untersucht werden."}
{"DOCID": "2557", "TEXT": "Über den Zeitbedarf einer Folge von Matrixprodukten: In diesem Beitrag wird die Multiplikation konformer Folgen von Zeilenvektoren, Spaltenvektoren und quadratischen Matrizen diskutiert. Die minimale Zeit, die erforderlich ist, um solche Produkte auf gewöhnlichen seriellen Computern sowie auf parallelen Computern zu evaluieren, wird diskutiert. Es werden Algorithmen vorgestellt, die solche Matrixsequenzen unter Berücksichtigung der Beschränkungen der Maschinenorganisation richtig parsen."}
{"DOCID": "2558", "TEXT": "Schutz in Programmiersprachen: Es werden sprachliche Mechanismen beschrieben, die verwendet werden können, um ein Unterprogramm vor Fehlfunktionen eines anderen zu schützen. Es werden funktionserzeugende Funktionen und verschiedene Type-Tagging-Schemata betrachtet. Es wird versucht, zwischen Zugriffsbeschränkung und Authentifizierung zu unterscheiden."}
{"DOCID": "2559", "TEXT": "Die Neuzuweisung von Hash-codierten Tabellen: Wenn die Platzzuweisung für eine Hash-codierte Tabelle geändert wird, müssen die Tabelleneinträge über den neuen Platz neu verteilt werden. Eine Technik zum Erreichen dieser Neustreuung wird vorgestellt. Die Technik ist sowohl von der Länge der Tabelle als auch von der verwendeten Hashing-Funktion unabhängig und kann in Verbindung mit einer linearen Neuzuweisung der neu verteilten Tabelle verwendet werden. Darüber hinaus kann es verwendet werden, um zuvor markierte Löschungen aus jeder Hash-codierten Tabelle zu entfernen oder von einer Hash-Methode zu einer anderen zu wechseln. Die Effizienz der Technik wird diskutiert und theoretische Statistiken werden gegeben."}
{"DOCID": "2560", "TEXT": "Ein Warteschlangenmodell eines mehrfach programmierten Computers mit einem zweistufigen Speichersystem: Es werden die Ergebnisse einer Analyse eines probabilistischen Modells eines mehrfach programmierten Computersystems mit einem zweistufigen Speichersystem präsentiert, bei dem eine sequentielle Abhängigkeit der Zugriffe zwischen den Geräten besteht. Es werden Ausdrücke für die langfristige Wahrscheinlichkeit erhalten, dass sowohl die CPU als auch alle Speichergeräte ausgelastet sind. Es werden einige numerische Ergebnisse angegeben, die die Gewinne in der CPU-Nutzung quantifizieren, die durch Mehrfachprogrammierung in Gegenwart dieses Typs von Speichersystem erhältlich sind."}
{"DOCID": "2561", "TEXT": "Ein heuristischer Ansatz zur induktiven Inferenz in Fact-Retrieval-Systemen: Es werden heuristische Verfahren vorgestellt, die entwickelt wurden, um Inferenzen durch Verallgemeinerung aus verfügbaren Informationen durchzuführen. Die Verfahren verwenden eine Ähnlichkeitsstruktur, die der Datenbank unter Verwendung von nichtnumerischen Clustering-Algorithmen auferlegt wird. Sie sind in einem Modell-Faktenabrufsystem implementiert, das eine formale Abfragesprache und eine Eigenschaftslisten-Datenstruktur verwendet. Es wird ein Versuchsprogramm beschrieben, bei dem die Verfahren mit Testdatenbanken verwendet werden, die durch Löschen eines Teils der Daten und durch absichtliches Einfügen falscher Daten verändert werden. Es hat sich herausgestellt, dass das System unter einer Vielzahl von Bedingungen, die unvollständige und inkonsistente Daten beinhalten, auf die richtige Antwort schließen kann."}
{"DOCID": "2562", "TEXT": "Routing-Problem (Algorithmus R456)"}
{"DOCID": "2563", "TEXT": "Sortieralgorithmus zusammenführen (R426)"}
{"DOCID": "2564", "TEXT": "Programm zum Zeichnen verdeckter Linien (Algorithmus R420)"}
{"DOCID": "2565", "TEXT": "Ein Gaußscher Pseudozufallszahlengenerator (Algorithmus 488)"}
{"DOCID": "2566", "TEXT": "Exakte kumulative Verteilung der Kolmogorov-Smirnov-Statistik für kleine Stichproben (Algorithmus A487)"}
{"DOCID": "2567", "TEXT": "Ein exponentielles Verfahren zur Lösung von Systemen gewöhnlicher Differentialgleichungen: Es wird ein explizites, gekoppeltes, einstufiges Verfahren zur numerischen Lösung von Anfangswertproblemen für Systeme gewöhnlicher Differentialgleichungen vorgestellt. Die Methode wurde entwickelt, um allgemeiner Natur zu sein, aber besonders effizient zu sein, wenn es um steife Systeme von Differentialgleichungen geht. Es ist im Allgemeinen zweiter Ordnung, außer im Fall eines linearen Systems mit konstanten Koeffizienten und linearen Zwangstermen; in diesem Fall ist das Verfahren dritter Ordnung. Es wurde in biologischen Anwendungen implementiert und zur routinemäßigen Verwendung gebracht – wo Steifheit häufig auftritt – mit günstigen Ergebnissen. Im Vergleich zu einer standardmäßigen Runge-Kutta-Implementierung vierter Ordnung reichte die für dieses Verfahren erforderliche Rechenzeit von vergleichbar für bestimmte nichtsteife Probleme bis zu mehr als zwei Größenordnungen schneller für einige hochsteife Systeme."}
{"DOCID": "2568", "TEXT": "A Graph Formulation of a School Scheduling Algorithm: Das Problem mit dem klassischen Titel \"The Examination Schedule Problem\" nimmt in der Literatur verschiedene Formen an. Die meisten dieser Formulierungen lassen sich in der Terminologie der klassischen Netzwerktheorie darstellen. Eine solche Formulierung ist: Bei einem gegebenen ungerichteten Netzwerk, partitioniere seine Knoten in eine minimale Anzahl von Teilmengen, so dass keine zwei Mitglieder derselben Teilmenge durch einen Bogen verbunden sind. Eine offensichtliche Untergrenze für diese Zahl ist die Größe des größten stark verbundenen Teilgraphen. Kirchgassner hat bewiesen, dass eine Obergrenze diese Größe plus eins ist. Eine logische Erweiterung der vorherigen Arbeit ist die Einführung von Prüfungen mit variabler Länge, wobei W(I) die Anzahl der Perioden für Prüfung I ist. Das Ziel dieses Papiers ist es, die Definition des größten stark zusammenhängenden Teilgraphen zu verallgemeinern, um die Gewichtung von Knoten einzuschließen, einen Näherungsalgorithmus vorzustellen, der normalerweise den größten stark zusammenhängenden Teilgraphen findet, und die Anwendung dieses Algorithmus zur Lösung von Schulplanungs- und Prüfungsplanungsproblemen zu diskutieren."}
{"DOCID": "2569", "TEXT": "Computererzeugung von Gamma-Zufallsvariablen mit nicht ganzzahligen Formparametern: Wenn der Formparameter a ganzzahlig ist, ist die Erzeugung von Gamma-Zufallsvariablen mit einem digitalen Computer unkompliziert. Es gibt kein einfaches Verfahren zum Generieren von Gamma-Zufallsvariablen mit nicht ganzzahligen Formparametern. Eine gängige Vorgehensweise besteht darin, solche Zufallsvariablen näherungsweise durch die sogenannte Probability-Switch-Methode zu erzeugen. Ein anderes Verfahren, das exakt ist, ist Johnk zu verdanken. Dieses Papier stellt ein Zurückweisungsverfahren zum genauen Generieren von Gamma-Zufallsvariablen vor, wenn a größer als 1 ist. Es wird gezeigt, dass die Effizienz des Zurückweisungsverfahrens besser ist als die Effizienz des Johnk-Verfahrens. Der Artikel kommt zu dem Schluss, dass, wenn a nicht ganzzahlig ist, die folgende Mischung von Verfahren die beste Kombination aus Genauigkeit und Effizienz ergibt: (1) wenn a kleiner als 1 ist, verwende Johnks Methode; (2) wenn 1 kleiner als a und a kleiner als 5 ist, verwende das Zurückweisungsverfahren; (3) wenn a größer als 5 ist, verwende das Wahrscheinlichkeitswechselverfahren."}
{"DOCID": "2570", "TEXT": "Ein Vergleich von Listenplänen für parallele Verarbeitungssysteme: Es wird das Problem des Planens von zwei oder mehr Prozessoren untersucht, um die Ausführungszeit eines Programms zu minimieren, das aus einer Menge teilweise geordneter Aufgaben besteht. Fälle, in denen Aufgabenausführungszeiten deterministisch sind, und andere, in denen Ausführungszeiten Zufallsvariablen sind, werden analysiert. Es wird gezeigt, dass verschiedene in der Literatur vorgeschlagene Algorithmen in der Ausführungszeit erheblich variieren und dass der B-Zeitplan von Coffman und Graham nahezu optimal ist. Eine dynamische Programmierlösung für den Fall, dass Ausführungszeiten Zufallsvariablen sind, wird vorgestellt."}
{"DOCID": "2571", "TEXT": "Ein analytisches Modell des Hasp Execution Task Monitor: Der HASP Execution Task Monitor ordnet die OS/360-Dispatching-Kette regelmäßig neu, um Tasks eine präventive Ausführungspriorität in umgekehrter Reihenfolge zu der ihres CPU-Auslastungsverlaufs zu geben. Der Effekt besteht darin, die E/A-gebundenen Tasks aktiv zu halten und zu verhindern, dass CPU-gebundene Tasks andere Tasks aussperren. Dieses Dokument entwickelt ein einfaches Modell des Execution Task Monitors und verwendet es, um die Effektivität des Monitors bei der Verbesserung der Systemleistung zu untersuchen. Für den Fall der Aufgabenausführung in einer Speicherhierarchie unterschiedlicher Geschwindigkeit wird eine modifizierte Strategieüberwachungssteuerung untersucht."}
{"DOCID": "2572", "TEXT": "Argumente für ein Moratorium für den Aufbau eines Community-Informationsdienstprogramms: In diesem Artikel drängt der Autor auf eine umsichtige und dezentralisierte Herangehensweise an die Frage der Gestaltung und Wünschbarkeit computergestützter Community-Informationsdienstprogramme. Bevor wir die Unvermeidlichkeit und Wünschbarkeit dieser oder einer anderen Technologie akzeptieren, sollten wir: (1) uns der Machbarkeit (intern und extern) dessen sicher sein, was vorgeschlagen wird; (2) projizieren und vielleicht auf Änderungen in komplementären Techniken warten; (3) aktuelle und geplante ergänzende Techniken bewerten; (4) das Bestehen einer Nachfrage nach dem, was vorgeschlagen wird, festzustellen; (5) Schritte unternehmen, um eine repräsentative Gruppe von Endbenutzern in das Systemdesign einzubeziehen, und (6) mögliche Nebenwirkungen auf den Menschen und sein Weltbild sorgfältig durchdenken. In diesem Rahmen werden aktuelle Vorschläge für gemeinschaftliche Informationsdienstprogramme untersucht, und es wird der Schluss gezogen, dass die Gesellschaft noch nicht in der Lage ist, entweder den Aufbau eines Informationsdienstprogramms in einer Prototypgemeinschaft oder die Akzeptanz einer Politik zugunsten seiner weit verbreiteten Implementierung zu rechtfertigen ."}
{"DOCID": "2573", "TEXT": "Computerprogrammierung als Kunst"}
{"DOCID": "2574", "TEXT": "Mehrere Existents aus einer Schleife, die weder GO TO noch Labels verwenden"}
{"DOCID": "2575", "TEXT": "Das Best-Match-Problem beim Abrufen von Dokumenten"}
{"DOCID": "2576", "TEXT": "Eine einfache Technik zur Darstellung von Zeichenketten in Fortran IV"}
{"DOCID": "2577", "TEXT": "Eine Vor-Ort-Datenverwaltungssystemanwendung in der Feldarchäologie"}
{"DOCID": "2578", "TEXT": "Selbststabilisierende Systeme trotz verteilter Kontrolle"}
{"DOCID": "2579", "TEXT": "Registerzuweisung über Nutzungszählungen: Dieses Dokument führt in den Begriff der Nutzungszählungen ein, zeigt, wie Nutzungszählungen durch Algorithmen entwickelt werden können, die redundante Berechnungen eliminieren, und beschreibt, wie Nutzungszählungen die Grundlage für die Registerzuweisung bilden können. Das Papier vergleicht die Registerzuordnung basierend auf Nutzungszählungen mit anderen allgemein verwendeten Registerzuordnungstechniken und präsentiert Beweise, die zeigen, dass die Nutzungszählungstechnik signifikant besser ist als diese anderen Techniken."}
{"DOCID": "2580", "TEXT": "Ein Verfahren zum Komponieren einfacher traditioneller Musik durch Computer: Es wird ein Verfahren zum Komponieren musikalischer Runden durch Computer beschrieben. Diese Methode verwendet etwas Musiktheorie plus zusätzliche Heuristiken. Grundlegend für das Verfahren ist ein Satz von Produktionen zusammen mit Sätzen von Anwendbarkeitsregeln und Gewichtungsregeln, die auf die Produktionen einwirken und entscheiden, wann und in welchem ​​Umfang sie zur Verwendung verfügbar sind. Mehrere durch die Computerimplementierung des Verfahrens erzeugte Runden werden vorgestellt. Im Allgemeinen klingt die resultierende Musik für den Fachmann mittelmäßig, obwohl sie für den Laien normalerweise angenehm ist. Es scheint, dass für Runden keine ausgewachsene Musiktheorie erforderlich ist – die gesamte Hardware, die für strukturelle Ebenen erforderlich ist, ist für diese Stücke nicht erforderlich. Der Autor hat versucht, sowohl Musiker als auch Informatiker anzusprechen."}
{"DOCID": "2581", "TEXT": "Ein lokal organisierter Parser für gesprochene Eingaben: Dieses Dokument beschreibt LPARS, ein lokal organisiertes Parsing-System, das für die Verwendung in einem kontinuierlichen Spracherkenner entwickelt wurde. LPARS verarbeitet eine Reihe von Phonemen, die Mehrdeutigkeiten und Fehler enthalten. Das System ist in dem Sinne lokal organisiert, dass es lokale Parsing-Strukturen aus zuverlässigen Wortkandidaten aufbaut, die irgendwo in einer Eingabeäußerung erkannt werden. Diese lokalen Strukturen werden als \"Inseln der Zuverlässigkeit\" verwendet, um die Suche nach stärker verstümmelten Wörtern zu leiten, die die Äußerung vervollständigen könnten."}
{"DOCID": "2582", "TEXT": "Verbesserung der Lokalität durch kritische Arbeitssätze: Ein neuer Ansatz zur Verbesserung der Lokalität von Programmen durch Umstrukturierung wird beschrieben. Das Verfahren ist besonders für solche Systeme geeignet, bei denen der Primärspeicher gemäß einer Arbeitssatzstrategie verwaltet wird. Es basiert auf dem Konzept des kritischen Arbeitssatzes, einem Arbeitssatz, der nicht die nächste Speicherreferenz enthält. Die Daten, mit denen das Verfahren arbeitet, werden aus einer Ablaufverfolgung des umzustrukturierenden Programms extrahiert. Es zeigt sich, dass das Verfahren, abgesehen von einigen Sonderfällen, nicht optimal ist. Die experimentellen Ergebnisse, die durch die Verwendung des Verfahrens zum Umstrukturieren eines interaktiven Texteditors und des Dateisystemmoduls eines Betriebssystems erhalten wurden, haben jedoch seine wesentliche Überlegenheit gegenüber den anderen in der Literatur vorgeschlagenen Verfahren gezeigt."}
{"DOCID": "2583", "TEXT": "Richtlinien zur Humanisierung computergestützter Informationssysteme: Ein Bericht von Stanley House"}
{"DOCID": "2584", "TEXT": "Aufzählung von Vollzeitprogrammierern: Daten aus der Volkszählung von 1970 und den Gebietslohnerhebungen des Arbeitsministeriums werden verwendet, um Schätzungen der Zahl der Vollzeitprogrammierer abzuleiten, die in den Jahren 1969 bis 1973 beschäftigt waren. Die Zahl von 180.000 für 1973 ist erheblich geringer als angenommen in früheren Berichten. Bildungsverwaltern wird empfohlen zu prüfen, ob die vielen Kurse, die sich an die Ausbildung von Programmierern richten, beruflich gerechtfertigt sind."}
{"DOCID": "2585", "TEXT": "Effiziente Implementierung eines variablen Projektionsalgorithmus für nichtlineare Kleinste-Quadrate-Probleme (Errata)"}
{"DOCID": "2586", "TEXT": "Anpassung der optimalen Codegenerierung für arithmetische Ausdrücke an die auf heutigen Computern verfügbaren Befehlssätze (Errata)"}
{"DOCID": "2587", "TEXT": "Zur Konstruktion einer repräsentativen synthetischen Arbeitslast (Errata)"}
{"DOCID": "2588", "TEXT": "Minimierung der Rosenbrock-Funktion (Algorithmus R450)"}
{"DOCID": "2589", "TEXT": "Eine Computerroutine für quadratische und lineare Programmierprobleme (Algorithmus R431)"}
{"DOCID": "2590", "TEXT": "Hypergeometrisch (Algorithmus C191)"}
{"DOCID": "2591", "TEXT": "Numerische Inversion der Laplace-Transformation (Algorithmus A486)"}
{"DOCID": "2592", "TEXT": "Über die Erzeugung von Testproblemen für lineare Programmiercodes: Benutzer von Computercodes für lineare Programmierung haben die Notwendigkeit erkannt, die Kapazität, Effektivität und Genauigkeit der von solchen Codes bereitgestellten Lösungen zu bewerten. Bei den meisten Installationen wird angenommen, dass lineare Programmiercodes in großem Umfang korrekte Lösungen erzeugen, ohne jemals durch Testprobleme mit bekannten Lösungen \"benchmarkiert\" worden zu sein. Der Grund für dieses Versäumnis, die Codes angemessen zu testen, liegt darin, dass es selten große Probleme mit bekannten Lösungen gibt, die leicht verfügbar sind. Dieser Beitrag präsentiert eine theoretische Begründung und eine anschauliche Implementierung eines Verfahrens zur Generierung von Testproblemen der linearen Programmierung mit bekannten Lösungen. Das Verfahren erlaubt die Generierung von Testproblemen beliebiger Größe und unterschiedlichster numerischer Ausprägung."}
{"DOCID": "2593", "TEXT": "Ein Back-End-Computer für die Datenbankverwaltung: Es wird vorgeschlagen, dass die Datenbank-Verwaltungsfunktion auf einem dedizierten Back-End-Computer platziert wird, der Befehle akzeptiert (in einer relativ hohen Sprache wie dem Bericht der CODASYL Data Base Task Group, April 1971). ) von einem Host-Computer, greift auf die Datenbank im Sekundärspeicher zu und gibt Ergebnisse zurück. Die Vorteile einer solchen Konfiguration werden diskutiert. Eine experimentelle Implementierung, genannt das experimentelle Datenmanagementsystem, XDMS, wird beschrieben und bestimmte Schlussfolgerungen über den Back-End-Ansatz werden aus dieser Implementierung gezogen."}
{"DOCID": "2594", "TEXT": "Strukturierte Datenstrukturen: Programmiersysteme, die beliebige verknüpfte Listenstrukturen zulassen, ermöglichen es dem Benutzer, komplizierte Strukturen ohne ausreichenden Schutz zu erstellen. Löschungen können zu unerreichbaren Datenelementen führen, und es gibt keine Garantie dafür, dass Hinzufügungen ordnungsgemäß durchgeführt werden. Um hier Abhilfe zu schaffen, schlägt dieser Aufsatz ein Maß vor, das die Erstellung einer eingeschränkten Klasse von Datenstrukturen vorsieht, aber die Korrektheit des Programms sicherstellt. Dies wird durch eine explizite Strukturdeklaration, eine Beschränkung der zulässigen Operationen und Ausführungszeitprüfungen erreicht."}
{"DOCID": "2595", "TEXT": "Ein Hinweis zur Berechnung der Größe des Arbeitssatzes: Es werden Referenzzeichenfolgen endlicher Länge mit willkürlicher Struktur betrachtet, und es wird ein exakter Ausdruck für die durchschnittliche Größe des Arbeitssatzes in Form von \"korrigierten\" Interreferenzintervallstatistiken abgeleitet. Ein Beispiel wird diskutiert; Ober- und Untergrenzen werden erhalten; und es wird gezeigt, dass die Funktion der durchschnittlichen Arbeitssatzgröße effizient für einen Satz von Seitengrößen in einem einzigen Durchlauf der Referenzzeichenfolge erhalten wird. Diese Arbeit folgt den Entwicklungen eines Artikels von Denning und Schwartz, die Referenzketten unendlicher Länge betrachten, die bestimmte statistische Eigenschaften erfüllen, und die einen Ausdruck ableiten, der die asymptotische durchschnittliche Größe des Arbeitssatzes mit der asymptotischen Funktion der Rate fehlender Seiten beim Ersetzen des Arbeitssatzes in Beziehung setzt."}
{"DOCID": "2596", "TEXT": "Ein gewichtetes Buddy-Verfahren für die dynamische Speicherzuordnung: Eine Erweiterung des Buddy-Verfahrens, die als gewichtetes Buddy-Verfahren bezeichnet wird, für die dynamische Speicherzuordnung wird vorgestellt. Die gewichtete Buddy-Methode erlaubt Blockgrößen von 2^k und 3(2^k), während die ursprüngliche Buddy-Methode nur Blockgrößen von 2^k zuließ. Diese Erweiterung wird mit zusätzlichen Kosten von nur zwei Bits pro Block erreicht. Es werden Simulationsergebnisse vorgestellt, die diese Methode mit der Buddy-Methode vergleichen. Diese Ergebnisse weisen darauf hin, dass das Buddy-System für eine gleichmäßige Anforderungsverteilung eine geringere Gesamtspeicherfragmentierung aufweist als der gewichtete Buddy-Algorithmus. Allerdings ist die Gesamtfragmentierung für das Weighted-Buddy-Verfahren kleiner, wenn die Anforderungen für exponentiell verteilte Blockgrößen sind."}
{"DOCID": "2597", "TEXT": "Monitore: Ein Konzept zur Strukturierung eines Betriebssystems: Dieses Dokument entwickelt Brinch-Hansens Konzept eines Monitors als Methode zur Strukturierung eines Betriebssystems. Es führt eine Form der Synchronisation ein, beschreibt eine mögliche Methode der Implementierung in Form von Semaphoren und gibt eine geeignete Beweisregel an. Veranschaulichende Beispiele umfassen einen einzelnen Ressourcenplaner, einen begrenzten Puffer, einen Wecker, einen Pufferpool, einen Plattenkopfoptimierer und eine Version des Problems von Lesern und Schreibern."}
{"DOCID": "2598", "TEXT": "Erweiterung des informationstheoretischen Ansatzes zur Umwandlung von Entscheidungstabellen mit beschränkter Eingabe in Computerprogramme: Dieses Papier modifiziert einen früheren Algorithmus zur Umwandlung von Entscheidungstabellen in Flussdiagramme, die die nachfolgende Ausführungszeit minimieren, wenn sie in ein Computerprogramm kompiliert werden. Die in diesem Beitrag betrachteten Algorithmen führen eine begrenzte Suche durch und führen dementsprechend nicht unbedingt zu global optimalen Lösungen. Der größere Suchaufwand, der erforderlich ist, um eine global optimale Lösung für komplexe Entscheidungstabellen zu erhalten, wird jedoch in der Regel nicht durch eine ausreichende Einsparung an Ausführungszeit gerechtfertigt. Es besteht eine Analogie zwischen dem Problem der Umwandlung von Entscheidungstabellen in effiziente Flussdiagramme und dem wohlverstandenen Problem der Informationstheorie der rauschfreien Codierung. Die Ergebnisse der rauschlosen Codierungsliteratur werden verwendet, um die Grenzen von Algorithmen zu untersuchen, die verwendet werden, um das Entscheidungstabellenproblem zu lösen. Die Analogie zwischen den beiden Problemen wird auch verwendet, um Verbesserungen des Informationsalgorithmus zu entwickeln, indem die Suchtiefe unter bestimmten Bedingungen erweitert und zusätzliche Bedingungen vorgeschlagen werden, die der Entscheidungstabelle hinzugefügt werden sollen. Abschließend wird der Informationsalgorithmus mit einem Algorithmus verglichen, der in einer neueren Arbeit von Verhelst vorgeschlagen wurde."}
{"DOCID": "2599", "TEXT": "Annäherung erster Ordnung an das optimale Checkpoint-Intervall"}
{"DOCID": "2600", "TEXT": "Berechnung von g-Splines über ein Faktorisierungsverfahren [E2] (Algorithmus A485)"}
{"DOCID": "2601", "TEXT": "Auswertung der modifizierten Bessel-Funktionen K0(Z) und K1(Z) für komplexe Argumente [S17] (Algorithmus A484)"}
{"DOCID": "2602", "TEXT": "Maskiertes dreidimensionales Plotprogramm mit Rotationen [J6] (Algorithmus A483)"}
{"DOCID": "2603", "TEXT": "Die Äquivalenz von reduzierenden Übergangssprachen und deterministischen Sprachen: Die von Eickel, Paul, Bauer und Samelson eingeführte Klasse reduzierender Übergangssprachen wurde von Morris als echte Oberklasse der einfachen Präzedenzsprachen gezeigt. In diesem Aufsatz wird dieses Ergebnis erweitert und zeigt, dass die erste Klasse tatsächlich der Klasse der deterministischen kontextfreien Sprachen entspricht."}
{"DOCID": "2604", "TEXT": "Eine interaktive grafische Anzeige zur Bereichsaufteilung durch lineare Programmierung: Unter Verwendung linearer Programmierung wurde ein interaktives grafisches Anzeigesystem implementiert, um das Bereichsentwurfsproblem der Aufteilung eines Bereichs in N nicht überlappende Unterbereiche derart zu lösen, dass ihre Bereiche in festgelegten Proportionen liegen und das die Gesamtkosten für deren Wartung sind minimal. Im Dialog kann ein Benutzer leicht unterschiedliche Aufteilungen erhalten, indem er die Grenze, die Standorte der Servicezentren, die Flächenanteile und die Kostenfunktionen spezifiziert und modifiziert. Beispiele sind enthalten."}
{"DOCID": "2605", "TEXT": "Ein Programm zur präzisen numerischen Analyse: Es wird ein Programm zum Berechnen der Lösung einer kleinen Anzahl von Standardproblemen der numerischen Analyse mit einer bestimmten Genauigkeit bis zu einer Grenze von 2000 korrekten Dezimalstellen beschrieben. Jede berechnete Zahl ist in einem Intervall mit einem Mittelpunkt mit mehrfacher Genauigkeit begrenzt. Arithmetische Operationen, die diese Zahlen betreffen, werden gemäß Intervallarithmetikkonzepten ausgeführt, wobei nicht signifikante Ziffern automatisch verworfen werden. Details zur Problemspezifikation und Problemberechnung werden bereitgestellt."}
{"DOCID": "2606", "TEXT": "Ein neuer Integrationsalgorithmus für gewöhnliche Differentialgleichungen basierend auf Kettenbruchnäherungen: Ein neuer Integrationsalgorithmus wird gefunden, und eine Implementierung wird mit anderen programmierten Algorithmen verglichen. Der neue Algorithmus ist ein schrittweises Verfahren zur Lösung des Anfangswertproblems in gewöhnlichen Differentialgleichungen. Es ist dafür ausgelegt, Pole kleiner ganzzahliger Ordnung in den Lösungen der Differentialgleichungen durch fortgesetzte Brüche anzunähern, die durch Manipulieren der Summen von abgeschnittenen Taylor-Reihenentwicklungen erhalten werden. Die neue Methode wird mit Gragg-Bulirsh-Stoer und der Taylor-Reihenmethode verglichen. Das Verfahren der Taylor-Reihe und das neue Verfahren haben sich hinsichtlich Geschwindigkeit und Genauigkeit als überlegen erwiesen, während sich das neue Verfahren als am besten erwiesen hat, wenn die Lösung in der Nähe einer Singularität erforderlich ist. Es zeigt sich schließlich, dass die neue Methode automatisch Singularitäten passiert, wo alle anderen diskutierten Methoden versagt haben."}
{"DOCID": "2607", "TEXT": "Eine Problemliste von Problemen in Bezug auf Computer und öffentliche Ordnung"}
{"DOCID": "2608", "TEXT": "Wiederholungsbeziehungen für das Fresnel-Integral und ähnliche Integrale"}
{"DOCID": "2609", "TEXT": "Interpolation mit gerundeten Rampenfunktionen: Eine neue Interpolationsfunktion wird eingeführt. Sie hat unendlich viele stetige Ableitungen und ist eine Zusammensetzung von Rampenfunktionen mit geglätteten Kurven, die abgerundete Rampenfunktionen genannt werden. Es wird gezeigt, wie die Interpolationsfunktion auf mehr als eine Variable erweitert werden kann. Es wird ein effizientes Fortran-Programm angegeben, mit dem die Interpolationsfunktion für eine gegebene Punktmenge erhalten werden kann."}
{"DOCID": "2610", "TEXT": "Gaußsche harmonische Interpolationsformeln: Sei R ein offener, begrenzter, einfach zusammenhängender Bereich in der (x,y)-Ebene und sei (x*,y*) ein Punkt in R. Angenommen, R sei sternförmig in Bezug auf (x* ,y*) diskutieren wir eine Methode zur Berechnung von Gaussschen harmonischen Interpolationsformeln für R und den Punkt (x*,y*). Solche Formeln approximieren eine harmonische Funktion bei (x*,y*) durch eine lineare Kombination ihrer Werte an bestimmten ausgewählten Punkten auf der Grenze von R. Solche Formeln sind nützlich, um die Lösung des Dirichlet-Problems für R zu approximieren."}
{"DOCID": "2611", "TEXT": "Die komplexe Methode zur eingeschränkten Optimierung (Algorithmus R454)"}
{"DOCID": "2612", "TEXT": "Minimierung der Rosenbrock-Funktion (Algorithmus R450)"}
{"DOCID": "2613", "TEXT": "Transitivitätsmengen [G7] (Algorithmus A482)"}
{"DOCID": "2614", "TEXT": "Pfeil zur Präzedenz-Netzwerk-Transformation [H] (Algorithmus A481)"}
{"DOCID": "2615", "TEXT": "Prozeduren zum Berechnen von Glätten und Interpolieren natürlicher Splines [E1] (Algorithmus A480)"}
{"DOCID": "2616", "TEXT": "Zur Konvertierung von Programmen in Entscheidungstabellen: Methode und Zielsetzung: Es wird die Problematik der Konvertierung von Programmen in Entscheidungstabellen untersucht. Ziele dieser Konvertierungen sind in der Praxis vor allem Programm-Debugging und -Optimierung. Erweiterungen der Theorie des Rechnens und der Berechenbarkeit werden vorgeschlagen."}
{"DOCID": "2617", "TEXT": "Ein Hinweis zur Reihenfolge der Teilausdrücke bei der Auswertung arithmetischer Ausdrücke"}
{"DOCID": "2618", "TEXT": "Eine neue Lösung für das Problem der gleichzeitigen Programmierung von Dijkstra: Es wird eine einfache Lösung für das Problem des gegenseitigen Ausschlusses vorgestellt, die es dem System ermöglicht, trotz des Ausfalls einer einzelnen Komponente weiter zu arbeiten."}
{"DOCID": "2619", "TEXT": "Graph Coloring Bedingungen für die Existenz von Lösungen des Stundenplanproblems: Es wird eine notwendige und hinreichende Bedingung für die Existenz einer Lösung des Gotlieb-Klassenlehrer-Stundenplanproblems präsentiert. Zwischen dem Klassenlehrer-Stundenplanproblem und Graphen mit Vorbedingungen werden mehrere Beziehungen hergestellt. Diese Voraussetzungen schränken die Farbgebung eines Graphen zusätzlich ein. Die Voraussetzungen entsprechen den Nichterreichbarkeitsbedingungen und Terminvorgaben im Klassen-Lehrer-Stundenplan-Problem. Unter Verwendung einiger neuerer Ergebnisse, die Graphen mit Vorbedingungen in Graphen ohne Vorbedingungen umwandeln, wird gezeigt, dass die Existenz einer Färbung eines Graphen die erforderliche notwendige und hinreichende Bedingung ist."}
{"DOCID": "2620", "TEXT": "Anforderungen an die Ausführungszeit für Verschlüsselungsprogramme: Obwohl die Verschlüsselung oft als Mittel zum Schutz von Computerdaten diskutiert wurde, sind ihre Kosten nicht gut bekannt. Fünf Experimente wurden durchgeführt, um die CPU-Zeit auf einem CDC 6400 zu messen, die von additiven Chiffren benötigt wird, die sowohl in Assemblersprache als auch in Fortran programmiert sind: eine \"Nulltransformation\", um die Zeit zu messen, um Daten ohne Verschlüsselung zu verschieben; Verschlüsselung mit Ein-Wort-Schlüssel; Verschlüsselung mit einem 125-Wort-Schlüssel; Doppelschlüsselverschlüsselung; und Verschlüsselung unter Verwendung eines pseudozufälligen Schlüssels. Die Ergebnisse wurden über 100 Läufe auf Konsistenz analysiert, und die Auswirkungen konstanter und intermittierender Fehler wurden berücksichtigt. Die Zeitraten für die Assemblersprachenverschlüsselung reichten von 498.800 Zeichen pro Sekunde für eine pseudozufällige Schlüsselchiffre bis zu 2.092.000 Zeichen pro Sekunde für eine konstante Ein-Wort-Schlüsselchiffre. Letzteres entspricht fast der Rate, die erforderlich ist, um Daten einfach ohne Verschlüsselung zu verschieben. Fortran-Tests benötigten mehr als viermal so viel CPU-Zeit. Dieses Papier führt die Idee des Verschlüsselungszeitkoeffizienten ein, dem Verhältnis der Verschlüsselungszeit zu der Zeit, die benötigt wird, um Daten ohne Verschlüsselung abzurufen und zu speichern."}
{"DOCID": "2621", "TEXT": "Ein hochsicheres Anmeldeverfahren: Der Schutz von Time-Sharing-Systemen vor unbefugten Benutzern wird häufig durch die Verwendung von Passwörtern erreicht. Durch die Verwendung von Einwegchiffren zur Verschlüsselung der Passwörter können die Risiken vermieden werden, die mit der Speicherung der Passwörter im Computer verbunden sind. Wir diskutieren die Auswahl einer geeigneten Einwegchiffre und schlagen vor, dass für diesen Zweck Polynome über einem Primzahlmodul den von Sannon-Codes abgeleiteten Einwegchiffren überlegen sind."}
{"DOCID": "2622", "TEXT": "Ein Benutzerauthentifizierungsschema, das im Computer keine Geheimhaltung erfordert: In vielen Computerbetriebssystemen authentifiziert sich ein Benutzer durch Eingabe eines geheimen Passworts, das nur ihm und dem System bekannt ist. Das System vergleicht dieses Passwort mit einem, das in einer Passworttabelle aufgezeichnet ist, die nur dem Authentifizierungsprogramm zur Verfügung steht. Die Integrität des Systems hängt davon ab, dass die Tabelle geheim gehalten wird. In diesem Beitrag wird ein Passwortschema vorgestellt, das keine Geheimhaltung im Computer erfordert. Alle Aspekte des Systems, einschließlich aller relevanten Codes und Datenbanken, können jedem bekannt sein, der versucht, einzudringen. Das Schema basiert auf der Verwendung einer Funktion H, die der potenzielle Eindringling nicht invertieren kann. Diese Funktion wird auf das Passwort des Benutzers angewendet und das Ergebnis mit einem Tabelleneintrag verglichen, wobei eine Übereinstimmung als Authentifizierung des Benutzers interpretiert wird. Der Eindringling mag alles über H wissen und Zugriff auf die Tabelle haben, aber er kann nur dann in das System eindringen, wenn er H invertieren kann, um eine Eingabe zu bestimmen, die eine bestimmte Ausgabe erzeugt. Dieses Papier diskutiert Fragen rund um die Auswahl eines geeigneten H. Zwei verschiedene plausible Argumente werden angeführt, dass die Penetration außerordentlich schwierig wäre, und es wird dann argumentiert, dass strengere Ergebnisse unwahrscheinlich sind. Abschließend werden einige ingenieurtechnische Probleme im Zusammenhang mit dem Schema diskutiert."}
{"DOCID": "2623", "TEXT": "Eine neue Technik zum Komprimieren und Speichern von Daten: Die weitverbreitete Tendenz zum Speichern großer Programme und Textblöcke hat einen Bedarf an effizienten Verfahren zum Komprimieren und Speichern von Daten erzeugt. Dieses Dokument beschreibt Techniken, die in den meisten Fällen die Speichergröße um den Faktor zwei bis vier verringern können. Die Techniken umfassen eine spezielle Behandlung von führenden und nachgestellten Leerzeichen und die Codierung anderer Symbole in Gruppen fester Größe als eindeutige Festkommazahlen. Die Effizienz des Systems wird betrachtet und es werden relevante Statistiken angegeben und mit Statistiken für andere Informationscodierungstechniken verglichen."}
{"DOCID": "2624", "TEXT": "Formale Anforderungen an virtualisierbare Architekturen der dritten Generation: Virtuelle Maschinensysteme wurden auf einer begrenzten Anzahl von Computersystemen der dritten Generation implementiert, z. CP-67 auf dem IBM 360/67. Aus früheren empirischen Studien ist bekannt, dass bestimmte Computersysteme der dritten Generation, z. der DEC PDP-10, kann kein virtuelles Maschinensystem unterstützen. In dieser Arbeit wird ein Modell eines der dritten Generation ähnlichen Computersystems entwickelt. Formale Techniken werden verwendet, um genaue ausreichende Bedingungen abzuleiten, um zu testen, ob eine solche Architektur virtuelle Maschinen unterstützen kann."}
{"DOCID": "2625", "TEXT": "Fähigkeitsbasierte Adressierung: Verschiedene Adressierungsschemata, die Segmenttabellen verwenden, werden untersucht. Die Unzulänglichkeiten dieser Schemata im Umgang mit gemeinsam genutzten Adressen werden erläutert. Diese Unzulänglichkeiten werden auf das Fehlen einer effizienten absoluten Adresse für Objekte in diesen Systemen zurückgeführt. Es wird gezeigt, dass die direkte Verwendung einer Fähigkeit als Adresse diese Schwierigkeiten überwindet, weil sie die benötigte absolute Adresse bereitstellt. Die Implementierung einer fähigkeitsbasierten Adressierung wird diskutiert. Es wird vorhergesagt, dass die Verwendung von Tags zur Identifizierung von Fähigkeiten dominieren wird. Es wird ein Hardware-Adressenübersetzungsschema vorgeschlagen, das niemals die Modifikation der Darstellung von Fähigkeiten erfordert. Das Schema verwendet eine Hauptspeicher-Hash-Tabelle, um den Ort eines Segments im Hauptspeicher zu erhalten, wenn dessen eindeutiger Code gegeben ist. Die Hash-Tabelle wird für Segmente, auf die kürzlich zugegriffen wurde, mittels eines Satzes von assoziativen Registern vermieden. Ein Computer, der eine fähigkeitsbasierte Adressierung verwendet, kann gegenwärtigen Systemen auf der Grundlage des Schutzes, der Einfachheit der Programmierkonventionen und der effizienten Implementierung wesentlich überlegen sein."}
{"DOCID": "2626", "TEXT": "Schutz und Kontrolle der gemeinsamen Nutzung von Informationen in Multics: Der Entwurf von Mechanismen zur Kontrolle der gemeinsamen Nutzung von Informationen im Multics-System wird beschrieben. Fünf Designprinzipien helfen dabei, einen Einblick in die Kompromisse zwischen verschiedenen möglichen Designs zu geben. Die beschriebenen Schlüsselmechanismen umfassen Zugriffskontrolllisten, hierarchische Kontrolle von Zugriffsspezifikationen, Identifizierung und Authentifizierung von Benutzern und Primärspeicherschutz. Das Papier endet mit einer Erörterung mehrerer bekannter Schwachstellen im aktuellen Design von Schutzmechanismen."}
{"DOCID": "2627", "TEXT": "Planen unabhängiger Tasks zum Reduzieren der durchschnittlichen Endzeit: Das Sequenzieren zum Minimieren der durchschnittlichen Endzeit (oder der durchschnittlichen Zeit im System) ist nicht nur für den Benutzer wünschenswert, sondern es neigt auch dazu, zu jedem Zeitpunkt den Speicherplatz zu minimieren, der zum Halten unvollständiger Aufgaben erforderlich ist. In dieser Arbeit wird ein deterministisches Modell unabhängiger Aufgaben eingeführt und neue Ergebnisse abgeleitet, die die bekannten Algorithmen zur Minimierung der mittleren Bearbeitungszeit erweitern und verallgemeinern. Neben der Präsentation und Analyse neuer Algorithmen wird gezeigt, dass das allgemeinste Mean-Finishing-Time-Problem für unabhängige Aufgaben polynomial vollständig ist und daher wahrscheinlich keine nicht-enumerative Lösung zulässt"}
{"DOCID": "2628", "TEXT": "Trommel- und Datenträger-Scheduling-Disziplinen mit minimaler Gesamtverarbeitungszeit: Dieser Artikel untersucht die Anwendung von Minimal-Total-Processing-Time (MTPT)-Scheduling-Disziplinen auf rotierende Speichereinheiten, wenn zufällige Anfragen zulässig sind. Es werden Fixed-Head-Trommel- und Moving-Head-Trommel- und Moving-Head-Plattenspeichereinheiten betrachtet, und die Betonung wird auf die relativen Vorzüge der MTPT-Scheduling-Disziplin in Bezug auf die Shortest-Latency-Time-First (SLTF)-Scheduling-Disziplin gelegt. Die Ergebnisse der vorgestellten Simulationsstudien zeigen, dass keine Planungsdisziplin der anderen bedingungslos überlegen ist. Für die meisten Trommelanwendungen mit festem Kopf ist die SLTF-Disziplin MTPT vorzuziehen, aber für die zylinderinterne Plattenplanung bietet die MTPT-Disziplin einen deutlichen Vorteil gegenüber der SLTF-Disziplin. Es wird gezeigt, dass die Rechenanforderungen eines Algorithmus, der die MTPT-Scheduling-Disziplin implementiert, mit SLTF-Algorithmen vergleichbar sind. In beiden Fällen ist der Sortiervorgang die zeitaufwändigste Phase des Algorithmus."}
{"DOCID": "2629", "TEXT": "Das UNIX-Time-Sharing-System: UNIX ist ein universelles, interaktives Mehrbenutzer-Betriebssystem für die PDP-11/40- und 11/45-Computer der Digital Equipment Corporation. Es bietet eine Reihe von Funktionen, die selbst in größeren Betriebssystemen selten zu finden sind, darunter: (1) ein hierarchisches Dateisystem mit auswechselbaren Datenträgern; (2) kompatible Datei-, Geräte- und Interprozess-E/A; (3) die Fähigkeit, asynchrone Prozesse zu initiieren; (4) Systembefehlssprache, die auf einer Benutzerbasis wählbar ist; und (5) über 100 Subsysteme, darunter ein Dutzend Sprachen. Dieses Dokument diskutiert die Art und Implementierung des Dateisystems und der Benutzerbefehlsschnittstelle."}
{"DOCID": "2630", "TEXT": "Zur Berechnung von Sätzen kürzester Pfade in einem Graphen: Es werden zwei Algorithmen vorgestellt, die die k kürzesten Pfade zwischen jedem Knotenpaar in einem gerichteten Graphen konstruieren. Diese Algorithmen verallgemeinern den Floyd-Algorithmus und den Dantzig-Algorithmus, um den kürzesten Pfad zwischen jedem Paar von Scheitelpunkten in einem gerichteten Graphen zu finden."}
{"DOCID": "2631", "TEXT": "An Information-Theoretic Approach to Text Searching in Direct Access Systems: Unter Verwendung von Computerdateien mit direktem Zugriff auf bibliografische Informationen wird versucht, eines der Probleme zu überwinden, die häufig mit der Informationsbeschaffung verbunden sind, nämlich die Pflege und Verwendung großer Wörterbücher ein Teil davon nur selten genutzt wird. Es wird ein neuartiges Verfahren vorgestellt, das die hyperbolische Häufigkeitsverteilung abbildet. Dies ist besser geeignet für die Implementierung auf Speichergeräten. Dieses Verfahren behandelt Text als Zeichenkette und nicht als durch Leerzeichen begrenzte Wörter und wählt Teilmengen von Zeichenketten so aus, dass ihre Häufigkeit des Auftretens gleichmäßiger ist als die der Wortarten. Die Mitglieder dieser Teilmenge werden dann als Indexschlüssel zum Abrufen verwendet. Die rechteckige Verteilung der Tastenfrequenzen führt zu einer stark vereinfachten Dateiorganisation und verspricht erhebliche Kostenvorteile."}
{"DOCID": "2632", "TEXT": "HYDRA: Der Kernel eines Multiprozessor-Betriebssystems: Dieses Dokument beschreibt die Designphilosophie von HYDRA – dem Kernel eines Betriebssystems für C.mmp, den Carnegie-Mellon Multi-Mini-Prozessor. Diese Philosophie wird durch die Einführung eines verallgemeinerten Begriffs von \"Ressourcen\", sowohl physisch als auch virtuell, der als \"Objekt\" bezeichnet wird, verwirklicht. Es werden Mechanismen für den Umgang mit Objekten vorgestellt, einschließlich der Erstellung neuer Typen, der Spezifikation neuer Operationen, die auf einen bestimmten Typ anwendbar sind, der gemeinsamen Nutzung und des Schutzes jeder Referenz auf ein bestimmtes Objekt vor einer unsachgemäßen Anwendung einer der in Bezug auf diesen Typ definierten Operationen des Objekts. Die Mechanismen bieten eine kohärente Grundlage für die Erweiterung des Systems in zwei Richtungen: die Einführung neuer Einrichtungen und die Schaffung hochsicherer Systeme."}
{"DOCID": "2633", "TEXT": "Kompakte Darstellung von Konturdiagrammen für Telefonleitungsübertragung: Verfahren zur kompakten Darstellung von Konturdiagrammen werden beschrieben und getestet. Diese sollen die Kosten für die Übertragung von Konturdiagrammen über Telefonleitungen reduzieren. Wir glauben, dass einige dieser Methoden verwendet werden könnten, um Konturdiagramme über Telefonleitungen mit Sprachqualität zu übertragen."}
{"DOCID": "2634", "TEXT": "Eine Bewertung von Statistiksoftware in den Sozialwissenschaften: Mehrere hundert Computerinstallationen an Hochschulen und Universitäten bieten jetzt verschiedene Arten von Statistikpaketen für den allgemeinen Gebrauch an. Zu den am weitesten verbreiteten gehören OSIRIS, SPSS, BMD, DATA-TEXT und TSAR. Um den Anwendern eine Auswahl- und Einsatzgrundlage zu bieten, wurden für jedes dieser Systeme Tests durchgeführt und die Ergebnisse hinsichtlich Kosten und Leistung zusammengefasst."}
{"DOCID": "2635", "TEXT": "Exakte Wahrscheinlichkeiten für R X C-Kontingenztabellen (Algorithmus R434)"}
{"DOCID": "2636", "TEXT": "Generierung zufälliger korrelierter Normalvariablen (Algorithmus R425)"}
{"DOCID": "2637", "TEXT": "Programm zum Zeichnen verdeckter Linien (Algorithmus R420)"}
{"DOCID": "2638", "TEXT": "Programm zum Zeichnen verdeckter Linien (Algorithmus R420)"}
{"DOCID": "2639", "TEXT": "Berechnung von Fourier-Integralen (Algorithmus R418)"}
{"DOCID": "2640", "TEXT": "Modifizierte Havie-Integration (Algorithmus R400)"}
{"DOCID": "2641", "TEXT": "Ein minimales Spanning-Tree-Clustering-Verfahren [Z] (Algorithmus A479)"}
{"DOCID": "2642", "TEXT": "Lösung eines überbestimmten Gleichungssystems in der L1-Norm [F4] (Algorithmus A478)"}
{"DOCID": "2643", "TEXT": "The Minimization of Spatially-Multiplexed Character Sets: Das Papier beschreibt eine Technik zur Komprimierung von Zeichensätzen in einem digitalen Computer, während ein schneller Zugriff auf einzelne Bits beibehalten wird. Es betrachtet das Problem der Minimierung des Speicherplatzes, der zum Enthalten solcher Tabellen benötigt wird. Reduktionstechniken werden entwickelt, und es wird gezeigt, dass sich das Problem auf ein Überdeckungsproblem reduziert."}
{"DOCID": "2644", "TEXT": "Eine Theorem-Beweissprache zum Experimentieren: Aufgrund der großen Anzahl von Strategien und Inferenzregeln, die derzeit beim automatisierten Theorem-Beweisen in Betracht gezogen werden, besteht ein Bedarf an der Entwicklung einer Sprache, die speziell auf das automatisierte Theorem-Beweisen ausgerichtet ist. In diesem Dokument werden einige der Funktionen und Anweisungen dieser Sprache behandelt. Die Verwendung dieser Sprache ermöglicht eine einfache Erweiterung automatisierter Theorem-Beweisprogramme, um neue Strategien und/oder neue Inferenzregeln einzubeziehen. Eine solche Erweiterungsfähigkeit wird ein allgemeines Experimentieren mit den verschiedenen alternativen Systemen ermöglichen."}
{"DOCID": "2645", "TEXT": "Zwei Sprachen zur Schätzung der Programmeffizienz: Es werden zwei Sprachen vorgestellt, die es ihren Benutzern ermöglichen, die Effizienz von Computerprogrammen einzuschätzen. Das Programm, dessen Effizienz man einschätzen möchte, ist in der ersten Sprache geschrieben, einer Go-to-less-Programmiersprache, die die meisten Funktionen von Algol 60 enthält. Die zweite Sprache besteht aus interaktiven Befehlen, die es den Benutzern ermöglichen, zusätzliche Informationen über das Programm bereitzustellen in der Erstsprache geschrieben und Ergebnisse ausgeben, die ihre Effizienz einschätzen. Prozessoren für die beiden Sprachen werden ebenfalls beschrieben. Der erste Prozessor ist ein syntaxgesteuerter Übersetzer, der ein Programm in eine symbolische Formel kompiliert, die die Ausführungszeit für dieses Programm darstellt. Der Soundprozessor ist eine Reihe von Prozeduren für dieses Programm. Der zweite Prozessor ist ein Satz von Prozeduren zur algebraischen Manipulation, die vom Benutzer aufgerufen werden können, um die vom ersten Prozessor erzeugte Formel zu bearbeiten. Beispiele für die Verwendung der beiden Sprachen sind enthalten. Die Grenzen des gegenwärtigen Systems, seine Beziehung zu Knuths Arbeit über die Analyse von Algorithmen und einige der Richtungen für weitere Forschung werden ebenfalls diskutiert."}
{"DOCID": "2646", "TEXT": "A Model for Masking Rotational Latency by Dynamic Disk Allocation: Dieses Whitepaper stellt den Hintergrund und die Algorithmen zum Maskieren der Rotationslatenz einer Platte oder Trommel vor. Es diskutiert die vorausschauende Eingabe und Ausgabe von Datenblöcken in Puffer- und Primärspeicher für ein monoprogrammiertes Computersystem. Ein grundlegender Permutationsalgorithmus und mehrere Variationen werden angegeben. Aufgrund der vorausschauenden Natur der E/A-Planung sind diese Algorithmen auf Klassen von Programmen mit vorhersagbarem Verhalten beschränkt. Während die Verfahren nicht auf numerische Berechnungen beschränkt sind, sind Matrix- und partielle Differentialgleichungsverfahren typische Beispiele für ihre Verwendung. Es wird gezeigt, dass die Latenz unter Verwendung einer kleinen Menge an Pufferspeicher maskiert werden kann. Die diskutierten Verfahren sind unabhängig von der Gesamtgröße der betrachteten Datenbank."}
{"DOCID": "2647", "TEXT": "Mehr zu Algorithmen, die Eigenschaften von Gleitkomma-Arithmetikeinheiten offenbaren"}
{"DOCID": "2648", "TEXT": "Ein Design für ein Zahlentheorie-Paket mit einer optimierten Trial-Division-Routine: Es wird ein Zahlentheorie-Paket beschrieben, das doppelt verknüpfte Listenstrukturen zum Speichern von multipräzisen ganzen Zahlen verwendet. Das Paket wurde in IBMs Basic Assembly Language kodiert und macht intensiven Gebrauch von der Makrosprache und der bedingten Assemblierung. Außerdem wird eine optimal codierte Versuchsdivisionsroutine beschrieben, die verwendet werden kann, um die eindeutige Faktorisierung großer ganzer Zahlen zu bestimmen."}
{"DOCID": "2649", "TEXT": "Zu den Verteilungen signifikanter Stellen und Rundungsfehler: Für die Verteilung der ersten t signifikanten Stellen einer zufälligen digitalen Ganzzahl wird ein verallgemeinertes logarithmisches Gesetz abgeleitet. Dieses Ergebnis wird dann verwendet, um die Verteilung der Rundungsfehler bei Gleitkommaoperationen zu bestimmen, die eine Mischung aus gleichmäßigen und reziproken Verteilungen ist."}
{"DOCID": "2650", "TEXT": "Order-n-Korrektur für reguläre Sprachen: Es wird ein Verfahren zum Berechnen einer Zeichenkette B vorgestellt, die zu einer gegebenen regulären Sprache L gehört und die (in der Anzahl von Editieroperationen) einer gegebenen Eingabezeichenkette a \"am nächsten\" ist. B wird als vernünftige \"Korrektur\" für die möglicherweise fehlerhafte Zeichenfolge a angesehen, wobei a ursprünglich als Zeichenfolge von L gedacht war. Die Berechnung von B durch das vorgestellte Verfahren erfordert Zeit, die proportional zu |a|, der Anzahl der Zeichen in a, ist . Das Verfahren sollte Anwendungen in Informationswiedergewinnung, künstlicher Intelligenz und Rechtschreibkorrektursystemen finden."}
{"DOCID": "2651", "TEXT": "Die Behandlung von Datentypen in EL1: Beim Aufbau einer Allzweck-Programmiersprache besteht ein Schlüsselproblem darin, einen ausreichenden Satz von Datentypen und zugehörigen Operationen in einer Weise bereitzustellen, die sowohl eine natürliche problemorientierte Notation als auch eine effiziente Implementierung ermöglicht. Die EL1-Sprache enthält eine Reihe von Merkmalen, die speziell darauf ausgelegt sind, beide Anforderungen gleichzeitig zu erfüllen. Die daraus resultierende Behandlung von Datentypen umfasst die Bereitstellung von programmiererdefinierten Datentypen, Datentypen und generischen Routinen, die Programmiersteuerung über die Typumwandlung und ein sehr flexibles Datentypverhalten in einem Kontext, der einen effizienten kompilierten Code und eine kompakte Datendarstellung ermöglicht."}
{"DOCID": "2652", "TEXT": "Reduzierung der Kompilierungskosten durch Sprachkontraktion: Programmiersprachen, die auf bestimmte Benutzergruppen zugeschnitten sind, können oft konstruiert werden, indem unerwünschte Merkmale aus einer Allzwecksprache entfernt werden. Dieses Papier beschreibt die Verwendung von Simulationstechniken, um die durch einen solchen Ansatz erreichbaren Einsparungen bei den Kompilierungskosten vorherzusagen. Die Ergebnisse legen eine Funktion nahe, die den Effekt von Änderungen in der Macht einer Sprache auf die Kompilierungskosten eines in dieser Sprache ausgedrückten Algorithmus beschreibt: Wenn Merkmale, die nicht wirklich vom Algorithmus verwendet werden, aus der Sprache entfernt werden, sinken die Kosten für die Kompilierung des Algorithmus moderat, aber wenn benötigte Funktionen entfernt werden, steigen die Kompilierungskosten stark an."}
{"DOCID": "2653", "TEXT": "Lösung der transzendenten Gleichung w*exp(x)=x (Algorithmus R443)"}
{"DOCID": "2654", "TEXT": "Generator von Mengenpartitionen zu genau R-Teilmengen [G7] (Algorithmus A477)"}
{"DOCID": "2655", "TEXT": "Sechs Unterprogramme zur Kurvenanpassung unter Verwendung von Splines unter Spannung [E2] (Algorithmus A476)"}
{"DOCID": "2656", "TEXT": "Skalar- und planarwertige Kurvenanpassung unter Verwendung von Splines unter Spannung: Die Spline unter Spannung wurde von Schweikert in einem Versuch eingeführt, kubische Splines zu imitieren, aber die störenden kritischen Punkte zu vermeiden, die sie hervorrufen. Die Definitionsgleichungen werden hier zusammen mit einer effizienten Methode zur Bestimmung der erforderlichen Parameter und zur Berechnung des resultierenden Splines vorgestellt. Das standardmäßige skalarwertige Kurvenanpassungsproblem wird diskutiert, ebenso wie die Anpassung offener und geschlossener Kurven in der Ebene. Als Anwendung wird die Verwendung dieser Kurven und die Bedeutung der Spannung beim Einpassen von Höhenlinien genannt."}
{"DOCID": "2657", "TEXT": "Ein verbesserter Programm-Synthesizer-Algorithmus und seine Korrektheit: Ein verbesserter Programm-Synthesizer-Algorithmus, der auf dem 1969 von Waldinger und Lee vorgeschlagenen Algorithmus basiert, wird angegeben. Bei dem alten Algorithmus wird das Programmsyntheseproblem in ein Theorembeweisproblem übersetzt, und ein Programm wird durch Analysieren eines Beweises erhalten. Für den verbesserten Algorithmus ist die Analyse nicht erforderlich, und ein Programm wird erhalten, sobald der Beweis abgeschlossen ist. Dies wird durch die Verwendung eines modifizierten Variablen-Tracing-Mechanismus erreicht, der 1969 von Green erfunden wurde. Die Korrektheit des verbesserten Algorithmus wird auch bewiesen; d.h. das so erhaltene Programm erfüllt immer die Spezifikation."}
{"DOCID": "2658", "TEXT": "Ein alternativer Ansatz zur gegenseitigen Rekursion in Algol 60 mit eingeschränkten Compilern"}
{"DOCID": "2659", "TEXT": "Einige Bemerkungen zur Suche nach strukturierten Variablen"}
{"DOCID": "2660", "TEXT": "Nachtrag zu M. L. Patrick Paper"}
{"DOCID": "2661", "TEXT": "Ideale Lehrmaschinen – Eine Lösung für das Problem der pädagogischen Sprache"}
{"DOCID": "2662", "TEXT": "Graduiertenausbildung: Der Ph.D. Glut: Antwort und Widerlegung"}
{"DOCID": "2663", "TEXT": "Eine Studie zur Computernutzung an einer Graduate School of Business"}
{"DOCID": "2664", "TEXT": "Parallelität beim Bandsortieren: Zwei Verfahren zum Anwenden von Parallelität beim Bandsortieren werden vorgestellt. Methode A ist die natürliche Art, Parallelität zu verwenden. Methode B ist neu. Beide erreichen ungefähr das Ziel, die Verarbeitungszeit um einen Teiler zu reduzieren, der die Anzahl der Prozessoren ist."}
{"DOCID": "2665", "TEXT": "Kopieren von Listenstrukturen unter Verwendung eines begrenzten Arbeitsbereichs: Es werden zwei neue Algorithmen zum Kopieren von Listenstrukturen unter Verwendung eines begrenzten Arbeitsbereichs vorgestellt. Die erste, hauptsächlich von theoretischem Interesse, zeigt, dass die Aufgabe ohne Zellenmarkierungsbits in der Zeit n^2 durchgeführt werden kann. Der zweite Algorithmus liefert unter der Annahme eines Tag-Bits in jeder Zelle eine attraktive praktische Geschwindigkeit. Jede nicht zyklische Struktur wird mit linearer Geschwindigkeit kopiert, während zyklische Strukturen in einer durchschnittlichen Zeit von weniger als nlogn kopiert werden. Um eine lineare Geschwindigkeit zu erreichen, ist kein Vorwissen über das Fehlen von Zyklen erforderlich. Eine Variation des zweiten Algorithmus löst ein offenes Problem bezüglich der Markierung von Listenstrukturen. Dieses Ergebnis zeigt, dass das Markieren in der durchschnittlichen Zeit nlogn ohne die Hilfe von zusätzlichen Tag-Bits oder -Stapeln durchgeführt werden kann."}
{"DOCID": "2666", "TEXT": "On Lions' Counter Beispiel für Gotliebs Methode zur Konstruktion von Schulstundenplänen: Das Stundenplanproblem ist ein im Wesentlichen diskretes Problem. Obwohl das diskrete Problem möglicherweise keine zulässige Lösung hat, kann es eine Lösung für das äquivalente kontinuierliche Problem geben. Es wird ein Beispiel gegeben, für das die nichtdiskrete Lösung als eine Menge von Wochenplänen interpretiert werden kann, die sich von Woche zu Woche unterscheiden und zusammen die langfristigen Anforderungen des Fahrplanproblems erfüllen."}
{"DOCID": "2667", "TEXT": "Ausführungsmerkmale von Programmen in einem Page-on-Demand-System: Es werden Daten präsentiert, die die Ausführungsmerkmale von zwei Arten von häufig verwendeten Programmen in einem großen, zeitgeteilten Computersystem zeigen. Eine in den Supervisor eingebaute Software-Überwachungseinrichtung wurde für die Datenerfassung während des normalen Systembetriebs verwendet. Diese Daten wurden analysiert, und die Ergebnisse dieser Analyse werden für einen Fortran-Compiler und einen interaktiven Line-File-Editor präsentiert. Wahrscheinlichkeitsverteilungsfunktionen und andere Daten werden für Dinge wie CPU-Intervalle, E/A-Intervalle und die Anzahl solcher Intervalle während der Ausführung angegeben. Empirische Verteilungen werden mit einfachen theoretischen Verteilungen (exponentiell, hyperexponentiell und geometrisch) verglichen. Andere Daten zeigen Paging-Eigenschaften von Aufgaben als Funktion der Anzahl von Seiten, die diese Aufgaben im Kern haben."}
{"DOCID": "2668", "TEXT": "Berechnung der Seitenfehlerwahrscheinlichkeit aus dem Programmübergangsdiagramm: Es wird ein Algorithmus zum Berechnen der Seitenfehlerwahrscheinlichkeit in einem virtuellen Speichersystem angegeben, das unter Bedarfs-Paging mit verschiedenen Speichergrößen und Ersetzungsregeln arbeitet. Es wird ein Markov-Modell erster Ordnung des Programmverhaltens angenommen und eine Darstellung des Systems basierend auf Speicherzuständen, Steuerzuständen und Speicherunterzuständen präsentiert. Der Algorithmus ist allgemein in dem Sinne, dass die Seitenfehlerwahrscheinlichkeiten für nicht vorhersagende Ersetzungsregeln berechnet werden können, die auf jedes Programm angewendet werden, das durch eine einstufige Markov-Kette dargestellt wird. Ein detailliertes Beispiel wird gegeben, um den Algorithmus für Ersetzungsregeln für zufällige und am wenigsten verwendete (LRU) zu veranschaulichen."}
{"DOCID": "2669", "TEXT": "Ein einfaches lineares Modell der Demand-Paging-Leistung: Das Vorhersagen der Leistung eines vorgeschlagenen automatisch verwalteten Mehrebenen-Speichersystems erfordert ein Modell der Muster, durch die Programme auf die im Speicher gespeicherten Informationen verweisen. Einige neuere experimentelle Messungen am virtuellen Speicher von Multics legen nahe, dass für grobe Annäherungen ein bemerkenswert einfaches Programmreferenzmodell ausreichen wird. Das einfache Modell kombiniert die Wirkung des Informationsreferenzmusters mit der Wirkung des automatischen Verwaltungsalgorithmus, um eine einzige zusammengesetzte Aussage zu erzeugen: Die mittlere Anzahl von Speicherreferenzen zwischen Paging-Ausnahmen steigt linear mit der Größe des Paging-Speichers. Das resultierende Modell ist einfach zu manipulieren und auf so unterschiedliche Probleme anwendbar, wie das Auswählen einer optimalen Größe für einen Paging-Speicher, das Arrangieren reproduzierbarer Speichernutzungsgebühren und das Abschätzen der Menge an gemeinsam genutztem Kernspeicher."}
{"DOCID": "2670", "TEXT": "Effiziente Implementierung eines Variablenprojektionsalgorithmus für nichtlineare Kleinste-Quadrate-Probleme: Häufig treten nichtlineare Kleinste-Quadrate-Probleme auf, bei denen die aufzulösenden Variablen in einen linearen und einen nichtlinearen Anteil zerlegt werden können. Kürzlich wurde ein Variablenprojektionsalgorithmus entwickelt, der die Struktur eines Problems ausnutzen soll, dessen Variablen sich auf diese Weise trennen. Dieses Papier gibt eine etwas effizientere und etwas allgemeinere Version dieses Algorithmus als zuvor erschienen."}
{"DOCID": "2671", "TEXT": "Eine Anmerkung zu einem kombinatorischen Problem von Burnett und Coffman"}
{"DOCID": "2672", "TEXT": "Emotionaler Inhalt gilt als gefährlich"}
{"DOCID": "2673", "TEXT": "Quadratische Suche nach Hash-Tabellen der Größe p^n"}
{"DOCID": "2674", "TEXT": "Abtastumwandlungsalgorithmen für eine zellorganisierte Rasteranzeige: Rasterabtast-Computergraphiken mit \"Echtzeit\"-Zeichengeneratoren waren bisher auf alphanumerische Zeichen beschränkt. Es wurde eine Anzeige beschrieben, die die Fähigkeiten dieser Organisation erweitert, um allgemeine Graphiken einzuschließen. Es werden zwei grundlegend unterschiedliche Abtastumwandlungsalgorithmen vorgestellt, die entwickelt wurden, um diese Anzeige zu unterstützen. Einer eignet sich am besten für nicht interaktive Anwendungen und der andere für interaktive Anwendungen. Die Algorithmen wurden in Fortran auf dem Computer CDC 6400 implementiert. Aus den Implementierungen erhaltene Ergebnisse zeigen, dass die nicht interaktiven Algorithmen die Speicheranforderungen für Anzeigedateien bei geringen Kosten in der Ausführungszeit gegenüber denen einer herkömmlichen Rasteranzeige erheblich reduzieren können. Der interaktive Algorithmus kann die Antwortzeit verbessern und die Speicheranforderungen reduzieren."}
{"DOCID": "2675", "TEXT": "Eine Computerroutine für quadratische und lineare Programmierprobleme (Algorithmus R431)"}
{"DOCID": "2676", "TEXT": "Nullstellen eines komplexen Polynoms (Algorithmus R419)"}
{"DOCID": "2677", "TEXT": "Unvollständiges Beta-Verhältnis (Algorithmus R179)"}
{"DOCID": "2678", "TEXT": "Zeichenprogramm für sichtbare Oberflächen [J6] (Algorithmus A475)"}
{"DOCID": "2679", "TEXT": "Einige Leistungstests von \"quicksort\" und Descendants: Detaillierte Leistungsbewertungen werden für sechs ACM-Algorithmen präsentiert: Quicksort (Nr. 64), Shellsort (Nr. 201), Stringsort (Nr. 207), \"TREESORT3\" (Nr. 245), quickersort (Nr. 271) und qsort (Nr. 402). Die Algorithmen 271 und 402 sind Verfeinerungen des Algorithmus 64, und alle drei werden ausführlich diskutiert. Die hier gegebenen Beweise zeigen, dass qsort (Nr. 402) viel mehr Vergleiche erfordert, als der Autor behauptet. Von all diesen Algorithmen erfordert Quickersort die wenigsten Vergleiche, um zufällige Arrays zu sortieren."}
{"DOCID": "2680", "TEXT": "Optimale Speicherplatzzuweisung auf Plattenspeichergeräten: Wenn die Menge an Speicherplatz, die für die Dateispeicherung erforderlich ist, die Menge übersteigt, die online gehalten werden kann, müssen Entscheidungen getroffen werden, welche Dateien permanent resident und welche montierbar sind. Diese Entscheidungen wirken sich auf die Anzahl der Mount-Anforderungen aus, die an die Operatoren ausgegeben werden. Dies ist häufig ein Engpass in einer Rechenanlage, und die Verringerung der Anzahl der Halterungen verringert somit die Bearbeitungszeit. Es wird ein Optimierungsmodell für die Zuweisung von Dateien zu Plattenpaketen und Paketen mit entweder residentem oder nichtresidentem Status vorgestellt. Heuristiken werden für jene Fälle vorgeschlagen, in denen es ineffizient ist, das tatsächliche Optimum zu berechnen."}
{"DOCID": "2681", "TEXT": "Dynamisches Neupacken des Speichers: Ein probabilistisches Modell eines Multiprogramming-Systems wird angewandt, um die Bedingungen zu bestimmen, unter denen das dynamische Neupacken des Hauptspeichers vorteilhaft ist. Es wird ein Ausdruck für die maximale Interferenz abgeleitet, die ein Neuverpackungsprozess einführen kann, bevor die ursprüngliche Leistung des Systems verschlechtert wird. Alternative Ansätze zum Umpacken werden diskutiert, und die Betriebsbedingungen, die zu einem verbesserten Systemdurchsatz durch Umpacken führen, werden skizziert."}
{"DOCID": "2682", "TEXT": "Zur Konstruktion einer repräsentativen synthetischen Arbeitslast: Es wird ein allgemeines Verfahren zur Konstruktion einer Antriebsarbeitslast beschrieben, die repräsentativ für eine reale Arbeitslast ist. Die reale Auslastung ist durch ihre Anforderungen an die verschiedenen Systemressourcen gekennzeichnet. Diese Eigenschaften der tatsächlichen Arbeitsbelastung werden aus den Systemabrechnungsdaten erhalten. Die Eigenschaften der Fahrbelastung werden bestimmt, indem die gemeinsame Wahrscheinlichkeitsdichte der realen Belastung mit derjenigen der Fahrbelastung abgeglichen wird. Die Antriebsauslastung wird durch die Verwendung eines synthetischen Programms realisiert, in dem die Eigenschaften durch Variieren der entsprechenden Parameter variiert werden können. Kalibrierungsexperimente werden durchgeführt, um Ausdrücke zu bestimmen, die die synthetischen Programmparameter mit den Arbeitsbelastungseigenschaften in Beziehung setzen. Das allgemeine Verfahren wird auf den Fall von zwei Variablen, CPU-Sekunden und Anzahl der I/O-Aktivitäten, angewendet; und die synthetische Arbeitsbelastung mit 88 Arbeitsplätzen wird so konstruiert, dass sie die Arbeitsbelastung eines Monats darstellt, die aus etwa 6000 Arbeitsplätzen besteht."}
{"DOCID": "2683", "TEXT": "Die Synthese von Schleifenprädikaten: Gegenwärtige Verfahren zur mechanischen Programmverifikation erfordern eine vollständige Prädikatspezifikation für jede Schleife. Da dies mühsam und fehleranfällig ist, ist die Erzeugung eines Programms mit vollständigen, korrekten Prädikaten ziemlich schwierig und würde durch maschinelle Unterstützung erleichtert. Dieses Papier diskutiert Techniken zum mechanischen Synthetisieren von Schleifenprädikaten. Zwei Klassen von Techniken werden betrachtet: (1) heuristische Methoden, die Schleifenprädikate aus Randbedingungen und/oder teilweise spezifizierten induktiven Behauptungen ableiten; (2) Extraktionsmethoden, die Eingabeprädikate und geeignete schwache Interpretationen verwenden, um bestimmte Klassen von Schleifenprädikaten durch eine Auswertung zu erhalten auf die schwache Interpretation."}
{"DOCID": "2684", "TEXT": "Produktionssysteme: oder können wir es besser als BNF?: Seit der Entwicklung von BNF wird die Definition der Syntax von Programmiersprachen fast überall mit kontextfreien Anforderungen in Verbindung gebracht. Dennoch ergeben sich zahlreiche interessante und schwierige Probleme in der Syntax aus den kontextsensitiven Anforderungen, insbesondere die Kompatibilität zwischen der Deklaration eines Bezeichners und seiner Verwendung, die Übereinstimmung zwischen tatsächlichen und formalen Parametern und Probleme, die sich aus der Blockstruktur ergeben. Dieses Papier untersucht die Verwendung einer formalen Notation namens Produktionssysteme, um eine lesbare und vollständige formale Definition der Syntax bereitzustellen. Zur praktischen Veranschaulichung wird eine kleine, aber bedeutende Teilmenge von PL/I betrachtet. Eine ausführlichere Darstellung sowie die Anwendung zur Definition abstrakter Syntax und Übersetzungen zwischen Sprachen findet sich in einem früheren Artikel des Autors."}
{"DOCID": "2685", "TEXT": "Die parallele Ausführung von DO-Schleifen: Es werden Verfahren zur parallelen Ausführung verschiedener Iterationen einer DO-Schleife entwickelt. Betrachtet werden sowohl asynchrone Mehrprozessorrechner als auch Array-Rechner. Die praktische Anwendung auf das Design von Compilern für solche Computer wird diskutiert."}
{"DOCID": "2686", "TEXT": "Eine ungefähre Methode zum Generieren von asymmetrischen Zufallsvariablen: Tukeys Lambda-Verteilung wird verallgemeinert, um einen Algorithmus zum Generieren von Werten von unimodalen asymmetrischen Zufallsvariablen bereitzustellen. Dieser Algorithmus hat die gleichen Vorteile wie der zuvor von den Autoren angegebene symmetrische Zufallsvariablengenerator, außer dass das Hinzufügen eines weiteren Parameters das Problem verkompliziert, die Parameterwerte zu finden, die zu einer Verteilung passen."}
{"DOCID": "2687", "TEXT": "Eine zellorganisierte Rasteranzeige für Strichzeichnungen: Rasterscan-Computergraphikanzeigen mit \"Echtzeit\"-Zeichengeneratoren waren bisher auf alphanumerische Zeichen beschränkt. Es wird eine Anzeige beschrieben, die die Fähigkeiten dieser Organisation erweitert, um allgemeine Graphiken einzuschließen. Die Machbarkeit einer solchen Anzeige wird gezeigt, indem die minimale Anzahl von Mustern abgeleitet wird, die in dem Nur-Lese-Speicher des Zeichengenerators erforderlich sind, um eine beliebige Zeile zu synthetisieren. Der Syntheseprozess beeinträchtigt die Bildqualität nicht, da die resultierenden Punktmuster mit denen einer herkömmlichen Rasteranzeige identisch sind. Darüber hinaus wird gezeigt, dass die Zeitbeschränkungen einer Rasteranzeige für ein typisches Design für sehr komplexe Strichzeichnungen erfüllt sind."}
{"DOCID": "2688", "TEXT": "Attributbasierte Dateiorganisation in einer ausgelagerten Speicherumgebung: Die hohen Kosten des Seitenzugriffs implizieren eine Notwendigkeit für eine sorgfältigere Datenorganisation in einem ausgelagerten Speicher, als dies für die meisten invertierten Dateien und ähnliche Ansätze zum Abrufen mit mehreren Schlüsseln typisch ist. Dieser Artikel analysiert diese Kosten und schlägt eine Methode namens Multiple Key Hashing vor, die versucht, sie zu minimieren. Da dieser Ansatz der Inversion nicht immer vorzuziehen ist, wird ein kombiniertes Verfahren beschrieben. Die genaue Spezifikation dieser Kombination für eine Datei mit gegebenen Daten und Verkehrseigenschaften wird als mathematisches Programm formuliert. Die vorgeschlagene heuristische Lösung für dieses Programm kann eine einfache Inversionstechnik oft um den Faktor 2 oder 3 verbessern."}
{"DOCID": "2689", "TEXT": "Ein CRT-Berichterstellungssystem"}
{"DOCID": "2690", "TEXT": "Ein Nummernsystem für Kombinationen"}
{"DOCID": "2691", "TEXT": "Kommentare zu den Algorithmen von Verhelst für die Umwandlung von Entscheidungstabellen mit begrenztem Eintrag in Flussdiagramme"}
{"DOCID": "2692", "TEXT": "Reentrant Polygon Clipping: Eine neue Familie von Clipping-Algorithmen wird beschrieben. Diese Algorithmen sind in der Lage, Polygone in drei Dimensionen gegen unregelmäßige konvexe Volumen mit ebener Oberfläche zu schneiden, wobei die Teile des Polygons entfernt werden, die außerhalb des Volumens liegen. In zwei Dimensionen erlauben die Algorithmen das Abschneiden gegen unregelmäßige konvexe Fenster. Zu beschneidende Polygone werden als eine geordnete Folge von Eckpunkten ohne Wiederholung des ersten und letzten dargestellt, im deutlichen Gegensatz zur Darstellung als eine Ansammlung von Kanten, wie es bisher das übliche Verfahren war. Ausgabepolygone haben ein identisches Format, wobei neue Scheitelpunkte nacheinander eingeführt werden, um alle neu geschnittenen Kanten oder Kanten zu beschreiben. Die Algorithmen handhaben leicht das besonders schwierige Problem des Erfassens, dass ein neuer Scheitelpunkt an einer Ecke des Abschneidefensters erforderlich sein kann. Die beschriebenen Algorithmen erreichen eine beträchtliche Einfachheit, indem sie getrennt gegen jede Schnittebene oder Fenstergrenze abgeschnitten werden. Code, der in der Lage ist, das Polygon gegen eine einzelne Grenze zu schneiden, wird erneut eingegeben, um gegen nachfolgende Grenzen zu schneiden. Jede solche Wiedereintrittsstufe des Abschneidens braucht nur zwei Scheitelwerte zu speichern und kann mit ihrer Verarbeitung beginnen, sobald die erste Ausgabescheitel von der vorangehenden Stufe fertig ist. Da derselbe Code zum Abschneiden an nachfolgenden Begrenzungen erneut eingegeben wird, ist das Abschneiden an sehr komplexen Fensterformen praktisch. Für perspektivische Anwendungen in drei Dimensionen wird als Ausschnittsvolumen ein Pyramidenstumpf mit sechs Ebenen gewählt. Die beiden zusätzlichen Ebenen parallel zum Projektionsschirm dienen dazu, den durch die Projektion erhaltenen Tiefenbereich zu begrenzen. Es wird ein perspektivisches Projektionsverfahren beschrieben, das trotz einfacher fester Schnittebenen beliebige Blickwinkel und Schärfentiefe ermöglicht. Diese Methode ist ideal für nachfolgende verdeckte Oberflächenberechnungen."}
{"DOCID": "2693", "TEXT": "Bivariate Interpolation und glatte Oberflächenanpassung basierend auf lokalen Prozeduren [E2] (Algorithmus A474)"}
{"DOCID": "2694", "TEXT": "Berechnung der Koeffizienten der Legendre-Reihe [C6] (Algorithmus A473)"}
{"DOCID": "2695", "TEXT": "Tridiagonalisierung durch Permutationen: Die Tridiagonalisierung einer Matrix durch Ähnlichkeitstransformationen ist ein wichtiges Rechenwerkzeug in der numerischen linearen Algebra. Betrachten Sie die Klasse von Matrizen mit geringer Dichte, die tridiagonalisiert werden können, indem nur Zeilen- und entsprechende Spaltenpermutationen verwendet werden. Zu den Vorteilen der Verwendung einer solchen Transformation gehören das Fehlen von Rundungsfehlern und eine verbesserte Rechenzeit im Vergleich zu Standardtransformationen. Es wird ein graphentheoretischer Algorithmus angegeben, der eine beliebige n x n-Matrix untersucht und bestimmt, ob sie in tridiagonale Form permutiert werden kann oder nicht. Der Algorithmus erfordert keine Arithmetik, während die Anzahl der Vergleiche, die Anzahl der Zuweisungen und die Anzahl der Inkremente in n linear sind. Dies schneidet im Vergleich zu Standardtransformationsmethoden sehr gut ab. Wenn die Matrix in eine tridiagonale Form permutierbar ist, gibt der Algorithmus die explizite tridiagonale Form an. Andernfalls kommt es zu einer vorzeitigen Ablehnung."}
{"DOCID": "2696", "TEXT": "Ein Verfahren zur bivariaten Interpolation und glatten Oberflächenanpassung basierend auf lokalen Prozeduren: Ein Verfahren ist entworfen zum Interpolieren von Werten, die an Punkten eines rechteckigen Gitters in einer Ebene gegeben sind, durch eine glatte bivariate Funktion z = z(x, Y). Die Interpolationsfunktion ist ein bikubisches Polynom in jeder Zelle des rechteckigen Gitters. Der Schwerpunkt liegt auf der Vermeidung einer übermäßigen Welligkeit zwischen gegebenen Gitterpunkten. Das vorgeschlagene Verfahren ist eine Erweiterung des zuvor vom Autor entwickelten Verfahrens der univariaten Interpolation und basiert ebenfalls auf lokalen Verfahren."}
{"DOCID": "2697", "TEXT": "Ein schnelles Verfahren zum Lösen einer Klasse tridiagonaler linearer Systeme: Es wird die Lösung linearer Systeme mit reellen, symmetrischen, diagonaldominanten, tridiagonalen Koeffizientenmatrizen mit konstanten Diagonalen betrachtet. Es ist bewiesen, dass die Diagonalen der LU-Zerlegung bei Gleitkommagenauigkeit konvergieren. Es ist auch bewiesen, dass die berechnete LU-Zerlegung konvergiert, wenn Gleitkomma-Arithmetik verwendet wird, und dass die Grenzen der LU-Diagonalen unter Verwendung von Gleitkomma ungefähr innerhalb der Maschinengenauigkeit der Grenzen liegen, die reelle Arithmetik verwenden. Diese Tatsache wird ausgenutzt, um die Anzahl der Gleitkommaoperationen zu reduzieren, die erforderlich sind, um ein lineares System von 8n-7 auf 5n+2k-3 zu lösen, wobei k viel kleiner als n ist, die Ordnung der Matrix. Wenn die Elemente der Nebendiagonalen und Superdiagonalen 1 sind, dann werden nur 4n+2k-3 Operationen benötigt. Die gesamte LU-Zerlegung benötigt k Speicherworte, und es werden beträchtliche Einsparungen bei der Array-Subskription erreicht. Obere und untere Grenzen von k werden in Form des Verhältnisses der Diagonalkonstanten der Koeffizientenmatrix und der Parameter des Gleitkommazahlensystems erhalten. Verschiedene Verallgemeinerungen dieser Ergebnisse werden diskutiert."}
{"DOCID": "2698", "TEXT": "Syntaxgesteuerte Kleinste-Fehler-Analyse für kontextfreie Sprachen: Ein praktischer Ansatz: Ein Kleinste-Fehler-Erkenner wird informell unter Verwendung des wohlbekannten Erkenners von Earley zusammen mit Elementen der dynamischen Programmierung von Bellman entwickelt. Der Analysator nimmt eine allgemeine Klasse von kontextfreien Grammatiken als Treiber und jede endliche Zeichenkette als Eingabe. Die Erkennung besteht aus einer Zählung der kleinsten Fehler für eine korrigierte Version der Eingabe relativ zur Treibergrammatik. Das Algorithmusdesign betont praktische Aspekte, die bei der Programmierung helfen."}
{"DOCID": "2699", "TEXT": "Automatische Datenstrukturwahl in einer Sprache auf sehr hohem Niveau: SETL ist eine mengentheoretisch orientierte Sprache auf sehr hohem Niveau, deren Repertoire an semantischen Objekten endliche Mengen, geordnete n-Tupel und Mengen geordneter n-Tupel umfasst, die als Abbildungen verwendbar sind. Dieses Papier beschreibt die Struktur eines Optimierers für diese Sprache. Neben anderen interessanten Methoden verwendet der Optimierer Techniken, die es ermöglichen, Beziehungen von Inklusion und Zugehörigkeit herzustellen, die Domänen und Bereiche von (tabellierten) Abbildungen von oben und unten zu schätzen und die Eindeutigkeit von (tabellierten) Abbildungen zu bestimmen bewiesen. Sind solche Fakten erst einmal festgestellt, wird eine automatische Auswahl von Datenstrukturen möglich. Die verwendeten Verfahren basieren auf bekannten Techniken der Datenflussanalyse und erweitern diese."}
{"DOCID": "2700", "TEXT": "Reduktion: Eine Methode zum Beweis von Eigenschaften paralleler Programme: Beim Beweis, dass ein paralleles Programm eine gegebene Eigenschaft hat, ist es oft bequem anzunehmen, dass eine Anweisung unteilbar ist, d.h. dass die Anweisung nicht mit dem Rest des Programms verschachtelt werden kann. Hier werden ausreichende Bedingungen erreicht, um zu zeigen, dass die Annahme, dass eine Aussage unteilbar ist, gelockert werden kann und dennoch Eigenschaften wie das Anhalten erhalten bleiben. Damit können Korrektheitsbeweise eines parallelen Systems oft stark vereinfacht werden."}
{"DOCID": "2701", "TEXT": "Ein schneller und gewöhnlich linearer Algorithmus für die globale Flussanalyse (nur Zusammenfassung – vollständiges Papier JACM 23, 1. Januar 1976): Ein neuer Algorithmus für die globale Flussanalyse auf reduzierbaren Graphen wird vorgestellt. Es wird gezeigt, dass der Algorithmus eine sehr allgemeine Klasse von Funktionenräumen behandelt. Für einen Graphen mit e Kanten hat der Algorithmus eine ungünstigste Zeitgrenze von O(e log e) Funktionsoperationen. Es wird auch gezeigt, dass in Programmiersprache die Anzahl der Operationen proportional zu e plus der Anzahl der Ausgänge aus Programmschleifen ist. Folglich eine Beschränkung auf die Linearität von Kontrollstrukturen mit einem Eingang und einem Ausgang. Der Algorithmus kann auf noch größere Klassen von Funktionenräumen und Graphen erweitert werden, indem die Zeitgrenze gelockert wird. Es werden Beispiele für Codeverbesserungsprobleme gegeben, die unter Verwendung des Algorithmus gelöst werden können."}
{"DOCID": "2702", "TEXT": "Zur Komplexität des LR(k)-Testens: Das Problem der Bestimmung, ob eine beliebige kontextfreie Grammatik ein Mitglied einer leicht zu analysierenden Unterklasse von Grammatiken wie etwa der LR(k)-Grammatiken ist, wird betrachtet. Die zeitliche Komplexität dieses Problems wird analysiert, sowohl wenn k als feste ganze Zahl betrachtet wird, als auch wenn k als Parameter des Tests betrachtet wird. Im ersten Fall wird gezeigt, dass es für jedes k einen O(n(k+2))-Algorithmus zum Testen der LR(k)-Eigenschaft gibt, wobei n die Größe der betreffenden Grammatik ist. Wenn andererseits sowohl k als auch die Fachgrammatik Problemparameter sind, dann hängt die Komplexität des Problems sehr stark von der für k gewählten Darstellung ab. Genauer gesagt wird gezeigt, dass dieses Problem NP-vollständig ist, wenn k unär ausgedrückt wird. Wenn k binär ausgedrückt wird, ist das Problem für die nichtdeterministische Exponentialzeit vollständig. Diese Ergebnisse lassen sich auf viele andere parametrisierte Klassen von Grammatiken übertragen, wie z. B. die Grammatiken LL(k), starke LL(k), SLR(k), LC(k) und starke LC(k)."}
{"DOCID": "2703", "TEXT": "Die intrinsisch exponentielle Komplexität des Zirkularitätsproblems für Attributgrammatiken: Attributgrammatiken sind eine Erweiterung kontextfreier Grammatiken, die von Knuth als Mechanismus zum Einbeziehen der Semantik einer kontextfreien Sprache in die Syntax der Sprache entwickelt wurden. Das Zirkularitätsproblem für eine Grammatik besteht darin, zu bestimmen, ob die Semantik für alle möglichen Sätze (Programme) tatsächlich wohldefiniert sein wird. Es ist bewiesen, dass dieses Problem im Allgemeinen rechnerisch nicht lösbar ist. Insbesondere wird gezeigt, dass jeder deterministische Algorithmus, der das Problem löst, für unendlich viele Fälle eine exponentielle Zeit verwenden muss. Eine verbesserte Version von Knuths Zirkularitätstestalgorithmus wird ebenfalls angegeben, die das Problem tatsächlich innerhalb einer exponentiellen Zeit löst."}
{"DOCID": "2704", "TEXT": "Behandlung von Ausnahmen: Probleme und eine vorgeschlagene Notation: Dieses Dokument definiert Ausnahmebedingungen, diskutiert die Anforderungen, die Sprachfunktionen für die Behandlung von Ausnahmen erfüllen müssen, und schlägt einige neue Sprachfunktionen für die ordnungsgemäße und zuverlässige Behandlung von Ausnahmen vor. Die vorgeschlagenen Sprachmerkmale dienen dazu, Probleme bei der Behandlung von Ausnahmen hervorzuheben, indem sie zeigen, wie Mängel in aktuellen Ansätzen behoben werden können."}
{"DOCID": "2705", "TEXT": "Programmiersprachen, natürliche Sprachen und Mathematik: Einige soziale Aspekte des Programmierens werden durch Analogien zu ähnlichen Aspekten der Mathematik und natürlicher Sprachen beleuchtet. Die Trennung zwischen reiner und angewandter Mathematik findet sich ähnlich in der Programmierung wieder. Die Entwicklung natürlicher Sprachen hin zu flexionslosen, auf Wortreihenfolgen basierenden Sprachtypen spricht für ein Programmiersprachendesign, das auf allgemeinen, abstrakten Konstrukten basiert. In Analogie zu Ereignissen in der Geschichte der künstlichen Hilfssprachen wird suggeriert, dass Fortran und Cobol noch lange dominant bleiben werden. Die vielversprechendsten Wege für weitere Arbeiten mit weitreichendem Einfluss werden als qualitativ hochwertige Programmliteratur (d. h. Programme) von allgemeinem Nutzen und Studien zu Fragen im Zusammenhang mit dem Programmstil angesehen."}
{"DOCID": "2706", "TEXT": "Eine Anmerkung zum Set-Basis-Problem im Zusammenhang mit der Verdichtung von Zeichensätzen: Diese Anmerkung diskutiert die Reduzierung des Set-Basis-Problems auf das Clique-Cover-Problem."}
{"DOCID": "2707", "TEXT": "Backtrack-Programmiertechniken: Der Zweck dieses Papiers ist zweifach. Zuerst wird eine kurze Darstellung der allgemeinen Backtrack-Technik und ihrer Geschichte gegeben. Zweitens wird gezeigt, wie der Einsatz von Makros in vielen Fällen die Rechenzeit erheblich verkürzen kann. Insbesondere hat diese Technik die Lösung von zwei zuvor offenen kombinatorischen Problemen, die Berechnung neuer Terme in einer wohlbekannten Reihe und die wesentliche Verringerung der Rechenzeit für die Lösung eines anderen kombinatorischen Problems ermöglicht."}
{"DOCID": "2708", "TEXT": "Praktische Wiederherstellung nach syntaktischen Fehlern: Dieses Dokument beschreibt ein Wiederherstellungsschema für Syntaxfehler, das eine automatisch generierte Wiederherstellung hoher Qualität mit guten diagnostischen Informationen zu relativ geringen Kosten bereitstellt. Frühere Wiederherstellungstechniken werden zusammengefasst und es werden empirische Vergleiche angestellt. Vorschläge für weiterführende Forschungen zu diesem Thema runden den Beitrag ab."}
{"DOCID": "2709", "TEXT": "Eine Genealogie von Kontrollstrukturen: Das Thema Programmkontrollstrukturen hat eine lange Geschichte heftiger Kontroversen hinter sich. Um dieses Thema auf eine solide Grundlage zu stellen, werden in diesem Beitrag zahlreiche theoretische Ergebnisse zu Kontrollstrukturen überprüft und ihre praktischen Implikationen untersucht. Das klassische Ergebnis von Bohm und Jacopini zur theoretischen Vollständigkeit von if-then-else und while-do wird diskutiert. Anschließend werden mehrere neuere Ideen zu Kontrollstrukturen untersucht. Dazu gehören ein Überblick über verschiedene andere Kontrollstrukturen, Ergebnisse zu Zeit-/Raumbeschränkungen und Theoreme, die sich auf die relative Macht von Kontrollstrukturen unter Äquivalenzbegriffen beziehen. Abschließend werden die Auswirkungen theoretischer Ergebnisse auf den praktizierenden Programmierer und die Bedeutung von One-In-One-Out-Kontrollstrukturen als operative Abstraktionen diskutiert. Es wird weiter argumentiert, dass es nicht genügend Beweise gibt, um mehr als If-then-else, While-do und ihre Varianten zu rechtfertigen."}
{"DOCID": "2710", "TEXT": "Abfragen als relationale Ausdrücke spezifizieren: Die SQUARE-Datenteilsprache: Dieses Dokument stellt eine Datenteilsprache namens SQUARE vor, die für die Verwendung bei der interaktiven Ad-hoc-Problemlösung durch Nicht-Computerspezialisten gedacht ist. SQUARE basiert auf dem relationalen Datenmodell und erweist sich als relational vollständig; es vermeidet jedoch die Quantifizierer und gebundenen Variablen, die von Sprachen benötigt werden, die auf dem relationalen Kalkül basieren. Einrichtungen zum Abfragen, Einfügen, Löschen und Aktualisieren von tabellarischen Datenbanken werden beschrieben. Es wird eine Syntax angegeben und es werden Vorschläge für alternative Syntaxen gemacht, einschließlich einer Syntax, die auf englischen Schlüsselwörtern für Benutzer mit begrenztem mathematischem Hintergrund basiert."}
{"DOCID": "2711", "TEXT": "Ein Vektorraummodell für die automatische Indexierung: In einer Dokumentabruf- oder anderen Mustervergleichsumgebung, in der gespeicherte Entitäten (Dokumente) miteinander oder mit eingehenden Mustern (Suchanfragen) verglichen werden, scheint es, dass der beste Indexierungs-(Eigenschafts-)Raum einer ist wo jede Entität so weit wie möglich von den anderen entfernt liegt; unter diesen Umständen kann der Wert eines Indizierungssystems als Funktion der Dichte des Objektraums ausgedrückt werden; insbesondere kann die Abrufleistung umgekehrt mit der Raumdichte korrelieren. Ein auf Raumdichteberechnungen basierender Ansatz wird verwendet, um ein optimales Indizierungsvokabular für eine Sammlung von Dokumenten auszuwählen. Es werden typische Evaluationsergebnisse gezeigt, die die Nützlichkeit des Modells demonstrieren."}
{"DOCID": "2712", "TEXT": "Hornersche Regel zur Auswertung allgemeiner geschlossener Warteschlangennetze: Die Lösung trennbarer geschlossener Warteschlangennetze erfordert die Auswertung homogener multinomialer Ausdrücke. Die Anzahl der Terme in diesen Ausdrücken wächst kombinatorisch mit der Größe des Netzwerks, so dass eine direkte Summierung unpraktisch werden kann. Es wird ein Algorithmus angegeben, der keinen kombinatorischen Operationszähler anzeigt. Der Algorithmus basiert auf einer Verallgemeinerung der Hornerschen Regel für Polynome. Es wird auch gezeigt, wie die mittlere Warteschlangengröße und der mittlere Durchsatz mit vernachlässigbaren zusätzlichen Kosten erhalten werden können, wenn die Normalisierungskonstante ausgewertet wird."}
{"DOCID": "2713", "TEXT": "Bemerkung zur stabilen Aktualisierung des Mittelwerts und der Standardabweichung von Daten (Korrigendum)"}
{"DOCID": "2714", "TEXT": "Zusammenführen mit parallelen Prozessoren: Stellen Sie sich zwei linear geordnete Mengen A, B, |A|=m, |B|=n, m<=n und p, p<=m vor, parallele Prozessoren, die synchron arbeiten. Die Arbeit stellt einen Algorithmus zum Zusammenführen von A und B mit den p parallelen Prozessoren vor, der höchstens 2[log2 (2m+1)]+[3m/p] + [m/p][log2 (n/m)] Schritte erfordert . Wenn n = (2^B)m (B eine ganze Zahl) ist, benötigt der Algorithmus höchstens 2[log2 (m+1)] + [m/p](2+B) Schritte. Für den Fall, dass m und n in der gleichen Größenordnung liegen, d. h. n=km mit k als Konstante, erfordert der Algorithmus 2[log2 (m+1)] + [m/p](3+k) Schritte. Diese Leistungen sind im Vergleich zum vorherigen besten parallelen Zusammenführungsalgorithmus, dem Batcher-Algorithmus, der im allgemeinen Fall n/p + ((m+n)/2p)log2 m Schritte und km/p + ((k+1)/ 2)(m/p)log2 m im Spezialfall n=km."}
{"DOCID": "2715", "TEXT": "Implementierung einer strukturierten englischen Abfragesprache: Das relationale Datenmodell, das XRM Relational Memory System und die SEQUEL-Sprache wurden in früheren Artikeln behandelt und werden überprüft. SEQUEL ist eine Teilsprache für relationale Daten, die für die interaktive Ad-hoc-Problemlösung durch Nicht-Computerspezialisten gedacht ist. Eine Version von SEQUEL, die in einem Prototyp-Interpreter implementiert wurde, wird beschrieben. Der Interpreter ist dafür ausgelegt, die Datenzugriffsoperationen zu minimieren, die erforderlich sind, um auf eine beliebige Abfrage zu antworten. Die dafür konzipierten Optimierungsalgorithmen werden beschrieben."}
{"DOCID": "2716", "TEXT": "Optimierung der Leistung einer relationalen Algebra-Datenbankschnittstelle: Ein Ansatz zur Implementierung einer \"intelligenten\" Schnittstelle zur Unterstützung einer relationalen Datenansicht wird vorgeschlagen. Die Grundidee besteht darin, automatische Programmiertechniken zu verwenden, so dass die Schnittstelle die vom Benutzer bereitgestellte Abfragespezifikation auf hoher Ebene analysiert und effizient verfeinert. Eine relationale Algebra-Schnittstelle namens SQUIRAL, die unter Verwendung dieses Ansatzes entworfen wurde, wird detailliert beschrieben. SQUIRAL versucht, die Abfrageantwortzeit und die Speicherplatznutzung zu minimieren, indem es: (1) eine globale Abfrageoptimierung durchführt, (2) disjunkte und Pipeline-Parallelität ausnutzt, (3) Sortierreihenfolgen in temporären Beziehungen koordiniert, (4) Verzeichnisanalysen einsetzt und (5) Beibehaltung der Lokalität in Seitenreferenzen. Algorithmen zum Implementieren der Operatoren der relationalen Algebra von E. F. Codd werden vorgestellt, und eine Methodik zum Zusammenstellen dieser Operatoren zum Optimieren der Leistung einer bestimmten Benutzerabfrage wird beschrieben."}
{"DOCID": "2717", "TEXT": "CONVERT: Eine hochrangige Übersetzungsdefinitionssprache für die Datenkonvertierung: Dieses Dokument beschreibt eine hochrangige und nicht prozedurale Übersetzungsdefinitionssprache, CONVERT, die sehr leistungsstarke und hochflexible Datenumstrukturierungsfähigkeiten bereitstellt. Sein Design basiert auf dem einfachen Grundkonzept eines Formulars, das es den Benutzern ermöglicht, die Übersetzungsprozesse zu visualisieren, und somit die Datenübersetzung zu einer viel einfacheren Aufgabe macht. \"CONVERT\" wurde gewählt, um den Zweck der Sprache zu vermitteln und sollte nicht mit anderen Sprachen oder Programmen mit demselben Namen verwechselt werden."}
{"DOCID": "2718", "TEXT": "Ein vorläufiges System für den Entwurf von DBTG-Datenstrukturen: Der funktionale Ansatz für den Datenbankentwurf wird eingeführt. Bei diesem Ansatz besteht das Ziel des Entwurfs darin, eine Datenstruktur abzuleiten, die in der Lage ist, einen Satz erwarteter Abfragen zu unterstützen, und nicht eine Struktur, die auf andere Weise \"das Geschäft modelliert\". Es wird ein betriebsbereites Computerprogramm beschrieben, das den funktionalen Ansatz zum Entwerfen von Datenstrukturen verwendet, die den Spezifikationen der Data Base Task Group entsprechen. Die von diesem Programm verwendete automatische Programmiertechnologie wird hier, obwohl sie normalerweise zum Generieren von Prozeduren verwendet wird, zum Generieren von Deklarativen verwendet."}
{"DOCID": "2719", "TEXT": "Mechanische Programmanalyse: Ein Mittel zur Analyse der Programmleistung besteht darin, geschlossene Ausdrücke für ihr Ausführungsverhalten abzuleiten. Dieses Papier diskutiert die Mechanisierung einer solchen Analyse und beschreibt ein System, Metric, das in der Lage ist, einfache Lisp-Programme zu analysieren und beispielsweise Ausdrücke in geschlossener Form für ihre Laufzeit zu erzeugen, ausgedrückt in Bezug auf die Größe der Eingabe. Dieses Papier stellt die Gründe für die Mechanisierung der Programmanalyse vor, beschreibt die Funktionsweise von Metric, erklärt seine Implementierung und diskutiert seine Grenzen."}
{"DOCID": "2720", "TEXT": "Optimales Ausgleichen von E/A-Anforderungen an Platten: Das Bestimmen einer Richtlinie für eine effiziente Zuordnung und Nutzung einer Gruppe von Plattenlaufwerken mit unterschiedlichen Betriebseigenschaften wird unter Verwendung analytischer Techniken untersucht. Unter Verwendung der Standard-Warteschlangentheorie ist jedes Plattenlaufwerk durch ein Warteschlangenmodell gekennzeichnet, wobei die Betriebszeit eines Plattenlaufwerks durch die Wahrscheinlichkeitsdichtefunktion der Summe zweier gleichförmiger Verteilungen dargestellt wird. Die Gesamtantwortzeit des Satzes von Plattenmodellen wird dann unter variierenden Lastbedingungen minimiert. Die Ergebnisse zeigen, dass schnellere Geräte höhere Auslastungsfaktoren haben sollten und dass die Anzahl der verwendeten unterschiedlichen Gerätetypen mit abnehmender Last tendenziell abnimmt. Spezifische Beispiele, die 2314- und 3330-Kombinationen verwenden, werden untersucht."}
{"DOCID": "2721", "TEXT": "The Digital Simulation of River Plankton Population Dynamics: Dieser Artikel befasst sich mit der Entwicklung eines mathematischen Modells und der digitalen Simulation in Fortran IV von Phytoplankton- und Zooplankton-Populationsdichten in einem Fluss unter Verwendung zuvor entwickelter Ratenausdrücke. Um die Beziehungen zwischen den beteiligten ökologischen Mechanismen zu untersuchen, wurden die Simulationsparameter variiert, um die Reaktion des Ökosystems auf verschiedene Bedingungen zu veranschaulichen, einschließlich solcher, die bestimmten Arten chemischer und thermischer Verschmutzung entsprechen. Als Untersuchung der Genauigkeit der Simulationsmethoden wurde eine Simulation der tatsächlichen Populationsdynamik von Asterionella im Columbia River basierend auf Annäherungen an die Bedingungen in diesem Fluss durchgeführt. Obwohl nicht ganz genau, wurde festgestellt, dass die Simulation das allgemeine jährliche Muster des Planktonwachstums ziemlich gut vorhersagte und insbesondere die Bedeutung des jährlichen Geschwindigkeitszyklus bei der Bestimmung solcher Muster aufzeigte. Darüber hinaus demonstriert die Studie die Nützlichkeit digitaler Simulationen bei der Untersuchung bestimmter aquatischer Ökosysteme sowie bei der Umweltplanung mit solchen Untersuchungen."}
{"DOCID": "2722", "TEXT": "Mehrdimensionale binäre Suchbäume, die für assoziative Suche verwendet werden: Dieses Papier entwickelt den mehrdimensionalen binären Suchbaum (oder k-d-Baum, wobei k die Dimensionalität des Suchraums ist) als eine Datenstruktur zum Speichern von Informationen, die durch assoziative Suchen abgerufen werden sollen. Der k-d-Baum wird definiert und es werden Beispiele gegeben. Es zeigt sich, dass es ziemlich in seinen Speicheranforderungen ist. Ein wesentlicher Vorteil dieser Struktur besteht darin, dass eine einzige Datenstruktur viele Arten von Abfragen sehr effizient handhaben kann. Es werden verschiedene Hilfsalgorithmen entwickelt; ihre nachgewiesenen durchschnittlichen Laufzeiten in einer n-Record-Datei sind: Insertion, O (log n); Löschung der Wurzel, O (n^(k-1)/k); Löschen eines zufälligen Knotens, O (log n); und Optimierung (garantiert logarithmische Suchleistung), O (n log n). Suchalgorithmen werden für Teilübereinstimmungsabfragen mit t angegebenen Schlüsseln [bewiesene maximale Laufzeit von O (n^(k-t)/k)] und für Nächste-Nachbar-Abfragen [empirisch beobachtete durchschnittliche Laufzeit von O (log n)] angegeben. Diese Leistungen die besten derzeit bekannten Algorithmen für diese Aufgaben bei weitem übertreffen. Es wird ein Algorithmus vorgestellt, um jede allgemeine Schnittmengenabfrage zu handhaben. Theoretische Schwerpunkte dieser Arbeit. Es wird jedoch angenommen, dass k-d-Bäume in vielen Anwendungen sehr nützlich sein könnten, und es werden Beispiele möglicher Verwendungen gegeben."}
{"DOCID": "2723", "TEXT": "Multiprocessing Compactifying Garbage Collection: Algorithmen für einen Multiprocessing Compactifying Garbage Collector werden vorgestellt und diskutiert. Der einfache Fall von zwei Prozessoren, von denen einer LISP-ähnliche Listenoperationen durchführt und der andere kontinuierlich eine Garbage-Collection durchführt, wird gründlich untersucht. Die notwendigen Fähigkeiten jedes Prozessors werden definiert, ebenso wie die Kommunikation zwischen den Prozessoren und Verriegelungen. Vollständige Prozeduren für die Garbage-Collection und für Standard-Listenverarbeitungs-Primitive werden vorgestellt und gründlich erklärt. Besondere Aufmerksamkeit wird den Problemen des Markierens und Verschiebens von Listenzellen geschenkt, während ein anderer Prozessor sie bearbeiten kann. Das Hauptziel besteht darin, dem Listenprozessor zu ermöglichen, ungehindert zu laufen, während der andere Prozessor den Listenspeicher zurückfordert. Die komplexeren Fälle mit mehreren Listenprozessoren und einem oder mehreren Speicherbereinigungsprozessoren werden ebenfalls kurz diskutiert."}
{"DOCID": "2724", "TEXT": "Die Lemniskatenkonstanten (Korrigendum)"}
{"DOCID": "2725", "TEXT": "Ein Vergleich von Algorithmen für Simulationsereignislisten (Korrigendum)"}
{"DOCID": "2726", "TEXT": "Kombinieren von Entscheidungsregeln in einer Entscheidungstabelle: Die Techniken zum Minimieren von Logikschaltungen werden auf die Vereinfachung von Entscheidungstabellen durch Kombinieren von Entscheidungsregeln angewendet. Dieses Verfahren ist logisch äquivalent zum Quien-McCluskey-Verfahren zum Auffinden von Primimplikanten. Wenn einige der in der ELSE-Regel implizierten Entscheidungsregeln mit geringer Häufigkeit auftreten, kann die ELSE-Regel verwendet werden, um die Entscheidungstabelle weiter zu vereinfachen. Bei der Optimierung einer Entscheidungstabelle sollten mehrere Ziele berücksichtigt werden: (1) Reduzierung der Maschinenausführungszeit; (2) Verringerung der Vorverarbeitungszeit; (3) Reduzieren des erforderlichen Maschinenspeichers; (4) Reduzieren der Anzahl von Entscheidungsregeln. (Dies verbessert oft die Klarheit der Entscheidungstabelle für einen menschlichen Leser.) Es wird gezeigt, dass die Ziele (3) und (4) mit den obigen Verfahren gefördert werden können. Ziel (1) wird auch erreicht, wenn überspezifizierte Entscheidungsregeln nicht kombiniert werden. Ziel (2) muss mit den potenziellen Vorteilen der Ziele (1), (3) und (4) verglichen werden, um zu entscheiden, ob die oben genannten Methoden verwendet werden sollen."}
{"DOCID": "2727", "TEXT": "Mehrfach-Byte-Verarbeitung mit Vollwortbefehlen: Es wird ein Verfahren beschrieben, das eine parallele Verarbeitung gepackter Datenelemente unter Verwendung nur gewöhnlicher Vollwort-Computerbefehle ermöglicht, obwohl die Verarbeitung Operationen erfordert, deren Ausführung vom Wert eines Datums abhängig ist. Es bietet eine nützliche Technik zum Verarbeiten kleiner Datenelemente wie alphanumerischer Zeichen."}
{"DOCID": "2728", "TEXT": "Konsekutive Speicherung relevanter Datensätze mit Redundanz: Dieses Dokument untersucht die Eigenschaften einer neuen Klasse von Dateiorganisationen (CRWR), bei der Datensätze, die für jede Abfrage relevant sind, an aufeinanderfolgenden Speicherorten gespeichert werden, die Organisationen jedoch Redundanz enthalten. Es wurden auch einige Theoreme entwickelt, die Werkzeuge zum Reduzieren von Redundanz in CRWR-Organisationen bereitstellen. Durch die Anwendung dieser Theoreme erhaltene Redundanzen werden mit denen von abfrageinvertierten Dateiorganisationen verglichen. Einige CRWR-Organisationen mit minimaler Redundanz wurden auch für Abfragen entwickelt, die Sätze von Schlüsseln spezifizieren."}
{"DOCID": "2729", "TEXT": "Kommentare zu einem Artikel von T. C. Chen und I. T. Ho"}
{"DOCID": "2730", "TEXT": "Interaktive Beratung über natürliche Sprache: Interaktive Programmiersysteme enthalten häufig Hilfebefehle, um dem Programmierer Online-Anweisungen bezüglich der Verwendung der verschiedenen Systembefehle zu geben. Es wird argumentiert, dass es relativ einfach wäre, diese Hilfebefehle wesentlich hilfreicher zu machen, indem sie Anfragen in natürlicher Sprache akzeptieren. Zur Demonstration wurde das ELIZA-Programm von Weizenbaum mit einem Skript versehen, das es zu einem natürlichen Sprachsystemberater macht."}
{"DOCID": "2731", "TEXT": "Bemerkung zur stabilen Aktualisierung des Mittelwerts und der Standardabweichung von Daten"}
{"DOCID": "2732", "TEXT": "Guarded Commands, Nondeterminacy and Formal Derivation of Programs: Sogenannte „Guarded Commands“ werden als Baustein für alternative und repetitive Konstrukte eingeführt, die nicht deterministische Programmkomponenten zulassen, für die zumindest die evozierte Aktivität, möglicherweise aber auch der Endzustand, nicht gilt notwendigerweise eindeutig durch den Anfangszustand bestimmt. Zur formalen Ableitung von Programmen, die durch diese Konstrukte ausgedrückt werden, wird ein Kalkül gezeigt."}
{"DOCID": "2733", "TEXT": "Deterministisches Parsing mehrdeutiger Grammatiken: Es werden Methoden zur Beschreibung der Syntax von Programmiersprachen betrachtet, die flexibler und natürlicher sind als herkömmliche BNF-Beschreibungen. Diese Verfahren beinhalten die Verwendung mehrdeutiger kontextfreier Grammatiken zusammen mit Regeln zum Auflösen syntaktischer Mehrdeutigkeiten. Es wird gezeigt, wie effiziente LR- und LL-Parser direkt aus bestimmten Klassen dieser Spezifikationen konstruiert werden können."}
{"DOCID": "2734", "TEXT": "Zur externen Speicherfragmentierung, die durch First-Fit- und Best-Fit-Zuweisungsstrategien erzeugt wird: Veröffentlichte Vergleiche der externen Fragmentierung, die durch First-Fit- und Best-Fit-Speicherzuweisung erzeugt wird, waren nicht konsistent. Durch Simulation wurde eine Reihe von Experimenten durchgeführt, um bessere Daten über die relative Leistung von First-Fit und Best-Fit zu erhalten und die Gründe für beobachtete Unterschiede besser zu verstehen. Die Zeit-Gedächtnis-Produkteffizienzen von First-Fit und Best-Fit lagen im Allgemeinen innerhalb von 1 bis 3 Prozent voneinander. Abgesehen von kleinen Populationen hatte die Größe der Anforderungspopulation wenig Einfluss auf die Zuweisungseffizienz. Bei exponentiellen und hyperexponentiellen Verteilungen von Anforderungen war First-Fit besser als Best-Fit; aber für normale und gleichmäßige Verteilungen und für Exponentialverteilungen, die auf verschiedene Weise verzerrt sind, übertraf die beste Anpassung die erste Anpassung. Es wird die Hypothese aufgestellt, dass, wenn First-Fit Best-Fit übertrifft, dies geschieht, weil First-Fit durch die bevorzugte Zuordnung zu einem Ende des Speichers große Blöcke dazu anregt, am anderen Ende zu wachsen. Dadurch steht eher ausreichend zusammenhängender Platz für größere Anfragen zur Verfügung. Ergebnisse von Simulationsexperimenten unterstützten diese Hypothese und zeigten, dass die relative Leistung von First-Fit und Best-Fit von der Häufigkeit der Anfrage abhängt. Wenn der Variationskoeffizient der Anforderungsverteilung größer oder ungefähr gleich Eins ist, übertrifft die First-Fit-Methode die Best-Fit-Methode."}
{"DOCID": "2735", "TEXT": "Diskriminierung bei der Beschäftigung von Frauen in der Computerindustrie"}
{"DOCID": "2736", "TEXT": "Ein Hinweis zum Hash-Linking"}
{"DOCID": "2737", "TEXT": "Bestimmen des einschließenden Rechtecks ​​mit minimaler Fläche für eine beliebige geschlossene Kurve: Dieses Dokument beschreibt ein Verfahren zum Auffinden des Rechtecks ​​mit minimaler Fläche, in dem eine gegebene beliebige ebene Kurve enthalten sein kann. Das Verfahren ist bei bestimmten Packungs- und optimalen Layoutproblemen von Interesse. Es besteht darin, zuerst das konvexe Polygon mit minimalem Umfang zu bestimmen, das die gegebene Kurve umschließt, und dann das Rechteck mit minimaler Fläche auszuwählen, das dieses Polygon enthalten kann. Drei Theoreme werden eingeführt, um zu zeigen, dass eine Seite des Rechtecks ​​mit minimaler Fläche kolinear mit einer Kante des umschlossenen Polygons sein muss und dass das umhüllende Rechteck mit minimaler Fläche für das konvexe Polygon auch das Rechteck mit minimaler Fläche für die Kurve ist."}
{"DOCID": "2738", "TEXT": "Verwendung des Transparenzkonzepts beim Entwurf hierarchisch strukturierter Systeme: Diese Arbeit befasst sich mit dem Entwurf hierarchisch strukturierter Programmiersysteme. Es entwickelt eine Methode zur Bewertung der Kosten, die entstehen, wenn Programmierer mit einer Abstraktion einer realen Maschine arbeiten müssen. Zur Veranschaulichung des Verfahrens werden eine Reihe von Beispielen aus Hard- und Software angegeben."}
{"DOCID": "2739", "TEXT": "Die Beschränkungssprache für Computergrammatiken natürlicher Sprache: In den letzten Jahren basierte eine Reihe von Systemen für die Computeranalyse von Sätzen natürlicher Sprache auf erweiterten kontextfreien Grammatiken: einer kontextfreien Grammatik, die einen Satz von Analysebäumen definiert für einen Satz plus eine Gruppe von Einschränkungen, denen ein Baum entsprechen muss, um eine gültige Satzanalyse zu sein. Mit zunehmender Abdeckung der Grammatik wird eine effiziente Darstellung für die weitere Entwicklung unerlässlich. Dieses Papier stellt eine Programmiersprache vor, die speziell für die kompakte und übersichtliche Angabe von Beschränkungen einer natürlichsprachlichen Grammatik entwickelt wurde. Es basiert auf zehnjähriger Erfahrung beim Analysieren von Textsätzen mit der umfassenden englischen Grammatik der N.Y.U. Linguistic String Project und verkörpert in seiner Syntax und seinen Routinen die Beziehungen, die sich als nützlich und angemessen für die computergestützte Analyse natürlicher Sprache erwiesen haben. Die Sprache wird in der aktuellen Implementierung des Linguistic String Parser verwendet."}
{"DOCID": "2740", "TEXT": "A Large Semaphore Based Operating System: Das Papier beschreibt die interne Struktur eines großen Betriebssystems als eine Reihe kooperierender sequentieller Prozesse. Die Prozesse synchronisieren sich mittels Semaphoren und erweiterten Semaphoren (Warteschlangen-Semaphoren). Die Anzahl paralleler Prozesse wird sorgfältig begründet und die verschiedenen Semaphorkonstruktionen werden erläutert. Das System ist nachweislich frei von „Deadly Umarmung“ (Deadlock). Das Designprinzip ist eine Alternative zu Dijkstras hierarchischer Strukturierung von Betriebssystemen. Auch das Projektmanagement und die Durchführung werden besprochen. Das Betriebssystem ist das erste große, das das Multiprogramming-System RC 4000 verwendet."}
{"DOCID": "2741", "TEXT": "Zerlegbarkeit, Instabilitäten und Sättigung in Multiprogramming-Systemen: Ein schrittweiser Ansatz zur Modellierung des dynamischen Verhaltens und zur Bewertung der Leistung von Computersystemen wird vorgeschlagen. Es basiert auf einer Technik der Aggregation von Variablen und dem Konzept des nahezu zerlegbaren Systems, die beide der Ökonometrie entlehnt sind. Dieser Ansatz wird gewählt, um in Multiprogramming-Paging-Systemen (i) instabile Betriebsregime und (ii) kritische Rechenlasten zu identifizieren, die das System in Sättigungszustände bringen. Diese Analyse führt zu einer vollständigeren Definition der Umstände, unter denen \"Prügel\" eintreten können."}
{"DOCID": "2742", "TEXT": "Verbesserte Event-Scanning-Mechanismen für diskrete Event-Simulation: Simulationsmodelle von großen, komplexen \"Real-World\"-Anwendungen haben gelegentlich den Ruf erworben, Stunden an Computerzeit zu verschlingen. Dieses Problem kann teilweise auf Schwierigkeiten wie langsame stochastische Konvergenz zurückgeführt werden. Ein zusätzliches Problem liegt jedoch in der Tatsache, dass eine beträchtliche Menge an Buchhaltungszeit erforderlich ist, um zukünftige Ereignisse in ihrer richtigen Reihenfolge zu halten. Dieses Papier stellt eine Methode vor, um den Zeitaufwand für das Durchsuchen zukünftiger Ereignislisten in diskreten Ereignissimulationen erheblich zu reduzieren. Dort werden Modelle vorgestellt, die sich alle in ihrer Effektivität verbessern, wenn das Problem des Scannens von Ereignislisten lästiger wird."}
{"DOCID": "2743", "TEXT": "X + Y sortieren"}
{"DOCID": "2744", "TEXT": "Addition in an Arbitrary Base Without Radix Conversion: Dieses Papier präsentiert eine Verallgemeinerung einer alten Programmiertechnik; Mit ihm kann man Zahlen addieren und subtrahieren, die in einer beliebigen Basis dargestellt sind, einschließlich einer gemischten Basis, und eine Ziffer pro Byte in Bytes ausreichender Größe gespeichert werden. Eine Radix-Konvertierung ist nicht erforderlich, es ist keine Schleife erforderlich, und Zahlen können sogar in einem Anzeigeformat (E/A) gespeichert werden. Anwendungen auf Cobol, MIX und Hexadezimalsummen werden diskutiert."}
{"DOCID": "2745", "TEXT": "Ein linearer Raumalgorithmus zum Berechnen maximaler gemeinsamer Teilfolgen: Das Problem, eine längste gemeinsame Teilfolge zweier Zeichenfolgen zu finden, wurde in quadratischer Zeit und im quadratischen Raum gelöst. Es wird ein Algorithmus vorgestellt, der dieses Problem in quadratischer Zeit und im linearen Raum löst."}
{"DOCID": "2746", "TEXT": "Effizienter String-Matching: Eine Hilfe bei der bibliographischen Suche: Dieses Dokument beschreibt einen einfachen, effizienten Algorithmus, um alle Vorkommen eines beliebigen einer begrenzten Anzahl von Schlüsselwörtern in einem Text-String zu finden. Der Algorithmus besteht darin, aus den Schlüsselwörtern eine Finite-State-Mustervergleichsmaschine zu konstruieren und dann die Mustervergleichsmaschine zu verwenden, um die Textzeichenfolge in einem einzigen Durchgang zu verarbeiten. Der Aufbau der Mustervergleichsmaschine nimmt Zeit in Anspruch, die proportional zur Summe der Längen der Schlüsselwörter ist. Die Anzahl von Zustandsübergängen, die von der Mustervergleichsmaschine beim Verarbeiten der Textzeichenfolge durchgeführt wird, ist unabhängig von der Anzahl von Schlüsselwörtern. Der Algorithmus wurde verwendet, um die Geschwindigkeit eines bibliografischen Suchprogramms in Bibliotheken um den Faktor 5 bis 10 zu verbessern."}
{"DOCID": "2747", "TEXT": "Ein vereinfachtes Rekombinationsschema für das Fibonacci-Buddy-System: Ein vereinfachtes Rekombinationsschema für das Fibonacci-Buddy-System, das weder Tabellen noch sich wiederholende Berechnungen erfordert und nur zwei zusätzliche Bits pro Puffer verwendet, wird vorgestellt."}
{"DOCID": "2748", "TEXT": "Indirect Threaded Code: Eine effiziente Anordnung für interpretierenden Code wird beschrieben. Es ist mit Bells Begriff des Threaded-Codes verwandt, benötigt jedoch weniger Platz und ist für maschinenunabhängige Implementierungen zugänglicher."}
{"DOCID": "2749", "TEXT": "Significant Event Simulation: Dieser Artikel vergleicht eine neue Methode der Simulationsorganisation, die Significant Event Method genannt wird, mit einer alten, die Clock Pulse Method genannt wird, wobei als Beispiele zwei Autoverkehrsmodelle verwendet werden. Es hat sich herausgestellt, dass die Methode signifikanter Ereignisse bei niedrigen Ebenen der Systeminteraktion effizienter und bei hohen Ebenen weniger effizient ist als die Taktimpulsmethode. Ein einfaches mathematisches Modell für den Trade-off in der relativen Laufzeit der beiden Verfahren wird entwickelt. Das Modell hilft bei der Auswahl zwischen den beiden Simulationsmethoden für ein bestimmtes Experiment. Es wird geschlussfolgert, dass die Methode signifikanter Ereignisse bei der Simulation einiger Systeme von Wert sein kann, wenn die Recheneffizienz von ausreichender Bedeutung ist."}
{"DOCID": "2750", "TEXT": "Ein kostenorientierter Algorithmus für die Datensatzzuweisung in Speicherhierarchien: Die Datensatzzuweisung in heutigen mehrstufigen Speichersystemen basiert normalerweise auf qualitativen Ad-hoc-Entscheidungen. Während es wünschenswert wäre, eine optimale Lösung für dieses Zuordnungsproblem zu erhalten, ist es klar, dass die Anzahl der beteiligten Parameter es für eine einfache Lösung unhandlich macht. In einer solchen Situation müssen wir eine Reihe von Annahmen finden, die das Problem stark vereinfachen, aber dennoch eine Grundlage für die Berücksichtigung aller wesentlichen Kostenelemente bieten. Dieser Beitrag stellt einen solchen ersten, quantitativen Allokationsschritt vor. Es berücksichtigt viele der erheblichen detaillierten Kosten der Systemnutzung, Datenspeicherung, Datenbereitstellung und Datenmigration. Obwohl viele Wege zur weiteren Verbesserung verfügbar sind, scheint der vorliegende Algorithmus nützlich genau zu sein. Als solches kann es bei der Quantifizierung der Probleme der Datensatzzuweisung, Speichersystemkonfiguration und neuen Gerätedesigns helfen."}
{"DOCID": "2751", "TEXT": "Beleuchtung für computererzeugte Bilder: Die Qualität von computererzeugten Bildern von dreidimensionalen Szenen hängt von der Schattierungstechnik ab, die verwendet wird, um die Objekte auf dem Bildschirm der Kathodenstrahlröhre zu malen. Der Schattierungsalgorithmus selbst hängt teilweise von der Methode zum Modellieren des Objekts ab, die auch den Algorithmus für verborgene Oberflächen bestimmt. Die verschiedenen Methoden der Objektmodellierung, Schattierung und Entfernung verdeckter Oberflächen sind somit stark miteinander verbunden. Hier werden mehrere Schattierungstechniken vorgestellt, die verschiedenen Methoden der Objektmodellierung und den zugehörigen Algorithmen für verdeckte Oberflächen entsprechen. Die menschliche visuelle Wahrnehmung und die grundlegenden Gesetze der Optik werden bei der Entwicklung einer Schattierungsregel berücksichtigt, die eine bessere Qualität und einen erhöhten Realismus in erzeugten Bildern bietet."}
{"DOCID": "2752", "TEXT": "Erzeugung aller Zyklen eines Graphen aus einem Satz von Grundzyklen [H] (Algorithmus 492)"}
{"DOCID": "2753", "TEXT": "Ein heuristisches Problemlösungs-Designsystem für Ausstattungs- oder Möbellayouts: Der Designer Problem Solver (DPS) demonstriert, dass der Computer einfache Designaufgaben ausführen kann. Insbesondere entwirft es Möbel- und Ausstattungslayouts. Diese Aufgabe wurde ausgewählt, weil sie einfach, gut definiert und charakteristisch für viele Entwurfsaufgaben in Architektur, Ingenieurwesen, Stadtplanung und Verwaltung natürlicher Ressourcen ist. Diese Raumplanungsaufgaben umfassen normalerweise die Manipulation zweidimensionaler Darstellungen von Objekten, um realisierbare oder optimale Lösungen für Probleme mit topologischen und metrischen räumlichen Einschränkungen zu schaffen. Das Papier beschreibt umfangreiche Tests, die mit dem Programm durchgeführt wurden. DPS ist ein heuristischer Problemlöser, dem eine Planungsphase vorangestellt ist. Es verwendet den Planungsprozess, um ihm einen Orientierungssinn zu geben, diagnostische Verfahren, um Schwierigkeiten zu lokalisieren, und Abhilfemaßnahmen, um sich von Schwierigkeiten zu erholen. Es verwendet eine konvexe Polygondarstellung, um die Objekte und das Layout genau zu beschreiben. Diese Darstellung ermöglicht es, topologische und metrische Einschränkungen zu testen und das Design einfach zu aktualisieren. DPS wurde auf 50 Probleme angewendet. Obwohl es langsam und in seinem Umfang begrenzt ist, sind die Ideen dahinter allgemein. Es demonstriert die Notwendigkeit der Selektivität bei der Steuerung der Suche und die Methoden, die verwendet werden, um dies zu erreichen: aufgabenspezifische Informationen, Planung, Diagnoseverfahren, Abhilfemaßnahmen und selektive Alternativgeneratoren."}
{"DOCID": "2754", "TEXT": "Ein syntaktischer Algorithmus zur Peak-Erkennung in Wellenformen mit Anwendungen in der Kardiographie: Peaks in einer digitalisierten Wellenform werden durch einen Algorithmus erkannt, der stückweise lineare Annäherung und tabellarische Parsing-Techniken enthält. Mehrere Parameter dienen dazu, den Zusammenhang der Wellenform zu identifizieren, was eine genaue Messung der Spitzenamplitude, -dauer und -form ermöglicht. Der Algorithmus ist von ausreichender Geschwindigkeit, um eine Online-Echtzeitverarbeitung zu ermöglichen. Ein Anwendungsbeispiel wird anhand eines Elektrokardiogramms demonstriert."}
{"DOCID": "2755", "TEXT": "Die neue Mathematik der Computerprogrammierung (Korrigendum)"}
{"DOCID": "2756", "TEXT": "Eine Problemliste von Fragen der öffentlichen Ordnung in Bezug auf Computer und Gesundheitswesen"}
{"DOCID": "2757", "TEXT": "Mehr zu k-ten kürzesten Wegen"}
{"DOCID": "2758", "TEXT": "Eine Anmerkung zur LU-Faktorisierung einer symmetrischen Matrix"}
{"DOCID": "2759", "TEXT": "Lösung eines überbestimmten Gleichungssystems in der L1-Norm (Algorithmus R478)"}
{"DOCID": "2760", "TEXT": "Darstellungsprogramm für sichtbare Oberflächen (Algorithmus R475)"}
{"DOCID": "2761", "TEXT": "Darstellungsprogramm für sichtbare Oberflächen (Algorithmus R475)"}
{"DOCID": "2762", "TEXT": "Zehn Subroutinen zur Manipulation von Tschebyscheff-Reihen (Algorithmus R446, C446)"}
{"DOCID": "2763", "TEXT": "Basiszykluserzeugung [H] (Algorithmus 491)"}
{"DOCID": "2764", "TEXT": "An Intelligent Analyzer and Understander of English: Das Papier beschreibt ein funktionierendes Analyse- und Generierungsprogramm für natürliche Sprache, das die Eingabe von Absatzlängen handhabt. Sein Kern ist ein System der bevorzugten Wahl zwischen tiefen semantischen Mustern, basierend auf dem, was wir „semantische Dichte“ nennen. Das System wird kontrastiert: (1) mit syntaxorientierten linguistischen Ansätzen und (2) mit theorembeweisenden Ansätzen für das Verständnisproblem."}
{"DOCID": "2765", "TEXT": "Analyse und Leistung von invertierten Datenbankstrukturen: Es wird die Notwendigkeit betont, Datenbanksysteme in einem hierarchischen Rahmen von Ebene zu Ebene vorzustellen und zu strukturieren. Die invertierte Datenbank-(Datei-)Organisation wird dann unter Berücksichtigung von umsetzungsorientierten Aspekten analysiert. Das invertierte Verzeichnis wird realistisch als eine weitere große Datenbank angesehen, die selbst einer Inversion unterzogen wird. Formulierungen werden abgeleitet, um die durchschnittliche Zugriffszeit (nur Lesezugriff) und Speicheranforderungen abzuschätzen, wobei die Interaktion von Datenbankinhaltsmerkmalen, logischer Komplexität von Abfragen und Maschinentiming- und Blockierungsspezifikationen formalisiert werden, von denen festgestellt wurde, dass sie eine Auswirkung erster Ordnung auf die Leistung haben. Die dargestellten Formulierungen müssen in Verbindung mit beliebigen Indexauswahlkriterien verwendet werden, um den optimalen Satz von Indexschlüsseln zu bestimmen."}
{"DOCID": "2766", "TEXT": "Kopieren zyklischer Listenstrukturen in linearer Zeit unter Verwendung eines begrenzten Arbeitsbereichs: Ein begrenzter Arbeitsbereich-Kopieralgorithmus für beliebige Listenstrukturen wird angegeben. Dieser Algorithmus arbeitet in linearer Zeit und erfordert keine Tag-Bits. Die besten früheren Kopieralgorithmen für begrenzte Arbeitsbereiche erreichten n^2 Mal ohne Tag-Bits und n log n Mal mit einem Tag. Die einzige Einschränkung des hier angegebenen Algorithmus besteht darin, dass die Kopie in einem zusammenhängenden Speicherabschnitt platziert werden muss. Das Verfahren ist auf Knoten mit fester oder variabler Größe anwendbar."}
{"DOCID": "2767", "TEXT": "Ein Vergleich von Simulationsereignislistenalgorithmen: Es werden vier Algorithmen betrachtet, die verwendet werden können, um Ereignisse in einem diskreten Mehrzweck-Simulationssystem zu planen. Zwei der Algorithmen sind neu, einer basiert auf einer Endreihenfolge-Baumstruktur für Ereignisbenachrichtigungen und ein anderer verwendet eine indizierte lineare Liste. Die Algorithmen werden mit einem Satz typischer stochastischer Scheduling-Verteilungen getestet, die speziell ausgewählt wurden, um die Vorteile und Grenzen der Algorithmen aufzuzeigen. Der End-Order-Tree-Algorithmus erweist sich als vorteilhafter, unmittelbarer Ersatz für den Algorithmus, der mit aktuellen Simulationssprachen verwendet wird. Der vielversprechendste Algorithmus verwendet das Konzept der indizierten Liste. Es wird eine adaptive Routine erfordern, bevor es in Mehrzwecksimulatoren eingesetzt werden kann, aber seine Leistungsfähigkeit ist derart, dass weitere Studien fruchtbar wären."}
{"DOCID": "2768", "TEXT": "Ein Algorithmus zum Lokalisieren benachbarter Speicherblöcke im Buddy-System: Ein einfaches Schema zum Bestimmen der Position eines Speicherblocks relativ zu anderen Blöcken wird beschrieben. Dieses Schema ist auf die Speicherzuordnungssysteme des Buddy-Typs anwendbar."}
{"DOCID": "2769", "TEXT": "Eine Modifikation des Warshall-Algorithmus für die transitive Schließung binärer Beziehungen: Es wird ein Algorithmus zur Berechnung der transitiven Schließung einer binären Beziehung angegeben, die durch eine Boolesche Matrix dargestellt wird. Der Algorithmus ähnelt dem von Warshall, obwohl er auf den meisten Computern für dünnbesetzte Matrizen schneller ausgeführt wird, insbesondere in einer Paging-Umgebung."}
{"DOCID": "2770", "TEXT": "Das quadratische Hash-Verfahren, wenn die Tabellengröße keine Primzahl ist: Die bisherige Arbeit an quadratischen Hash-Verfahren ist hauptsächlich auf den Fall beschränkt, in dem die Tabellengröße eine Primzahl ist. Hier werden bestimmte Ergebnisse für zusammengesetzte Zahlen abgeleitet. Es wird gezeigt, dass alle zusammengesetzten Zahlen, die mindestens das Quadrat einer der Primzahlen enthalten, quadratische Hash-Funktionen mit ganzzahligen Koeffizienten haben."}
{"DOCID": "2771", "TEXT": "Die Synthese von Festkörpern, die durch viele Flächen begrenzt sind: Es wird eine Technik vorgestellt, die es ermöglicht, eine Klasse von Festkörpern unter Verwendung eines Computers zu synthetisieren und zu speichern. Die Synthese beginnt mit primitiven Festkörpern wie einem Würfel, Keil oder Zylinder. Jeder Körper kann verschoben, skaliert oder gedreht werden. Feststoffe können auch addiert oder subtrahiert werden. Es werden zwei Algorithmen zur Durchführung der Addition beschrieben. Für praktische Konstrukteure hat die Technik den Vorteil, dass die Operationen prägnant, leicht kombinierbar und in Form von leicht vorstellbaren Körpern gegeben sind. Ziemlich kurze Abfolgen von Operationen reichen aus, um komplexe Körper aufzubauen, die durch viele Flächen begrenzt sind."}
{"DOCID": "2772", "TEXT": "Zur Pflege der Opportunity-Liste bei Klassenlehrer-Stundenplanproblemen: Einer der Hauptbestandteile von Verfahren zur Lösung von Klassenlehrer-Stundenplan-Problemen ist die Pflege der Opportunity-Liste. Methoden zur Pflege von Opportunity-Listen basieren auf notwendigen Bedingungen für die Existenz einer Lösung. Ein allgemeiner Rahmen für notwendige Bedingungen wird zusammen mit vier spezifischen Sätzen notwendiger Bedingungen angegeben."}
{"DOCID": "2773", "TEXT": "Eine gewichtete Buddy-Methode für die dynamische Speicherzuweisung (Korrigendum)"}
{"DOCID": "2774", "TEXT": "Bemerkung zu Algorithmus 475"}
{"DOCID": "2775", "TEXT": "Die Dilogarithmusfunktion eines reellen Arguments [S22] (Algorithmus 490)"}
{"DOCID": "2776", "TEXT": "Computernetzwerke in der Hochschulbildung: Sozioökonomisch-politische Faktoren: Diese Studie präsentiert die Ergebnisse einer landesweiten Erhebung über Computernetzwerke in der Hochschulbildung, die zwischen 1971 und 1973 durchgeführt wurde. Es wurden fünf große und 18 kleinere Netzwerke identifiziert. Zu den fünf Hauptnetzwerken gehörten: das ARPA Net, das California State College-Netzwerk, das University of Iowa/Iowa State University-Netzwerk, die Michigan Educational Research Information Triad, Inc. und das Triangle Universities Computation Center-Netzwerk in North Carolina. Zu den beiden letztgenannten Netzen wurden eingehende Studien durchgeführt. Basierend auf den Erfahrungen dieser Betriebsnetzwerke wird eine Reihe von Faktoren zur Berücksichtigung bei der Entwicklung von Netzwerken identifiziert. Abschließend werden Empfehlungen für die zukünftige Entwicklung von Netzwerken in der Hochschulbildung gegeben."}
{"DOCID": "2777", "TEXT": "Über eine Lösung des Problems des Zigarettenrauchers (ohne bedingte Anweisungen): Dieser Bericht diskutiert ein Problem, das zuerst von Patil eingeführt wurde, der behauptet hat, dass das Problem des Zigarettenrauchers nicht mit den von Dijkstra eingeführten P- und V-Operationen gelöst werden kann, es sei denn, es werden bedingte Anweisungen verwendet. Eine Untersuchung von Patils Beweis zeigt, dass er diese Behauptung nur unter starken Einschränkungen bei der Verwendung von P und V aufgestellt hat. Diese Einschränkungen eliminieren Programmiertechniken, die von Dijkstra und anderen seit der ersten Einführung des Semaphor-Konzepts verwendet wurden. Dieses Papier enthält eine Lösung für das Problem. Es diskutiert auch die Notwendigkeit der von Patil vorgeschlagenen verallgemeinerten Operatoren."}
{"DOCID": "2778", "TEXT": "Störungen der Eigenwerte nichtnormaler Matrizen (Korrigendum)"}
{"DOCID": "2779", "TEXT": "Diskrete Polynomanpassungen der kleinsten Quadrate: Die Wiederholungsbeziehung zwischen orthogonalen Polynomen wird häufig für die diskrete Datenanpassung der kleinsten Quadrate verwendet. Eine Variante des klassischen Algorithmus mit besseren numerischen Eigenschaften wird vorgestellt und der Grund für die verbesserte Leistung erläutert."}
{"DOCID": "2780", "TEXT": "Zur Berechnung bestimmter Elemente des Inversen einer dünnbesetzten Matrix: Es wird ein rekursiver Algorithmus zum Berechnen des Inversen einer Matrix aus den LU-Faktoren basierend auf Beziehungen in Takahashi et al. untersucht. Die Formeln für den Algorithmus sind angegeben; die Abhängigkeitsbeziehungen werden abgeleitet; die Rechenkosten werden entwickelt; und einige allgemeine Bemerkungen zur Anwendung und Stabilität werden gemacht."}
{"DOCID": "2781", "TEXT": "Die Algorithmus-sequenzielle Zugriffsmethode: Eine Alternative zu Index Sequential"}
{"DOCID": "2782", "TEXT": "Eine Antwort auf Gentleman und Marovich"}
{"DOCID": "2783", "TEXT": "Der Algorithmus SELECT – zum Finden des i-ten kleinsten von n Elementen [M1] (Algorithmus 489)"}
{"DOCID": "2784", "TEXT": "Erwartete Zeitgrenzen für die Auswahl: Es wird ein neuer Auswahlalgorithmus vorgestellt, der sich sowohl theoretisch als auch praktisch als im Durchschnitt sehr effizient erwiesen hat. Die Anzahl der Vergleiche, die verwendet werden, um die i-te kleinste von n Zahlen auszuwählen, ist n+min(i,n-i)+o(n). Eine untere Grenze innerhalb von 9 Prozent der obigen Formel wird ebenfalls abgeleitet."}
{"DOCID": "2785", "TEXT": "Glypnir – Eine Programmiersprache für Illiac IV: GLYPNIR ist eine der frühesten existierenden Sprachen, die für die Programmierung des Illiac IV-Computers entwickelt wurde. Die Syntax der Sprache basiert auf ALGOL 60, wurde jedoch erweitert, um es dem Programmierer zu ermöglichen, die Parallelität seines Algorithmus explizit in Form von 64-Wort-Vektoren anzugeben. Dieses Papier beschreibt die Eigenschaften, Ziele und Philosophie der Sprache und diskutiert einige der Probleme, die mit parallelen Computerarchitekturen verbunden sind."}
{"DOCID": "2786", "TEXT": "A System for Typesetting Mathematics: Dieses Papier beschreibt den Entwurf und die Implementierung eines Systems für den Satz von Mathematik. Die Sprache wurde so konzipiert, dass sie von Personen (z. B. Sekretärinnen und mathematischen Schreibkräften), die weder Mathematik noch Schriftsatz kennen, leicht zu erlernen und zu verwenden ist. Die Erfahrung zeigt, dass die Sprache in etwa einer Stunde erlernt werden kann, da sie wenige Regeln und weniger Ausnahmen hat. Bei typischen Ausdrücken werden die Größen- und Schriftartänderungen, die Positionierung, das Zeichnen von Linien und dergleichen, die zum Drucken gemäß mathematischen Konventionen erforderlich sind, alle automatisch durchgeführt. Zum Beispiel ergibt die Eingangssumme von i=o bis unendlich x sub i=pi über 2 (Formel). Die Syntax der Sprache wird durch eine kleine kontextfreie Grammatik spezifiziert; Ein Compiler-Compiler wird verwendet, um einen Compiler zu erstellen, der diese Sprache in Satzbefehle übersetzt. Die Ausgabe kann entweder auf einem Fotosetzer oder auf einem Terminal mit Vorwärts- und Rückwärtsbewegungen in Halbzeilen erfolgen. Das System ist direkt mit Textformatierungsprogrammen verbunden, so dass Mischungen aus Text und Mathematik einfach gehandhabt werden können. Dieses Papier wurde von den Autoren unter Verwendung des beschriebenen Systems gesetzt"}
{"DOCID": "2787", "TEXT": "Matrixreduktion – eine effiziente Methode: Der Beitrag beschreibt eine effiziente Methode zur Reduktion der binären Matrizen, die bei manchen Stundenplanproblemen in der Schule auftreten. Es ist eine Weiterentwicklung dessen, was John Lions beschrieben hat. Es wurde verallgemeinert und angepasst, um in den gesamten Fahrplanprozess zu passen; eine kompaktere Datendarstellung und effizientere Verarbeitungstechniken zu verwenden; mögliches vorhandenes Vorwissen über die Matrix besser auszunutzen. Und es ist als strukturiertes Programm konzipiert, das vom Leser leicht in der Programmiersprache auf hoher oder niedriger Ebene seiner Wahl codiert werden kann. Praktische Tests des Verfahrens haben gezeigt, dass es eine gute Grundlage für einen realistischen Fahrplanalgorithmus darstellt."}
{"DOCID": "2788", "TEXT": "Finden von Kreisen durch ein Array von Akkumulatoren"}
{"DOCID": "2789", "TEXT": "Ein minimales Spanning-Tree-Clustering-Verfahren (Algorithmus R479)"}
{"DOCID": "2790", "TEXT": "Die Elementarschaltungen eines Graphen (Algorithmus R459)"}
{"DOCID": "2791", "TEXT": "Exakte Wahrscheinlichkeiten für R x C-Kontingenztabellen (Algorithmus R434)"}
{"DOCID": "2792", "TEXT": "Jacobi-Polynome (Algorithmus R332)"}
{"DOCID": "2793", "TEXT": "Chi-Quadrat-Quantile (Algorithmus C451)"}
{"DOCID": "2794", "TEXT": "Zustandsraum-, Problemreduktions- und Satzbeweis-Einige-Beziehungen: Dieses Papier schlägt eine bidirektionale Beziehung zwischen Zustandsraum- und Problemreduktionsdarstellungen vor. Es stellt einen Formalismus dar, der auf Operatoren mit mehreren Eingaben und mehreren Ausgaben basiert, der eine Grundlage dafür liefert, die zwei Arten von Darstellungen auf diese Weise zu betrachten. Zur Veranschaulichung wird eine Darstellung des Spracherkennungsproblems verwendet, die auf dem Cocke-Parsing-Algorithmus basiert. Ein Verfahren zum Darstellen von Problemen in der Logik erster Ordnung derart, dass das von einem auflösungsbasierten Theorem-Beweis verwendete Inferenzsystem bestimmt, ob der Satz von Klauseln im State-Spacer-Modus oder im Problemreduktionsmodus interpretiert wird. Die analogen Konzepte der Problemreduktion und des Theorembeweisens sowie die Terminologie, die zu ihrer Bezugnahme verwendet wird, werden erwähnt. Die Beziehung zwischen Problemreduktion, Eingabeauflösung und linearer Auflösung wird diskutiert."}
{"DOCID": "2795", "TEXT": "Satzparaphrasierung von einer konzeptuellen Basis: Ein Modell natürlicher Sprache, das auf einer zugrunde liegenden sprachfreien Bedeutungsrepräsentation basiert, wird beschrieben. Ein auf diesem Modell basierendes Programm ist in der Lage, Satzparaphrasen zu erzeugen, die das Verständnis in Bezug auf einen gegebenen Kontext demonstrieren. Dieser Generator arbeitet in Verbindung mit einem Analysator für natürliche Sprache und einem kombinierten Speicher- und Inferenzmodell. Beim Erzeugen von Sätzen aus Bedeutungsstrukturen verwendet das Programm sowohl die Informationsabruf- als auch die Deduktionsfähigkeiten des Gedächtnismodells. Das Modell umfasst mehrere unterschiedliche Klassen von linguistischem Wissen, die umfassen: (1) ausführbare Tests von konzeptuellen Eigenschaften, die in Unterscheidungsnetzen gespeichert sind; (2) Informationen in Bezug auf konzeptionelle und syntaktische Rollen, gespeichert in einem Wortsinn-Wörterbuch, und (3) grammatikalisches Oberflächenwissen, gespeichert in einer formalen Grammatik."}
{"DOCID": "2796", "TEXT": "Monitore: Ein Betriebssystem-Strukturierungskonzept (Berichtigung)"}
{"DOCID": "2797", "TEXT": "Eine Annäherung erster Ordnung an das optimale Checkpoint-Intervall (Korrigendum)"}
{"DOCID": "2798", "TEXT": "Analyse von verschachtelten Speichersystemen unter Verwendung von Blockierungspuffern: Ein Modell von verschachtelten Speichersystemen wird vorgestellt, und die Analyse des Modells durch Monte-Carlo-Simulation wird diskutiert. Die Simulationen untersuchen die Leistung verschiedener Systemstrukturen, d. h. Schemata zum Senden von Befehlen und Datenanforderungen an das Speichersystem. Die Leistung wird gemessen, indem die Verteilung der Anzahl von Speichermodulen bestimmt wird, die während eines Speicherzyklus in Betrieb sind. Eine wichtige Beobachtung aus diesen Untersuchungen ist, dass das getrennte Gruppieren von Befehls- und Datenanforderungen für Speicher die durchschnittliche Anzahl von Speichermodulen, die während eines Speicherzyklus in Betrieb sind, wesentlich erhöhen kann. Ergebnisse der Simulationen und einer analytischen Studie werden für verschiedene Systemstrukturen angezeigt."}
{"DOCID": "2799", "TEXT": "Stabiles Aktualisieren des Mittelwerts und der Standardabweichung von Daten: Indem der (Stichproben-)Mittelwert eines Datensatzes als Anpassung an diese Daten durch eine konstante Funktion betrachtet wird, wird eine Berechnungsmethode basierend auf einer Matrixformulierung und Givens-Transformationen angegeben. Der (Stichproben-) Mittelwert und die Standardabweichung können aktualisiert werden, wenn sich Daten ansammeln. Das Verfahren ist numerisch stabil und erfordert keine Speicherung der Daten. Methoden zum Umgang mit gewichteten Daten und Datenentfernung werden vorgestellt. Beim Aktualisieren des Mittelwerts und des Quadrats der Standardabweichung erfordert der Prozess keine Quadratwurzeln."}
{"DOCID": "2800", "TEXT": "Zusammenhänge zwischen Genauigkeit und Stabilitätseigenschaften linearer Mehrschrittformeln: Dieser Beitrag beschäftigt sich mit der Stabilität und Genauigkeit von Familien linearer k-Schrittformeln in Abhängigkeit von Parametern, mit besonderem Schwerpunkt auf der numerischen Lösung steifer gewöhnlicher Differentialgleichungen. Für die Genauigkeitsordnung von A(inf)-stabilen Formeln wird eine Obergrenze, p=k, hergeleitet. Für die A(0)-Stabilität werden drei Kriterien angegeben. Es wird gezeigt, dass (1) für p=k, k beliebig, A(inf)-Stabilität bestimmte notwendige Bedingungen für A(0)-Stabilität und strikte Stabilität impliziert (was bedeutet, dass die fremden Wurzeln von p(psi) |psi erfüllen |<1); (2) für p=k=2,3,4 und 5 impliziert A(inf)-Stabilität (für k=5 zusammen mit einer weiteren Nebenbedingung) strikte Stabilität; und (3) für bestimmte Ein-Parameter-Klassen von Formeln mit p=k=3,4 und/oder 5 impliziert A(inf)-Stabilität A(0)-Stabilität."}
{"DOCID": "2801", "TEXT": "Speichereffiziente Darstellung von Dezimaldaten: Normalerweise werden n Dezimalziffern in Computern durch 4n Bits dargestellt. Tatsächlich können zwei BCD-Ziffern durch einen sehr einfachen Algorithmus, der auf der Kombination von zwei Codierungen mit variabler Feldlänge mit fester Länge basiert, optimal und umkehrbar in 7 Bits und drei Ziffern in 10 Bits komprimiert werden. In über der Hälfte der Fälle ergibt sich der komprimierte Code aus dem herkömmlichen BCD-Code durch einfaches Entfernen redundanter 0-Bits. Eine lange Dezimalnachricht kann in dreistellige Blöcke unterteilt und separat komprimiert werden; das Ergebnis weicht nur um 0,34 Prozent von der asymptotischen Mindestlänge ab. Die Hardwareanforderungen sind gering und die Zuordnungen können manuell durchgeführt werden."}
{"DOCID": "2802", "TEXT": "Die neue Mathematik der Computerprogrammierung: Die strukturierte Programmierung hat sich als wichtige Methode für das systematische Entwerfen und Entwickeln von Programmen erwiesen. Strukturierte Programme werden in der Funktionenalgebra als zusammengesetzte Funktionsausdrücke identifiziert. Die algebraischen Eigenschaften dieser Funktionsausdrücke erlauben die Umformulierung (sowohl Erweiterung als auch Reduktion) eines verschachtelten Teilausdrucks unabhängig von seiner Umgebung und modellieren so die sogenannte schrittweise Programmverfeinerung sowie die Programmausführung. Schließlich ist die strukturierte Programmierung durch die Auswahl und Lösung bestimmter elementarer Gleichungen gekennzeichnet, die in der Funktionenalgebra definiert sind. Diese Lösungen können in allgemeinen Formeln angegeben werden, die jeweils einen einzigen Parameter beinhalten, die die gesamte Freiheit darstellen, die bei der Erstellung korrekt strukturierter Programme verfügbar ist."}
{"DOCID": "2803", "TEXT": "Pseudoinverse und konjugierte Gradienten: Dieses Papier ist der Untersuchung von Verbindungen zwischen Pseudoinversen von Matrizen und konjugierten Gradienten und konjugierten Richtungsroutinen gewidmet."}
{"DOCID": "2804", "TEXT": "Elementarteiler von Tensorprodukten: Die Elementarteiler eines Tensorprodukts linearer Transformationen sind seit 40 Jahren bekannt. Diese Arbeit liefert einen kurzen, leicht zugänglichen Beweis dieser Ergebnisse und weist auf eine interessante kombinatorische Konsequenz des Beweises hin."}
{"DOCID": "2805", "TEXT": "Störungen von Eigenwerten nicht normaler Matrizen: Das betrachtete Problem besteht darin, Grenzen für endliche Störungen einfacher und mehrfacher Eigenwerte nicht normaler Matrizen anzugeben, wobei sich diese Grenzen auf die Eigenwerte, die Abweichung von der Normalität und die Frobenius-Norm der Störung beziehen Matrix, aber nicht in Bezug auf das Eigensystem. Es wird gezeigt, dass die abgeleiteten Grenzen für jeden Satz von Matrizen nahezu erreichbar sind."}
{"DOCID": "2806", "TEXT": "Zwei Hadamard-Zahlen für Matrizen: Es wird eine Diskussion über zwei Funktionen der Einträge einer quadratischen Matrix gegeben, die sich beide auf Hadamards Determinantensatz beziehen und einige Vorzüge als Alternativen zu normgebundenen \"Bedingungszahlen\" haben. Einer (für lineare Systeme) ist bekannt; der andere (für Eigensysteme) scheint neu zu sein."}
{"DOCID": "2807", "TEXT": "Zur Stabilität der Gauß-Jordan-Elimination mit Pivotisierung: Die Stabilität des Gauß-Jordan-Algorithmus mit partieller Pivotisierung zur Lösung allgemeiner linearer Gleichungssysteme wird gemeinhin als fragwürdig angesehen. Es zeigt sich, dass Verdächtigungen in vielerlei Hinsicht unbegründet sind, und im Allgemeinen ist der absolute Fehler in der Lösung streng vergleichbar mit dem, der einer Gaußschen Elimination mit partiellem Pivotieren plus Rücksubstitution entspricht. Wenn A jedoch schlecht konditioniert ist, ist das der Gauß-Jordan-Lösung entsprechende Residuum oft viel größer als das der Gaußschen Eliminationslösung entsprechende."}
{"DOCID": "2808", "TEXT": "Die Lemniskaten-Konstanten: Die Lemniskaten-Konstanten und tatsächlich einige der Methoden, mit denen sie tatsächlich berechnet werden, haben eine enorme Rolle in der Entwicklung der Mathematik gespielt. Hier werden einige der verwendeten Methoden beschrieben - die meisten Ableitungen können mit elementaren Methoden erfolgen. Dieses Material kann für Unterrichtszwecke verwendet werden, und es gibt viel relevantes und interessantes historisches Material. Die zum Zweck der Auswertung dieser Konstanten entwickelten Beschleunigungsverfahren sind bei anderen Problemen nützlich."}
{"DOCID": "2809", "TEXT": "Positivität und Normen: In Anlehnung an einige gemeinsame Arbeiten mit A. S. Householder werden der Charakter und die Verwendung algebraischer Methoden in der Theorie der Normen demonstriert. Neue Ergebnisse zu Normen mit Werten in einem archimedischen Vektorverband (der nicht notwendigerweise vollständig geordnet ist) werden angegeben, insbesondere zur Verallgemeinerung von Ordnungseinheitsnormen, L-Normen und M-Normen. Ein Beispiel für die Anwendung auf Operatornormen wird bezüglich der Kontraktionseigenschaften positiver Operatoren gegeben."}
{"DOCID": "2810", "TEXT": "Professionalität im Computerbereich: Der Begriff „professionell“ bedeutet für verschiedene Menschen unterschiedliche Dinge; Dennoch gibt es bestimmte allgemeine technische und soziale Standards, die normalerweise mit einem Fachmann verbunden sind. Außerdem bezieht sich der Begriff eher auf den Praktiker als auf den Forscher. Aber innerhalb der ziemlich weit gefassten Definition wird der Computerpraktiker noch nicht als Fachmann angesehen. Jede der vier Arten von Institutionen – Akademiker, Industrie, Regierung und Berufsgesellschaft – die den Praktiker ausbilden, beschäftigen, regulieren und formen, trägt zum „nicht-professionellen“ Status des Computerpraktikers bei. Die Rollen dieser Institutionen werden untersucht, verschiedene Mängel festgestellt und empfohlene Änderungen vorgeschlagen. Der Berufsstatus wird letztlich nicht verliehen; es ist verdient. Universitäten und insbesondere die Industrie können jedoch bestimmte Verbesserungen vornehmen, um dem Computerpraktiker zu helfen, einen professionellen Status zu erreichen."}
{"DOCID": "2811", "TEXT": "Strukturelle Mustererkennung von Carotis-Pulswellen unter Verwendung eines allgemeinen Wellenform-Parsing-Systems: Ein allgemeines Wellenform-Parsing-System mit Anwendung auf die strukturelle Mustererkennung von Carotis-Pulswellen wird beschrieben. Die Halsschlagader-Pulswelle ist von medizinischer Bedeutung wegen der Veränderung ihrer Struktur, die durch Arterienalterung und kardiovaskuläre Erkrankung induziert wird. Das syntaxgesteuerte Wellenformanalysesystem wurde mit guten Ergebnissen auf diese Pulswellen angewendet, um strukturelle Variationen zu erkennen und zu messen. Das Wellenformanalysesystem ist einem Compiler-Compiler-System nachempfunden und ermöglicht dem Benutzer, anwendungsspezifische Informationen als Daten einzugeben. Es ist somit allgemein genug, um auf andere Wellenformen anwendbar zu sein."}
{"DOCID": "2812", "TEXT": "Computergestützte Analyse und Design von Informationssystemen: Dieses Papier beschreibt die Verwendung computergestützter Analyse für das Design und die Entwicklung eines integrierten Finanzmanagementsystems durch die Navy Material Command Support Activity (NMCSA). Die computergestützte Analyse besteht aus einer Reihe von Verfahren und Computerprogrammen, die speziell entwickelt wurden, um den Prozess des Anwendungssoftwaredesigns, der Computerauswahl und der Leistungsbewertung zu unterstützen. Es gibt vier Hauptkomponenten: Problem Statement Language, Problem Statement Analyzer, Generator of Alternative Designs und Performance Evaluator. Das Anforderungsprofil wurde in ADS (Accurately Defined Systems) geschrieben und mit einem Problem Statement Analyzer für ADS analysiert. Die ADS-Problemdefinition wurde um zusätzliche Informationen ergänzt, um eine vollständige Problemdefinition zu erstellen. Die analysierte Problemstellung wurde in die Form übersetzt, die zur Verwendung durch das SODA-Programm (Systems Optimization and Design Algorithm) zur Generierung alternativer Spezifikationen von Programmmodulen und logischen Datenbankstrukturen erforderlich ist."}
{"DOCID": "2813", "TEXT": "Das Computer Science and Engineering Research Study (COSERS): Das Computer Science and Engineering Research Study (COSERS) wird kurz beschrieben. Die Motivation, Organisation und der Zeitplan für diese NSF-unterstützte Studie werden angegeben. Für mögliche weitere Bezugnahmen sind die Vorsitzenden des Fachgremiums und die Mitglieder des Lenkungsausschusses angegeben."}
{"DOCID": "2814", "TEXT": "Liste der Programmiersprachen für 1974-75"}
{"DOCID": "2815", "TEXT": "Bindung auf hoher Ebene mit Linkern auf niedriger Ebene: Es wird ein einfach zu implementierendes Schema beschrieben, mit dem ein Compiler eine Übereinstimmung zwischen komplexen Datentypen in separat kompilierten Modulen erzwingen kann. Das Schema ist so konzipiert, dass es mit jedem bestehenden Link-Editor oder Link-Loader funktioniert, egal wie mangelhaft. Obskure Laufzeitfehler, die durch inkonsistente Verwendungen verursacht werden, werden durch statische Fehler verhindert, die zur Verbindungszeit erkannt werden."}
{"DOCID": "2816", "TEXT": "Optimale Reorganisation von Distributed Space Disk Files: In den meisten Datenbankorganisationen steigen die Kosten für den Zugriff auf die Datenbank aufgrund von strukturellen Änderungen, die durch Aktualisierungen und Einfügungen verursacht werden. Durch die Reorganisation der Datenbank können die Zugriffskosten reduziert werden. Ein grundlegendes Problem besteht darin, den richtigen Kompromiss zwischen Leistung, Speicherkosten und Reorganisationskosten zu finden. In diesem Dokument werden die optimalen Punkte für die Reorganisation einer Datenbank betrachtet. Es wird eine Plattendateiorganisation beschrieben, die verteilten freien Speicherplatz ermöglicht. Es wird eine Kostenfunktion definiert, die die Mehrkosten aufgrund physikalischer Desorganisation beschreibt, und diese Funktion wird minimiert, um die optimalen Reorganisationspunkte zu erhalten. Numerische Beispiele, die auf den Eigenschaften vorhandener Plattenspeichergeräte basieren, werden gegeben."}
{"DOCID": "2817", "TEXT": "Die Begriffe Konsistenz und Prädikatsperren in einem Datenbanksystem: In Datenbanksystemen greifen Benutzer auf gemeinsam genutzte Daten unter der Annahme zu, dass die Daten bestimmte Konsistenzbedingungen erfüllen. Dieses Papier definiert die Konzepte von Transaktion, Konsistenz und Zeitplan und zeigt, dass Konsistenz erfordert, dass eine Transaktion keine neuen Sperren anfordern kann, nachdem sie eine Sperre freigegeben hat. Dann wird argumentiert, dass eine Transaktion eher eine logische als eine physische Teilmenge der Datenbank sperren muss. Diese Teilmengen können durch Prädikate spezifiziert werden. Es wird eine Implementierung von Prädikatsperren vorgeschlagen, die die Konsistenzbedingung erfüllt."}
{"DOCID": "2818", "TEXT": "Störungen in Multiprozessor-Computersystemen mit verschachteltem Speicher (Berichtigung)"}
{"DOCID": "2819", "TEXT": "Experimente zur Komprimierung von Textdateien: Ein System zur Komprimierung von Dateien, die als Zeichenketten betrachtet werden, wird vorgestellt. Die Methode ist allgemein und gilt gleichermaßen für Englisch, PL/I oder digitale Daten. Das System besteht aus einem Encoder, einem Analyseprogramm und einem Decoder. Zwei Algorithmen zum Codieren einer Zeichenkette unterscheiden sich geringfügig von früheren Vorschlägen. Das Analyseprogramm versucht, einen optimalen Satz von Codes zum Darstellen von Teilzeichenketten der Datei zu finden. Vier neue Algorithmen für diese Operation werden beschrieben und verglichen. Verschiedene Parameter in den Algorithmen werden optimiert, um einen hohen Komprimierungsgrad für Beispieltexte zu erhalten."}
{"DOCID": "2820", "TEXT": "Das Design und die Implementierung eines tabellengesteuerten, interaktiven Diagnoseprogrammiersystems: CAPS ist ein hochgradig interaktiver Diagnose-Compiler/Interpreter, der Programmieranfängern ermöglicht, ziemlich einfache Programme an einem Grafikanzeigeterminal vorzubereiten, zu debuggen und auszuführen. Eine vollständige Syntaxprüfung und die meisten semantischen Analysen werden durchgeführt, wenn das Programm eingegeben und anschließend bearbeitet wird. Die Analyse erfolgt Zeichen für Zeichen. Das bemerkenswerteste Merkmal von CAPS ist seine Fähigkeit, Fehler sowohl zur Kompilierzeit als auch zur Laufzeit automatisch zu diagnostizieren. Fehler werden nicht automatisch korrigiert. Stattdessen interagiert CAPS mit dem Schüler, um ihm zu helfen, die Ursache seines Fehlers zu finden. Die meisten Komponenten von CAPS sind tabellengesteuert, sowohl um den Platzbedarf für die Implementierung zu reduzieren als auch um die Flexibilität des mehrsprachigen Systems zu erhöhen. Über 500 Studenten haben CAPS verwendet, um Fortran, PL/I oder Cobolin in Verbindung mit einem computergestützten Kurs zur Einführung in die Informatik zu lernen."}
{"DOCID": "2821", "TEXT": "Cobol Under Control: Ein Mustersatz von Cobol-Programmierstandards wird angeboten. Diese Standards schränken ein, dass Code sowohl für Daten- als auch für Steuerstrukturen in einer \"strukturierten\" Form entwickelt werden muss. Sie erfordern keine Syntax, die über die vorhandene Cobol-Sprache hinausgeht, und verwenden tatsächlich eine typische begrenzte Teilmenge des ANS-Cobol-Standards von 1974. Diese Standards haben sich in der Praxis als äußerst wertvoll erwiesen und die Kosten und den Zeitaufwand für die Erstellung und Wartung großer Softwaresysteme reduziert, die in Live-Umgebungen mehrerer Kunden eingesetzt wurden."}
{"DOCID": "2822", "TEXT": "Predigten für bescheidene Standards: Copyright 1976, Association for Computing Machinery, Inc. Allgemeine Erlaubnis zur Wiederveröffentlichung, jedoch nicht zu Gewinnzwecken, des gesamten oder eines Teils dieses Materials wird erteilt, vorausgesetzt, dass der Urheberrechtsvermerk von ACM angegeben und auf die Veröffentlichung verwiesen wird seine Ausgabedaten und die Tatsache, dass Nachdruckrechte mit Genehmigung der Association for Computing Machinery gewährt wurden."}
{"DOCID": "2823", "TEXT": "Der Status von Frauen und Minderheiten in der akademischen Informatik: Es werden die Ergebnisse einer Umfrage unter Frauen und Minderheiten in Informatik in den Jahren 1971 bis 1975 vorgestellt. Die Analyse der Daten zeigte, dass effektive Förderprogramme für die Rekrutierung in Graduiertenstudiengängen erforderlich sind, um die Zahl der Frauen und Minderheiten zu erhöhen, die für eine spätere Beschäftigung in der Informatik qualifiziert sind. Außerdem wurde eine mögliche Diskriminierung bei der Beschäftigung von Frauen und Hochschulabsolventen aus Minderheiten aufgedeckt."}
{"DOCID": "2824", "TEXT": "Eine Verbesserung des Martin-Algorithmus zur Berechnung linearer Vorrangfunktionen"}
{"DOCID": "2825", "TEXT": "Die BMD- und BMDP-Serie statistischer Computerprogramme"}
{"DOCID": "2826", "TEXT": "Interaktive Skeleton-Techniken zur Verbesserung der Bewegungsdynamik in der Keyframe-Animation: Eine signifikante Steigerung der Fähigkeit zur Steuerung der Bewegungsdynamik in der Keyframe-Animation wird durch die Skeleton-Steuerung erreicht. Diese Technik ermöglicht es einem Animator, eine komplexe Bewegungssequenz zu entwickeln, indem er eine Strichmännchendarstellung eines Bildes animiert. Diese Steuersequenz wird dann verwendet, um eine Bildsequenz durch die gleiche Bewegung zu treiben. Die Einfachheit des Strichmännchenbildes fördert ein hohes Maß an Interaktion während der Designphase. Seine Kompatibilität mit der grundlegenden Keyframe-Animationstechnik ermöglicht es, dass die Skelettsteuerung selektiv nur auf diejenigen Komponenten einer zusammengesetzten Bildsequenz angewendet wird, die eine Verbesserung erfordern."}
{"DOCID": "2827", "TEXT": "Ein parametrischer Algorithmus zum Zeichnen von Bildern fester Objekte, die aus quadrischen Oberflächen zusammengesetzt sind: Ein Algorithmus zum Zeichnen von Bildern von dreidimensionalen Objekten mit Oberflächen, die aus Patches von quadratischen Oberflächen bestehen, wird beschrieben. Der Schwerpunkt dieses Algorithmus liegt auf der Berechnung der Schnittpunkte von quadratischen Flächen. Es wird ein Parametrierungsschema verwendet. Jede quadrische Oberflächenschnittkurve (QSIC) wird als Satz von Koeffizienten und Parametergrenzen dargestellt. Jeder Wert des Parameters repräsentiert höchstens zwei Punkte, und diese können leicht unterschieden werden. Dieses Schema kann die Koordinaten von Punkten gerader quartischer (vierter Ordnung) Schnittkurven finden, wobei Gleichungen von nicht mehr als zweiter Ordnung verwendet werden. Parametrisierungsmethoden für jeden OSIC-Typ werden ebenso diskutiert wie die Oberflächenbegrenzung und das Entfernen verborgener Oberflächen."}
{"DOCID": "2828", "TEXT": "Hierarchische geometrische Modelle für sichtbare Oberflächenalgorithmen: Die geometrische Struktur, die der Definition der Formen dreidimensionaler Objekte und Umgebungen innewohnt, wird nicht nur zur Definition ihrer relativen Bewegung und Platzierung verwendet, sondern auch zur Unterstützung bei der Lösung vieler anderer Probleme von Produktionssystemen Bilder per Computer. Durch die Verwendung einer Erweiterung traditioneller Strukturinformationen oder einer geometrischen Hierarchie sind fünf signifikante Verbesserungen gegenüber aktuellen Techniken möglich. Erstens wird der Bereich der Komplexität einer Umgebung stark erhöht, während die sichtbare Komplexität einer gegebenen Szene innerhalb einer festen Obergrenze gehalten wird. Zweitens wird ein sinnvoller Weg bereitgestellt, um die in einer Szene dargestellte Menge an Details zu variieren. Drittens wird \"Clipping\" zu einer sehr schnellen logarithmischen Suche nach den auflösbaren Teilen der Umgebung innerhalb des Sichtfelds. Viertens definieren die Rahmen-zu-Rahmen-Kohärenz und das Abschneiden einen grafischen \"Arbeitssatz\" oder Bruchteil der Gesamtstruktur, der im Primärspeicher für den sofortigen Zugriff durch den sichtbaren Oberflächenalgorithmus vorhanden sein sollte. Schließlich legt die geometrische Struktur einen rekursiv absteigenden, sichtbaren Oberflächenalgorithmus nahe, bei dem die Rechenzeit potenziell linear mit der sichtbaren Komplexität der Szene wächst."}
{"DOCID": "2829", "TEXT": "Textur und Reflexion in computergenerierten Bildern: 1974 entwickelte Catmull einen neuen Algorithmus zum Rendern von Bildern bivariater Oberflächenflecken. Dieses Papier beschreibt Erweiterungen dieses Algorithmus in den Bereichen Textursimulation und Beleuchtungsmodelle. Die Parametrisierung eines Patches definiert ein Koordinatensystem, das als Schlüssel zum Abbilden von Mustern auf der Oberfläche verwendet wird. Die Intensität des Musters bei jedem Bildelement wird als gewichteter Durchschnitt von Bereichen der Musterdefinitionsfunktion berechnet. Die Form und Größe dieser Gewichtungsfunktion werden unter Verwendung der Theorie der digitalen Signalverarbeitung gewählt. Der Patch-Rendering-Algorithmus ermöglicht eine genaue Berechnung der Oberfläche senkrecht zum Patch bei jedem Bildelement, wodurch die Simulation der Spiegelreflexionen ermöglicht wird. Die Lichtmenge, die aus einer bestimmten Richtung kommt, wird ähnlich wie bei der Texturabbildung modelliert und dann zu der Intensität addiert, die aus der Texturabbildung erhalten wird. Mehrere Beispiele von Bildern, die unter Verwendung dieser neuen Techniken synthetisiert wurden, sind enthalten."}
{"DOCID": "2830", "TEXT": "Ein Leitfaden für Praktiker zur Adressierung von Algorithmen (Korrigendum)"}
{"DOCID": "2831", "TEXT": "Analyse des PFF-Ersetzungsalgorithmus über ein Semi-Markov-Modell (Korrigendum)"}
{"DOCID": "2832", "TEXT": "Schnellerer Abruf aus Kontextbäumen (Korrigendum): Kontextbäume bieten eine bequeme Möglichkeit, Daten zu speichern, die als Hierarchie von Kontexten betrachtet werden sollen. Diese Anmerkung stellt einen Algorithmus vor, der frühere Kontextbaum-Abrufalgorithmen verbessert. Es basiert auf der Beobachtung, dass bei typischen Verwendungen Kontextänderungen relativ zu Abrufen selten sind, so dass Daten zwischengespeichert werden können, um das Abrufen zu beschleunigen. Eine Suche wird von der Position der vorherigen Suche gestartet und Hilfsstrukturen werden aufgebaut, um die Suche schnell zu machen. Algorithmen zum Hinzufügen und Löschen von Daten und zum Garbage Collection werden skizziert."}
{"DOCID": "2833", "TEXT": "Ein effizienter, inkrementeller, automatischer Garbage Collector: Dieses Dokument beschreibt einen neuen Weg zur Lösung des Speicherrückgewinnungsproblems für ein System wie Lisp, das Speicher automatisch von einem Heap zuweist und den Programmierer nicht dazu auffordert, einen Hinweis darauf zu geben, dass bestimmte Elemente keine sind länger nutzbar oder zugänglich. Ein Referenzzählschema zum Zurückgewinnen von nicht-selbstreferenziellen Strukturen und ein Schema zum Linearisieren, Komprimieren und Kopieren zum Reorganisieren des gesamten Speichers nach Ermessen des Benutzers werden vorgeschlagen. Die Algorithmen sind so ausgelegt, dass sie gut in Systemen funktionieren, die mehrere Speicherebenen und einen großen virtuellen Adressraum verwenden. Sie hängen von der Tatsache ab, dass die meisten Zellen genau einmal referenziert werden und dass die Referenzzählungen nur genau sein müssen, wenn der Speicher zurückgefordert werden soll. Eine Transaktionsdatei speichert Änderungen an Referenzzählungen, und eine Mehrfachreferenztabelle speichert die Zählung für Elemente, auf die mehr als einmal verwiesen wird."}
{"DOCID": "2834", "TEXT": "Effiziente Erzeugung des binär reflektierten Gray-Codes und seine Anwendungen: Es werden Algorithmen vorgestellt, um den binär reflektierten n-Bit-Gray-Code und Codewörter mit festem Gewicht in diesem Code zu erzeugen. Beide Algorithmen sind dahingehend effizient, dass die Zeit, die erforderlich ist, um das nächste Element aus dem aktuellen zu erzeugen, konstant ist. Anwendungen auf die Generierung der Kombinationen von n Dingen, die k gleichzeitig genommen werden, die Zusammensetzung von ganzen Zahlen und die Permutationen einer Multimenge werden diskutiert."}
{"DOCID": "2835", "TEXT": "Rekursionsanalyse zur Compiler-Optimierung: Eine relativ einfache Methode zur Erkennung rekursiver Verwendung von Prozeduren wird zur Verwendung bei der Compiler-Optimierung vorgestellt. Überlegungen zur Implementierung werden diskutiert, und eine Modifikation des Algorithmus wird angegeben, um die Optimierung weiter zu verbessern. Diese Analyse kann auch verwendet werden, um zu bestimmen, welche mögliche Teilmenge von Werten von Variablen angenommen werden könnte, die nur eine relativ kleine diskrete Menge von Werten annehmen können. Am gebräuchlichsten sind Parameter von Variablen, die Werte vom Label-, Prozedur- oder Aufzählungstyp von Pascal annehmen."}
{"DOCID": "2836", "TEXT": "Gewichtete Ableitungsbäume: Die Knoten eines gewichteten Ableitungsbaums sind Gewichtungsfunktionen über dem Vokabular einer kontextfreien Grammatik zugeordnet. Es wird ein Algorithmus zum Konstruieren des optimalen Ableitungsbaums mit der gleichen Struktur wie ein gegebener gewichteter Ableitungsbaum vorgestellt. Außerdem wird die Korrektheit des Algorithmus festgestellt. Das Verfahren kann auf Probleme angewendet werden, die probabilistisches Parsing oder kombinatorische Optimierung beinhalten."}
{"DOCID": "2837", "TEXT": "Neue obere Schranken für die Auswahl: Die minimale Anzahl der Vergleichskomplexität Vi(n) des i-ten Auswahlproblems im ungünstigsten Fall wird betrachtet. Eine neue Obergrenze für Vi(n) verbessert die durch den standardmäßigen Hadian-Sobel-Algorithmus gegebene Grenze durch eine Verallgemeinerung des Kirkpatrick-Hadian-Sobel-Algorithmus und erweitert das Verfahren von Kirkpatrick auf einen viel breiteren Anwendungsbereich. Diese Verallgemeinerung schneidet im Vergleich zu einem neueren Algorithmus von Hyafil gut ab."}
{"DOCID": "2838", "TEXT": "Analyse eines Algorithmus für Echtzeit-Garbage-Collection: Ein Echtzeit-Garbage-Collection-System vermeidet das Anhalten der Operationen eines Listenprozessors für die langen Zeiten, die die Garbage-Collection normalerweise erfordert, indem die Garbage-Collection auf einem zweiten Prozessor parallel zu Listenverarbeitungsoperationen oder darüber durchgeführt wird ein einziger Prozessor, der mit ihnen time-shared ist. Algorithmen zum Wiederherstellen verworfener Listenstrukturen auf diese Weise werden vorgestellt und analysiert, um ausreichende Bedingungen zu bestimmen, unter denen der Listenprozessor niemals auf den Kollektor warten muss. Es hat sich gezeigt, dass diese Techniken höchstens doppelt so viel Verarbeitungsleistung benötigen wie normale Garbage Collectors, wenn sie effizient eingesetzt werden. Es zeigt sich, dass das durchschnittliche Verhalten des Programms sehr nahe an der Worst-Case-Performance liegt, so dass die hinreichenden Bedingungen auch geeignet sind, das typische Verhalten des Algorithmus zu messen."}
{"DOCID": "2839", "TEXT": "Eine Einfügetechnik für einseitig höhenausgeglichene Bäume: Eine Einschränkung für höhenausgeglichene Binärbäume wird vorgestellt. Es ist ersichtlich, dass diese Einschränkung die zusätzlichen Speicheranforderungen um die Hälfte reduziert (von zwei zusätzlichen Bits pro Knoten auf eins) und schnelle Suchfähigkeiten auf Kosten erhöhter Zeitanforderungen zum Einfügen neuer Knoten aufrechterhält."}
{"DOCID": "2840", "TEXT": "Schutz in Betriebssystemen: Ein Modell von Schutzmechanismen in Computersystemen wird vorgestellt und seine Angemessenheit wird argumentiert. Das „Sicherheitsproblem“ für Schutzsysteme nach diesem Modell besteht darin, in einer gegebenen Situation festzustellen, ob ein Subjekt ein bestimmtes Recht an einem Objekt erwerben kann. In eingeschränkten Fällen kann gezeigt werden, dass dieses Problem entscheidbar ist, d. h. es gibt einen Algorithmus, um festzustellen, ob ein System in einer bestimmten Konfiguration sicher ist. Im Allgemeinen und unter überraschend schwachen Annahmen kann nicht entschieden werden, ob eine Situation sicher ist. Verschiedene Implikationen dieser Tatsache werden diskutiert."}
{"DOCID": "2841", "TEXT": "Flächengestaltung in 3-D: Ein experimentelles System zur computergestützten Gestaltung von Freiformflächen in 3D wird beschrieben. Die Flächen werden im System als parametrische Basis-Splines dargestellt. Die Hauptmerkmale des Systems sind: (1) Die Oberflächen werden als isoparametrische Linienzeichnungen auf einem Head-Mounted-Display wiedergegeben und sie werden mit Hilfe eines dreidimensionalen \"Stabs\" entworfen, der 3-D-Bewegungen der ermöglicht Punkte, die die Formen der Oberflächen steuern, (2) alle Interaktionen mit den Oberflächen erfolgen in Echtzeit, und (3) die verwendeten mathematischen Formulierungen setzen keine Kenntnis darüber durch den Benutzer des Systems voraus. Außerdem werden einige der Merkmale untersucht, die Teil eines praktischen 3-D-Systems zum Entwerfen von Raumformen sein sollten."}
{"DOCID": "2842", "TEXT": "The Denotational Semantics of Programming Languages: Dieses Papier ist eine Tutorial-Einführung in die Theorie der Programmiersprachen-Semantik, die von D. Scott und C. Strachey entwickelt wurde. Die Anwendung der Theorie auf die formale Sprachspezifikation wird demonstriert und andere Anwendungen werden untersucht. Die erste betrachtete Sprache, LOOP, ist sehr elementar und ihre Definition führt lediglich in die Notation und Methodik des Ansatzes ein. Dann werden die semantischen Konzepte von Umgebungen, Speichern und Fortsetzungen in Modellklassen von Programmiersprachenmerkmalen eingeführt, und die zugrunde liegende mathematische Theorie der Berechnung nach Scott wird motiviert und skizziert. Abschließend präsentiert der Beitrag eine formale Definition der Sprache GEDANKEN."}
{"DOCID": "2843", "TEXT": "Tools und Philosophie für die Softwareausbildung: Dieses Papier beschreibt eine Reihe von Tools und eine Philosophie für das Unterrichten von Software, die sich in den letzten sieben Jahren im Kurs am MIT als sehr nützlich erwiesen haben. Zu den Tools gehören Programme wie Simulatoren, Grader, Compiler und Monitore. Diese ermöglichen es dem Dozenten, die Grundkonzepte mit relevanten, spannenden und wirtschaftlichen studentischen Projektaktivitäten zu ergänzen."}
{"DOCID": "2844", "TEXT": "Auf ereignisgesteuerte Mechanismen angewendete Heaps"}
{"DOCID": "2845", "TEXT": "Eine Variation des Buddy-Systems für die Plattenspeicherzuweisung: Es wird eine Verallgemeinerung des Buddy-Systems für die Speicherzuweisung beschrieben. Der Satz zulässiger Blockgrößen {SIZE(i)}, i=0,n, muss die Bedingung SIZE(i)=SIZE(i-1)+SIZE(i-k(i)) erfüllen, wobei k ein beliebiges sinnvolles Integer sein kann. geschätzte Funktion. Dadurch ist es möglich, logische Speicherblöcke dazu zu zwingen, mit physikalischen Speicherblöcken, wie Spuren und Zylindern, zusammenzufallen."}
{"DOCID": "2846", "TEXT": "Komprimierte Tries: Dieses Dokument stellt eine neue Datenstruktur vor, die als komprimierter Trie oder C-Trie bezeichnet wird und in Informationsabrufsystemen verwendet werden soll. Es hat die gleiche zugrunde liegende m-äre Baumstruktur wie ein Trie, wobei m ein Parameter des Tries ist, aber während die Felder der Knoten in einem Trie groß genug sein müssen, um einen Schlüssel oder zumindest einen Zeiger zu enthalten, die Felder in einem C-Trie sind nur ein Bit lang. Im Analyseteil der Arbeit wird gezeigt, dass für eine Sammlung von n Schlüsseln die Abrufzeit, gemessen in Form von Bitinspektionen eines Schlüssels, in der Größenordnung von logm(n) und der Speicherbedarf in der Größenordnung von n*( m+log2 n) Bits. Diese Verbesserung der Speicheranforderungen und der Abrufzeit wird auf Kosten der Verringerung der Flexibilität der Struktur erreicht, und daher werden die Aktualisierungskosten erhöht. Zuerst wird der C-Trie als Datenstruktur analysiert, und dann werden verschiedene Methoden seiner Verwendung für relativ statische Datenbanken diskutiert."}
{"DOCID": "2847", "TEXT": "Sampling aus der Gamma-Verteilung auf einem Computer: Dieses Papier beschreibt eine Methode zur Generierung von Gamma-Variablen, die weniger kostspielig zu sein scheint als die kürzlich von Wallace vorgeschlagene Methode. Für große Formparameter (a); die Berechnungskosten sind proportional zu (a), während die Methode von Wallace proportional zu (a) ist. Experimente von Robinson und Lewis zeigen, dass die hier vorgeschlagene Methode für kleine (a) auch die kürzlich von Dieter und Ahrens vorgeschlagenen Methoden dominiert, obwohl diese Methoden für große (a) dominieren. Das hier vorgeschlagene Verfahren verwendet die Zurückweisungstechnik."}
{"DOCID": "2848", "TEXT": "Synthese von Entscheidungsregeln: Entscheidungstabellen können als effektives Werkzeug während eines Interviews verwendet werden, um die Logik von zu automatisierenden Prozessen zu erfassen. Das Ergebnis eines solchen Interviews ist keine Struktur vollständiger Entscheidungstabellen, sondern eine Reihe von Entscheidungsregeln. Der Zweck dieses Papiers ist es, ein Verfahren zur Synthese der Entscheidungsregeln bereitzustellen und somit eine Hilfestellung bei der Entwicklung einer Struktur vollständiger Entscheidungstabellen zu geben."}
{"DOCID": "2849", "TEXT": "Ethernet: Verteilte Paketvermittlung für lokale Computernetzwerke: Ethernet ist ein verzweigtes Broadcast-Kommunikationssystem zum Übertragen digitaler Datenpakete zwischen lokal verteilten Rechenstationen. Der von Ethernet bereitgestellte Pakettransportmechanismus wurde verwendet, um Systeme aufzubauen, die entweder als lokale Computernetzwerke oder lose gekoppelte Multiprozessoren angesehen werden können. Die gemeinsame Kommunikationseinrichtung eines Ethernets, sein Ether, ist ein passives Übertragungsmedium ohne zentrale Steuerung. Die Koordination des Zugangs zum Ether für Paketsendungen wird unter den konkurrierenden Sendestationen unter Verwendung einer kontrollierten statistischen Arbitrierung verteilt. Die Vermittlung von Paketen zu ihren Zielen auf dem Ether wird unter Verwendung von Paketadresserkennung auf die empfangenden Stationen verteilt. Entwurfsprinzipien und Implementierung werden basierend auf Erfahrungen mit einem funktionierenden Ethernet mit 100 Knoten entlang eines Kilometers Koaxialkabel beschrieben. Der Vollständigkeit halber sind ein Modell zum Abschätzen der Leistung unter hoher Last und ein Paketprotokoll für fehlerkontrollierte Kommunikation enthalten."}
{"DOCID": "2850", "TEXT": "Symbolische Ausführung und Programmtest: Dieses Dokument beschreibt die symbolische Ausführung von Programmen. Anstatt einem Programm die normalen Eingaben (z. B. Zahlen) zuzuführen, liefert man Symbole, die willkürliche Werte darstellen. Die Ausführung geht wie bei einer normalen Ausführung weiter, außer dass Werte symbolische Formeln über den Eingabesymbolen sein können. Die schwierigen, aber interessanten Probleme entstehen während der symbolischen Ausführung von bedingten Verzweigungsanweisungen. Ein bestimmtes System namens EFFIGY, das eine symbolische Ausführung zum Testen und Debuggen von Programmen bereitstellt, wird ebenfalls beschrieben. Es führt interpretativ Programme aus, die in einer einfachen Programmiersprache im PL/I-Stil geschrieben sind. Es enthält viele Standard-Debugging-Funktionen, die Fähigkeit, Dinge über symbolische Ausdrücke zu verwalten und zu beweisen, einen einfachen Programmtest-Manager und einen Programmverifizierer. Eine kurze Erörterung der Beziehung zwischen symbolischer Ausführung und Programmprüfung ist ebenfalls enthalten."}
{"DOCID": "2851", "TEXT": "Formale Verifikation paralleler Programme: Zwei formale Modelle für parallele Berechnungen werden vorgestellt: ein abstraktes konzeptionelles Modell und ein Modell paralleler Programme. Das erstgenannte Modell unterscheidet nicht zwischen Steuer- und Datenzuständen. Das letztere Modell beinhaltet die Fähigkeit zur Darstellung eines unendlichen Satzes von Steuerzuständen, indem es erlaubt, dass es beliebig viele Befehlszeiger (oder Prozesse) gibt, die das Programm ausführen. Es wird ein Induktionsprinzip vorgestellt, das die Steuer- und Datenzustandssätze auf der gleichen Grundlage behandelt. Durch die Verwendung von \"Ortsvariablen\" wird beobachtet, dass bestimmte Korrektheitsbedingungen ohne Aufzählung des Satzes aller möglichen Steuerzustände ausgedrückt werden können. Es werden Beispiele vorgestellt, in denen das Induktionsprinzip verwendet wird, um Beweise für gegenseitigen Ausschluss zu demonstrieren. Es wird gezeigt, dass aussageorientierte Beweisverfahren Spezialfälle des Induktionsprinzips sind. Ein Spezialfall der Behauptungsmethode, der Parallelplatz-Behauptungen genannt wird, erweist sich als unvollständig. Anschließend wird eine Formalisierung von \"Deadlock\" vorgestellt. Das Konzept einer \"Norm\" wird eingeführt, was eine Erweiterung des Deadlock-Problems von Floyds Technik zum Beweis der Terminierung ergibt. Ebenfalls diskutiert wird eine Erweiterung des Programmmodells, die es jedem Prozess ermöglicht, seine eigenen lokalen Variablen zu haben, und gemeinsam genutzte globale Variablen zulässt. Auch die Korrektheit bestimmter Implementierungsformen wird diskutiert. Ein Anhang ist enthalten, der diese Arbeit mit früheren Arbeiten über die Erfüllbarkeit bestimmter logischer Formeln in Beziehung setzt."}
{"DOCID": "2852", "TEXT": "The Technology of Computer Center Management: A Proposed Course for Graduate Professional Programs in Computer Science or in Information Systems: McFarlan und Nolan haben sich stark dafür ausgesprochen, den 13 vom ACM Curriculum Committee on Computer vorgeschlagenen Kursen einen Kurs zur Verwaltung von Informationssystemen hinzuzufügen Managementausbildung für Graduate Professional Programs in Information Systems. Dieses Dokument ist ein Bericht über einen Kurs mit dem Titel \"The Technology of Computer Center Management\", der in den letzten vier Jahren bei Purdue angeboten wurde. Der Studiengang ist sowohl für berufsbegleitende Studiengänge der Wirtschaftsinformatik als auch für berufsbegleitende Studiengänge der Informatik geeignet."}
{"DOCID": "2853", "TEXT": "Ein Nummerierungssystem für Permutationen von Kombinationen"}
{"DOCID": "2854", "TEXT": "Multiprocessing Compactifying Garbage Collection (Korrigendum)"}
{"DOCID": "2855", "TEXT": "Ein effizienter Algorithmus zum Verschieben von Listen unter Verwendung eines konstanten Arbeitsbereichs: Es wird ein effizienter Algorithmus zum Verschieben beliebiger Listenstrukturen vorgestellt, wobei kein Speicher (abgesehen von Programmvariablen) verwendet wird, außer dem, der erforderlich ist, um die ursprüngliche Liste und die Kopie zu halten. Die ursprüngliche Liste wird beim Verschieben zerstört. Es sind keine Markierungsbits erforderlich, aber Zeiger auf die Kopie müssen von Zeigern auf das Original unterscheidbar sein. Der Algorithmus ist in der Ausführungsgeschwindigkeit früheren Algorithmen für das gleiche Problem überlegen. Einige Variationen und Erweiterungen des Algorithmus werden diskutiert."}
{"DOCID": "2856", "TEXT": "Der synthetische Ansatz zur Konvertierung von Entscheidungstabellen: Frühere Ansätze für das Problem der automatischen Konvertierung von Entscheidungstabellen in Computerprogramme basierten auf Zerlegung. In jedem Stadium wird eine Bedingung zum Testen ausgewählt und zwei kleinere Probleme (Entscheidungstabellen mit einer Bedingung weniger) werden erstellt. Ein optimales Programm (beispielsweise hinsichtlich durchschnittlicher Ausführungszeit oder Speicherplatz) wird nur durch implizite Aufzählung aller möglichen Entscheidungsbäume unter Verwendung einer Technik wie Branch-and-Bound gefunden. Der in diesem Artikel beschriebene neue Ansatz verwendet die dynamische Programmierung, um einen optimalen Entscheidungsbaum zu synthetisieren, aus dem ein Programm erstellt werden kann. Unter Verwendung dieses Ansatzes wird die Effizienz der Erstellung eines optimalen Programms wesentlich erhöht, was die Erzeugung optimaler Programme für Entscheidungstabellen mit nicht weniger als zehn bis zwölf Bedingungen ermöglicht."}
{"DOCID": "2857", "TEXT": "Referenzieren von Listen durch eine Kante: Eine Kantenreferenz in eine Listenstruktur ist ein Paar von Zeigern auf benachbarte Knoten. Eine solche Referenz erfordert oft wenig zusätzlichen Platz, aber ihre Verwendung kann effiziente Algorithmen liefern. Beispielsweise ist ein kreisförmiger Link zwischen den Enden einer Liste redundant, wenn die Liste immer von dieser Kante referenziert wird, und das Durchlaufen der Liste ist einfacher, wenn dieser Link null ist. Kantenreferenzen ermöglichen auch das Threading von nicht rekursiven Listen, können einige Header-Zellen ersetzen und den berühmten Exklusiv-Oder-Trick zum Doppelverknüpfen von Listen verbessern"}
{"DOCID": "2858", "TEXT": "Ein Verfahren zur Bestimmung von Adressen bei der Adressierung mit variabler Länge: Es wird ein Algorithmus zur Zuweisung von Befehlsadressen und -formaten unter den folgenden Bedingungen vorgestellt: (1) Die Länge des Befehls variiert als Funktion der Entfernung des Befehls von seinem Ziel ; (2) es gibt ein Optimalitätskriterium, das einige bevorzugte Wahlmöglichkeiten vorbehaltlich der Adressierungsbeschränkungen impliziert. Dies kann beispielsweise das Erreichen der kleinsten Anzahl langer Befehle sein, wobei in diesem Fall die Gesamtcodelänge minimiert wird, oder das Minimieren der zugewiesenen Adresse einer bestimmten Stelle im Programm. Der Algorithmus eignet sich für beliebige Programmstrukturen und eine Auswahl von Optimierungskriterien."}
{"DOCID": "2859", "TEXT": "Interferenzen in Multiprozessor-Computersystemen mit verschachteltem Speicher: Dieser Artikel analysiert die Speicherinterferenz, die durch mehrere Prozessoren verursacht wird, die gleichzeitig mehrere Speichermodule verwenden. Exakte Ergebnisse werden für ein einfaches Modell eines solchen Systems berechnet. Der Grenzwert wird für den relativen Grad der Speicherbeeinflussung mit zunehmender Systemgröße abgeleitet. Das Modell des Begrenzungsverhaltens des Systems liefert ungefähre Ergebnisse für das einfache Modell und legt auch nahe, dass die Ergebnisse für eine viel größere Klasse von Modellen gültig sind, einschließlich solcher, die realen Systemen ähnlicher sind, bei denen das einfache Modell gegen einige Programmmessungen getestet wird Verhalten und Simulationen von Systemen unter Verwendung von Speicherreferenzen aus realen Programmen. Die Modellergebnisse liefern einen guten Hinweis auf die Leistung, die von einem realen System dieses Typs erwartet werden sollte."}
{"DOCID": "2860", "TEXT": "A Practitioner's Guide To Addressing Algorithms: Dieses Dokument konsolidiert eine Reihe beliebter Faustregeln, die für das Design von Datensatzadressierungsalgorithmen vorgeschlagen wurden, und diskutiert die Anwendbarkeit dieser Regeln auf große kommerzielle Datenbanken. Richtlinien für die Auswahl von Identifikatortransformationen, Überlauftechniken, Ladefaktoren, Bucket-Größen und Ladereihenfolge und berücksichtigt. Besonderes Augenmerk wird auf die Angemessenheit gängiger Heuristiken zur Bestimmung der primären oder sekundären Bucket-Größen gerichtet. Ein mathematisches Modell, das Speichergeräteeigenschaften und Zeit-/Platzkosten-Kompromisse explizit berücksichtigt, wird verwendet, um die Auswirkung von Designparametern auf die Gesamtsystemkosten zu analysieren. Ein konkretes Gestaltungsbeispiel wird vorgestellt und gelöst."}
{"DOCID": "2861", "TEXT": "Produktion und Beschäftigung von Doktoranden in Informatik"}
{"DOCID": "2862", "TEXT": "Analyse des PFF-Ersetzungsalgorithmus über ein Semi-Markov-Modell: Ein analytisches Modell wird vorgestellt, um die Leistung des Seitenfehlerhäufigkeits(PFF)-Ersetzungsalgorithmus abzuschätzen. In diesem Modell wird das Programmverhalten durch das LRU-Stapelabstandsmodell dargestellt, und der PFF-Ersetzungsalgorithmus wird durch ein Semi-Markov-Modell dargestellt. Unter Verwendung dieser Modelle können solche Parameter wie die Interpage-Fault-Intervallverteilung, die Wahrscheinlichkeit der Anzahl unterschiedlicher Seiten, auf die während eines Interpage-Fault-Intervalls verwiesen wird, etc. analytisch bestimmt werden. Die Verwendung dieser Modelle zum Bewerten dieser Parameterwerte ermöglicht eine Untersuchung der Leistung des Ersetzungsalgorithmus durch Simulieren der Seitenfehlerereignisse anstelle jedes Seitenbezugsereignisses. Dies reduziert die erforderliche Rechenzeit beim Schätzen der Leistung des PFF-Algorithmus erheblich."}
{"DOCID": "2863", "TEXT": "VMIN – Ein optimaler Seitenersetzungsalgorithmus mit variablem Raum: Ein Kriterium zum Vergleichen von Seitenersetzungsalgorithmen mit variablem Raum wird präsentiert. Ein optimaler Seitenersetzungsalgorithmus, VMIN genannt, wird beschrieben und hinsichtlich dieses Kriteriums als optimal gezeigt. Die Ergebnisse der Simulation von VMIN, Dennings Arbeitssatz und der Seitenpartitionierungs-Ersetzungsalgorithmen in fünf virtuellen Speicherprogrammen werden präsentiert, um die mögliche Verbesserung gegenüber den bekannten realisierbaren Algorithmen für variablen Raum zu demonstrieren."}
{"DOCID": "2864", "TEXT": "Merkmale von Programmlokalitäten: Der Begriff \"Lokalität\" wurde verwendet, um die Teilmenge der Segmente eines Programms zu bezeichnen, auf die während einer bestimmten Phase seiner Ausführung Bezug genommen wird. Das Verhalten eines Programms kann hinsichtlich seines Aufenthalts in Lokalitäten unterschiedlicher Größe und Lebensdauer und der Übergänge zwischen diesen Lokalitäten charakterisiert werden. In diesem Papier wird das Konzept einer Lokalität expliziter gemacht durch eine formale Definition dessen, was eine Phase lokalisierten Referenzverhaltens ausmacht, und durch einen entsprechenden Mechanismus für die Erkennung von Lokalitäten in tatsächlichen Referenzketten. Diese Definition sieht die Existenz einer Hierarchie von Orten zu jedem gegebenen Zeitpunkt vor, und die Angemessenheit der Definition wird durch Beispiele belegt, die aus aktuellen Programmen entnommen wurden. Empirische Daten aus einer Stichprobe von Algol 60-Produktionsprogrammen werden verwendet, um Verteilungen von Lokalitätsgrößen und Lebensdauern darzustellen, und diese Ergebnisse werden hinsichtlich ihrer Implikationen für die Modellierung des Programmverhaltens und der Speicherverwaltung in virtuellen Speichersystemen diskutiert."}
{"DOCID": "2865", "TEXT": "Verifizieren von Eigenschaften paralleler Programme: Ein axiomatischer Ansatz: Eine axiomatische Methode zum Beweisen einer Reihe von Eigenschaften paralleler Programme wird vorgestellt. Hoare hat eine Reihe von Axiomen für teilweise Korrektheit angegeben, aber sie sind in den meisten Fällen nicht stark genug. Dieses Papier definiert ein leistungsfähigeres deduktives System, das in gewissem Sinne vollständig für teilweise Korrektheit ist. Ein entscheidendes Axiom sieht die Verwendung von Hilfsvariablen vor, die einem parallelen Programm als Hilfsmittel zum Korrektheitsbeweis hinzugefügt werden. Die Informationen in einem partiellen Korrektheitsbeweis können verwendet werden, um solche Eigenschaften wie gegenseitigen Ausschluss, Blockierungsfreiheit und Programmabbruch zu beweisen. Techniken zur Verifizierung dieser Eigenschaften werden vorgestellt und durch Anwendung auf das Dining-Philosophen-Problem veranschaulicht."}
{"DOCID": "2866", "TEXT": "Prüfung von Monitoren: Interessante Planungs- und sequentielle Eigenschaften von Monitoren können durch die Verwendung von Zustandsvariablen, die die Historie des Monitors aufzeichnen, und durch die Definition erweiterter Beweisregeln für ihre Warte- und Signaloperationen nachgewiesen werden. Diese beiden Techniken werden definiert, diskutiert und auf Beispiele angewendet, um Eigenschaften wie die Freiheit von unbegrenzt wiederholtem Überholen oder unnötiges Warten, Obergrenzen für Warteschlangenlängen und historisches Verhalten zu beweisen."}
{"DOCID": "2867", "TEXT": "Modularisierung und Hierarchie in einer Familie von Betriebssystemen: Dieses Dokument beschreibt die Designphilosophie, die beim Aufbau einer Familie von Betriebssystemen verwendet wird. Es wird gezeigt, dass die Begriffe Modul und Ebene in einer Funktionshierarchie nicht zusammenfallen. Familienmitglieder können viel Software als Ergebnis der Implementierung von Laufzeitmodulen auf der untersten Systemebene gemeinsam nutzen."}
{"DOCID": "2868", "TEXT": "Reflexionen über ein Betriebssystemdesign: Die Hauptmerkmale eines Allzweck-Mehrfachzugriffs-Betriebssystems, das für den CDC 6400 in Berkeley entwickelt wurde, werden vorgestellt, und seine guten und schlechten Punkte werden diskutiert, wie sie im Nachhinein erscheinen. Besondere Merkmale des Entwurfs waren die Verwendung von Schutzfunktionen und die Organisation des Systems in einer Abfolge von Schichten, die jeweils auf den von früheren Schichten bereitgestellten Einrichtungen aufbauen und sich selbst vor den Fehlfunktionen späterer Schichten schützen. Es gab ernsthafte Probleme beim Aufrechterhalten des Schutzes zwischen Schichten, wenn Ebenen zur Speicherhierarchie hinzugefügt wurden; diese Probleme werden diskutiert und eine neue Lösung wird beschrieben."}
{"DOCID": "2869", "TEXT": "Sicherheitskernel-Validierung in der Praxis: Ein Sicherheitskernel ist ein Software- und Hardwaremechanismus, der Zugriffskontrollen innerhalb eines Computersystems erzwingt. Die Korrektheit eines Sicherheitskerns auf einem PDP-11/45 wird bewiesen. Dieses Papier beschreibt die Technik, die verwendet wird, um den ersten Schritt des Beweises auszuführen: die Validierung einer formalen Spezifikation des Programms in Bezug auf ein Axiom für ein sicheres System."}
{"DOCID": "2870", "TEXT": "A Lattice Model of Secure Information Flow: Dieser Beitrag untersucht Mechanismen, die einen sicheren Informationsfluss in einem Computersystem garantieren. Diese Mechanismen werden in einem mathematischen Rahmen untersucht, der geeignet ist, die Anforderungen an einen sicheren Informationsfluss zwischen Sicherheitsklassen zu formulieren. Zentraler Bestandteil des Modells ist eine aus den Sicherheitsklassen abgeleitete und durch die Semantik des Informationsflusses begründete Gitterstruktur. Die Gittereigenschaften erlauben prägnante Formulierungen der Sicherheitsanforderungen verschiedener existierender Systeme und erleichtern den Aufbau von Mechanismen, die Sicherheit erzwingen. Das Modell bietet eine vereinheitlichende Sicht auf alle Systeme, die den Informationsfluss einschränken, ermöglicht deren Klassifizierung nach Sicherheitszielen und schlägt einige neue Ansätze vor. Es führt auch zum Aufbau automatischer Programmzertifizierungsmechanismen zum Verifizieren des sicheren Informationsflusses durch ein Programm."}
{"DOCID": "2871", "TEXT": "Logische Analyse von Programmen: Die meisten gegenwärtigen Systeme zur Verifizierung von Computerprogrammen sind insofern unvollständig, als zwischenzeitliche induktive Behauptungen vom Benutzer manuell bereitgestellt werden müssen, die Beendigung nicht nachgewiesen wird und fehlerhafte Programme nicht behandelt werden. Als einheitliche Lösung für diese Probleme schlägt dieser Artikel vor, eine logische Analyse von Programmen durchzuführen, indem Invarianten verwendet werden, die ausdrücken, was tatsächlich in dem Programm auftritt. Der erste Teil der Arbeit ist Techniken zur automatischen Generierung von Invarianten gewidmet. Der zweite Teil liefert Kriterien für die Verwendung der Invarianten, um gleichzeitig auf Korrektheit (einschließlich Terminierung) oder Unrichtigkeit zu prüfen. Ein dritter Teil untersucht die Implikationen des Ansatzes für die automatische Diagnose und Korrektur logischer Fehler."}
{"DOCID": "2872", "TEXT": "Ein kontraintuitives Beispiel für Computer-Paging (Berichtigung)"}
{"DOCID": "2873", "TEXT": "LG: A Language for Analytic Geometry: Eine dialogorientierte Programmiersprache für analytische Geometrie wird zusammen mit einigen Aspekten ihrer Implementierung beschrieben. Die Sprache ermöglicht die flexible Definition geometrischer Objekte und Elemente, berechnet ihre Parameter und zeigt die Ergebnisse an. Es bietet auch die Möglichkeit, eine geometrische Figur über eine Sammlung von Parametern zu spezifizieren und verschiedene Ortskurven anzuzeigen, die diesen Parametern entsprechen. Ein drittes Merkmal besteht in der Möglichkeit, diese Sprache zu verwenden, um andere benutzerorientierte Sprachen zu entwerfen. LG wurde speziell für die Verwendung durch Nicht-Programmierer entwickelt; es ist leicht zu erlernen und der natürlichen Sprache der Geometrie sehr nahe."}
{"DOCID": "2874", "TEXT": "Eine vergleichende Bewertung der BASIC-Versionen: Von Anfang an ist die BASIC-Sprache in Bezug auf ihre Verwendung, ihren Umfang und ihre Funktionen gewachsen. Dieser Artikel vergleicht zehn der aktuellen Versionen von BASIC miteinander, mit zwei früheren Versionen und mit dem vorgeschlagenen Standard für minimales BASIC. Der Vergleich erfolgt nach den Merkmalen der Versionen und durch rechnerischen Vergleich von Rechen- und Zeit- und Verarbeitungskosten."}
{"DOCID": "2875", "TEXT": "Entwicklung eines internationalen Systems zum rechtlichen Schutz von Computerprogrammen"}
{"DOCID": "2876", "TEXT": "Vorsätzliche Auflösung des Datenschutzes in Datenbanksystemen: Unter Datenschutz in Datenbanksystemen wird traditionell die Kontrolle darüber verstanden, welche Informationen ein bestimmter Benutzer aus einer Datenbank erhalten kann. Dieses Papier befasst sich mit einer anderen, unabhängigen Dimension des Datenschutzes, der Kontrolle darüber, was ein Benutzer mit einer ihm von der Datenbank gelieferten Information tun darf. Die Fähigkeit, die Bereitstellung von Informationen von ihrem Verwendungszweck abhängig zu machen, wird hier als „vorsätzliche Auflösung“ des Datenschutzes bezeichnet. Die praktische Bedeutung der absichtlichen Auflösung wird an mehreren Beispielen demonstriert und ihre Umsetzung diskutiert. Es wird gezeigt, dass eine absichtliche Auflösung erreicht werden kann, dass dies jedoch eine radikale Änderung des traditionellen Ansatzes zum Prozess der Benutzer-Datenbank-Interaktion erfordert. Insbesondere scheint es notwendig zu sein, dass die Datenbank ein gewisses Maß an Kontrolle über das interne Verhalten der mit ihr interagierenden Benutzerprogramme ausübt. Ein Modell für die Benutzer-Datenbank-Interaktion, das eine solche Kontrolle zulässt, wird entwickelt."}
{"DOCID": "2877", "TEXT": "Ein Programmdatenfluss-Analyseverfahren: Die globalen Datenbeziehungen in einem Programm können durch die in diesem Dokument beschriebenen statischen Analyseverfahren offengelegt und kodiert werden. Es wird eine Prozedur angegeben, die alle Definitionen bestimmt, die möglicherweise jeden Knoten des Kontrollflußgraphen des Programms \"erreichen\" können, und alle Definitionen, die an jeder Kante des Graphen \"lebend\" sind. Die Prozedur verwendet eine \"Intervall\"-geordnete Kantenauflistungsdatenstruktur und handhabt reduzierbare und irreduzible Graphen ununterscheidbar."}
{"DOCID": "2878", "TEXT": "Beitritt zu Richtlinien in einem Batch-Computersystem mit mehreren Prioritäten und mehreren Klassen: Man betrachte ein Batch-Computersystem mit mehreren Prioritäten, dem Benutzer aus mehreren unterschiedlichen Klassen beitreten können, seine Gebühren, Dienste und Wartegebühren. Ein solches System wird hier als Semi-Markov-Entscheidungsprozess formuliert, bei dem das Ziel ankommender Benutzer darin besteht, ihren erwarteten Verlust zu minimieren. Die optimale Beitrittsrichtlinie ist eine Richtlinie für ankommende Benutzer, die dem System an einigen seiner Warteschlangen beitreten können, eine Steuerbegrenzungsrichtlinie mit einer einzigen Steuernummer für jede mögliche Warteschlange und die Klasse des Benutzers; ein neu ankommender Benutzer tritt einer Warteschlange bei, die nicht bis zu der Kontrollnummer gefüllt ist, die dieser Warteschlange und der Klasse des Benutzers entspricht. In diesem Papier werden Kontrollzahlen sowie Unter- und Obergrenzen für die Kontrollzahlen und die Kapazitäten der Warteschlangen des Systems abgeleitet."}
{"DOCID": "2879", "TEXT": "Informatik als empirische Untersuchung: Symbole und Suche"}
{"DOCID": "2880", "TEXT": "Eine schnelle Divisionstechnik für konstante Teiler: Ein schneller Algorithmus zur Division durch konstante Teiler wird vorgestellt. Das Verfahren hat sich als sehr nützlich erwiesen, implementiert als Mikrocode auf einer Binärmaschine und kann direkt in Hardware adaptiert werden. Die mathematischen Grundlagen des Algorithmus werden ebenso vorgestellt wie einige Leistungsmaße."}
{"DOCID": "2881", "TEXT": "Ein kontraintuitives Beispiel für Computer-Paging: Ein Gegenbeispiel zu einer natürlichen Vermutung bezüglich der optimalen Art und Weise, Datensätze in Seiten im unabhängigen Referenzmodell des Computer-Paging zu gruppieren, wird gezeigt (eine Organisation gilt als optimal, wenn die \"am längsten nicht verwendete\" Fehlerquote ist minimiert)."}
{"DOCID": "2882", "TEXT": "Ein stochastisches Bewertungsmodell für die Datenbankorganisation in Datenabrufsystemen: Experimentelle Arbeiten zur Bewertung von Datenabrufsystemen im großen Maßstab waren aufgrund ihrer Schwierigkeit und unerschwinglichen Kosten rar. In diesem Dokument wird ein Simulationsmodell eines Datenabrufsystems diskutiert, das die Wirkung hat, die Experimentierkosten erheblich zu senken und Forschungen zu ermöglichen, die noch nie zuvor versucht wurden. Das Modell wurde entwickelt, um die Abrufarbeitslast alternativer Datenabrufsysteme abzuschätzen. Diese Datenabrufsysteme können unter mehreren Datenbankorganisationen organisiert werden, einschließlich Organisationen mit invertierter Liste, verzweigter Liste und zellularer Liste und hybriden Kombinationen dieser Systeme. Die Wirksamkeit der Methodik wird demonstriert, indem das Modell verwendet wird, um die Wirkung von Datenbankorganisationen in Datenabrufsystemen zu untersuchen. Insbesondere wird der Einfluss der Abfragekomplexität analysiert."}
{"DOCID": "2883", "TEXT": "An Application of Heuristic Search Methods to Edge and Contour Detection: Dieses Paper stellt ein Verfahren zur Erkennung von Kanten und Konturen in verrauschten Bildern vor. Die Eigenschaften einer Kante werden in eine Gütezahl eingebettet und das Problem der Kantenerkennung wird zum Problem der Minimierung der gegebenen Gütezahl. Dieses Problem kann als Kürzeste-Wege-Problem auf einem Graphen dargestellt werden und kann unter Verwendung wohlbekannter Graphsuchalgorithmen gelöst werden. Die Beziehungen zwischen dieser Darstellung des Minimierungsproblems und einem dynamischen Programmieransatz werden diskutiert, wobei gezeigt wird, dass das Graphsuchverfahren zu erheblichen Verbesserungen der Rechenzeit führen kann. Darüber hinaus hängt die Rechenzeit bei Verwendung heuristischer Suchverfahren von der Menge des Rauschens im Bild ab. Einige experimentelle Ergebnisse werden angegeben; diese zeigen, wie verschiedene Informationen über die Form der Kontur eines Objekts in die Gütezahl eingebettet werden können, wodurch die Extraktion von Konturen aus verrauschten Bildern und die Trennung von sich berührenden Objekten ermöglicht wird."}
{"DOCID": "2884", "TEXT": "Permutationsaufzählung: Vier neue Permutationsalgorithmen: Klassische Permutationsaufzählungsalgorithmen stoßen auf Sonderfälle, die bei jeder n-ten Permutation zusätzliche Berechnungen erfordern, wenn die n! Permutationen auf n Markierungen. Vier neue Algorithmen haben die Eigenschaft, dass Sonderfälle alle n(n-1)Permutationen auftreten. Zwei der Algorithmen erzeugen die nächste Permutation mit einem einzigen Austausch von zwei Markierungen. Die anderen beiden Algorithmen tauschen selten mehr als zwei Markierungen aus, aber die Regeln zum Erzeugen der nächsten Permutation sind sehr einfach. Leistungstests, die die Ausführung von Zuweisungsanweisungen, Vergleichen, arithmetischen Operationen und subskriptierten Array-Referenzen gezählt haben, haben die Überlegenheit der neuen Algorithmen im Vergleich zu Boothroyds Implementierung des M. B. Well-Algorithmus und Ehrlichs Implementierung des Johnson-Trotter-Algorithmus gezeigt."}
{"DOCID": "2885", "TEXT": "Über Self-Organizing Sequential Search Heuristics: Dieses Papier untersucht eine Klasse von Heuristiken zur Aufrechterhaltung einer sequentiellen Liste in ungefähr optimaler Reihenfolge in Bezug auf die durchschnittliche Zeit, die zum Suchen nach einem bestimmten Element erforderlich ist, unter der Annahme, dass jedes Element mit einer festen Wahrscheinlichkeit unabhängig gesucht wird von früheren durchgeführten Suchen. Es wird gezeigt, dass die Heuristiken \"nach vorne verschieben\" und \"Transposition\" innerhalb eines konstanten Faktors optimal sind, und die Transpositionsregel ist die effizientere der beiden. Empirische Beweise deuten darauf hin, dass die Transposition tatsächlich für jede Verteilung von Suchwahrscheinlichkeiten optimal ist."}
{"DOCID": "2886", "TEXT": "Semantische Bewertung von links nach rechts: Dieses Papier beschreibt Attributgrammatiken und ihre Verwendung für die Definition von Programmiersprachen und Compilern; eine formale Definition von Attributgrammatiken und eine Diskussion einiger ihrer wichtigen Aspekte sind enthalten. Die Arbeit konzentriert sich auf die Auswertung semantischer Attribute in wenigen Durchgängen von links nach rechts über den Ableitungsbaum eines Programms. Es wird eine Bedingung für eine Attributgrammatik angegeben, die sicherstellt, dass die Semantik eines beliebigen Programms in einem einzigen Durchgang über den Ableitungsbaum ausgewertet werden kann, und ein Algorithmus diskutiert, der entscheidet, wie viele Durchgänge von links nach rechts bei gegebenem Attribut im Allgemeinen notwendig sind Grammatik. Diese Begriffe werden anhand einer Beispielgrammatik erläutert, die die Geltungsbereichsregeln von Algol 60 beschreibt. Praktische Fragen, wie die relative Effizienz verschiedener Bewertungsschemata und die Leichtigkeit der Anpassung der Attributgrammatik einer gegebenen Programmiersprache, finden Sie unter left-to -richtige Bewertungsschemata werden diskutiert."}
{"DOCID": "2887", "TEXT": "A Study of Errors, Error-Proneness, and Error Diagnosis in Cobol: Dieses Papier liefert Daten zur Cobol-Fehlerhäufigkeit zur Korrektur von Fehlern in schülerorientierten Compilern, Verbesserung des Unterrichts und Änderungen in der Programmiersprache. Cobol wurde aufgrund der wirtschaftlichen Bedeutung, der weit verbreiteten Verwendung, möglicher Fehler einschließlich des Designs und des Mangels an Forschung untersucht. Die Fehlerarten wurden in einer Pilotstudie identifiziert; Anschließend wurden unter Verwendung der 132 gefundenen Fehlertypen 1.777 Fehler in 1.4000 Läufen von 73 Cobol-Studenten klassifiziert. Die Fehlerdichte war hoch: 20 Prozent der Typen enthielten 80 Prozent der Gesamthäufigkeit, was eine hohe potenzielle Wirksamkeit für eine softwarebasierte Korrektur von Cobol impliziert. Überraschenderweise waren nur vier hochfrequente Fehler fehleranfällig, was ein minimales fehlerinduzierendes Design impliziert. 80 Prozent der Cobol-Schreibfehler waren den vier Fehlerkategorien früherer Forscher zuzuordnen, was impliziert, dass Cobol-Schreibfehler durch bestehende Algorithmen korrigierbar sind. Die Verwendung reservierter Wörter war nicht fehleranfällig, was eine minimale Störung der Verwendung reservierter Wörter impliziert. Über 80 Prozent der Fehlerdiagnosen erwiesen sich als ungenau. Ein solches Feedback ist für Benutzer nicht optimal, insbesondere für den lernenden Benutzer von Cobol."}
{"DOCID": "2888", "TEXT": "Information Reference Coding: Elemente in Geschäftssystemen müssen durch Referenzcodes identifiziert werden, die später als Datencodes und Dateischlüssel in einem zugehörigen Datenverarbeitungssystem verwendet werden können. In Geschäftssystemen, die mit großen Sammlungen integrierter Dateien (Datenbank) verbunden sind, ist es wichtig, Codes auf methodische Weise zuzuweisen, um zukünftige Erweiterungen und Änderungen zu kontrollieren und gleichzeitig die korrekte Programmaktion aufrechtzuerhalten. Die Prinzipien des methodischen Codierens werden diskutiert, und die Art und Weise, wie logische Verbindungen zwischen Datenelementen im Referenzcode-Rahmen widergespiegelt werden müssen, wird anhand eines mengentheoretischen Informationsmodells gezeigt."}
{"DOCID": "2889", "TEXT": "Leistung von höhenausgeglichenen Bäumen: Dieses Papier stellt die Ergebnisse von Simulationen vor, die die Leistung von höhenausgeglichenen (HB[k]) Bäumen untersuchen. Es wird gezeigt, dass die einzige Statistik von HB[1]-Bäumen (AVL-Bäumen), die eine Funktion der Größe des Baums ist, die Zeit ist, um nach einem Element in dem Baum zu suchen. Für ausreichend große Bäume sind die Ausführungszeiten aller Prozeduren zum Pflegen von HB[1]-Bäumen unabhängig von der Größe des Baums. Insbesondere sind durchschnittlich 0,465 Umstrukturierungen pro Einfügung erforderlich, wobei durchschnittlich 2,78 Knoten erneut besucht werden, um die HB[1]-Eigenschaft wiederherzustellen; Pro Löschung sind durchschnittlich 0,214 Umstrukturierungen erforderlich, wobei durchschnittlich 1,91 Knoten erneut besucht werden, um die HB[1]-Eigenschaft wiederherzustellen. Darüber hinaus sind die Ausführungszeiten von Prozeduren zum Aufrechterhalten von HB[k]-Bäumen für k > 1 auch unabhängig von der Größe des Baums, mit Ausnahme der durchschnittlichen Anzahl von Knoten, die bei einer Löschoperation erneut besucht werden, um die HB[k]-Bäume wiederherzustellen. Eigentum auf der Spur zurück. Die Kosten für die Aufrechterhaltung von HB[k]-Bäumen fallen stark ab, wenn das zulässige Ungleichgewicht (k) zunimmt. Sowohl analytische als auch experimentelle Ergebnisse, die die Kosten für die Aufrechterhaltung von HB[k]-Bäumen als Funktion von k zeigen, werden diskutiert."}
{"DOCID": "2890", "TEXT": "Über quadratische adaptive Routingalgorithmen: Zwei analytische Modelle eines Store-and-Forward-Kommunikationsnetzwerks werden konstruiert, eines zum Finden des optimalen Nachrichtenroutings und das andere zum Veranschaulichen des Gleichgewichts (stationärer Zustand), das durch einen adaptiven Routingalgorithmus aufrechterhalten wird. Diese Modelle zeigen, dass adaptives Routing die notwendigen Bedingungen für ein optimales Routing nicht erfüllt. Adaptives Routing neigt dazu, den direkten Pfad zu überlasten und alternative Routen zu wenig zu nutzen, da es die Auswirkungen seiner aktuellen Routing-Entscheidung auf den zukünftigen Zustand des Netzwerks nicht berücksichtigt. Die Form der Optimalitätsbedingungen legt nahe, dass eine Modifikation des adaptiven Algorithmus zu einer Optimalität führen wird. Die Modifikation erfordert die Substitution eines quadratischen Bias-Terms anstelle eines linearen in der Routing-Tabelle, die an jedem Netzwerkknoten geführt wird. Es werden Simulationsergebnisse präsentiert, die die theoretische Analyse für ein einfaches Netzwerk bestätigen."}
{"DOCID": "2891", "TEXT": "An Anomaly in Disk Scheduling: A Comparison of FCFS and SSTF Seek Scheduling Using an Empirical Model for Disk Accesss: Ein Modell für Plattenzugriffe basierend auf veröffentlichten Messungen wird entwickelt. Das Modell wird verwendet, um zu zeigen, dass unter sehr wahrscheinlichen Bedingungen die FCFS-Suchplanung der SSTF-Planung im Sinne einer geringeren mittleren Warteschlangenlänge überlegen ist. Ein einfaches Beispiel einer Ankunftssequenz-Illustration dieser Anomalie wird präsentiert."}
{"DOCID": "2892", "TEXT": "Eine Untersuchung des Leitungs-Overheads im Arpanet: Es werden Form, Umfang und Wirkung des Kommunikations-Leitungs-Overheads im ARPANET betrachtet. Die Quelle dieses Overheads wird in verschiedene Ebenen der Protokollhierarchie unterteilt, und die Eigenschaften jeder Ebene werden zusammengefasst. Dann wird die Leitungseffizienz für verschiedene Modelle der Systemnutzung untersucht. Einige Messungen der Leitungseffizienz für das ARPANET werden präsentiert und durch Extrapolation werden diese Messungen verwendet, um Overhead in einem stark belasteten Netzwerk vorherzusehen. Ähnliche Ergebnisse werden für ein kürzlich vorgeschlagenes Netzwerkprotokoll hergeleitet und mit denen für das aktuelle System verglichen."}
{"DOCID": "2893", "TEXT": "Computer als Innovation in amerikanischen Kommunalverwaltungen: Computer und elektronische Datenverarbeitung sind eine bedeutende technologische Innovation in den Abläufen amerikanischer Kommunalverwaltungen. Dieses Papier stellt fest, dass es zwischen den größeren Kommunalverwaltungen erhebliche Unterschiede in der Geschwindigkeit gibt, mit der sie Computertechnologie einführen, in der Höhe der finanziellen Unterstützung, die sie für EDV bereitstellen, und in Umfang und Ausgereiftheit ihrer automatisierten Anwendungen. Die zentrale Frage, die angesprochen wird, lautet: Was könnte die Unterschiede zwischen den Regierungen in dem Ausmaß erklären, in dem sie Computer einführen und nutzen? Hypothesen werden anhand von Daten von mehr als 500 Stadt- und Landkreisverwaltungen auf mehrere Ströme erklärender Faktoren getestet. Die Ergebnisse identifizieren bestimmte lokale Regierungsmilieus, die für ein höheres Maß an Computerinnovation besonders förderlich sind. Etwas unerwartete Ergebnisse zeigen die signifikanten Auswirkungen der Verteilung der Kontrolle über EDV-Entscheidungen und der vorherrschenden politischen Werte innerhalb der Regierung. Weitere wichtige Faktoren sind der gemessene Bedarf an Computeranwendungen und das Vorhandensein externer Finanzierungsunterstützung für Computer. Schließlich schlägt das Papier einen Rahmen vor, um die wichtigsten Determinanten anderer technologischer Innovationen zu identifizieren."}
{"DOCID": "2894", "TEXT": "Eine Methodik für die Messung interaktiver Computerdienste: Es wird eine Messmethodik beschrieben, die auf interaktive Computerdienste anwendbar ist. Sein Hauptzweck besteht darin, eine externe, benutzerorientierte Bewertung der Computerleistung zu ermöglichen, anstelle der häufiger verwendeten systeminternen Messtechniken. Als externes Messinstrument kommt das NBS Network Measurement System zum Einsatz. Beispieldaten wurden gesammelt und analysiert. Eine Demonstration der Methodik, die zu einer pragmatischen Leistungsbewertung der Ergebnisse führt, ist enthalten."}
{"DOCID": "2895", "TEXT": "Eine Sprache zur formalen Problemspezifikation: Eine Sprache zur Spezifikation des beabsichtigten Verhaltens bei der Kommunikation paralleler Prozesse wird beschrieben. Die Spezifikationen sind Einschränkungen hinsichtlich der Reihenfolge, in der Ereignisse einer Berechnung auftreten können. Die Sprache wird verwendet, um Spezifikationen des Leser/Schreiber-Problems und der Schreiberpriorität des zweiten Leser/Schreiber-Problems zu schreiben."}
{"DOCID": "2896", "TEXT": "Eine Übung zum Korrektheitsnachweis paralleler Programme: Ein paralleles Programm, Dijkstras On-the-Fly-Garbage-Collector, wird mit einer von Owicki entwickelten Beweismethode als korrekt bewiesen. Die feine Verschachtelung in diesem Programm macht es besonders schwer verständlich und erschwert den Beweis erheblich. Schwierigkeiten beim Nachweis der Korrektheit solcher Parallelprogramme werden diskutiert."}
{"DOCID": "2897", "TEXT": "Eine Fallstudie einer neuen Codegenerierungstechnik für Compiler: Jüngste Entwicklungen bei Optimierungstechniken haben ein neues Design für Compiler entstehen lassen. Ein solcher Compiler übersetzt den geparsten Quellcode durch eine Abfolge von Schritten in Code einer niedrigeren Ebene. Jeder Schritt erweitert Anweisungen auf höherer Ebene in Blöcke von Code auf niedrigerer Ebene und führt dann Optimierungen am Ergebnis durch. Jede Anweisung hat nur eine mögliche Erweiterung – die Aufgabe, diesen Code so anzupassen, dass er Sonderfälle ausnutzt, wird von den Optimierungen erledigt. Dieses Papier liefert den Beweis, dass diese Strategie tatsächlich zu gutem Objektcode führen kann. Als ausführliches Beispiel wurde die traditionell schwierige PL/I-Verkettungsaussage untersucht. Es wurde eine Reihe ziemlich einfacher Optimierungen identifiziert, die es dem Compiler ermöglichen, guten Code zu produzieren. Ausgefeiltere Optimierungen können den Objektcode weiter verbessern. Für die meisten Kontexte der verketteten Anweisung schneidet der Code, der von einem Compiler erzeugt wird, der die oben beschriebene Expansions-Optimierungs-Strategie verwendet, im Vergleich zu dem Code, der von einem herkömmlichen PL/I-Optimierungscompiler erzeugt wird, vorteilhaft ab."}
{"DOCID": "2898", "TEXT": "A Conceptual Framework for a Nonprocedural Programming Language: Eine sequentielle Programmiersprache zwingt den Programmierer, explizit die Reihenfolge vorzugeben, in der die Operationen in seinem Programm ausgeführt werden müssen, auch wenn die Reihenfolge für die Lösung seines Problems nicht relevant ist. Die Anforderung, eine irrelevante Reihenfolge anzugeben, kann entfernt werden, wenn die Sprache Möglichkeiten bietet, eine Aufgabe auf nicht prozedurale Weise zu spezifizieren. Im Allgemeinen ermöglicht ein so spezifiziertes Programm eine gleichzeitige Auswertung. Dieses Papier beschreibt einen konzeptionellen Rahmen für eine höhere Programmiersprache, die sowohl nichtprozedurale als auch sequentielle Möglichkeiten bietet. Innerhalb eines Programms können nichtprozedurale und sequentielle Programmmodule frei verschachtelt werden."}
{"DOCID": "2899", "TEXT": "Eine Übersicht über Informatikangebote an kleinen Liberal Arts Colleges.: Die jüngste Lehrplanentwicklung in Informatik zusammen mit Studenten, die daran interessiert sind, Themen in Informatik über die üblichen Programmierkurse hinaus zu verfolgen, hat kleine Liberal Arts Colleges ermutigt, ihr Angebot zu erweitern. Dieses Papier fasst die Ergebnisse einer Umfrage zusammen, die durchgeführt wurde, um die Art der Informatikprogramme zu bestimmen, die an diesen Colleges angeboten werden. Die Ergebnisse zeigen, dass mehr als die Hälfte dieser Hochschulen entweder kein Informatikprogramm haben oder nur Programmierkurse anbieten."}
{"DOCID": "2900", "TEXT": "Einige Theoreme zur Hilfe beim Lösen des Dateizuordnungsproblems: Das Dateizuordnungsproblem – d.h. Das Problem, den optimalen Satz von Netzwerkstandorten zu finden, an denen Kopien einer Datei lokalisiert werden können, ist im Allgemeinen als polynomial vollständig bekannt. Heuristiken und andere Hilfsmittel zum Finden optimaler oder nahezu optimaler Lösungen werden daher dringend benötigt. In diesem Papier stellen wir drei Theoreme vor, die a priori angewendet werden können, um anzuzeigen, dass bestimmte Standorte in eine optimale Allokation einbezogen werden sollten (oder nicht)."}
{"DOCID": "2901", "TEXT": "Ein Codierungsverfahren für Mehrfeld-Sortierung und -Indizierung: Folgen von Zeichenfolgen mit einer zwischen Folgen auferlegten Ordnungsbeziehung werden betrachtet. Es wird ein Codierungsschema beschrieben, das aus einer Folge von Zeichenfolgen eine einzige, die Reihenfolge bewahrende Zeichenfolge erzeugt. Die ursprüngliche Sequenz kann aus der codierten Zeichenfolge wiederhergestellt werden, und eine Sequenz von Zeichenfolgen geht einer anderen voraus, wenn und nur wenn die Codierung der ersten der Codierung der zweiten vorausgeht. Die Zeichenfolgen können eine variable Länge haben, ohne Beschränkung der maximalen Länge, und es müssen keine Symbole für Steuerzwecke reserviert werden. Daher kann jedes Symbol in jeder Zeichenfolge vorkommen. Das Schema ist nützlich für Mehrfeld-Sortierung, Mehrfeld-Indizierung und andere Anwendungen, bei denen das Ordnen in mehr als einem Feld wichtig ist."}
{"DOCID": "2902", "TEXT": "Dynamische Speicherzuweisung in der Computersimulation: Dieses Papier untersucht die Leistung von 35 dynamischen Speicherzuweisungsalgorithmen, wenn sie zur Wartung von Simulationsprogrammen verwendet werden, wie durch 18 Testfälle dargestellt. Die Leistung des Algorithmus wurde in Bezug auf die Verarbeitungszeit, die Speichernutzung und die Fragmentierung des externen Speichers gemessen. Algorithmen, die für jede Größe des verwendeten Speicherblocks separate Listen mit freiem Speicherplatz führen, tendierten dazu, im Vergleich zu anderen Algorithmen recht gut zu funktionieren. Einfache Algorithmen, die auf speichergeordneten Listen (ohne freie Liste) arbeiten, haben überraschend gut funktioniert. Algorithmen, die Zweierpotenz-Blockgrößen verwenden, hatten günstige Verarbeitungsanforderungen, aber im Allgemeinen eine ungünstige Speichernutzung. Algorithmen, die LIFO, FIFO oder speichergeordnete freie Listen verwenden, schnitten im Allgemeinen im Vergleich zu anderen schlecht ab."}
{"DOCID": "2903", "TEXT": "Verbessern von Programmen durch die Einführung von Rekursion: Eine neue Technik der Programmtransformation, \"Rekursion in Einführung\" genannt, wird beschrieben und auf zwei Algorithmen angewendet, die Mustervergleichsprobleme lösen. Durch die Verwendung von Rekursion in der Einführung werden Algorithmen, die einen Stack manipulieren, zunächst in rekursive Algorithmen übersetzt, in denen keine Stack-Operationen auftreten. Diese Algorithmen werden dann einer zweiten Transformation unterzogen, einer Methode der Rekursionseliminierung, die als \"Tabulation\" bezeichnet wird, um Programme mit einer sehr effizienten Laufzeit zu erzeugen. Insbesondere wird gezeigt, wie der schnelle lineare Mustervergleichsalgorithmus von Knuth, Morris und Pratt in wenigen Schritten aus einem einfachen nichtlinearen Stapelalgorithmus abgeleitet werden kann."}
{"DOCID": "2904", "TEXT": "Ein Algorithmus zur Reduktion der Operatorstärke: Ein einfacher Algorithmus, der eine indizierte temporäre Tabelle verwendet, um eine Reduktion der Operatorstärke in stark verbundenen Regionen durchzuführen, wird vorgestellt. Mehrere Erweiterungen, einschließlich des Ersetzens von linearen Funktionstests, werden diskutiert. Diese Algorithmen sollten gut in ein integriertes Paket lokaler Optimierungsalgorithmen passen."}
{"DOCID": "2905", "TEXT": "Perfekte Hashing-Funktionen: Ein Abrufverfahren mit einer einzigen Sonde für statische Sätze: Es wird eine Verfeinerung des Hashings betrachtet, die das Abrufen eines Elements in einer statischen Tabelle mit einer einzigen Sonde ermöglicht. Ausgehend von einem Satz I von Identifikatoren werden zwei Methoden vorgestellt, um auf mechanische Weise perfekte Hash-Funktionen zu erstellen, d. h. Funktionen, die die Elemente von I in eindeutige Adressen umwandeln. Die erste Methode, die „Quotientenreduktionsmethode“, erweist sich als vollständig in dem Sinne, dass für jede Menge I die kleinste Tabelle existiert, in der die Elemente von I gespeichert und aus der sie unter Verwendung einer konstruierten perfekten Hash-Funktion abgerufen werden können nach dieser Methode gefunden werden. Bei ungleichmäßig verteilten Mengen kann dieses Verfahren jedoch ziemlich spärliche Tabellen liefern. Die zweite Methode, die Methode der \"Restreduktion\", ist im obigen Sinne nicht vollständig, aber sie scheint minimale (oder fast minimale) Tabellen für jede Art von Menge zu liefern. Die beiden Techniken sind direkt auf kleine Sets anwendbar. Einige Methoden zur Erweiterung dieser Ergebnisse auf größere Mengen werden ebenfalls vorgestellt. Es wird ein grober Vergleich mit gewöhnlichem Hashing gegeben, der zeigt, dass dieses Verfahren in mehreren praktischen Anwendungen bequem verwendet werden kann."}
{"DOCID": "2906", "TEXT": "Eine Programmiersprache auf sehr hohem Niveau für Datenverarbeitungsanwendungen: Die Anwendungsentwicklung ist heute zu arbeitsintensiv. In den letzten Jahren wurden zunehmend Hochsprachen als Lösung für dieses Problem erforscht. Die Business Definition Language (BDL) ist eine solche Sprache, die auf Probleme der Geschäftsdatenverarbeitung abzielt. Die Konzepte in BDL ahmen diejenigen nach, die sich im Laufe der Jahre in Unternehmen mit manuellen Methoden entwickelt haben. Daraus ergeben sich drei verschiedene Teilsprachen bzw. Komponenten: eine zur Definition der Geschäftsformulare, eine zur Beschreibung der Geschäftsorganisation und eine zum Schreiben von Kalkulationen."}
{"DOCID": "2907", "TEXT": "Der optimale Ansatz für rekursive Programme: Der klassische Fixpunkt-Ansatz für rekursive Programme schlägt vor, den \"am wenigsten definierten Fixpunkt\" als die geeignetste Lösung für ein rekursives Programm zu wählen. Es wird ein neuer Ansatz beschrieben, der einleitend einen \"optimalen Fixpunkt\" vorstellt, der im Gegensatz zum am wenigsten definierten Fixpunkt t die maximale Menge an wertvoller Information verkörpert, die in das Programm eingebettet ist. Die praktischen Implikationen dieses Ansatzes werden diskutiert und Techniken zum Beweis der Eigenschaften des optimalen Fixpunkts t werden angegeben. Die Präsentation ist informell, mit Schwerpunkt auf Beispielen."}
{"DOCID": "2908", "TEXT": "Eine Anmerkung zur reflexionsfreien Permutationsaufzählung"}
{"DOCID": "2909", "TEXT": "Was können wir gegen die unnötige Notationsvielfalt für syntaktische Definitionen tun?"}
{"DOCID": "2910", "TEXT": "Äquivalenz der Hough-Curve-Erkennung zum Template-Matching"}
{"DOCID": "2911", "TEXT": "Anomales Verhalten der Fifty-Prozent-Regel bei der dynamischen Speicherzuweisung: Dieses Papier berichtet von Simulationsdaten, die zeigen, dass bei der dynamischen Speicherzuweisung das durchschnittliche Verhältnis freier zu zugewiesener Blöcke erheblich und in beide Richtungen von den Vorhersagen der 50 Prozent abweichen kann Regel. Es wird eine neue Herleitung angegeben und es wird gezeigt, dass frühere Herleitungen eine Annahme treffen, die häufig verletzt werden kann. Auf der Grundlage der Simulationsdaten und der Ableitung wird die Hypothese aufgestellt, dass das anomale Verhalten aus den kombinierten Effekten der systematischen Platzierung und der Statistik des Freisetzungsprozesses resultiert. Zusätzliche Simulationen unterstützen diese Hypothese. Die systematische Platzierung, die sich auf die natürliche Konvention bezieht, Speicheranforderungen immer demselben Ende des freien Blocks zuzuweisen, der durch die Zuweisungsstrategie ausgewählt wurde, tendiert dazu, Blöcke innerhalb zusammenhängender Gruppen entsprechend ihrer Zuweisungszeit zu ordnen. Der Grad des anomalen Verhaltens hängt davon ab, inwieweit zugewiesene Blöcke in der Reihenfolge ihrer Zuweisung freigegeben werden. Bei nicht-Markovschen Freigabeprozessen variiert das Ausmaß der Korrelation zwischen Zuordnungsreihenfolge und Freigabereihenfolge ungefähr umgekehrt mit dem Variationskoeffizienten der Speicherverweilzeitverteilung. Die Simulationen zeigen, dass die Allokationseffizienz stark von der Verweilzeitverteilung abhängt; Die Effizienz nimmt ab, wenn der Variationskoeffizient der Verteilung zunimmt. Einige praktische Implikationen werden kurz diskutiert."}
{"DOCID": "2912", "TEXT": "Gleichzeitiges Lesen und Schreiben: Das Problem der gemeinsamen Nutzung von Daten durch asynchrone Prozesse wird betrachtet. Es wird davon ausgegangen, dass jeweils nur ein Prozess die Daten ändern kann, gleichzeitiges Lesen und Schreiben jedoch erlaubt ist. Zwei allgemeine Theoreme werden bewiesen, und einige Algorithmen werden vorgestellt, um ihre Verwendung zu veranschaulichen. Dazu gehören eine Lösung für das allgemeine Problem, bei dem ein Lesevorgang wiederholt wird, wenn er möglicherweise ein falsches Ergebnis erhalten hat, und zwei Techniken zum Übertragen von Nachrichten zwischen Prozessen. Diese Lösungen setzen keinen anderen Synchronisierungsmechanismus als Daten voraus, die von einem Prozess geschrieben und von anderen Prozessen gelesen werden können."}
{"DOCID": "2913", "TEXT": "Das Aliasing-Problem in computererzeugten schattierten Bildern: Bestimmte Fehler, wie z. B. gezackte Kanten und verschwindende Details, waren lange ein Ärgernis in digital erzeugten schattierten Bildern. Obwohl sie durch Erhöhen der Auflösung oder Defokussieren des Displays abgeschwächt werden können, führt ein Verständnis dieser Defekte zu effektiveren Methoden. Dieses Papier erklärt die beobachteten Defekte in Form des Aliasing-Phänomens, das abgetasteten Signalen innewohnt, und diskutiert das Vorfiltern als anerkanntes Heilmittel. Eine Methode zur Bewertung von Filtern wird vorgestellt, die Anwendung der Vorfilterung auf Algorithmen für verborgene Oberflächen diskutiert und eine Implementierung eines filternden Tilers zusammen mit Beispielen seiner Wirksamkeit gezeigt."}
{"DOCID": "2914", "TEXT": "Verwendung der LRU-Stapeltiefenverteilung zur Simulation des Paging-Verhaltens: Zwei Familien von Wahrscheinlichkeitsverteilungen wurden zur Verwendung durch ein virtuelles Speichersimulationsmodell benötigt: Fortschritt zwischen Seitenfehlerverteilungen und Arbeitssatzgrößenverteilungen. Alle Mitglieder beider Familien können aus der LRU-Stapeltiefenverteilung abgeleitet werden. Es werden einfache Ausdrücke zur Berechnung beider Arten von Verteilungen angegeben. Abschließend werden Beispiele für beide Familien von Verteilungen gegeben, wie sie aus einer veröffentlichten Stapeltiefenverteilung berechnet wurden."}
{"DOCID": "2915", "TEXT": "Überlegungen zu zukünftigen Aktivitäten zu Programmiersprachenstandards: Dieses Dokument gibt einen Überblick über den aktuellen Stand der Aktivitäten zu Programmiersprachenstandards in Bezug auf die Anomalien, die zwischen den verschiedenen veröffentlichten und vorgeschlagenen Standards für Fortran, Cobol, PL/I und Basic bestehen. Es werden Vorschläge für die Aufnahme von Formalismen in zukünftige Standards und die Erweiterung der Standards um zusätzliche Elemente wie Fehlerbedingungen und Dokumentation gemacht."}
{"DOCID": "2916", "TEXT": "Ein schneller Zeichenfolgen-Suchalgorithmus: Es wird ein Algorithmus vorgestellt, der nach der Position „i“ des ersten Vorkommens einer Zeichenfolge „pat“ in einer anderen Zeichenfolge „string“ sucht. Während der Suchoperation werden die Zeichen von pat, beginnend mit dem letzten Zeichen von pat, abgeglichen. Die Informationen, die durch das Beginnen der Übereinstimmung am Ende des Musters gewonnen werden, ermöglichen es dem Algorithmus oft, in großen Sprüngen durch den zu durchsuchenden Text vorzugehen. Der Algorithmus hat also die ungewöhnliche Eigenschaft, dass in den meisten Fällen nicht alle ersten i Zeichen von string untersucht werden. Die Zahl der tatsächlich untersuchten Zeichen (im Durchschnitt) nimmt mit der Länge des Musters ab. Für ein zufälliges englisches Muster der Länge 5 untersucht der Algorithmus typischerweise i/4 Zeichen der Zeichenfolge, bevor er eine Übereinstimmung bei i findet. Außerdem wurde der Algorithmus so implementiert, dass (im Durchschnitt) weniger als i+patlen Maschinenbefehle ausgeführt werden. Diese Schlussfolgerungen werden durch empirische Beweise und eine theoretische Analyse des durchschnittlichen Verhaltens des Algorithmus gestützt. Das Worst-Case-Verhalten des Algorithmus ist linear in i+patlen, vorausgesetzt, die Verfügbarkeit von Array-Speicherplatz für lineare Tabellen in patlen plus die Größe des Alphabets."}
{"DOCID": "2917", "TEXT": "SITAR: Ein interaktives Textverarbeitungssystem für kleine Computer (Berichtigung)"}
{"DOCID": "2918", "TEXT": "Multiprozessor-Speicherorganisation und Speicherinterferenz: Die Struktur des gemeinsam genutzten Speichers in einem Multiprozessor-Computersystem wird unter besonderer Berücksichtigung des nicht verschachtelten Speichers untersucht. Alternative Speicherorganisationen werden verglichen, und es wird gezeigt, dass eine Heimspeicherorganisation, in der jeder Prozessor einem oder mehreren Speichern zugeordnet ist, in denen sein Adressraum konzentriert ist, beim Reduzieren von Speicherinterferenzen ziemlich effektiv ist. Es hat sich gezeigt, dass die Heimspeicherorganisation für bestimmte spezialisierte Berechnungsprobleme besonders geeignet ist und auch Vorteile in Bezug auf Interferenz und Zuverlässigkeit für allgemeine Berechnungen besitzt. Die Ergebnisse für den verschachtelten Speicher stammen aus früheren Arbeiten und werden zum Vergleich verwendet. Trace-gesteuerte Simulationen werden verwendet, um die Schlussfolgerungen der Analyse zu verifizieren."}
{"DOCID": "2919", "TEXT": "Die Werkbank des Programmierers – eine Maschine für die Softwareentwicklung: Bei fast allen Softwareentwicklungsprojekten wird davon ausgegangen, dass die Programmentwicklungsfunktion auf derselben Maschine ausgeführt wird, auf der das letztendliche System laufen wird. Erst wenn diese Produktionsmaschine ausfällt oder deren Programmierumgebung völlig unzureichend ist, werden Alternativen in Betracht gezogen. In diesem Dokument wird angedeutet, dass es viele andere Situationen gibt, in denen es vorteilhaft wäre, die Programmentwicklung und die Wartungsfunktion auf einem spezialisierten Computer zu trennen, der für diesen Zweck bestimmt ist. Ein solcher Computer wird hier Programmierwerkbank genannt. Die vier grundlegenden Abschnitte des Papiers führen in das Thema ein, skizzieren das allgemeine Konzept, diskutieren Bereiche, in denen sich ein solcher Ansatz als vorteilhaft erweisen könnte, und beschreiben ein funktionierendes System, das dieses Konzept verwendet."}
{"DOCID": "2920", "TEXT": "Spielinterpretation des Deadlock-Vermeidungsproblems: Das Deadlock-Vermeidungsproblem kann informell definiert werden als die Bestimmung der \"sicheren Situationen\" aus einigen a priori-Informationen über die Prozesse, Ressourcen, das Betriebssystem usw., die realisiert werden können, ohne das System zu gefährden reibungslosen Ablauf des Systems. Wenn jeder Prozess seine zukünftigen Bedürfnisse durch ein Flussdiagramm bedarfsdefinierter Schritte spezifiziert, ermöglicht ein globaler Ansatz für das Phänomen und seine Interpretation als Spiel zwischen dem Betriebssystem und den Prozessen die Formalisierung von Risiko- und Sicherheitskonzepten. Die zweiteilige graphische Darstellung dieses Spiels kann dann verwendet werden, um explizit die Menge sicherer Zustände zu konstruieren und ihre Eigenschaften zu untersuchen."}
{"DOCID": "2921", "TEXT": "Reguläre Rechtsteil-Grammatiken und ihre Parser: Dieses Dokument stellt eine Alternative zu kontextfreien Grammatiken vor, die als reguläre Rechtsteil-Grammatiken (RRP) bezeichnet werden und PASCAL-Syntaxdiagrammen ähneln. Formal haben RRP-Grammatiken produktionsrechte Teile, die nichtdeterministische endliche Zustandsmaschinen (FSMs) sind, und als Sonderfall reguläre Ausdrücke, da diese in FSMs konvertiert werden können. RRP-Grammatiken beschreiben die Syntax von Programmiersprachen prägnanter und verständlicher, als dies mit CF-Grammatiken möglich ist. Ebenfalls eingeführt wird eine Klasse von Parsern, RRP LR(m, k)-Parser, die die CF LR(k)-Parser enthält und die gleichen Vorteile bietet. Informell kann ein RRP LR(m, k)-Parser das rechte Ende jedes Handles bestimmen, indem er höchstens k Symbole rechts vom Handle berücksichtigt, und das linke Ende, nachdem das rechte Ende gefunden wurde, indem er höchstens m Symbole berücksichtigt links vom Griff. Ein Mechanismus zum Bestimmen des linken Endes ist erforderlich, da die Länge des Griffs nicht begrenzt ist."}
{"DOCID": "2922", "TEXT": "Zweistufige Kontrollstruktur für nichtdeterministische Programmierung: Die Grundideen der nichtdeterministischen Programmierung werden kritisch überdacht, um eine geeignete Einstellung und einen geeigneten Programmierstil für die Sprache herauszuarbeiten, die eine direkte Kontrolle nichtdeterministischer Merkmale ermöglichen. Die vorgeschlagene Haltung zielt darauf ab, die Reinheit der nichtdeterministischen Formulierung von Suchprozessen auf einer Ebene (der Versuchsebene) beizubehalten und die Koordination der Problemlösungsbemühungen auf eine andere (die Entscheidungsebene) zu verschieben. Die Machbarkeit der Anerkennung dieser beiden Ebenen wird diskutiert, wobei betont wird, dass die auf der Entscheidungsebene zu verwaltende Struktur kontextfrei ist. Die Blätter sind Rechenumgebungen, die jeweils eine untersuchte Alternative enthalten, während die anderen Knoten Auswahlpunkten zugeordnet sind. Gemäß dem vorgeschlagenen Programmierstil wird jedem Auswahlpunkt t eine generative Funktion zugeordnet, die die gewünschte Auswahlstrategie ausdrückt. Der Hauptvorteil dieses Ansatzes ist die Lokalisierung der Suchstrategien: Jeder nichtterminale Knoten des Baums verfolgt den Zustand der Berechnung, wie er war, als der Auswahlpunkt zuletzt abgefragt wurde, und hält gleichzeitig die Strategie zum Koordinieren der verfügbaren Alternativen. Beispiele werden in Bezug auf ND-Lisp gegeben, eine Erweiterung von Lisp, die gemäß diesen Richtlinien entworfen und implementiert wurde."}
{"DOCID": "2923", "TEXT": "High-Level-Datenflussanalyse: Im Gegensatz zur vorherrschenden Verwendung von Low-Level-Zwischentext befasst sich High-Level-Datenflussanalyse mit Programmen im Wesentlichen auf Quellebene und nutzt die im Parse-Baum implizite Kontrollflussinformation. Die Notwendigkeit einer High-Level-Flussanalyse ergibt sich aus mehreren Aspekten der jüngsten Arbeiten zu fortgeschrittenen Methoden der Programmzertifizierung und -optimierung. Dieses Papier schlägt eine einfache allgemeine Methode zur Datenflussanalyse auf hoher Ebene vor, die die freie Verwendung von Escape- und Sprunganweisungen ermöglicht, große Diagramme beim Kompilieren großer Programme vermeidet, die Aktualisierung von Datenflussinformationen erleichtert, um Programmänderungen widerzuspiegeln, und neue globale Informationen ableitet, die hilfreich sind Lösung vieler bekannter globaler Strömungsanalyseprobleme. Eine beispielhafte Anwendung zur Live-Variablenanalyse wird vorgestellt. Viele der beteiligten Graphen werden konstruiert und analysiert, bevor irgendwelche Programme kompiliert werden, wodurch gewisse Kosten vermieden werden, die Low-Level-Methoden wiederholt zur Kompilierzeit verursachen."}
{"DOCID": "2924", "TEXT": "Ein interaktiver Computergrafik-Ansatz zur Oberflächendarstellung: Ein interaktives Computergrafik-Verfahren wurde für die schnelle Erzeugung willkürlich geformter dreidimensionaler Oberflächen entwickelt. Das Verfahren ist eine Synthese aus Spline-Theorie und Algorithmen, einem interaktiven Mittel für die Mensch-Maschine-Kommunikation und Software für die statische oder dynamische Grafikanzeige. Die verwendete Grundtechnik ist ein modifiziertes Lofting-Verfahren, bei dem Schnittkurven durch einheitliche B-Splines dargestellt werden und die Oberfläche zwischen den Schnitten durch Kardinal-Splines interpoliert wird. Zu den Merkmalen dieses Verfahrens gehören Algorithmen, die eine interaktive Modifikation der B-Spline-Darstellung der Schnittkurven ermöglichen. In allen Phasen des Prozesses werden die räumlichen Informationen dem Benutzer grafisch angezeigt. Komplexe Oberflächen können durch die Kombination einer Reihe von Formen erstellt werden, die separat erzeugt und automatisch verbunden wurden. Das System wurde erfolgreich an eine Vielzahl analytischer Routinen für strukturelle, medizinische und grafische Anwendungen angebunden."}
{"DOCID": "2925", "TEXT": "Optimale Oberflächenrekonstruktion aus planaren Konturen: Bei vielen wissenschaftlichen und technischen Unternehmungen muss ein dreidimensionaler Festkörper aus Serienschnitten rekonstruiert werden, entweder um das Verständnis der Objektstruktur zu unterstützen oder um seine automatische Manipulation und Analyse zu erleichtern. Dieses Papier präsentiert eine allgemeine Lösung für das Problem der Konstruktion einer Oberfläche über einem Satz von Querschnittskonturen. Diese Oberfläche, die aus dreieckigen Kacheln zusammengesetzt werden soll, wird konstruiert, indem separat eine optimale Oberfläche zwischen jedem Paar aufeinanderfolgender Konturen bestimmt wird. Die Bestimmung einer solchen Fläche reduziert sich auf das Problem, bestimmte Minimalkostenzyklen in einem gerichteten toroidalen Graphen zu finden. Ein neuer schneller Algorithmus zum Auffinden solcher Zyklen wird verwendet. Ebenfalls entwickelt ist ein geschlossener Ausdruck hinsichtlich der Anzahl von Konturpunkten für eine Obergrenze der Anzahl von Operationen, die erforderlich sind, um den Algorithmus auszuführen. Ein illustriertes Beispiel, das die Konstruktion einer Oberfläche mit minimaler Fläche beinhaltet, die einen menschlichen Kopf beschreibt, ist enthalten."}
{"DOCID": "2926", "TEXT": "Paginierung von B*-Bäumen mit Datensätzen variabler Länge: Es wird eine Strategie für die Paginierung von B*-Bäumen mit Datensätzen variabler Länge vorgestellt. Wenn Datensätze jeder Länge gleichmäßig innerhalb der Datei verteilt sind und wenn eine breite Verteilung von Datensatzlängen innerhalb der Datei existiert, führt diese Strategie zu flachen Bäumen mit schnellen Zugriffszeiten. Die Leistung dieser Strategie in einer Anwendung wird dargestellt, mit der einer anderen Strategie verglichen und analysiert."}
{"DOCID": "2927", "TEXT": "Einige neue Obergrenzen für die Generierung von Primzahlen: Wie hoch ist die Rechenkomplexität bei einer gegebenen ganzen Zahl N, um alle Primzahlen zu finden, die kleiner als N sind? Ein modifiziertes Sieb von Eratosthenes, das doppelt verknüpfte Listen verwendet, ergibt einen Algorithmus von O(N) arithmetischer Komplexität. Es wird gezeigt, dass diese Obergrenze der theoretischen Untergrenze für Siebverfahren ohne Vorverarbeitung entspricht. Die Verwendung von Vorverarbeitungstechniken, die Raum-Zeit- und additiv-multiplikative Kompromisse beinhalten, reduziert diese obere Grenze auf O(N/log logN) und die Bitkomplexität auf O(N logN log log logN). Eine Speicheranforderung wird auch unter Verwendung von O(N logN/log logN)-Bits beschrieben."}
{"DOCID": "2928", "TEXT": "Hardware-Schätzung der primären Speicheranforderungen eines Prozesses: Eine geringfügige Hardware-Erweiterung des Honeywell 6180-Prozessors wird demonstriert, um die ungefähre Bestimmung der primären Speicheranforderungen eines Prozesses in Multics zu ermöglichen. Die für die Berechnung dieser Schätzung erforderliche zusätzliche Hardware besteht aus einem programmzugänglichen Register, das die Fehltrefferrate des für Seitentabellenwörter verwendeten Assoziativspeichers enthält. Diese Schätzung des primären Speicherbedarfs wurde in einer experimentellen Version von Multics verwendet, um den Grad der Multiprogrammierung im System zu steuern und die Speichernutzung in Rechnung zu stellen. Die Abstimmungsparameter des resultierenden Systems zeigen Konfigurationsunempfindlichkeit, und es wird vermutet, dass das System auch Verschiebungen in den Referenzierungseigenschaften seiner Arbeitslast verfolgen und das System in Abstimmung halten würde."}
{"DOCID": "2929", "TEXT": "Eine Analyse der Inline-Substitution für eine strukturierte Programmiersprache: Eine als Inline-Substitution bekannte Optimierungstechnik wird analysiert. Die Optimierung besteht darin, einen Prozeduraufruf durch eine modifizierte Kopie des Prozedurkörpers zu ersetzen. Das allgemeine Problem der Verwendung von Inline-Substitution zur Minimierung der Ausführungszeit in Abhängigkeit von Größenbeschränkungen ts wird formuliert, und es wird eine ungefähre algorithmische Lösung vorgeschlagen. Der Algorithmus hängt von Laufzeitstatistiken über das zu optimierende Programm ab. Vorläufige Ergebnisse für die strukturierte CLU-Programmiersprache weisen darauf hin, dass in Programmen mit einem geringen Rekursionsgrad über 90 Prozent aller Prozeduraufrufe eliminiert werden können, wobei die Größe des kompilierten Codes nur geringfügig zunimmt und die Ausführungszeit geringfügig eingespart wird. Andere Schlussfolgerungen auf der Grundlage dieser Ergebnisse werden ebenfalls präsentiert."}
{"DOCID": "2930", "TEXT": "Der GRE Advanced Test in Computer Science: Dieser Bericht beschreibt den Advanced Test in Computer Science, der kürzlich im Graduate Record Examination Program eingeführt wurde. Das GRE-Programm wird allgemein beschrieben und die Ereignisse, die zur Etablierung des Advanced Computer Science Test geführt haben, werden diskutiert. Inhaltliche Vorgaben und deren Begründung werden gegeben. Eine Reihe von Beispielfragen ist enthalten."}
{"DOCID": "2931", "TEXT": "Logik und Programmiersprachen: Die Logik interessiert sich schon lange dafür, ob Antworten auf bestimmte Fragen prinzipiell berechenbar sind, da das Ergebnis den Möglichkeiten der Formalisierung Grenzen setzt. In jüngerer Zeit sind durch die Entwicklungen in der Komplexitätstheorie präzise Vergleiche der Effizienz von Entscheidungsmethoden verfügbar geworden. Dies sind jedoch Anwendungen auf die Logik, und eine große Frage ist, ob Methoden der Logik für die eher angewandten Teile der Berechenbarkeitstheorie eine Bedeutung in der anderen Richtung haben. Programmiersprachen bieten eine offensichtliche Chance, da ihre syntaktische Formalisierung weit fortgeschritten ist; Die semantische Theorie kann jedoch kaum als vollständig bezeichnet werden. Obwohl wir viele Beispiele haben, müssen wir noch weitreichende mathematische Antworten auf diese Fragen geben: Was ist eine Maschine? Was ist ein berechenbarer Prozess? Wie (oder wie gut) simuliert eine Maschine einen Prozess? Programme geben natürlicherweise Beschreibungen von Prozessen. Die Definition der genauen Bedeutung eines Programms erfordert dann, dass wir erklären, was die Objekte der Berechnung sind (in gewisser Weise die Statik des Problems) und wie sie zu transformieren sind (die Dynamik). Bisher haben die Automaten- und Netztheorien, obwohl sie für die Dynamik am interessantesten sind, nur einen Teil des Gebiets formalisiert, und es wurde vielleicht zu viel Konzentration auf die endlichen und algebraischen Aspekte gegeben. Es scheint, dass das Verständnis von Programmfunktionen auf höherer Ebene uns mit unendlichen Objekten involviert und uns zwingt, mehrere Erklärungsebenen zu durchlaufen, um von den konzeptionellen Ideen bis zur endgültigen Simulation auf einer realen Maschine zu gelangen. Diese Ebenen können mathematisch exakt gemacht werden, wenn wir die richtigen Abstraktionen finden, um die notwendigen Strukturen darzustellen. Die Erfahrung vieler unabhängiger Arbeiter mit der Methode von Datentypen als Gitter (oder Teilordnungen) unter einer Informationsgehaltsordnung und mit ihren kontinuierlichen Abbildungen hat die Flexibilität dieses Ansatzes bei der Bereitstellung von Definitionen und Beweisen demonstriert, die sauber und ohne übertrieben sind Abhängigkeit von Implementierungen. Dennoch bleibt noch viel zu tun, um zu zeigen, wie abstrakte Konzeptualisierungen aktualisiert werden können (oder nicht), bevor wir sagen können, dass wir eine einheitliche Theorie haben."}
{"DOCID": "2932", "TEXT": "Komplexität von Berechnungen: Der Forschungsrahmen für die Theorie der Komplexität von Berechnungen wird beschrieben, wobei die Wechselbeziehung zwischen scheinbar unterschiedlichen Problemen und Methoden betont wird. Anschauliche Beispiele von praktischer und theoretischer Bedeutung werden gegeben. Richtungen für neue Forschung werden diskutiert."}
{"DOCID": "2933", "TEXT": "Ein weiterer Vorteil der Schlüsselwortnotation für die Parameterkommunikation mit Unterprogrammen"}
{"DOCID": "2934", "TEXT": "Kommentar zu Berechnung der k kürzesten Wege in einem Graphen"}
{"DOCID": "2935", "TEXT": "Produktion und Beschäftigung von Doktoranden in Informatik-1976 (Berichtigung)"}
{"DOCID": "2936", "TEXT": "Eine effiziente Datenstruktur für den Simulationsereignissatz: Kürzlich wurden Algorithmen zur Realisierung von Ereignisplanungsroutinen präsentiert, die für Mehrzweck-Simulationssysteme mit diskreten Ereignissen geeignet sind. Einige zeigten eine Leistung, die der von üblicherweise verwendeten einfachen Linked-List-Algorithmen überlegen war. In diesem Artikel wird ein neuer Event-Scheduling-Algorithmus vorgestellt, der zwei Aspekte der besten der zuvor veröffentlichten Algorithmen verbessert. Erstens ist die Leistung des neuen Algorithmus ziemlich unempfindlich gegenüber schiefen Verteilungen, und zweitens beträgt seine Komplexität im ungünstigsten Fall O(n), wobei n die Anzahl der Ereignisse in der Menge ist. Darüber hinaus zeigten Tests, die zur Schätzung der durchschnittlichen Komplexität durchgeführt wurden, dass sie nahezu unabhängig von n ist."}
{"DOCID": "2937", "TEXT": "Eine experimentelle Bewertung von Datentypkonventionen: Die Sprache, in der Programme geschrieben werden, kann einen erheblichen Einfluss auf die Zuverlässigkeit der resultierenden Programme haben. Dieses Papier diskutiert ein Experiment, das die Programmierzuverlässigkeit von Subjekten vergleicht, die eine statisch typisierte Sprache und eine \"typlose\" Sprache verwenden. Die Analyse der Anzahl von Fehlern und der Anzahl von Läufen mit Fehlern zeigt, dass zumindest in einer Umgebung die Verwendung einer statisch typisierten Sprache die Programmierzuverlässigkeit erhöhen kann. Eine detaillierte Analyse der Fehler, die die Probanden beim Programmieren von Lösungen für relativ kleine Probleme machten, zeigt, dass die Probanden Schwierigkeiten hatten, die Darstellung von Daten zu manipulieren."}
{"DOCID": "2938", "TEXT": "Auf dem Weg zu einer Disziplin der Echtzeitprogrammierung: Die Programmierung wird in drei Hauptkategorien mit zunehmender Komplexität der Argumentation bei der Programmvalidierung unterteilt: sequentielle Programmierung, Multiprogrammierung und Echtzeitprogrammierung. Durch Einhaltung einer strengen Programmierdisziplin und durch Verwendung einer geeigneten Hochsprache, die nach dieser Disziplin geformt ist, kann die Komplexität der Argumentation über Nebenläufigkeit und Ausführungszeitbeschränkungen drastisch reduziert werden. Dies ist möglicherweise der einzig praktikable Weg, um Echtzeitsysteme analytisch überprüfbar und letztendlich zuverlässig zu machen. Eine mögliche Disziplin wird skizziert und in Form der Sprachmodula ausgedrückt."}
{"DOCID": "2939", "TEXT": "Abstraktionsmechanismen in CLU: CLU ist eine neue Programmiersprache, die entwickelt wurde, um die Verwendung von Abstraktionen bei der Programmkonstruktion zu unterstützen. Die Arbeit in der Programmiermethodik hat zu der Erkenntnis geführt, dass drei Arten von Abstraktionen – Verfahrens-, Steuerungs- und insbesondere Datenabstraktionen – im Programmierprozess nützlich sind. Von diesen wird nur die prozedurale Abstraktion durch herkömmliche Sprachen durch die Prozedur oder das Unterprogramm gut unterstützt. CLU bietet zusätzlich zu Prozeduren neuartige linguistische Mechanismen, die die Verwendung von Daten unterstützen und Abstraktionen steuern. Dieses Papier bietet eine Einführung in die Abstraktionsmechanismen in CLU. Anhand von Programmierbeispielen wird die Nützlichkeit der drei Arten von Abstraktionen bei der Programmkonstruktion veranschaulicht, und es wird gezeigt, wie CLU-Programme geschrieben werden können, um Abstraktionen zu verwenden und zu implementieren. Die CLU-Bibliothek, die eine inkrementelle Programmentwicklung mit vollständiger Typprüfung zur Kompilierzeit ermöglicht, wird ebenfalls besprochen."}
{"DOCID": "2940", "TEXT": "Abstraktion und Verifizierung in Alphard: Definieren und Spezifizieren von Iterationen und Generatoren: Das Alphard-„Formular“ bietet dem Programmierer ein hohes Maß an Kontrolle über die Implementierung abstrakter Datentypen. In diesem Beitrag werden die Abstraktionstechniken von der einfachen Datendarstellung und Funktionsdefinition bis zur Iterationsanweisung, dem wichtigsten Interaktionspunkt zwischen Daten und der Kontrollstruktur der Sprache selbst, erweitert. Ein Mittel zum Spezialisieren von Alphards Schleifen, um auf abstrakten Entitäten ohne explizite Abhängigkeit von der Repräsentation dieser Entitäten zu arbeiten, wird eingeführt. Es werden Spezifikations- und Verifikationstechniken entwickelt, die es ermöglichen, die Eigenschaften der Generatoren für solche Iterationen in Form von Beweisregeln auszudrücken. Es werden Ergebnisse erhalten, die für allgemeine Sonderfälle dieser Schleifen im Wesentlichen identisch mit den entsprechenden Konstrukten in anderen Sprachen sind. Es wird auch ein Mittel bereitgestellt, um anzuzeigen, dass ein Generator beendet wird."}
{"DOCID": "2941", "TEXT": "Frühe Erfahrungen mit Mesa: Die Erfahrungen der ersten Benutzer von Mesa – hauptsächlich seiner Implementierer – werden diskutiert, und es werden einige Implikationen für Mesa und ähnliche Programmiersprachen vorgeschlagen. Die behandelten spezifischen Themen sind: Modulstruktur und ihre Verwendung beim Definieren von Abstraktionen, Datenstrukturierungsfunktionen in Mesa, ein Äquivalenzalgorithmus für Typen und Typumwandlungen, die Vorteile des Typsystems und warum es gelegentlich verletzt wird, und die Schwierigkeit, die Behandlung von Variantensätzen sicher."}
{"DOCID": "2942", "TEXT": "Eine Algol-basierte Implementierung von SNOBOL 4 Patterns"}
{"DOCID": "2943", "TEXT": "Lucid, eine nichtprozedurale Sprache mit Iteration: Lucid ist ein formales System, in dem Programme geschrieben und Beweise von Programmen durchgeführt werden können. Die Beweise sind besonders einfach nachzuvollziehen und einfach zu erstellen, weil die Aussagen in einem Lucid-Programm einfach Axiome sind, von denen der Beweis durch (fast) herkömmliches logisches Denken mit Hilfe einiger Axiome und Schlußregeln für die speziellen Lucid-Funktionen ausgeht . Als Programmiersprache ist Lucid unkonventionell, weil unter anderem die Reihenfolge der Anweisungen irrelevant ist und Zuweisungsanweisungen Gleichungen sind. Dennoch müssen Lucid-Programme nicht viel anders aussehen als iterative Programme in einer herkömmlichen strukturierten Programmiersprache, die Zuweisungen und bedingte Anweisungen und Schleifen verwendet."}
{"DOCID": "2944", "TEXT": "Verschieben des Garbage-Collection-Overheads auf die Compile-Zeit: Dieses Dokument erörtert Techniken, die es ermöglichen, den Overhead der automatischen Speicherrückgewinnung teilweise auf die Compile-Zeit zu verlagern. Das Papier geht von einem transaktionsorientierten Sammelschema aus, wie es von Deutsch und Bobrow vorgeschlagen wird, dessen notwendige Merkmale zusammengefasst werden. Das Implementieren der beschriebenen Optimierungen erfordert, dass eine globale Flussanalyse auf dem Quellprogramm durchgeführt wird. Es wird gezeigt, dass zur Kompilierzeit bestimmte Programmaktionen abgeleitet werden können, die sich auf die Referenzzählungen von Zellen auswirken. Diese Informationen werden verwendet, um Aktionen zu finden, die abgebrochen werden, wenn der Code ausgeführt wird, und solche, die gruppiert werden können, um eine verbesserte Effizienz zu erreichen."}
{"DOCID": "2945", "TEXT": "Zertifizierung von Programmen für sicheren Informationsfluss: Dieses Dokument stellt einen Zertifizierungsmechanismus zur Überprüfung des sicheren Informationsflusses durch ein Programm vor. Da es die Eigenschaften einer Gitterstruktur zwischen Sicherheitsklassen ausnutzt, ist das Verfahren so einfach, dass es problemlos in die Analysephase der meisten existierenden Compiler aufgenommen werden kann. Angemessene Semantik wird präsentiert und als richtig bewiesen. Eine wichtige Anwendung ist das Confinement-Problem: Der Mechanismus kann nachweisen, dass ein Programm vermeintlich nicht vertrauliche Ergebnisse nicht von vertraulichen Eingabedaten abhängig machen kann."}
{"DOCID": "2946", "TEXT": "Eine Alternative zu Ereigniswarteschlangen für die Synchronisation in Monitoren: Im Monitorkonzept, wie es von Brinch Hansen und Hoare vorgeschlagen wurde, werden Ereignisse zur Synchronisation verwendet. Dieses Dokument beschreibt ein weiteres Synchronisierungs-Primitive, das fast so ausdrucksstark ist wie das bedingte Warten, aber effizienter implementiert werden kann. Eine Implementierung dieses Grundelements in Form von P- und V-Operationen wird zusammen mit einem Korrektheitsbeweis angegeben. Zwei Beispiele werden vorgestellt: das Problem der Leser und Schreiber und das Problem der Informationsströme, die sich einen endlichen Pufferpool teilen."}
{"DOCID": "2947", "TEXT": "SITAR: Ein interaktives Textverarbeitungssystem für kleine Computer: SITAR, ein kostengünstiges interaktives Textverarbeitungs- und Textanalysesystem für nichttechnische Benutzer, ist in vielerlei Hinsicht mit interaktiven bibliografischen Such- und Abrufsystemen vergleichbar, hat jedoch mehrere zusätzliche Merkmale. Es ist auf einem Time-Sharing-Computer PDP/11 implementiert, der von einer CRT mit mikroprogrammierten Editierfunktionen aufgerufen wird. Es verwendet eine einfache Befehlssprache, die eine Funktion, eine Datei und eine Suchschablone bezeichnet, die aus der gewünschten Textzeichenfolge und Zeichenfolgen besteht, die den Kontext begrenzen, in dem der Treffer geliefert werden soll. Umfangreiche Erfahrung mit SITAR zeigt, dass die kombinierten Kräfte einfacher Befehle, String-Orientierung, kreisförmiger Dateistruktur, einer CRT mit lokalem Speicher und Conversational Computing ein System ergeben, das viel leistungsfähiger ist als die Summe seiner Teile."}
{"DOCID": "2948", "TEXT": "Ein Terminal-orientiertes Kommunikationssystem: Dieses Dokument beschreibt ein System für eine Vollduplex-Kommunikation zwischen einem Time-Sharing-Computer und seinen Terminals. Das System besteht aus einem Kommunikationscomputer, der direkt mit dem Timesharing-System verbunden ist, einer Anzahl kleiner entfernter Computer, an denen die Terminals angeschlossen sind, und verbindenden Telefonleitungen mittlerer Geschwindigkeit. Es kann eine große Anzahl von Terminals verschiedener Typen bedienen. Das Gesamtsystemdesign wird zusammen mit den Algorithmen vorgestellt, die verwendet werden, um drei spezifische Probleme zu lösen: lokales Echo, Fehlererkennung und -korrektur auf den Telefonleitungen und Multiplexen der Zeichenausgabe."}
{"DOCID": "2949", "TEXT": "Ein Korrektheitsnachweis eines Wartungsprotokolls für Topologieinformationen für ein verteiltes Computernetzwerk: Damit die Knoten eines verteilten Computernetzwerks kommunizieren können, muss jeder Knoten Informationen über die Topologie des Netzwerks haben. Da Knoten und Links manchmal abstürzen, wird ein Schema benötigt, um diese Informationen zu aktualisieren. Eine der Hauptbeschränkungen für ein solches Topologie-Informationsschema besteht darin, dass es möglicherweise keinen zentralen Controller umfasst. Das im MERIT Computer Network implementierte Topology Information Protocol wird vorgestellt und erklärt; Dieses Protokoll ist ziemlich allgemein und könnte in jedem Computernetzwerk implementiert werden. Es basiert auf Barans „Hot Potato Heuristic Routing Doctrine“. Ein Korrektheitsnachweis dieses Topology Information Protocol wird ebenfalls präsentiert."}
{"DOCID": "2950", "TEXT": "A Unifying Approach to Scheduling: Dieses Papier präsentiert ein Schema zur Klassifizierung von Scheduling-Algorithmen basierend auf einem abstrakten Modell eines Scheduling-Systems, das den Begriff der Priorität formalisiert. Es werden verschiedene Klassen von Scheduling-Algorithmen definiert und mit bestehenden Algorithmen in Beziehung gesetzt. Ein Kriterium für die Implementierungseffizienz eines Algorithmus wird entwickelt und führt zur Definition von zeitinvarianten Algorithmen, die die meisten der allgemein implementierten beinhalten. Für zeitinvariante Algorithmen wird die Abhängigkeit von Verarbeitungsraten von Prioritäten abgeleitet. Das abstrakte Modell stellt einen Rahmen zum Implementieren flexibler Scheduler in realen Betriebssystemen bereit. Als Beispiel für eine solche Implementierung wird der Policy Driven Scheduler von Bernstein und Sharp diskutiert"}
{"DOCID": "2951", "TEXT": "Dynamische Antwortzeitvorhersage für Computernetzwerke: Wenn das letztendliche Ziel eines Computernetzwerks die gemeinsame Nutzung von Ressourcen ist, dann müssen die menschliche Komponente sowie die technische Komponente des Netzwerks vollständig untersucht werden, um dieses Ziel zu erreichen. Diese Forschung ist ein erster Schritt, um den Benutzer bei der Teilnahme an dem riesigen Vorrat an Ressourcen zu unterstützen, die in einem Netzwerk verfügbar sind. Analyse-, Simulations- und statistische Leistungsbewertungswerkzeuge werden verwendet, um die Machbarkeit eines dynamischen Antwortzeitmonitors zu untersuchen, der in der Lage ist, vergleichende Antwortzeitinformationen für Benutzer bereitzustellen, die verschiedene Datenverarbeitungsanwendungen an einem Netzwerk-Datenverarbeitungsknoten verarbeiten möchten. Die Forschung zeigt deutlich, dass derzeit zumindest für die fünf verschiedenen ARPA-Netzwerksysteme, die im Detail untersucht wurden, genügend Systemdaten verfügbar sind, um die Reaktionszeit für Time-Sharing-Netzwerksysteme zu beschreiben und vorherzusagen, da sie von einem gewissen Maß an Systemaktivität oder Lastniveau abhängt ."}
{"DOCID": "2952", "TEXT": "Funktionen realisierbar mit wortparallelen logischen und Zweierkomplement-Additionsanweisungen"}
{"DOCID": "2953", "TEXT": "Hinweise zur Rekursionselimination: Auf das schematische rekursive Verfahren werden verschiedene Methoden der Rekursionselimination angewendet: proc S(x); px dann N(x); S(fx); S(gx); M(x) fi. Prozeduren dieser allgemeinen Form entstehen im Zusammenhang mit Baumdurchquerungen und Sortieralgorithmen. Jede Methode der Rekursionsentfernung beinhaltet die Verwendung eines oder mehrerer Stacks, und die Lösungen werden auf der Grundlage ihrer Laufzeit verglichen."}
{"DOCID": "2954", "TEXT": "A Bounded Storage Algorithm for Copying Cyclic Structures: Ein neuer Algorithmus wird vorgestellt, der zyklische Listenstrukturen unter Verwendung von begrenztem Arbeitsbereich und linearer Zeit kopiert. Im Gegensatz zu einem früheren ähnlichen Algorithmus macht dieser keine Annahmen über das verwendete Speicherzuweisungssystem und verwendet nur Operationen, die wahrscheinlich in einer Hochsprache verfügbar sind. Die Besonderheit dieses Algorithmus ist eine Technik zum zweimaligen Durchlaufen der Struktur mit jeweils demselben Spannbaum, zuerst von links nach rechts und dann von rechts nach links."}
{"DOCID": "2955", "TEXT": "Buddy-Systeme: Es werden zwei Algorithmen zum Implementieren einer Klasse von Buddy-Systemen für die dynamische Speicherzuweisung vorgestellt. Jedes Buddy-System entspricht einem Satz von Wiederholungsbeziehungen, die die bereitgestellten Blockgrößen zueinander in Beziehung setzen. Es werden Analysen der internen Fragmentierung des binären Buddy-Systems, des Fibonacci-Buddy-Systems und des gewichteten Buddy-Systems gegeben. Außerdem werden vergleichende Simulationsergebnisse für interne, externe und vollständige Fragmentierung präsentiert."}
{"DOCID": "2956", "TEXT": "Einige Ideen zu Datentypen in Hochsprachen: Es wird eine Reihe von Fragen untersucht, die sich auf die Vorstellung beziehen, dass ein Datentyp eine Menge von Werten zusammen mit einer Menge primitiver Operationen an diesen Werten ist. Dazu gehören die Notwendigkeit einer Notation zum Iterieren über die Elemente einer beliebigen endlichen Menge (anstelle der engeren Notation für i:= 1 bis n), die Verwendung des Wertebereichs eines Arrays als Datentyp, die Notwendigkeit einer einfache Schreibweise, um Typen von Parametern selbst Parameter sein zu lassen (jedoch auf restriktive Weise), und daraus resultierende Probleme bei der Konvertierung von Werten von einem Typ in einen anderen."}
{"DOCID": "2957", "TEXT": "Datenbankabstraktionen: Aggregation: Aggregation wird als Abstraktion eingeführt, die für die Konzeptualisierung der realen Welt wichtig ist. Aggregation wandelt eine Beziehung zwischen Objekten in ein übergeordnetes Objekt um. Ein neuer Datentyp namens Aggregation wird entwickelt, der unter bestimmten Kriterien der \"Wohldefiniertheit\" Aggregationsabstraktionen spezifiziert. Relationale Datenbanken, die als Sammlungen von Aggregaten definiert sind, sind als Hierarchie auf n-stelligen Relationen strukturiert. Um die Wohldefiniertheit aufrechtzuerhalten, müssen Aktualisierungsoperationen auf solchen Datenbanken zwei Invarianten bewahren. Wohldefinierte Relationen unterscheiden sich von Relationen in dritter Normalform. Es wird gezeigt, dass diese Begriffe komplementär sind und beide beim Datenbankdesign wichtig sind. Es wird eine Top-Down-Methodik für das Datenbankdesign beschrieben, die Entscheidungen bezüglich der Aggregatstruktur von Entscheidungen bezüglich der Schlüsselidentifikation trennt. Es wird vorgeschlagen, dass Aggregattypen und andere Typen, die reale Abstraktionen unterstützen, ohne Implementierungsdetails einzuführen, in Programmiersprachen aufgenommen werden sollten."}
{"DOCID": "2958", "TEXT": "Abstrakte Datentypen und die Entwicklung von Datenstrukturen: Abstrakte Datentypen können eine wichtige Rolle bei der Entwicklung von Software spielen, die zuverlässig, effizient und flexibel ist. Dieser Beitrag präsentiert und diskutiert die Anwendung einer algebraischen Technik zur Spezifikation abstrakter Datentypen. Unter den vorgestellten Beispielen befindet sich eine Top-down-Entwicklung einer Symboltabelle für eine blockstrukturierte Sprache; eine Diskussion über den Beweis ihrer Korrektheit wird gegeben. Der Aufsatz enthält auch eine kurze Erörterung der Probleme, die mit der Konstruktion algebraischer Spezifikationen verbunden sind, die sowohl konsistent als auch vollständig sind."}
{"DOCID": "2959", "TEXT": "Das System für Geschäftsautomatisierung (SBA): Programmiersprache: Das System für Geschäftsautomatisierung (SBA) ist ein System, in dem Anwendungsexperten – Nicht-Programmierer – ihre Anwendungen auf einem Computer beschreiben und ausführen können. Der Benutzer von SBA betrachtet seine Anwendung als Manipulation von Informationen in zweidimensionalen Bildern von Tabellen, Geschäftsformularen und Berichten auf einem Anzeigeterminal. Er kann diese Anwendung schrittweise automatisieren, indem er dem System „Beispiele“ dafür gibt, wie er die Informationen manuell manipuliert. Die Datenbanksprache Query-by-Example ist eine Teilmenge der SBA-Programmiersprache."}
{"DOCID": "2960", "TEXT": "Zwei Ansichten der Datenabstraktion"}
{"DOCID": "2961", "TEXT": "Experimentelle Untersuchungen der Nützlichkeit detaillierter Flussdiagramme in der Programmierung: Dieses Papier beschreibt frühere Forschungen zu Flussdiagrammen und eine Reihe von kontrollierten Experimenten, um die Nützlichkeit detaillierter Flussdiagramme als Hilfsmittel für die Programmzusammensetzung, das Verständnis, die Fehlersuche und die Modifikation zu testen. Es wurde kein statistisch signifikanter Unterschied zwischen Flussdiagramm- und Nicht-Flussdiagramm-Gruppen gezeigt, wodurch die Nützlichkeit detaillierter Flussdiagramme in Frage gestellt wird. Ein Programm für weitere Forschungsarbeiten wird vorgeschlagen."}
{"DOCID": "2962", "TEXT": "Produktion und Beschäftigung von promovierten Informatikern 1976: Es werden Statistiken über die Produktion und Beschäftigung von promovierten Informatikern für das Kalenderjahr 1975-76 vorgelegt. Die Daten umfassen Profile von Doktoranden und Dozenten an 60 Fakultäten, die Doktortitel produzieren, sowie eine Aufschlüsselung der nach Fachgebieten verliehenen Abschlüsse. Signifikante Trends werden festgestellt und Vergleiche mit vergleichbaren Daten aus dem Kalenderjahr 1974-75 angestellt."}
{"DOCID": "2963", "TEXT": "Ein schneller Algorithmus zum Berechnen längster gemeinsamer Teilfolgen: Zuvor veröffentlichte Algorithmen zum Finden der längsten gemeinsamen Teilfolge von zwei Folgen der Länge n hatten im besten Fall eine Laufzeit von O(n^2). Ein Algorithmus für dieses Problem wird vorgestellt, der eine Laufzeit von O((r + n)log n) hat, wobei r die Gesamtzahl der geordneten Positionspaare ist, an denen die beiden Sequenzen übereinstimmen. Somit hat der Algorithmus im ungünstigsten Fall eine Laufzeit von O(n^2 log n). Für jene Anwendungen jedoch, bei denen die meisten Positionen einer Sequenz mit relativ wenigen Positionen in der anderen Sequenz übereinstimmen, kann eine Laufzeit von O(n log n) erwartet werden."}
{"DOCID": "2964", "TEXT": "Ein Ansatz zum optimalen Design von Speicherparametern in Datenbanken"}
{"DOCID": "2965", "TEXT": "Eine optimale Auswertung boolescher Ausdrücke in einem Online-Abfragesystem"}
{"DOCID": "2966", "TEXT": "Die Wahl von Referenzpunkten bei der Dateisuche mit der besten Übereinstimmung: Verbesserungen des erschöpfenden Suchverfahrens der Dateisuche mit der besten Übereinstimmung wurden zuvor erreicht, indem ein Vorverarbeitungsschritt durchgeführt wurde, der die Berechnung von Entfernungen von einem Referenzpunkt umfasste. Dieses Papier diskutiert die richtige Wahl von Referenzpunkten ts und erweitert den vorherigen Algorithmus, um mehr als einen Referenzpunkt t zu verwenden. Es wird gezeigt, dass Referenzpunkte außerhalb von Datenclustern liegen sollten. Die Ergebnisse von Computersimulationen werden präsentiert, die zeigen, dass große Verbesserungen durch die richtige Wahl und Anordnung mehrerer Referenzpunkte erreicht werden können."}
{"DOCID": "2967", "TEXT": "Ein Vergleich von Hardware- und Software-Assoziativspeichern im Zusammenhang mit Computergrafik: Das Associative Processing of Line Drawing (APLD)-System verwendet einen Hardware-Assoziativspeicher und erzeugt, modifiziert, löscht, speichert und ruft zweidimensionale Strichzeichnungen ab, die aus Punkten bestehen , Linien, Rechtecke und Dreiecke. Die APLD-Funktionen wurden auf dem TX-2-Computer im Lincoln Laboratory des M.I.T. unter LEAP Language and Data Structure dupliziert. Ein Vergleich des Hardware-Ansatzes mit der Software-Simulation veranschaulicht die Vorteile des Hardware-Assoziativspeichers in drei Bereichen: (1) Verarbeitungsgeschwindigkeit, (2) Speicheranforderungen und (3) Flexibilität. Die Hauptproblembereiche der Hardware-Assoziativspeichertechnologie, nämlich Eingabe/Ausgabe und Kosteneffektivität, werden ebenfalls angesprochen."}
{"DOCID": "2968", "TEXT": "Ein Vergleich von Baumausgleichsalgorithmen: Mehrere Algorithmen – Höhenausgleich (d. h. AVL und Erweiterungen), Gewichtsausgleich (d. h. BB und WB) und Gesamtumstrukturierung – zum Aufbau ausgeglichener binärer Suchbäume werden verglichen. Die Vergleichskriterien umfassen theoretische Aspekte (z. B. Pfadlängen) und implementierungsunabhängige sowie maschinen-/algorithmusabhängige Maße (z. B. Laufzeit). Eine detaillierte Analyse des Codes wird auch auf einer Ebene präsentiert, von der angenommen wird, dass sie sprach- und compilerunabhängig ist. Die Qualität der resultierenden Bäume und der Aufwand für deren Erstellung werden analysiert und einige Richtlinien für einen effizienten Einsatz der Methoden gegeben. Wenn das Einfügen und nachfolgende Abfragen die einzigen interessanten Operationen sind, dann weisen \"reine\" AVL-Bäume die insgesamt besten Qualitäten auf."}
{"DOCID": "2969", "TEXT": "Optimale Programm- und Datenorte in Computernetzwerken: Es wird ein Optimierungsverfahren für die Zuordnung von Programm- und Datendateien in einem Computernetzwerk vorgestellt. Dieser Algorithmus berücksichtigt die Abhängigkeiten zwischen Dateien und Programmen, wie sie in realen heterogenen Rechnernetzen vorkommen. Aus dem Modell können auch Erkenntnisse darüber gewonnen werden, ob Programme von einem Computer auf einen anderen konvertiert werden sollen oder nicht. Eine Suchprozedur für das Dateiortproblem wird zusammen mit einem Beispiel und einer möglichen Anwendung des Modells beschrieben."}
{"DOCID": "2970", "TEXT": "Erzielen spezifischer Genauigkeit bei der Simulationsausgabeanalyse: Dieses Dokument erweitert die Verwendung der regenerativen Eigenschaft von Warteschlangensystemen bei der Analyse der Simulationsausgabe. Insbesondere beschreibt sie ein sequentielles Schätzverfahren, das es bei Verwendung mit der Regenerationseigenschaft ermöglicht, Ergebnisse mit spezifizierter statistischer Genauigkeit zu erhalten. Dieses Verfahren beinhaltet einen Test zur Überprüfung der Normalitätsannahme, auf der das sequentielle Verfahren beruht. Das Papier veranschaulicht das Verfahren unter Verwendung des Leer- und Ruhezustands als regenerativen Zustand. Ein zweites Beispiel beschreibt dann, wie die Verwendung des am häufigsten eingetretenen Zustands als regenerativer Zustand die Wahrscheinlichkeit verringert, in einem vorläufigen Simulationslauf einen kostspieligen Fehler zu machen. Das Papier beschrieb auch, wie ein Varianzreduktionsverfahren nach Seite [9] verwendet werden kann, um eine spezifizierte Genauigkeit mit erheblich weniger Auftragsabschlüssen zu erhalten, als erforderlich wären, wenn kein Varianzreduktionsverfahren angewendet wird."}
{"DOCID": "2971", "TEXT": "SP/k: Ein System zum Lehren der Computerprogrammierung: SP/k ist eine kompatible Teilmenge der PL/I-Sprache, die zum Lehren der Programmierung entwickelt wurde. Die Merkmale der SP/k-Sprache wurden ausgewählt, um eine strukturierte Problemlösung durch Computer zu fördern, die Sprache leicht erlernbar und benutzerfreundlich zu machen, verwirrende und redundante Konstrukte zu eliminieren und die Sprache leicht kompilierbar zu machen. Die resultierende Sprache eignet sich zur Einführung von Programmierkonzepten, die in verschiedenen Anwendungen verwendet werden, darunter Geschäftsdatenverarbeitung, wissenschaftliche Berechnungen und nicht-numerische Berechnungen. SP/k ist eigentlich eine Folge von Sprachuntergruppen namens SP/1, SP/2, ... SP/8. Jede Teilmenge führt neue Programmiersprachenkonstrukte ein, während alle Konstrukte der vorhergehenden Teilmengen beibehalten werden. Jede Teilmenge ist genau definiert und kann ohne die folgenden Teilmengen erlernt oder implementiert werden."}
{"DOCID": "2972", "TEXT": "Beweistechniken für hierarchisch strukturierte Programme: Es wird eine Methode zur Beschreibung und Strukturierung von Programmen vorgestellt, die den Beweis ihrer Korrektheit vereinfacht. Die Methode stellt formal ein Programm in Form von Abstraktionsebenen dar, von denen jede Ebene durch eine in sich geschlossene, nicht prozedurale Spezifikation beschrieben werden kann. Die Nachweise sind, wie auch die Programme, nach Niveaus gegliedert. Obwohl in der Veröffentlichung nur manuelle Proofs beschrieben werden, ist das Verfahren auch auf halbautomatische und automatische Proofs anwendbar. Vorläufige Ergebnisse sind ermutigend und weisen darauf hin, dass die Methode auf große Programme wie Betriebssysteme angewendet werden kann."}
{"DOCID": "2973", "TEXT": "Sortieren auf einem mit Mesh verbundenen Parallelcomputer: Es werden zwei Algorithmen zum Sortieren von n^2 Elementen auf einem mit n X n Mesh verbundenen Prozessorarray vorgestellt, die O(n) Routing- und Vergleichsschritte erfordern. Der beste vorherige Algorithmus benötigt Zeit O(n log n). Es wird gezeigt, dass die Algorithmen dieses Papiers innerhalb kleiner konstanter Faktoren zeitlich optimal sind. Erweiterungen zu höherdimensionalen Arrays sind ebenfalls angegeben."}
{"DOCID": "2974", "TEXT": "Kommentar zur linearen Suche mit gewichtetem Inkrement für Scatter-Tabellen"}
{"DOCID": "2975", "TEXT": "Bemerkung zum einheitlichen Einfügen in strukturierte Datenstrukturen"}
{"DOCID": "2976", "TEXT": "Annäherung an Blockzugriffe in Datenbankorganisationen"}
{"DOCID": "2977", "TEXT": "Die Stufenhypothese und die S-Kurve: Einige widersprüchliche Beweise: Dieses Papier stellt die Ergebnisse einer Studie vor, die die S-förmige Budgetkurve von Nolans Stufenmodell der Computerentwicklung in einer Organisation testet. Untersuchungen zu den Datenverarbeitungsbudgets der kalifornischen Bezirke unterstützen weder die S-förmige Kurve noch die Verwendung von Budgets als Grundlage für ein Stufenmodell. Die Ergebnisse entkräften jedoch nicht das Konzept eines Bühnenmodells. Die Analyse schlägt ein alternatives Modell des Budgetwachstums und eine Trennung zwischen Modellen des Budgetwachstums und Wachstumsphasen in der Entwicklung der Computerressource vor."}
{"DOCID": "2978", "TEXT": "Analyse von Entwurfsalternativen für virtuelle Speicherindizes: Es wird eine Klasse von Indexstrukturen zur Verwendung in einer virtuellen Speicherumgebung beschrieben. Designalternativen innerhalb dieser Klasse von Indexstrukturen werden analysiert. Diese Alternativen beinhalten eine Wahl der Suchstrategie, ob Seiten im Index strukturiert sind oder nicht und ob Schlüssel komprimiert sind oder nicht. Die durchschnittlichen Kosten zum Abrufen von Einträgen aus diesen Indizes werden als gewichtete Summe der Kosten eines grundlegenden Schlüsselvergleichs und der Kosten zum Überschreiten einer Seitengrenze in der Indexstruktur ausgedrückt. Formeln für die Wiederbeschaffungskosten für mögliche Kombinationen von Gestaltungsalternativen werden angegeben. Diese werden in numerischen Fallstudien verwendet, die die Wiederherstellungskosten der Alternativen vergleichen. Auch qualitative Vergleiche der Wartungskosten (Einfügen, Löschen, Reorganisieren) der Gestaltungsalternativen sind enthalten."}
{"DOCID": "2979", "TEXT": "Studies in Machine Cognition Using The Game of Poker: Es wird ein Fortschrittsbericht über die laufenden Forschungsbemühungen zur menschlichen Entscheidungsfindung unter Unsicherheit und Risiko sowie zu menschlichen Problemlösungs- und Lernprozessen einerseits und maschinellem Lernen, groß angelegten Programmiersystemen, und neuartige Programmiertechniken auf der anderen Seite. Es gab auch Interesse daran, wie Menschen deduktive und induktive Schlussfolgerungen ziehen und heuristische Regeln bilden und optimieren, und wie Maschinen ähnliche Ergebnisse erzielen können. Obwohl das Vehikel dieser Untersuchungen das Pokerspiel war, wurde ein konzeptioneller Rahmen geschaffen, der einen ziemlich breiten Anwendungsbereich haben sollte. Die Modelle des menschlichen Urteilsvermögens, der Wahlmöglichkeiten und der Entscheidungsfindung sind in einem umfangreichen komplexen Programm enthalten. Sie repräsentieren sowohl deskriptive als auch normative Verhaltenstheorien. Kürzlich wurde eine interaktive Spielumgebung eingerichtet, die es Menschen neben ihrer Nützlichkeit für Experimente beim Spielen von Spielen ermöglicht, Maschinenstrategien \"online\" in einem Fragenbeantwortungs- und Ratannahmemodus zu konstruieren."}
{"DOCID": "2980", "TEXT": "Das Editieren von Bildsegmentierungen unter Verwendung einer lokalen Analyse von Graphen: Ein Hauptproblem bei der Bildverarbeitung ist die Eliminierung der großen Anzahl von störenden Regionen, die aus einer anfänglichen Segmentierung durch Regionswachstumstechniken resultieren. Solche Bereiche wurden entweder aufgrund semantischer Informationen oder aufgrund von Größe und Kontrast eliminiert. Es wird ein Schema vorgestellt, das Eliminierungen auf der Grundlage lokaler Eigenschaften des Bereichsadjazenzgraphen durchführt. Das Schema basiert auf Definitionen von Grapheneigenschaften, die erfüllt sind, wenn ein Störbereich vorhanden ist; dann ist die Bearbeitung äquivalent zu schnellen Graphoperationen. Eine Reihe von Beispielen wird gezeigt."}
{"DOCID": "2981", "TEXT": "Teilzielinduktion: Eine Beweismethode, die Teilzielinduktion, wird als Alternative oder Ergänzung zur allgemein verwendeten induktiven Behauptungsmethode vorgestellt. Sein Hauptvorteil besteht darin, dass es oft verwendet werden kann, um die Korrektheit einer Schleife direkt aus ihrer Eingabe-Ausgabe-Spezifikation ohne die Verwendung einer Invariante zu beweisen. Die Beziehung zwischen Teilzielinduktion und anderen häufig verwendeten Induktionsregeln wird untersucht und insbesondere gezeigt, dass Teilzielinduktion als eine spezialisierte Form der Recheninduktion angesehen werden kann. Es wird eine Reihe hinreichender Bedingungen präsentiert, die garantieren, dass eine Input-Output-Spezifikation stark genug ist, damit die Induktionsschritte eines Beweises durch Teilzielinduktion gültig sind."}
{"DOCID": "2982", "TEXT": "Die Speicheranforderung beim Precedence Parsing"}
{"DOCID": "2983", "TEXT": "Ein Vergleich von Next-Fit, First-Fit und Best-Fit"}
{"DOCID": "2984", "TEXT": "Kosten/Nutzung: Ein Maß für die Systemleistung: Es wird ein Verfahren zum Bewerten der Computersystemleistung im Hinblick auf einen Kosten/Nutzungsfaktor und ein Maß für das Ungleichgewicht vorgestellt. Diese Koeffizienten geben das Ausmaß an, in dem die Gesamtsystemkosten effektiv genutzt werden. Das Verfahren umfasst eine Technik zur visuellen Darstellung der Systemleistung."}
{"DOCID": "2985", "TEXT": "Auswirkungen von Chargeout auf die Einstellungen von Benutzern/Managern: Es wird der Zusammenhang zwischen internen Preissystemen für Computerdienste (Chargeout-Systeme) und den Einstellungen der Benutzerverwaltung zu ihren computergestützten Informationssystemen untersucht. Es wird nachgewiesen, dass die Beziehung einem allgemeinen Muster entspricht, das von der Hypothese der vier Stadien des EDV-Wachstums zu erwarten wäre [15]. Die Ergebnisse weisen auch darauf hin, dass die für fortgeschrittene EDV-Umgebungen charakteristischen Abrechnungssysteme mit relativ hohen Niveaus positiver Benutzereinstellungen und einer deutlichen Steigerung der EDV-Schulung für Benutzer verbunden sind. Beide Faktoren sind wichtig für die Beteiligung von Benutzern/Managern, die für eine effektive Steuerung computergestützter Systeme erforderlich ist. Die Entwicklung und Wartung computerbasierter Systeme wird als eine Kategorie des organisatorischen Wandels angesehen. Ein \"gefühltes Bedürfnis\" für die Änderung seitens des Benutzers/Managers ist Voraussetzung für jede Änderung, die stattfindet. Die Forschungsmethoden der Verhaltenswissenschaft werden angewendet, um das Benutzer-/Managerumfeld und die Auswirkungen von Chargeout zu untersuchen."}
{"DOCID": "2986", "TEXT": "Operationen mit Sparse-Relationen: Verschiedene Berechnungen mit Relationen, booleschen Matrizen oder gerichteten Graphen, wie z. B. die Berechnung von Vorrangbeziehungen für eine kontextfreie Grammatik, können durch einen praktischen Algorithmus durchgeführt werden, der asymptotisch schneller ist als die allgemein verwendeten. Beispielsweise wird gezeigt, wie Operatorvorrang oder Wirth-Weber-Vorrangbeziehungen in O(n^2)-Schritten berechnet werden, sowie wie lineare Vorrangfunktionen in O(n^2)-Schritten berechnet werden, und wie Berechnen Sie lineare Vorrangfunktionen in O(n) Schritten, wobei n die Größe eines Grammers ist. Das Herzstück der Algorithmen ist ein allgemeiner Satz, der ausreichende Bedingungen angibt, unter denen ein Ausdruck, dessen Operanden dünnbesetzte Beziehungen sind und dessen Operatoren Zusammensetzung, transitiver Abschluss, Vereinigung und Umkehrung sind, effizient berechnet werden kann."}
{"DOCID": "2987", "TEXT": "Darstellung von Polygonen und polygonalen Linien mit vielen Seiten für eine schnelle Verarbeitung: Es wird eine Darstellung für Polygone und polygonale Linien beschrieben, die es ermöglicht, Sätze von aufeinanderfolgenden Seiten gemeinsam zu untersuchen. Die Menge der Seiten wird durch Einbeziehung in einer binären Baumhierarchie angeordnet. Ein schneller Algorithmus zum Testen der Einbeziehung eines Punktes t in ein mehrseitiges Polygon wird angegeben. Die Geschwindigkeit des Algorithmus wird sowohl für ideale als auch für praktische Beispiele diskutiert. Es wird gezeigt, dass die Schnittpunkte zweier polygonaler Linien durch eine im Wesentlichen binäre Baumsuche lokalisiert werden können. Der Algorithmus und ein praktisches Beispiel werden diskutiert. Die Darstellung überwindet viele der Nachteile, die mit den verschiedenen Verfahren mit festem Gitter zur Darstellung von Kurven und Bereichen verbunden sind"}
{"DOCID": "2988", "TEXT": "Speicherverwaltung und Reaktionszeit: Dieses Papier stellt eine rechnerisch handhabbare Methodik vor, um die Auswirkungen der endlichen Speichergröße und der Arbeitslast-Speicheranforderungen in Warteschlangen-Netzwerkmodellen von Computersystemen genau einzubeziehen. Es wird über empirische Analysen und analytische Studien berichtet, die auf der Anwendung dieser Methodik auf ein tatsächliches interaktives Mehrfachzugriffssystem basieren. Beziehungen zwischen Workload-Variablen wie Speicherbedarfsverteilung und Jobwechselzeit und Leistungskennzahlen wie Antwortzeit und Speicherauslastung werden grafisch dargestellt. Es wird ein mehrphasiges, analytisch lösbares Modell vorgeschlagen, das allgemein auf die Analyse von interaktiven Computersystemen anwendbar ist, die Speicher ohne Seitenauslagerung verwenden."}
{"DOCID": "2989", "TEXT": "Empirische Bewertung einiger Merkmale von Befehlssatzprozessorarchitekturen: Dieses Papier stellt Methoden zur empirischen Bewertung von Merkmalen von Befehlssatzprozessoren (ISPs) vor. ISP-Features werden im Hinblick auf die verwendete oder eingesparte Zeit bewertet, indem das Feature vorhanden ist oder nicht. Die Methoden basieren auf der Analyse von Spuren von Programmausführungen. Das Konzept des Registerlebens wird eingeführt und verwendet, um Fragen zu beantworten wie: Wie viele Register werden gleichzeitig verwendet? Wie viele würden immer ausreichen? Meistens? Wie hoch wäre der Overhead, wenn die Anzahl der Register reduziert würde? Wofür werden Register während ihres Lebens verwendet? Das Papier diskutiert auch das Problem des Erfassens erwünschter, aber nicht vorhandener Anweisungen. Andere Probleme werden kurz diskutiert. Es werden experimentelle Ergebnisse präsentiert, die durch die Analyse von 41 Programmen erhalten wurden, die auf dem DEC-System 10 ISP laufen."}
{"DOCID": "2990", "TEXT": "Effektive Informationsbeschaffung unter Verwendung von Begriffsgenauigkeit: Die Leistung von Informationsbeschaffungssystemen kann auf verschiedene Weise bewertet werden. Ein Großteil der veröffentlichten Bewertungsarbeit basiert auf der Messung der Abrufleistung einer durchschnittlichen Benutzeranfrage. Leider sind formale Beweise für den Durchschnittsfall schwierig zu konstruieren. In der vorliegenden Studie basiert die Abrufbewertung auf der Optimierung der Leistung einer bestimmten Benutzeranfrage. Das Konzept der Genauigkeit des Suchbegriffs wird als die Wahrscheinlichkeit des Auftretens eines Suchbegriffs in den für diese Suchanfrage relevanten Dokumenten eingeführt. Indem die Begriffsgenauigkeit auf die Häufigkeit des Auftretens des Begriffs in den Dokumenten einer Sammlung bezogen wird, ist es möglich, formale Beweise für die Wirksamkeit einer Reihe von in experimentellen Situationen erfolgreich eingesetzten automatischen Erschließungssystemen in Bezug auf eine bestimmte Benutzeranfrage zu erbringen . Darunter befinden sich die inverse Dokumentenhäufigkeitsgewichtung, Thesauruskonstruktion und Phrasenerzeugung."}
{"DOCID": "2991", "TEXT": "Verbessern der Zugriffszeit für Dateien mit wahlfreiem Zugriff: Die Clusterbildung im Schlüsselsatz wird verringert, indem die Schlüssel-zu-Adresse-Transformation geglättet und einer offenen Verkettungsdatei Shadow-Buckets hinzugefügt werden. Die Schlüssel werden vor der Adressteilung vorgehasht, um den Effekt sequentieller Eigenschaften im Schlüsselsatz zu entfernen. Shadow-Buckets in der Schlüsselsuchsequenz reduzieren die Auswirkung von Ungleichmäßigkeiten beim Laden von Dateien und verringern die Anzahl der maximalen Sonden, die zum Auffinden eines Datensatzes erforderlich sind. Die kombinierten Wirkungen dieser Techniken führen zu einer verbesserten Dateileistung für sekundäre Speichergeräte, wie empirische Studien gezeigt haben."}
{"DOCID": "2992", "TEXT": "Ein Nummerierungssystem für Binärbäume"}
{"DOCID": "2993", "TEXT": "Auftreten von Zyklen und anderen Phänomenen, die in einer Klasse linearer Programmiermodelle auftreten: Eine Untersuchung der durchschnittlichen Warteschlangengröße für eine bestimmte Klasse von Warteschlangen hat zur Formulierung linearer Programmierprobleme geführt, die in einigen Fällen schlecht konditioniert sind. Bei dem Versuch, diese linearen Programmiermodelle unter Verwendung des MPS-Pakets von IBM zu lösen, wurden Fälle von Zyklen angetroffen. Kleine Störungen in den Eingabedaten führten zu Problemen, die nicht zyklisch waren. Diese Tatsache und mehrere andere beobachtete Phänomene deuten darauf hin, dass der Hauptgrund dafür, dass das zyklische Auftreten nicht bekanntermaßen häufiger auftritt, darin besteht, dass die Rundungsfehler in den Berechnungen das Problem ausreichend stören, um das zyklische Wechseln zu verhindern (oder zumindest um ein unbestimmtes zyklisches Wechseln zu verhindern). In einem Fall wurde versucht, eine objektive Funktion zu maximieren und zu minimieren, die der gleichen Beschränkung t set unterliegt, aber MPS löste nur eine davon, während es für die andere einen Hinweis auf die Undurchführbarkeit gab."}
{"DOCID": "2994", "TEXT": "Ein linearer Algorithmus für die inkrementelle digitale Anzeige von Kreisbögen: Kreisbögen können auf einem inkrementellen Anzeigegerät wie einer Kathodenstrahlröhre, einem digitalen Plotter oder einem Matrixdrucker gezeichnet werden, indem nur Vorzeichentests und elementare Addition und Subtraktion verwendet werden. Dieses Dokument beschreibt die Methodik zur Erzeugung von Punkt- oder Stufenmustern, die dem wahren Kreis am nächsten kommen."}
{"DOCID": "2995", "TEXT": "Zerlegbarkeit, Instabilitäten und Sättigung in Multiprogramming-Systemen (Berichtigung)"}
{"DOCID": "2996", "TEXT": "Statistik des transientenfreien Arbeitssatzes: Die transientenfreie durchschnittliche Arbeitssatzgröße und die transientenfreie Rate fehlender Seiten für eine begrenzte Stichprobe einer Referenzzeichenkette werden definiert. Die Verwendung dieser Statistiken ist angemessen, wenn der Inhalt des Arbeitssatzes am Anfang der aufgezeichneten Zeichenfolge unbekannt ist. Wenn eine bestimmte Stationaritätsbedingung zutrifft, liefern diese Statistiken unvoreingenommene Schätzungen der erwarteten Arbeitssatzgrößen, der Wahrscheinlichkeiten für fehlende Seiten und der Wahrscheinlichkeiten für die Distanz in Bezug auf die Referenz. Es wird gezeigt, dass zwei weitere Schätzerpaare voreingenommen sind. Ausdrücke für die transientenfreie Statistik werden in Form von Intervallstatistiken erhalten. Es werden mehrere Berechnungsmethoden diskutiert, deren Nützlichkeit von der Länge der Stichprobe, der Anzahl unterschiedlicher Referenzen und der Größe des Hauptspeichers abhängt, der dem Computer zur Verfügung steht, der die Berechnungen durchführt. Insbesondere werden Verfahren zum Handhaben langer Zeichenfolgen beschrieben, die viele unterschiedliche Seitennamen enthalten."}
{"DOCID": "2997", "TEXT": "Konvexe Hüllen von endlichen Mengen von Punkten in zwei und drei Dimensionen: Die konvexen Hüllen von Mengen von n Punkten in zwei und drei Dimensionen können mit O(n log n) Operationen bestimmt werden. Die vorgestellten Algorithmen verwenden die \"Teile-und-Herrsche\"-Technik und wenden rekursiv eine Zusammenführungsprozedur für zwei sich nicht schneidende konvexe Hüllen an. Da jeder Algorithmus mit konvexer Hülle mindestens O(n log n) Operationen erfordert, ist die Zeitkomplexität der vorgeschlagenen Algorithmen innerhalb einer multiplikativen Konstante optimal."}
{"DOCID": "2998", "TEXT": "Eine empirische Studie zur Listenstruktur in Lisp: Statische Messungen der Listenstruktur von fünf großen Lisp-Programmen werden in diesem Artikel beschrieben und analysiert. Diese Messungen zeigen eine beträchtliche Regelmäßigkeit oder Vorhersagbarkeit zwischen Zeigern auf Atome und insbesondere zwischen Zeigern auf Listen. Zeiger auf Atome gehorchen ungefähr dem Gesetz von Zipf, das die Worthäufigkeiten in natürlichen Sprachen regelt; Zeiger auf Listen verweisen normalerweise auf einen Ort im Speicher, der physisch in der Nähe liegt. Die Verwendung solcher Regelmäßigkeiten bei der platzsparenden Darstellung von Listenstrukturen wird diskutiert. Die Linearisierung von Listen, bei der aufeinanderfolgende cdrs (oder Autos) wann immer möglich an aufeinanderfolgenden Speicherorten platziert werden, verstärkt die beobachtete Regelmäßigkeit der Listenstruktur erheblich. Es wird gezeigt, dass unter einigen vernünftigen Annahmen die Entropie oder der Informationsgehalt eines Auto-CDR-Paares in den gemessenen Programmen etwa 10 bis 15 Bit vor der Linearisierung und etwa 7 bis 12 Bit nach der Linearisierung beträgt."}
{"DOCID": "2999", "TEXT": "An Approach to Multidimensional Data Array Processing by Computer: Es werden einige neuere Arbeiten zur Entwicklung computerbasierter Statistik- und Datenverarbeitungsfähigkeiten für allgemeine Zwecke zur Handhabung mehrdimensionaler Datenarrays vorgestellt. Die Aufmerksamkeit wird zuerst auf einige der allgemeinen Probleme der mehrdimensionalen Tabellen- und Array-Verarbeitung gerichtet. Darauf folgt eine Zusammenfassung einiger neuerer Entwicklungen bei den Array-Verarbeitungsfähigkeiten bei der Weltbank, insbesondere das als WRAPS (World Bank Retrieval and Array Processing System) bezeichnete System."}
{"DOCID": "3000", "TEXT": "Segmentgrößen und Lebensdauer in Algol 60-Programmen: Die Eigenschaften der virtuellen Speicheranforderungen einer Stichprobe von Algol 60-Programmen wurden gemessen. Verteilungen werden für die Größen von Speicheranforderungen und für ihre Haltezeiten (Lebensdauern) dargestellt. Die Ergebnisse werden in Form von Johnstons Konturmodell und einer einfachen abstrakten Maschine präsentiert. Sie liefern neue empirische Beweise für bestimmte Aspekte der Konstruktion und des Verhaltens realer Programme, und einige ihrer Implikationen für das Design virtueller Speichersysteme werden vorgestellt und diskutiert."}
{"DOCID": "3001", "TEXT": "Erkennung kombinierter Vorkommnisse: In dieser Arbeit wird angenommen, dass die Variablen X1, ..., Xn jeweils einen endlichen Bereich haben, wobei die Variable Xi Pi mögliche Werte annimmt, und dass sich die Werte der Variablen mit der Zeit ändern. Es wird ferner angenommen, dass es erwünscht ist, Vorkommnisse zu erfassen, bei denen eine Teilmenge der Variablen bestimmte Werte erreicht. Schließlich wird angenommen, dass das Problem die Erfassung einer großen Anzahl von kombinierten Vorkommen für eine große Anzahl von Änderungen von Werten von Variablen beinhaltet. Zwei effiziente Lösungen für dieses Problem werden beschrieben. Beide Methoden haben die ungewöhnliche Eigenschaft, schneller für Systeme zu sein, bei denen die Summe P1 + ... + Pn größer ist. Die erste Lösung ist fehlerfrei und für die meisten Fälle geeignet. Die zweite Lösung ist etwas eleganter und erlaubt sowohl Negation als auch Konjunktion, ist aber mit Fehlern behaftet. Für die zweite Methode wird eine Fehleranalyse gegeben und über eine empirische Studie berichtet."}
{"DOCID": "3002", "TEXT": "Ein Datensatz- und Dateipartitionierungsmodell: Eines der Hauptziele beim Entwurf eines Dateisystems ist die Reduzierung der Speicher- und Datenübertragungskosten. Dieses Dokument stellt ein Modell vor, bei dem mehrere Anforderungen auf das Dateisystem zugreifen und jede Anforderung Informationen von einem oder mehreren Datenelementen variabler Länge erfordert. Es wird angenommen, dass die Zugriffswahrscheinlichkeiten und die Verteilung der Länge jedes Datenelements bekannt und voneinander unabhängig sind. Das Dateisystem verwendet ein oder mehrere Speichergeräte, und jeder Datensatz kann in Unterdatensätze partitioniert werden, die auf verschiedenen Geräten gespeichert werden. Einer der Unterdatensätze wird als Primärdatensatz bezeichnet; Wenn eine Anforderung für einen Datensatz gestellt wird, wird zuerst auf den primären Datensatz zugegriffen, und auf andere Unterdatensätze wird nur zugegriffen, wenn die relevanten Informationen nicht im primären Datensatz gespeichert sind. Das Modell, das in diesem Artikel vorgestellt wird, ist sowohl als nichtlineares Programmiermodell als auch als gemischtes ganzzahliges Programmiermodell sehr allgemein; durch geeignete Auswahl seiner Parameter können mehrere Arten von Dateisystemen daraus abgeleitet werden. Dieses Modell wurde bereits bei der Optimierung der Speicherung von Bibliotheksroutinen bei einem großen Betriebssystem verwendet."}
{"DOCID": "3003", "TEXT": "Ein Überblick über die Literatur im Informatikunterricht seit Curriculum '68: Es wird eine Bibliographie von ungefähr zweihundert Referenzen im Informatikunterricht präsentiert, die in der Literatur seit der Veröffentlichung von \"Curriculum '68\" erschienen sind. Der Bibliographie selbst gehen kurze beschreibende Materialien voraus, die die Referenzen in die Kategorien Umfrageberichte, Aktivitäten von Berufsverbänden, Programmphilosophie, Beschreibung von Programmen, Beschreibung von Kursen und andere Materialien gliedern."}
{"DOCID": "3004", "TEXT": "Strukturierte Programmierung in Cobol: Ein Ansatz für Anwendungsprogrammierer: Techniken zum Entwerfen und Schreiben von Cobol-Programmen werden vorgestellt. Vorarbeiten zur strukturierten Programmierung werden aufgegriffen und adaptiert. Die Darstellung ist informell: Die Terminologie ist so weit wie möglich nicht mathematisch, es werden keine Theoreme bewiesen und es werden häufig Beispiele verwendet. Top-down-Programmdesign wird durch die Verwendung von strukturierten Flussdiagrammen, disziplinierten Spezifikationen und schrittweiser Verifizierung implementiert. Ein wohlgeformtes Cobol-Programm wird definiert. Die richtige Verwendung von GO TO und anderen Cobol-Codierungspraktiken werden diskutiert."}
{"DOCID": "3005", "TEXT": "Implikationen der strukturierten Programmierung für die Maschinenarchitektur: Basierend auf einer empirischen Untersuchung von mehr als 10.000 Programmtextzeilen, die in einer GOTO-losen Sprache geschrieben sind, wird eine speziell für strukturierte Programme entworfene Maschinenarchitektur vorgeschlagen. Da Zuweisungs-, CALL-, RETURN- und IF-Anweisungen zusammen 93 Prozent aller ausführbaren Anweisungen ausmachen, wird besonders darauf geachtet, dass diese Anweisungen effizient implementiert werden können. Es wird ein hochkompaktes Befehlscodierungsschema vorgestellt, das die Programmgröße um den Faktor 3 reduzieren kann. Im Gegensatz zu einem Huffman-Code, der Felder mit variabler Länge verwendet, verwendet dieses Verfahren nur Operationscode- und Adressfelder mit fester Länge (1 Byte). Die häufigsten Anweisungen bestehen aus einem einzelnen 1-Byte-Feld. Als Folge davon wird die Befehlsdekodierzeit minimiert und die Maschine ist sowohl platz- als auch zeiteffizient."}
{"DOCID": "3006", "TEXT": "Anomalien bei Paging-Algorithmen für variable Partitionen: Fünf Arten von anomalem Verhalten, die in Betriebssystemen mit ausgelagertem virtuellem Speicher auftreten können, wurden neu definiert. Eine Art von Anomalie betrifft beispielsweise die Tatsache, dass bei bestimmten Referenzzeichenfolgen und Paging-Algorithmen eine Erhöhung der mittleren Speicherzuweisung zu einer Erhöhung der Fehlerrate führen kann. Zwei Paging-Algorithmen werden hinsichtlich ihres Anomaliepotentials untersucht und Referenz-String-Beispiele verschiedener Anomalien vorgestellt. Zwei Paging-Algorithmus-Eigenschaften, die Inklusionseigenschaft und die verallgemeinerte Inklusionseigenschaft, werden diskutiert und die Anomalieimplikationen dieser Eigenschaften dargestellt."}
{"DOCID": "3007", "TEXT": "Komplexität von Berechnungen (Korrigendum)"}
{"DOCID": "3008", "TEXT": "Erhaltung der durchschnittlichen Nähe in Arrays: Programmierer und Designer von Datenstrukturen sind oft gezwungen, zwischen alternativen Strukturen zu wählen. Beim Speichern dieser Strukturen ist das Bewahren logischer Nachbarschaften oder \"Nähe\" normalerweise eine wichtige Überlegung. Das kombinatorische Problem des Speicherns von Arrays als verschiedene Arten von Listenstrukturen wird untersucht. Einbettungen von Graphen werden verwendet, um den mit solchen Speicherschemata verbundenen Nachbarschaftsverlust zu modellieren, und es wird ein elementarer Beweis dafür präsentiert, dass Arrays nicht als lineare Listen mit begrenztem Nachbarschaftsverlust gespeichert werden können. Dann wird der durchschnittliche Näherungsverlust betrachtet, und es wird gezeigt, dass Arrays nicht als lineare Listen mit nur begrenztem durchschnittlichem Näherungsverlust gespeichert werden können, sondern so in binären Bäumen gespeichert werden können. Das erstere Ergebnis impliziert beispielsweise, dass die Zeilenhauptordnung eine asymptotisch optimale Speicherstrategie für Arrays ist."}
{"DOCID": "3009", "TEXT": "Einfügungen und Löschungen in einseitig höhenausgeglichene Bäume: Kürzlich hat Hirschberg festgestellt, dass Einfügungen in einseitig höhenausgeglichene Bäume in 0(log^2N) Schritten durchgeführt werden können. Hier wird bewiesen, dass Löschungen auch in 0(log^2N) Schritten durchgeführt werden können, was das offene Problem von Hirschberg beantwortet."}
{"DOCID": "3010", "TEXT": "Wertorientierung von Informatikstudierenden: Technologische und nichttechnologische Wertorientierungen werden unter besonderer Berücksichtigung der Komplexität von Wertstrukturen untersucht. Informatikstudenten, die eng mit der Technik verbunden sind, stehen sozialwissenschaftliche Studenten gegenüber, die oft technologisch distanziert sind. Dies wird durch die Bewertung von 313 Studenten an der University of Minnesota im Jahr 1972 bestätigt. Es wurde festgestellt, dass Informatik-Majors eine komplexere Wertestruktur aufweisen als Sozialwissenschaften-Majors."}
{"DOCID": "3011", "TEXT": "Management-Nutzung von Computern in amerikanischen Kommunalverwaltungen: Traditionelle Konzepte von Management-Informationssystemen (MIS) haben wenig Bezug zu den Informationssystemen, die derzeit von der obersten Leitung in den meisten US-Kommunalverwaltungen verwendet werden. Was existiert, ist verwaltungsorientiertes Rechnen, das die Verwendung von relativ einfachen Anwendungen beinhaltet. Trotz der einfachen Natur dieser Systeme ist die Nutzung von Computern durch das Management überraschend verbreitet, aber auch in ihrem Ausmaß bei den Kommunalverwaltungen unterschiedlich. Management-Computing ist am weitesten verbreitet in Regierungen mit professionellen Managementpraktiken, in denen das Top-Management das Computing unterstützt und dazu neigt, Computing-Entscheidungen zu kontrollieren, und in denen Abteilungsbenutzer weniger Kontrolle über Design- und Implementierungsaktivitäten haben. Schließlich hat Management Computing eindeutig Auswirkungen auf Top-Manager, meist mit Verbesserungen der Entscheidungsinformationen."}
{"DOCID": "3012", "TEXT": "Die Verwendung eines interaktiven Informationsspeicher- und -abrufsystems in der medizinischen Forschung: Dieses Papier stellt die Ergebnisse einer Studie über die Verwendung eines interaktiven computergestützten Speicher- und Abrufsystems vor. Ein in das Computersystem eingebauter Monitor lieferte Nutzungsdaten für die Studie. Zusätzliche Daten zu Nutzerreaktionen wurden aus einem Fragebogen erhoben. Die Ergebnisse zeigen die wichtige Rolle, die häufig gewählte Laborreferenzleiter bei der Beeinflussung der Verwendung dieses Systems spielen. Die Implikationen der Studie für die Gestaltung ähnlicher Systeme werden diskutiert."}
{"DOCID": "3013", "TEXT": "Einige neue Methoden zum Erkennen von Stufenkanten in Digitalbildern: Dieser Hinweis beschreibt zwei Operatoren, die auf Stufenkanten reagieren, aber nicht auf Rampen. Der erste ähnelt dem digitalen Laplace-Operator, verwendet jedoch das Maximum und nicht die Summe der x- und y-Sekundendifferenzen. Die zweite verwendet die Differenz zwischen den mittleren und mittleren Graustufen in einer Nachbarschaft. Die von diesen Operatoren erhaltenen Ausgaben, angewendet auf einen Satz von Testbildern, werden miteinander und mit dem standardmäßigen digitalen Laplace-Operator und dem Gradienten verglichen. Ein dritter Operator, der den Abstand zwischen Zentrum und Schwerpunkt einer Nachbarschaft als Kantenwert verwendet, wird ebenfalls kurz betrachtet; es erweist sich als äquivalent zu einer der standardmäßigen digitalen Annäherungen an den Gradienten."}
{"DOCID": "3014", "TEXT": "Ist „irgendwann“ manchmal besser als „immer“? (Intermittent Assertions in Proving Program Correctness): Dieser Aufsatz untersucht eine Technik zum gleichzeitigen Beweis der Korrektheit und Beendigung von Programmen. Dieser Ansatz, die Methode der intermittierenden Behauptung, beinhaltet das Dokumentieren des Programms mit Behauptungen, die zu einem bestimmten Zeitpunkt wahr sein müssen, wenn die Steuerung den entsprechenden Punkt durchläuft, aber das muss nicht jedes Mal wahr sein. Die von Burstall eingeführte Methode verspricht eine wertvolle Ergänzung zu den konventionelleren Methoden. Die Methode der intermittierenden Behauptung wird mit einer Reihe von Beispielen für Korrektheits- und Beendigungsbeweise vorgestellt. Einige dieser Beweise sind deutlich einfacher als ihre konventionellen Gegenstücke. Andererseits wird gezeigt, dass ein Beweis der Korrektheit oder Beendigung durch irgendeine der konventionellen Techniken direkt als ein Beweis unter Verwendung intermittierender Behauptungen umformuliert werden kann. Abschließend wird gezeigt, wie die intermittent-assertion-Methode angewendet werden kann, um die Validität von Programmtransformationen und die Korrektheit von kontinuierlich arbeitenden Programmen zu beweisen."}
{"DOCID": "3015", "TEXT": "Relaxationsverfahren zur Bildrekonstruktion: Das Problem, ein Bild (eine Funktion zweier Variablen) aus experimentell verfügbaren Integralen seiner Grauwerte über dünne Streifen zurückzugewinnen, ist in einer Vielzahl wissenschaftlicher Bereiche von großer Bedeutung. Eine wichtige Variante des Problems in der Medizin ist die Ermittlung der exakten Dichteverteilung im menschlichen Körper aus Röntgenprojektionen. Ein Lösungsansatz für dieses Problem besteht darin, die vorliegenden Informationen in ein System linearer Ungleichungen zu übersetzen. Die Größe und die geringe Dichte des resultierenden Systems (typischerweise 25.000 Ungleichungen mit weniger als 1 Prozent der Koeffizienten ungleich Null) machen Methoden, die aufeinanderfolgende Lockerungen verwenden, rechnerisch attraktiv im Vergleich zu anderen Methoden zum Lösen von Ungleichungssystemen. In dieser Arbeit wird gezeigt, dass für ein konsistentes System linearer Ungleichungen jede Folge von Relaxarionsparametern, die streng zwischen 0 und 2 liegt, eine Folge von Vektoren erzeugt, die gegen eine Lösung konvergiert. Unter den gleichen Annahmen konvergiert das Relaxationsverfahren für ein System linearer Gleichungen gegen die minimale Normlösung. Es wird gezeigt, dass früher vorgeschlagene Techniken Sonderfälle unseres Verfahrens mit unterschiedlichen Wahlen von Relaxationsparametern sind. Die praktischen Konsequenzen der Wahl der Relaxationsparameter für die Bildrekonstruktion werden diskutiert."}
{"DOCID": "3016", "TEXT": "Ein Vergleich numerischer Techniken bei der Markov-Modellierung: Dieses Papier stellt mehrere numerische Methoden vor, die verwendet werden können, um die stationären Wahrscheinlichkeitsvektoren von Markov-Modellen zu erhalten. Es wird ein Beispiel eines nahezu zersetzbaren Systems betrachtet und die mit den verschiedenen Methoden erhaltenen Ergebnisse untersucht. Eine Autopsie zeigt, warum Standardtechniken oft nicht die richtigen Ergebnisse liefern. Schließlich wird ein Mittel zur Schätzung des Fehlers vorgestellt, der der Zerlegung bestimmter Modelle innewohnt."}
{"DOCID": "3017", "TEXT": "B-Bäume erneut untersucht: Der B-Baum und seine Varianten wurden mit zunehmender Häufigkeit als grundlegende Speicherstruktur für Mehrbenutzer-Datenbankanwendungen vorgeschlagen. Hier werden drei potenzielle Probleme angegeben, die in einer solchen Struktur behandelt werden müssen, die in traditionelleren statischen Verzeichnisstrukturen nicht auftreten. Ein Problem ist eine mögliche Leistungseinbuße."}
{"DOCID": "3018", "TEXT": "Covering Edges by Cliques in Reward to Keyword Conflicts and Intersection Graphs: Kellerman hat ein Verfahren zur Ermittlung von Keyword-Konflikten vorgestellt und einen heuristischen Algorithmus beschrieben, der ein bestimmtes kombinatorisches Optimierungsproblem im Zusammenhang mit diesem Verfahren löst. Dieses Optimierungsproblem wird hier als äquivalent zu dem Problem gezeigt, die Kanten eines Graphen durch vollständige Teilgraphen zu bedecken, mit dem Ziel, die Anzahl vollständiger Teilgraphen zu minimieren. Es wird eine Beziehung zwischen diesem Kanten-Cliquen-Abdeckungsproblem und dem Graphenfärbungsproblem hergestellt, die es ermöglicht, Algorithmen für eines dieser Probleme aus dem Algorithmus für das andere zu konstruieren. Als Folge dieser Beziehung wird gezeigt, dass das Schlüsselwortkonfliktproblem und das Edge-Clique-Cover-Problem NP-vollständig sind, und wenn P = / NP, dann lassen sie keine Polynomzeit-Approximationsalgorithmen zu, die immer Lösungen innerhalb eines Faktors weniger produzieren als 2 vom Optimum entfernt."}
{"DOCID": "3019", "TEXT": "Der GRE Advanced Test in Informatik"}
{"DOCID": "3020", "TEXT": "Systematische Rekursionsentfernung: Der von Strong und Walker vorgestellte Rekursionsentfernungsalgorithmus wird erweitert und auf ein relativ komplexes PL/I-Programm angewendet. Ziel ist es, systematische Rekursionsentfernungstechniken an etwas Komplexerem als Knuths \"robustem Kleinkind\" zu demonstrieren und Messungen der Kosten der Prozedurverknüpfung in PL/I und der durch Prozedurintegration bei Vorhandensein von Rekursion erreichbaren Einsparungen zu erhalten. Zunächst beschreibt das Papier den Rekursionsentfernungsprozess und das Beispiel, an dem er veranschaulicht wird. Die Rekursionsentfernung wird dann auf die beiden Hauptteile dieses Beispiels angewendet, und das Endergebnis des Prozesses wird angezeigt. Unsere Leistungsvergleichsergebnisse werden präsentiert und unsere Schlussfolgerungen werden kurz diskutiert."}
{"DOCID": "3021", "TEXT": "Ein Verfahren zum Erhalten digitaler Signaturen und Kryptosysteme mit öffentlichem Schlüssel: Es wird ein Verschlüsselungsverfahren mit der neuartigen Eigenschaft vorgestellt, dass das öffentliche Offenlegen eines Verschlüsselungsschlüssels dadurch nicht den entsprechenden Entschlüsselungsschlüssel offenbart. Dies hat zwei wichtige Konsequenzen: (1) Kuriere oder andere sichere Mittel werden nicht benötigt, um Schlüssel zu übertragen, da eine Nachricht unter Verwendung eines Verschlüsselungsschlüssels verschlüsselt werden kann, der von dem beabsichtigten Empfänger öffentlich offenbart wird. Nur er kann die Nachricht entschlüsseln, da nur er den entsprechenden Entschlüsselungsschlüssel kennt. (2) Eine Nachricht kann unter Verwendung eines privat gehaltenen Entschlüsselungsschlüssels \"signiert\" werden. Jeder kann diese Signatur mit dem entsprechenden öffentlich offenbarten Verschlüsselungsschlüssel verifizieren. Unterschriften können nicht gefälscht werden, und ein Unterzeichner kann später die Gültigkeit seiner Unterschrift nicht leugnen. Dies hat offensichtliche Anwendungen in \"elektronischen Post\"- und \"elektronischen Kapitaltransfer\"-Systemen. Eine Nachricht wird verschlüsselt, indem sie als Zahl M dargestellt wird, M mit einer öffentlich spezifizierten Potenz e potenziert wird und dann der Rest genommen wird, wenn das Ergebnis durch das öffentlich spezifizierte Produkt n zweier großer geheimer Primzahlen p und q dividiert wird. Die Entschlüsselung ist ähnlich; es wird nur eine andere, geheime Potenz d verwendet, wobei e * d = 1 (mod(p-1) * (q-1)). Die Sicherheit des Systems beruht zum Teil auf der Schwierigkeit, den veröffentlichten Divisor n zu berücksichtigen."}
{"DOCID": "3022", "TEXT": "Informatik-Fakultäten: Die aktuelle Stellung von Minderheiten und Frauen: Es werden die Ergebnisse einer im Herbst 1975 durchgeführten Erhebung zur Ermittlung der Stellung von Frauen und Angehörigen von Minderheiten in der akademischen Informatik vorgestellt. Die Fakultätsmitglieder wurden in Bezug auf beruflichen Hintergrund, Gehälter, Lehrdeputat, Publikationsleistungen und Forschungsstipendien verglichen. Die Analyse der Daten ergab, dass das Gesamturteil eine allgemeine Gleichstellung von Frauen, Minderheiten und Männern ist."}
{"DOCID": "3023", "TEXT": "Architektur des IBM System/370: Dieses Dokument diskutiert die Entwurfsüberlegungen für die architektonischen Erweiterungen, die System/370 von System/360 unterscheiden. Es kommentiert einige Erfahrungen mit den ursprünglichen Zielen für System/360 und die Bemühungen, diese zu erreichen, und es beschreibt die Gründe und Ziele für die Erweiterung der Architektur. Es umfasst virtuelle Speicherung, Programmsteuerung, Datenmanipulationsbefehle, Timing-Einrichtungen, Multiprocessing, Debugging und Überwachung, Fehlerbehandlung und Ein-/Ausgabeoperationen. Ein letzter Abschnitt tabelliert einige der wichtigen Parameter der verschiedenen IBM-Maschinen, die die Architektur implementieren."}
{"DOCID": "3024", "TEXT": "Das CRAY-1-Computersystem: Dieses Dokument beschreibt den CRAY-1, erörtert die Entwicklung seiner Architektur und gibt einen Bericht über einige der Probleme, die während seiner Herstellung überwunden wurden. Der CRAY-1 ist der einzige bisher gebaute Computer, der die Anforderungen der Klasse VI der ERDA erfüllt (ein Computer, der 20 bis 60 Millionen Gleitkommaoperationen pro Sekunde verarbeiten kann) [1]. Der Fortran-Compiler (CFT) des CRAY-1 wurde entwickelt, um dem wissenschaftlichen Benutzer den sofortigen Zugriff auf die Vorteile der Vektorverarbeitungsarchitektur des CRAY-1 zu ermöglichen. Ein optimierender Compiler, CFT, \"vektorisiert\" innerste DO-Schleifen. CFT ist mit dem ANSI 1966 Fortran Standard und mit vielen allgemein unterstützten Fortran-Erweiterungen kompatibel und erfordert keine Modifikationen des Quellprogramms oder die Verwendung zusätzlicher nicht standardmäßiger Fortran-Anweisungen, um eine Vektorisierung zu erreichen. Somit wird die Investition des Benutzers von Hunderten von Mannmonaten an Mühe zur Entwicklung von Fortran-Programmen für andere moderne Computer geschützt."}
{"DOCID": "3025", "TEXT": "Die Entwicklung des DEC-Systems 10: Das DEC-System 10, auch als PDP-10 bekannt, entwickelte sich aus dem PDP-6 (ca. 1963) über fünf Generationen von Implementierungen, um gegenwärtig Systeme zu umfassen, die eine Preisspanne von fünf bis eins abdecken. Der Ursprung und die Entwicklung der Hardware, des Betriebssystems und der Sprachen werden im Hinblick auf technologischen Wandel, Benutzeranforderungen und Benutzerentwicklungen beschrieben. Zu den Beiträgen des PDP-10 zur Computertechnologie gehören: Beschleunigung des Übergangs von Batch-orientierten zu Timesharing-Computersystemen; Übertragung von Hardwaretechnologie innerhalb von DEC (und anderswo) auf Design und Herstellung von Minicomputern; Unterstützung der Hardware- und Softwareentwicklung für Minicomputer; und als Modell für interaktive Einzelbenutzer- und Timesharing-Minicomputer/Mikrocomputersysteme dienen."}
{"DOCID": "3026", "TEXT": "Die Entwicklung der Serie 1100 von Sperry Univac: Geschichte, Analyse und Prognose: Die Systeme der Serie 1100 sind die großen Mainframe-Computersysteme von Sperry Univac. Beginnend mit dem 1107 im Jahr 1962 hat sich die 1100-Serie über eine Reihe von acht kompatiblen Computermodellen bis zum neuesten System, dem 1100/80, entwickelt, das 1977 eingeführt wurde. Die Hardwarearchitektur der 1100-Serie basiert auf einem 36-Bit-Wort, Einerkomplement Struktur, die einen Operanden aus dem Speicher und einen aus einem Hochgeschwindigkeitsregister oder zwei Operanden aus Hochgeschwindigkeitsregistern erhält. Das 1100-Betriebssystem ist darauf ausgelegt, eine symmetrische Mehrprozessorkonfiguration zu unterstützen, die gleichzeitig multiprogrammierte Batch-, Timesharing- und Transaktionsumgebungen bereitstellt."}
{"DOCID": "3027", "TEXT": "Die Entwicklung des MU5-Computersystems: Nach einem kurzen Überblick über den Hintergrund des MU5-Projekts werden die Ziele und Ideen für MU5 diskutiert. Dann wird eine Beschreibung des Befehlssatzes gegeben, der eine Reihe von Merkmalen enthält, die der Erzeugung eines effizienten kompilierten Codes aus Hochsprachen-Quellprogrammen förderlich sind. Das Design des Prozessors wird dann von den anfänglichen Ideen für einen assoziativ adressierten \"Namensspeicher\" bis zur endgültigen mehrstufigen Pipelinestruktur verfolgt, die einen Vorhersagemechanismus für das Vorabrufen von Befehlen und eine Funktionswarteschlange für den Zugriff auf Array-Elemente beinhaltet. Eine Gesamtansicht des gesamten MU5-Komplexes wird zusammen mit einem kurzen Hinweis auf seine Leistung präsentiert."}
{"DOCID": "3028", "TEXT": "Der Manchester Mark I und der Atlas: Eine historische Perspektive: In 30 Jahren Computerdesign an der Manchester University stechen zwei Systeme hervor: der Mark I (entwickelt im Zeitraum von 1946 bis 1949) und der Atlas (1955 bis 1962). Dieser Aufsatz stellt jeden Computer in seinen historischen Kontext und beschreibt dann die Architektur und Systemsoftware in heutiger Terminologie. Mehrere Designkonzepte wie Adressgenerierung und Geschäftsverwaltung haben sich im Verlauf von Mark I zu Atlas entwickelt. Der breitere Einfluss von Manchester-Innovationen in diesen und anderen Bereichen wird diskutiert, und die zeitgenössische Leistung von Mark I und Atlas wird bewertet."}
{"DOCID": "3029", "TEXT": "Vorwort zum Sonderheft Computerarchitektur"}
{"DOCID": "3030", "TEXT": "Ein Beispiel für hierarchisches Design und Beweis: Die hierarchische Programmierung wird zunehmend als hilfreich bei der Konstruktion großer Programme anerkannt. Benutzer von hierarchischen Techniken behaupten oder prognostizieren beträchtliche Steigerungen der Produktivität und der Zuverlässigkeit der produzierten Programme. In diesem Artikel beschreiben wir eine formale Methode zur hierarchischen Programmspezifikation, -implementierung und -beweis. Wir wenden diese Methode auf ein signifikantes Listenverarbeitungsproblem an und diskutieren auch eine Reihe von Erweiterungen für aktuelle Programmiersprachen, die den hierarchischen Programmentwurf und -beweis erleichtern."}
{"DOCID": "3031", "TEXT": "Abstrakte Datentypen und Software-Validierung: Eine Datenabstraktion kann natürlich mit algebraischen Axiomen spezifiziert werden. Der Vorteil dieser Axiome liegt darin, dass sie eine darstellungsunabhängige formale Spezifikation eines Datentyps erlauben. Es wird ein Beispiel gegeben, das zeigt, wie man algebraische Axiome auf aufeinanderfolgenden Ebenen der Implementierung verwendet. Der Hauptstoß des Papiers ist zweifach. Zunächst wird gezeigt, wie die Verwendung algebraischer Axiomatisierungen den Prozess des Beweises der Korrektheit einer Implementierung eines abstrakten Datentyps vereinfachen kann. Zweitens werden halbautomatische Werkzeuge beschrieben, mit denen sowohl solche Korrektheitsbeweise automatisiert werden können, als auch eine unmittelbare Implementierung aus den Axiomen abgeleitet werden kann. Diese Implementierung ermöglicht ein begrenztes Testen von Programmen zur Entwurfszeit, bevor eine herkömmliche Implementierung durchgeführt wird."}
{"DOCID": "3032", "TEXT": "Reverse Path Forwarding von Broadcast-Paketen: Ein Broadcast-Paket dient zur Zustellung an alle Knoten eines Netzwerks. Algorithmen zum Erzielen dieser Zustellung durch ein Paketvermittlungs-Computernetzwerk mit Speicherung und Weiterleitung umfassen (1) die Übertragung von separat adressierten Paketen. (2) Multidestination-Adressierung, (3) Hot-Potato-Weiterleitung, (4) Spanning-Tree-Weiterleitung und (5) quellenbasierte Weiterleitung. Zu dieser Liste von Algorithmen fügen wir (6) Reverse Path Forwarding hinzu, ein Broadcast-Routing-Verfahren, das Routing-Prozeduren und Datenstrukturen ausnutzt, die bereits für die Paketvermittlung verfügbar sind. Reverse Path Forwarding ist ein praktischer Algorithmus für Broadcast-Routing in Store-and-Forward-Paketvermittlungs-Computernetzwerken. Der Algorithmus wird als praktikabel beschrieben, weil er gemäß den für seine Analyse in diesem Papier entwickelten Metriken nicht optimal ist, und auch weil er in bestehenden Netzwerken mit weniger Komplexität implementiert werden kann, als dies für die bekannten Alternativen erforderlich ist."}
{"DOCID": "3033", "TEXT": "Optimierung von Entscheidungsbäumen durch heuristisch geführte Suche: Die optimale Konvertierung von Entscheidungstabellen wurde in der Literatur unter Verwendung von zwei Ansätzen angegangen, dynamischer Programmierung und Branch-and-Bound. Die erstere Technik ist ziemlich effektiv, aber ihr Zeit- und Platzbedarf ist unabhängig davon, wie \"einfach\" die gegebene Tabelle ist. Außerdem lassen sich damit keine guten, quasi optimalen Lösungen herstellen. Das Branch-and-Bound-Verfahren verwendet eine gute Heuristik zur Lenkung der Suche, ist aber durch einen enormen Suchraum überladen, da die Anzahl der Lösungen mit der Anzahl der Testvariablen gemäß einer doppelten Exponentialfunktion zunimmt. In diesem Beitrag schlagen wir einen heuristisch geführten Top-Down-Suchalgorithmus vor, der wie die dynamische Programmierung identische Teilprobleme erkennt, mit dem aber sowohl optimale als auch quasi-optimale Lösungen gefunden werden können. Das in diesem Beitrag vorgestellte heuristische Suchverfahren kombiniert die positiven Aspekte der beiden oben genannten Techniken. Komprimierte Tabellen mit einer großen Anzahl von Variablen können behandelt werden, ohne zuerst expandierte Tabellen abzuleiten."}
{"DOCID": "3034", "TEXT": "Erkennung logischer Fehler in Entscheidungstabellenprogrammen: In dieser Arbeit wird ein Algorithmus entwickelt, um logische Fehler in einer Entscheidungstabelle mit begrenztem Eintrag und in schleifenfreien Programmen mit eingebetteten Entscheidungstabellen zu erkennen. Alle Bedingungen in den Entscheidungstabellen werden als Ungleichungen oder Gleichheiten in Bezug auf lineare Ausdrücke angenommen. Es wird auch angenommen, dass Aktionen in einer Entscheidungstabelle linear in Variablen sind, die in dem Bedingungs-Stub der Entscheidungstabelle (oder -tabellen) auftreten, auf die die Steuerung von der Tabelle übertragen wird. Der Algorithmus basiert auf der Bestimmung, ob ein Satz linearer Ungleichungen eine Lösung hat oder nicht. Der in der Arbeit beschriebene Algorithmus ist in Fortran IV implementiert."}
{"DOCID": "3035", "TEXT": "A Strategic Planning Methodology for the Computing Effort in Higher Education: An Empirical Evaluation: Die Ergebnisse einer Studie, die sich mit den dringenden Problemen im Zusammenhang mit der strategischen Planung des Computereinsatzes in der Hochschulbildung befasst, werden hier vorgestellt. Eine Planungsmethodik wurde entwickelt und durch die Implementierung an einer Universität getestet. Zwei Jahre nach der Implementierung der Methodik wurde die Effektivität der Planungsmethodik im Hinblick auf die Verbesserung der Bereitstellung von Computerdiensten für die wichtigsten institutionellen Rollen der Lehre, Forschung und Verwaltung bewertet. Zwei Kontrollinstitute wurden eingesetzt, um die Verbesserungen am Testinstitut gegenüberzustellen. Die Forschungsergebnisse zeigen, dass die Planungsmethodik die Bereitstellung von Computerdiensten erheblich verbessert hat."}
{"DOCID": "3036", "TEXT": "Die Auswahl optimaler Reitereinstellungen: Eine neue Generation von Computerterminals ermöglicht die Auswahl und Einstellung von Reitereinstellungen durch den Computer. Diese Funktion kann verwendet werden, um die Anzahl der Zeichen zu reduzieren, die benötigt werden, um ein Dokument für die Übertragung und den Druck darzustellen. In dieser Anmerkung wird ein Algorithmus zum Auswählen des optimalen Satzes von Tabstopps zum Minimieren der Anzahl übertragener Zeichen angegeben. Eine Implementierung des Algorithmus hat die Anzahl der übertragenen Zeichen von 7 auf 30 Prozent reduziert, erfordert jedoch einen Vorlauf durch das Dokument, um eine Matrix zu berechnen, die zum Bestimmen der optimal eingestellten Tabstopps verwendet wird. Die Verwendung fester Tabstopps als heuristische Alternative kann ohne Vorlauf etwa 80 Prozent des Optimums erreichen."}
{"DOCID": "3037", "TEXT": "Ein linearer Sieb-Algorithmus zum Finden von Primzahlen: Es wird ein neuer Algorithmus vorgestellt, um alle Primzahlen zwischen 2 und n zu finden. Der Algorithmus wird zeitproportional zu n ausgeführt (unter der Annahme, dass die Multiplikation von ganzen Zahlen, die nicht größer als n sind, in Zeiteinheiten durchgeführt werden kann). Das Verfahren hat die gleiche arithmetische Komplexität wie der von Mairson [6] vorgestellte Algorithmus; unsere Version ist jedoch vielleicht einfacher und eleganter. Es lässt sich auch leicht erweitern, um die Primfaktorzerlegung aller ganzen Zahlen zwischen 2 und n in der Zeit proportional zu n zu finden."}
{"DOCID": "3038", "TEXT": "Verwendung von Verschlüsselung zur Authentifizierung in großen Computernetzwerken: Es wird die Verwendung von Verschlüsselung diskutiert, um eine authentifizierte Kommunikation in Computernetzwerken zu erreichen. Es werden Beispielprotokolle für den Aufbau authentifizierter Verbindungen, für die Verwaltung authentifizierter E-Mails und für die Signaturprüfung und Dokumentenintegritätsgarantie vorgestellt. Als Grundlage für Protokolle werden sowohl konventionelle als auch Public-Key-Verschlüsselungsalgorithmen betrachtet."}
{"DOCID": "3039", "TEXT": "On-the-Fly-Garbage-Collection: Eine Übung in Kooperation: Als Beispiel für die Kooperation zwischen sequentiellen Prozessen mit sehr geringer gegenseitiger Beeinflussung trotz häufiger Manipulationen eines großen gemeinsamen Datenraums wird eine Technik entwickelt, die nahezu alle für Garbage erforderlichen Aktivitäten zulässt Erkennung und Sammlung, die von einem zusätzlichen Prozessor durchgeführt werden, der gleichzeitig mit dem Prozessor arbeitet, der der eigentlichen Berechnung gewidmet ist. Ausschluss- und Synchronisierungsbeschränkungen wurden so schwach wie möglich gehalten; die schwerwiegenden Komplexitäten, die dadurch entstehen, werden veranschaulicht."}
{"DOCID": "3040", "TEXT": "Synthetisieren von Beschränkungsausdrücken: Eine Beschränkungsnetzdarstellung wird für ein kombinatorisches Suchproblem präsentiert: Finden von Werten für einen Satz von Variablen, die einem Satz von Beschränkungen unterliegen. Es wird eine Theorie der Konsistenzniveaus in solchen Netzwerken formuliert, die sich auf Probleme der Backtrack-Tree-Sucheffizienz bezieht. Es wird ein Algorithmus entwickelt, der jedes gewünschte Maß an Konsistenz erreichen kann, um das Problem für eine nachfolgende Backtrack-Suche vorzuverarbeiten oder als Alternative zur Backtrack-Suche zu fungieren, indem alle Lösungen explizit bestimmt werden."}
{"DOCID": "3041", "TEXT": "Median-Split-Bäume: Eine schnelle Suchtechnik für häufig vorkommende Schlüssel: Split-Bäume sind eine neue Technik zum Suchen von Schlüsselsätzen mit stark schiefen Häufigkeitsverteilungen. Ein geteilter Baum ist ein binärer Suchbaum, von dem jeder Knoten zwei Schlüsselwerte enthält – einen Knotenwert, der ein maximal häufiger Schlüssel in diesem Teilbaum ist, und einen geteilten Wert, der die verbleibenden Schlüssel (in Bezug auf ihre lexikalische Reihenfolge) zwischen den linken aufteilt und rechte Teilbäume. Ein Median-Split-Tree (MST) verwendet den lexikalischen Median der Nachkommen eines Knotens als seinen Split-Wert, um zu erzwingen, dass der Suchbaum perfekt ausbalanciert ist, wodurch sowohl eine platzsparende Darstellung des Baums als auch eine hohe Suchgeschwindigkeit erreicht werden. Im Gegensatz zu frequenzgeordneten binären Suchbäumen sind die Kosten einer erfolgreichen Suche eines MST log n-begrenzt und sehr stabil um minimale Werte herum. Ferner kann ein MST für eine gegebene Schlüsselreihenfolge und einen Satz von Frequenzen in der Zeit n log n aufgebaut werden, im Gegensatz zu n2 für einen optimalen binären Suchbaum. Eine Erörterung der Anwendung von MSTs zum Nachschlagen in Wörterbüchern für Englisch wird präsentiert, und die erzielte Leistung wird derjenigen anderer Techniken gegenübergestellt."}
{"DOCID": "3042", "TEXT": "Power Trees: Die neue Klasse von Pk-Bäumen wird vorgestellt, bei der die Höhenbalance für die auf bestimmten Pfaden liegenden Knoten aufrechterhalten wird. Die Anzahl der Knoten eines Pk-Baums wächst im ungünstigsten Fall asymptotisch mit der Höhe. Eine Prozedur zum Einfügen von Knoten wird angegeben, und die Klasse der betrachteten Bäume ist auf IPk-Bäume beschränkt, die durch eine solche Prozedur aufgebaut werden können. Das durchschnittliche Verhalten solcher Bäume, das durch eine umfangreiche Reihe von Simulationsläufen untersucht wurde, kommt dem von AVL-Bäumen nahe. Insbesondere wird die Familie der IPO-Bäume analysiert, deren Hauptvorteil die verringerte Anzahl von Umstrukturierungen ist, die nach dem Einfügen von Knoten erforderlich sind."}
{"DOCID": "3043", "TEXT": "Distributed Processes: A Concurrent Programming Concept: Ein Sprachkonzept für nebenläufige Prozesse ohne gemeinsame Variablen wird vorgestellt. Diese Prozesse kommunizieren und synchronisieren sich über Prozeduraufrufe und geschützte Bereiche. Dieses Konzept wird für Echtzeitanwendungen vorgeschlagen, die von Mikrocomputernetzwerken mit verteilter Speicherung gesteuert werden. Das Papier gibt mehrere Beispiele für verteilte Prozesse und zeigt, dass sie Prozeduren, Coroutinen, Klassen, Monitore, Prozesse, Semaphore, Puffer, Pfadausdrücke und Eingabe/Ausgabe als Sonderfälle umfassen."}
{"DOCID": "3044", "TEXT": "Ein Hinweis zu bedingten Ausdrücken: Die Auswertung eines bedingten Ausdrucks kann auch dann erfolgreich sein, wenn das \"entscheidende Prädikat\" divergiert und die Alternativen Datensätze (oder Knoten) sind, deren Felder unterschiedlichen Inhalt haben."}
{"DOCID": "3045", "TEXT": "Eine einfache Wiederherstellungsprozedur für einfache Präzedenzparser: Es wird eine einfache Methode beschrieben, die es einfachen Präzedenzparsern ermöglicht, sich von Syntaxfehlern zu erholen. Es wird kein Versuch unternommen, Fehler zu reparieren, aber das Analysieren und die meisten semantischen Verarbeitungen können fortgesetzt werden. Das Ergebnis ist eine gute \"erste Annäherung\" an die Behandlung von Syntaxfehlern mit einer vernachlässigbaren Erhöhung der Analysezeit, des Speicherplatzes und der Komplexität sowohl des Parsers als auch seines Tabellengenerators."}
{"DOCID": "3046", "TEXT": "Computergenerierung von Gamma-Zufallsvariablen – II: Zur Generierung von Gamma-Variablen mit nicht ganzzahligen Formparametern a, a > 1 wird eine Ablehnungsmethode vorgeschlagen. Diese Methode ähnelt anderen Methoden von Fishman, Wallace und Tadikamalla und ist schneller als diese Methoden für a> 2. Die Kernspeicheranforderungen und der Programmieraufwand für das vorgeschlagene Verfahren sind ähnlich denen der Verfahren von Wallace oder Tadikamalla. Die Rechenzeiten für das vorgeschlagene Verfahren bleiben für mittlere und große Werte von a ziemlich konstant und sind den Zeiten überlegen, die durch das Verfahren von Ahrens und Dieter für alle Werte von a erhalten werden. Das vorgeschlagene Verfahren ist einfacher als das Verfahren von Ahrens und Dieter."}
{"DOCID": "3047", "TEXT": "Verwendung synthetischer Bilder zur Registrierung echter Bilder mit Oberflächenmodellen: Eine Reihe von Bildanalyseaufgaben können von der Registrierung des Bildes mit einem Modell der abgebildeten Oberfläche profitieren. Die automatische Navigation unter Verwendung von sichtbarem Licht oder Radarbildern erfordert eine exakte Ausrichtung solcher Bilder mit digitalen Geländemodellen. Darüber hinaus erfordert die automatische Klassifizierung von Gelände unter Verwendung von Satellitenbildern eine solche Ausrichtung, um die Auswirkungen eines sich ändernden Sonnenwinkels und einer Oberflächenneigung richtig zu behandeln. Sogar Inspektionstechniken für bestimmte Industrieteile können dadurch verbessert werden. Wir erreichen die erforderliche Ausrichtung, indem wir das reale Bild mit einem synthetischen Bild abgleichen, das aus einem Oberflächenmodell und bekannten Positionen der Lichtquellen erhalten wird. Die Intensität des synthetischen Bildes wird unter Verwendung der Reflexionskarte berechnet, einer bequemen Methode zur Beschreibung der Oberflächenreflexion als Funktion des Oberflächengradienten. Wir veranschaulichen die Technik anhand von LANDSAT-Bildern und digitalen Geländemodellen."}
{"DOCID": "3048", "TEXT": "Leistungsbewertung von Computern mit hoher Nebenläufigkeit durch deterministische Simulation: Simulation wird als praktische Technik zur Leistungsbewertung alternativer Konfigurationen von Computern mit hoher Nebenläufigkeit vorgestellt. Es wird eine Technik zum Konstruieren eines detaillierten deterministischen Simulationsmodells eines Systems beschrieben. Im Modell ersetzt ein Steuerstrom die Befehls- und Datenströme des realen Systems. Die Simulation des Systemmodells liefert die für die Leistungsbewertung erforderlichen Zeitablauf- und Ressourcennutzungsstatistiken, ohne dass das System emuliert werden muss. Als Fallstudie wird die Implementierung eines Simulators eines Modells des CPU-Speicher-Subsystems des IBM 360/91 beschrieben. Die Ergebnisse der Bewertung einiger alternativer Systemdesigns werden diskutiert. Die Experimente zeigen, dass für die Fallstudie die Hauptengpässe im System die Speichereinheit und die Festkommaeinheit sind. Außerdem scheint es, dass viele der ausgeklügelten Pipelining- und Puffertechniken, die in der Architektur des IBM 360/91 implementiert sind, von geringem Wert sind, wenn Hochgeschwindigkeits-(Cache-)Speicher verwendet wird, wie im IBM 360/195."}
{"DOCID": "3049", "TEXT": "A Simply Extended and Modified Batch Environment Graphical System (SEMBEGS): SEMBEGS ist ein vollständiges grafisches Batch-Umgebungssystem, das Komponenten zur Handhabung von grafischen Datendateien, zur Anzeige des Inhalts dieser Dateien auf einer Vielzahl grafischer Hardware und zur Durchführung grafischer Batch-Input-Operationen enthält . SEMBEGS ist einfach zu erweitern und zu modifizieren, um den wachsenden Anforderungen einer großen Batch-Umgebung gerecht zu werden, und ist sogar zu einem vollständig interaktiven System erweiterbar. Das Papier präsentiert die konzeptionelle Ansicht von Grafiken, die zum Design von SEMBEGS führten, und skizziert die Hauptkomponenten des Systems. Das Design von SEMBEGS basiert auf der Grundannahme, dass das wahre Ziel der Computergrafik darin besteht, grafische Einheiten zu beschreiben, und nicht, wie allgemein angenommen, grafische Ein- und Ausgabefunktionalitäten bereitzustellen. SEMBEGS ist um ein Basic Graphical Data Management System (BAGDAMS) herum aufgebaut, das ein gemeinsames Mittel zum Kommunizieren der Beschreibungen grafischer Einheiten zwischen den verschiedenen Komponenten von SEMBEGS bereitstellt. BAGDAMS bietet Einrichtungen zum Speichern, Abrufen und Manipulieren der Beschreibungen von grafischen Entitäten, die von Anwendungsprogrammen, Grafikpaketen und Grafikgeräten bereitgestellt und empfangen werden."}
{"DOCID": "3050", "TEXT": "Systemdesign-Ausbildung: Ein spielerischer Ansatz: Eines der Probleme, mit denen Manager von Computerinstallationen konfrontiert sind, ist das Problem, das Computersystem so zu konfigurieren, dass es den Anforderungen entspricht, die durch die Mischung von Jobs gestellt werden, die das Rechenzentrum bedienen muss. Dieses Whitepaper stellt ein Managementspiel vor, das es dem Spieler ermöglicht, ein Computersystem so zu konfigurieren, dass es einen hypothetischen Jobmix erfüllt, der unter der Kontrolle eines Spieladministrators steht und variiert werden kann, um eine Vielzahl von realen Situationen zu simulieren (I/O-gebundene Jobs, Compute gebundene Aufträge usw.). Der Spieler des Spiels erhält eine Reihe von detaillierten Berichten über die Kosten seiner Auswahl und einen simulierten Lauf des Zentrums, das unter seiner Auswahl arbeitet."}
{"DOCID": "3051", "TEXT": "Ein Vergleich von Heaps und der TL-Struktur für den Simulationsereignissatz: Keine"}
{"DOCID": "3052", "TEXT": "Kaltstart- vs. Warmstart-Fehlschlagquoten: In einer zweistufigen Computerspeicherhierarchie werden Missschlagquotenmessungen häufig von einem \"Kaltstart\" durchgeführt, der bei anfänglich leerem Speicher der ersten Ebene durchgeführt wird. Bei großen Kapazitäten kann die Auswirkung der Fehlschläge, die beim Füllen des Speichers der ersten Ebene auftreten, auf das gemessene Fehlschlagverhältnis signifikant sein, sogar für lange Bezugsfolgen. Die Verwendung von \"Warmstart\"- anstelle von \"Kaltstart\"-Fehlschlagsverhältnissen lässt Zweifel an der weit verbreiteten Annahme aufkommen, dass die beobachtete \"S-Form\" der Lebensdauer (Reziprokwert des Fehlschlagsverhältnisses) gegenüber der Kapazitätskurve auf eine Verhaltenseigenschaft von Programmen hinweist, die aufrechterhalten werden eine konstante Anzahl von Seiten im Hauptspeicher. Wenn andererseits Kaltstart-Ausfallquoten als Funktion von Kapazität und Messlänge gemessen werden, dann sind sie beim Untersuchen von Systemen nützlich, in denen der Betrieb eines Programms periodisch durch Aufgabenwechsel unterbrochen wird. Es wird gezeigt, wie man unter einfachen Annahmen das Cache-Fehlschlagverhältnis für Mehrfachprogrammierung aus Kaltstart-Fehlschlagverhältniswerten erhält und wie man ungefähre Kaltstart-Fehlschlagverhältnisse aus Warmstart-Fehlschlagverhältnissen erhält."}
{"DOCID": "3053", "TEXT": "Gepackte Scatter-Tabellen: Scatter-Tabellen für die offene Adressierung profitieren von rekursiven Eintragsverschiebungen, Cutoffs für erfolglose Suchen und zusätzlichen Kostenfunktionen. Verglichen mit konventionellen Methoden liefern die neuen Techniken wesentlich verbesserte Tabellen, die lösungsgenauen optimalen Packungen ähneln. Die Verschiebungen sind tiefenbegrenzte Annäherungen an eine aufzählende (erschöpfende) Optimierung, obwohl die Packkosten bei Tabellengröße n linear – O(n) – bleiben. Die Techniken sind in erster Linie für wichtige feste (aber möglicherweise ziemlich große) Tabellen geeignet, für die Bezugshäufigkeiten bekannt sein können: Op-Code-Tabellen, Rechtschreibwörterbücher, Zugriffs-Arrays. Die Einführung von Frequenzgewichtungen verbessert die Abrufe weiter, aber die Verbesserung kann die Grenzfrequenzen verschlechtern."}
{"DOCID": "3054", "TEXT": "Implementierung von Quicksort-Programmen: Dieses Dokument ist eine praktische Studie zur Implementierung des Quicksort-Sortieralgorithmus und seiner besten Varianten auf echten Computern, einschließlich der Anwendung verschiedener Codeoptimierungstechniken. Eine detaillierte Implementierung, die die effektivsten Verbesserungen von Quicksort kombiniert, wird zusammen mit einer Diskussion darüber gegeben, wie man es in Assemblersprache implementiert. Analyseergebnisse, die die Leistung der Programme beschreiben, werden zusammengefasst. Eine Vielzahl von Sondersituationen wird vom praktischen Standpunkt aus betrachtet, um die breite Anwendbarkeit von Quicksort als internes Sortierverfahren zu veranschaulichen, das nur eine vernachlässigbare zusätzliche Lagerung erfordert."}
{"DOCID": "3055", "TEXT": "Eine Analyse von Algorithmen für das niederländische Nationalflaggenproblem: Lösungen für das niederländische Nationalflaggenproblem wurden von Dijkstra [1] und Meyer [3] gegeben. Dijkstra beginnt mit einem einfachen Programm und gelangt durch Verfeinerung zu einem verbesserten Programm. Es wird gezeigt, dass beide von Dijkstra angegebenen Algorithmen eine erwartete Anzahl von Swaps haben, die 2/3N + 0(1) beträgt, und dass sich diese Werte höchstens um 1/3 eines Swaps und asymptotisch um 1/4 eines Swaps unterscheiden. Es wird gezeigt, dass der Algorithmus von Meyer eine erwartete Swap-Komplexität von 5/9N hat."}
{"DOCID": "3056", "TEXT": "Zählen einer großen Anzahl von Ereignissen in kleinen Registern: Es ist möglich, einen kleinen Zähler zu verwenden, um ungefähre Zählungen großer Zahlen zu halten. Der resultierende erwartete Fehler kann ziemlich genau gesteuert werden. Es wird ein Beispiel angegeben, bei dem 8-Bit-Zähler (Bytes) verwendet werden, um bis zu 130.000 Ereignisse mit einem relativen Fehler zu verfolgen, der im Wesentlichen unabhängig von der Anzahl n von Ereignissen ist. Es ist zu erwarten, dass dieser relative Fehler in 95 Prozent der Fälle 24 Prozent oder weniger beträgt (d. h. o = n/8). Die Techniken könnten vorteilhaft in Mehrkanal-Zählhardware oder -software verwendet werden, die zur Überwachung von Experimenten oder Prozessen verwendet wird."}
{"DOCID": "3057", "TEXT": "Optimale His-Togram-Anpassung durch monotone Graustufentransformation: Dieser Beitrag untersucht das Problem der optimalen His-Togram-Anpassung durch monotone Graustufentransformation, die immer alle Bildpunkte einer gegebenen Graustufe i einer anderen Graustufe T(i) zuordnet, so dass wenn i > j, dann T(i) > T(j). Das Ziel besteht darin, ein transformiertes digitales Bild eines gegebenen Bildes so zu finden, dass die Summe der absoluten Fehler zwischen dem Graustufendiagramm des transformierten Bildes und dem eines Referenzbildes minimiert wird. Dies ist gleichbedeutend damit, k1 linear geordnete Objekte unterschiedlicher Größe eines nach dem anderen in k2 linear geordnete Kisten verschiedener Größen zu platzieren, so dass der kumulierte Platzfehler von zu wenig oder zu viel Platz in den Kisten minimiert wird; die Platzierungsfunktion ist monoton, was eine Lösung dieses Problems in polynomieller Zeit sicherstellt. Es wird ein Baumsuchalgorithmus zum optimalen Histogram-Matching vorgestellt, der eine Zeitkomplexität von O(k1 x k2) hat. Lässt man die Monotonie fallen, so wird das Problem NP-vollständig, auch wenn es auf k2 = 2 beschränkt ist."}
{"DOCID": "3058", "TEXT": "Sprungsuche: Eine schnelle sequentielle Suchtechnik: Wenn sequentielle Dateistrukturen verwendet werden müssen und eine binäre Suche nicht möglich ist, wird die Sprungsuche zu einer attraktiven Alternative. In diesem Artikel werden Varianten des klassischen Sprungsuchschemas untersucht, bei denen die optimale Sprunggröße die Quadratwurzel aus der Anzahl der Datensätze ist. Sprungstrategien mit mehreren Ebenen und variabler Größe werden untersucht, geeignete Anwendungen werden diskutiert und die Leistung bewertet."}
{"DOCID": "3059", "TEXT": "Modelle für parallele Verarbeitung innerhalb von Programmen: Anwendung auf CPU:I/O- und I/O:I/O-Überlappung: In diesem Artikel werden ungefähre Warteschlangenmodelle für die interne parallele Verarbeitung durch einzelne Programme in einem Mehrprogrammsystem entwickelt. Die Lösungstechnik wird durch Netzwerkzerlegung entwickelt. Die Modelle werden im Hinblick auf CPU:I/O- und I/O:I/O-Überlappungen formuliert und auf die Analyse dieser Probleme angewendet. Die prozentuale Leistungsverbesserung durch CPU:I/O-Überlappung erweist sich als am größten für Systeme, die sich in etwa in einem CPU:I/O-Auslastungsgleichgewicht befinden, und für niedrige Grade an Multiprogrammierung. Die prozentuale Verbesserung von E/A:E/A-Überlappung ist für Systemelemente am größten, bei denen das E/A-System stärker ausgelastet ist als die CPU."}
{"DOCID": "3060", "TEXT": "Fortran 77: Es gibt ein neues Standard-Fortran. Der offizielle Titel lautet „American National Standard Programming Language Fortran, X3.9-1978“, aber es wird häufiger als „Fortran 77“ bezeichnet, da seine Entwicklung 1977 abgeschlossen wurde. Es ersetzt den Fortran-Standard mit der Bezeichnung X3.9- 1966. Dieses Dokument beschreibt viele der Funktionen von Fortran 77 und liefert auch einige Informationen darüber, wie und warum der Standard entwickelt wurde."}
{"DOCID": "3061", "TEXT": "Simulationen dynamischer sequentieller Suchalgorithmen: Keine"}
{"DOCID": "3062", "TEXT": "Echtzeit-Plotten von ungefähren Höhenlinienkarten: Keine"}
{"DOCID": "3063", "TEXT": "Eine Anmerkung zu virtuellen Speicherindizes: Keine"}
{"DOCID": "3064", "TEXT": "Ereignismanipulation für diskrete Simulationen, die eine große Anzahl von Ereignissen erfordern: Das hier vorgestellte Ereignismanipulationssystem besteht aus zwei Hauptteilen. Der erste Teil befasst sich mit dem bekannten Problem der Effizienz der Ereignisplanung, wenn die Anzahl geplanter Ereignisse groß wird. Der zweite Teil befasst sich mit dem weniger offensichtlichen Problem der Bereitstellung von Effizienz und Flexibilität, wenn auf geplante Ereignisse zur Ausführung zugegriffen wird. Zusätzliche Merkmale und Probleme, die behandelt werden, umfassen die richtige Behandlung von gleichzeitigen Ereignissen; dass bestimmte Ereignisse zu denselben Zeitpunkten in der simulierten Zeit erstellt, geplant und ausgeführt werden müssen; dass Endlosschleifen, die durch die Verkettung solcher \"Nullzeit\"-Ereignisse verursacht werden, möglich sind und diagnostiziert werden müssen; dass die Aufrechterhaltung verschiedener Ereigniszahlen praktisch und wirtschaftlich ist; und dass eine Fähigkeit zum Handhaben von \"zeitlich verschiebbaren\" Ereignissen wünschenswert und möglich ist."}
{"DOCID": "3065", "TEXT": "Rechte Bruderbäume: Einfügen und Löschen sind für die Klasse von rechten (oder einseitigen) Bruderbäumen vorgesehen, die eine Leistung von O (log n) aufweisen. Die Bedeutung dieser Ergebnisse rührt von der engen Beziehung rechter Bruderbäume her, die einen Einfügungsalgorithmus haben, der in O (log2 n) arbeitet. Obwohl sowohl das Einfügen als auch das Löschen für rechte Bruderbäume in O (log n) Zeit ausgeführt werden können, scheint es ferner, dass der Einfügungsalgorithmus von Natur aus viel schwieriger ist als der Löschalgorithmus – das Gegenteil von dem, was man normalerweise erhält."}
{"DOCID": "3066", "TEXT": "Ein kontrolliertes Experiment zum Testen von Programmen und Code-Walkthroughs/Inspektionen: Dieses Dokument beschreibt ein Experiment zum Testen von Programmen, bei dem 59 sehr erfahrene Datenverarbeitungsexperten mit sieben Methoden zum Testen eines kleinen PL/I-Programms beschäftigt sind. Die Ergebnisse zeigen, dass die beliebte Code-Durchgangs-/Inspektionsmethode beim Auffinden von Fehlern genauso effektiv war wie andere computerbasierte Methoden, und dass die effektivsten Methoden (in Bezug auf gefundene Fehler und Kosten) Probandenpaare einsetzten, die das Programm unabhängig und dann testeten bündelten ihre Erkenntnisse. Die Studie zeigt auch, dass es eine enorme Variabilität zwischen den Probanden gibt und dass die Fähigkeit, bestimmte Arten von Fehlern zu erkennen, von Methode zu Methode unterschiedlich ist."}
{"DOCID": "3067", "TEXT": "Verallgemeinerte Arbeitssätze für Segmentreferenzzeichenfolgen: Das Arbeitssatzkonzept wird für Programme erweitert, die Segmente unterschiedlicher Größe referenzieren. Die verallgemeinerte Working-Set-Policy (GWS) behält als residenten Satz diejenigen Segmente bei, deren Aufbewahrungskosten ihre Abrufkosten nicht übersteigen. Das GWS ist ein Modell für die gesamte Klasse von Demand-Fetching-Speicherrichtlinien, die eine Resident-Set-Inclusion-Eigenschaft erfüllen. Eine verallgemeinerte optimale Richtlinie (GOPT) wird ebenfalls definiert; An seinen Betriebspunkten minimiert es die aggregierten Aufbewahrungs- und Austauschkosten. Sonderfälle der Kostenstruktur ermöglichen es GWS und GOPT, jeden bekannten Stapelalgorithmus, den Arbeitssatz und VMIN zu simulieren. Effiziente Verfahren zur Berechnung von Bedarfskurven, die die Auslagerungslast als Funktion der Speichernutzung zeigen, werden für GWS- und GOPT-Richtlinien entwickelt. Empirische Daten einer realen Anlage sind enthalten."}
{"DOCID": "3068", "TEXT": "Ein Modell zur Verifizierung der Datensicherheit in Betriebssystemen: Die auf Kernel-Architekturen angewendete Programmverifizierung bildet eine vielversprechende Methode zur Bereitstellung unumgehbar sicherer, gemeinsam genutzter Computersysteme. Anhand eines allgemeinen Modells für Betriebssysteme wird hier eine genaue Definition von Datensicherheit entwickelt. Dieses Modell eignet sich als Basis zur Verifizierung vieler jener Eigenschaften eines Betriebssystems, die notwendig sind, um eine zuverlässige Durchsetzung der Sicherheit zu gewährleisten. Die Anwendung dieses Ansatzes auf das sichere Betriebssystem der UCLA wird ebenfalls diskutiert."}
{"DOCID": "3069", "TEXT": "Ein praktischer interprozeduraler Datenflussanalysealgorithmus: Ein neuer interprozeduraler Datenflussanalysealgorithmus wird vorgestellt und analysiert. Der Algorithmus ordnet jeder Prozedur in einem Programm Informationen darüber zu, welche Variablen modifiziert werden können, welche verwendet werden können und welche möglicherweise durch einen Aufruf der Prozedur und all ihrer Unteraufrufe bewahrt werden. Der Algorithmus ist ausreichend leistungsfähig, um in rekursiven Programmen verwendet zu werden und um mit der gemeinsamen Nutzung von Variablen umzugehen, die durch Referenzparameter entsteht. Der Algorithmus ist insofern einzigartig, als er all diese Informationen in einem einzigen Durchgang berechnen kann, ohne dass ein Prepass erforderlich ist, um Anrufbeziehungen oder Muster zu teilen. Der Algorithmus ist hinsichtlich der Zeitkomplexität asymptotisch optimal. Es wurde implementiert und ist selbst bei recht großen Programmen praktisch."}
{"DOCID": "3070", "TEXT": "Hybride Simulationsmodelle von Computersystemen: Dieses Papier beschreibt die Struktur und den Betrieb eines hybriden Simulationsmodells, in dem sowohl ereignisdiskrete Simulation als auch Analysetechniken kombiniert werden, um effiziente und dennoch genaue Systemmodelle zu erzeugen. In einem Beispiel, das auf einem einfachen hypothetischen Computersystem basiert, wird eine diskrete Ereignissimulation verwendet, um die Ankunft und Aktivierung von Jobs zu modellieren, und ein Warteschlangennetzwerk eines zentralen Servers modelliert die Verwendung von Systemprozessoren. Die Genauigkeit und Effizienz der Hybridtechnik werden demonstriert, indem das Ergebnis und der Rechenaufwand des Hybridmodells des Beispiels mit denen eines äquivalenten reinen Simulationsmodells verglichen werden."}
{"DOCID": "3071", "TEXT": "An Algorithm Using Symbolic Techniques for the Bel-Petrov Classification of Gravitational Fields: In diesem Hinweis wird ein Algorithmus zur symbolischen Berechnung bestimmter algebraischer Invarianten des Weyl-Tensors vorgestellt, der die Bestimmung der Bel-Petrov-Typen eines Gravitationsfeldes erlaubt. Obwohl dieser Algorithmus spezialisierter ist als der von D'Inverno und Russell-Clark, erfordert er weder die Verwendung eines speziellen Koordinatensystems noch den Spinkoeffizienten-Formalismus. Der Algorithmus wurde in FORMAC implementiert und soll das von Petrov in seinem Buch vorgeschlagene Klassifizierungsschema vervollständigen. Ein Anhang enthält Beispiele, die die Verwendung des Algorithmus veranschaulichen."}
{"DOCID": "3072", "TEXT": "Richtlinien für die rückkopplungsgekoppelte Ressourcenzuweisung im Computersystem mit mehreren Programmen und mehreren Prozessoren: Es werden Modellstudien einiger integrierter, rückkopplungsgesteuerter Planungssysteme für Computersysteme mit mehreren Programmen und mehreren Prozessoren vorgestellt. Die verwendeten grundlegenden Steuervariablen sind die Datenflussraten für die Prozesse, die auf der CPU ausgeführt werden. Die Modellsysteme verfügen über simulierte Continuous-Flow- und Preempt-Resume-Scheduling von Input-Output-Aktivitäten. Es wird auf die Menge an Speicherressourcen geachtet, die für eine effektive Verarbeitung der E/A-Aktivität erforderlich ist (Pufferraumzuweisung). Die Modellstudien verwendeten sowohl verteilungsgesteuerte als auch spurgesteuerte Techniken. Selbst relativ einfache dynamische Scheduler verbessern nachweislich die Systemleistung (gemessen an der Benutzer-CPU-Zeit) gegenüber der Leistung optimaler oder nahezu optimaler statischer Scheduler, die in identische Systemstrukturen und Arbeitslastumgebungen eingebettet sind. Die Verbesserung ist am größten unter einer Arbeitslast mit hohem E/A-Bedarf."}
{"DOCID": "3073", "TEXT": "Kommunizieren sequentieller Prozesse: Dieses Papier legt nahe, dass Eingabe und Ausgabe grundlegende Primitiven der Programmierung sind und dass die parallele Komposition von kommunizierenden sequentiellen Prozessen eine grundlegende Methode zur Programmstrukturierung ist. In Kombination mit einer Weiterentwicklung von Dijkstras bewachtem Kommando sind diese Konzepte überraschend vielseitig. Ihre Anwendung wird durch Beispiellösungen einer Vielzahl bekannter Programmierübungen veranschaulicht."}
{"DOCID": "3074", "TEXT": "Ein zeit- und platzsparender Müllverdichtungsalgorithmus: Bei einem gegebenen Speicherbereich, der verstreute, markierte Knoten unterschiedlicher Größe enthält, möchte man sie möglicherweise zu einer kompakten Masse an einem Ende des Bereichs neu anordnen, während alle Zeiger auf markierte Knoten zum Anzeigen überarbeitet werden ihre neuen Standorte. Hier wird ein Algorithmus beschrieben, der diese Aufgabe relativ zur Größe des Speicherbereichs in linearer Zeit und in einem Raum in der Größenordnung von einem Bit für jeden Zeiger bewerkstelligt. Der Algorithmus arbeitet durch reversibles Codieren der Situation (dass eine Sammlung von Orten auf einen einzelnen Ort zeigt) durch eine lineare Liste, die von dem Ort ausgeht, auf den gezeigt wird, durch die Orte geht, auf die gezeigt wird, und mit den übertragenen Inhalten des Ortes, auf den gezeigt wird, endet."}
{"DOCID": "3075", "TEXT": "Schnelle parallele Sortieralgorithmen: Ein paralleler Bucket-Sortieralgorithmus wird vorgestellt, der Zeit O(log n) und die Verwendung von n Prozessoren erfordert. Der Algorithmus verwendet eine Technik, die mehr Platz benötigt als das Produkt aus Prozessoren und Zeit. Es wird ein realistisches Modell verwendet, bei dem keine Speicherkonkurrenz erlaubt ist. Es wird auch ein Verfahren vorgestellt, um n Zahlen in der Zeit O(k log n) unter Verwendung von n 1 + 1/k Prozessoren zu sortieren, wobei k eine beliebige ganze Zahl ist. Das Berechnungsmodell für diese Prozedur erlaubt gleichzeitiges Abrufen von der gleichen Speicherstelle."}
{"DOCID": "3076", "TEXT": "Wertekonflikte und soziale Wahlmöglichkeiten bei der Entwicklung elektronischer Geldtransfersysteme: In den letzten Jahren wurde damit begonnen, computerbasierte Systeme, die die Übertragung und Aufzeichnung von Lastschriften und Gutschriften automatisieren, in großem Umfang zu implementieren. Diese Systeme versprechen sowohl finanzielle Vorteile für die Institutionen, die sie verwenden, als auch potenzielle Annehmlichkeiten für ihre Kunden. Sie werfen jedoch auch erhebliche soziale, rechtliche und technische Fragen auf, die gelöst werden müssen, wenn umfassende Systeme für den elektronischen Zahlungsverkehr (EFT) der breiten Öffentlichkeit nicht mehr Probleme bereiten als lösen sollen. Dieses Papier untersucht die Anreize für EFT-Entwicklungen und die sozialen Probleme, die sie im Zusammenhang mit Konflikten zwischen fünf verschiedenen Wertpositionen aufwerfen, die häufig in Analysen vorgeschlagener EFT-Arrangements impliziert werden. Diese Konflikte spiegeln die relative Bedeutung bestimmter Probleme für bestimmte Gruppen wider. Die in EFT-Vorschlägen implizierten Wertpositionen helfen bei der Organisation von Analysen von Marktarrangements, Systemzuverlässigkeit und Vertraulichkeit von Transaktionen. Diese Themen werden in diesem Artikel analysiert und mit den Wertpositionen betroffener Parteien in Beziehung gesetzt. Abschließend werden die Wege, auf denen die Öffentlichkeit etwas über die sozialen Qualitäten verschiedener EFT-Arrangements erfahren kann, und das Tempo der EFT-Entwicklungen beide im Zusammenhang mit der sozialen Wahl diskutiert."}
{"DOCID": "3077", "TEXT": "Kann die Programmierung vom von-Neumann-Stil befreit werden? Ein funktionaler Stil und seine Algebra der Programme: Herkömmliche Programmiersprachen werden immer gewaltiger, aber nicht stärker. Inhärente Fehler auf der grundlegendsten Ebene machen sie sowohl dick als auch schwach: ihr primitiver Programmierstil, der von ihrem gemeinsamen Vorfahren - dem von Neumann-Computer - geerbt wurde, ihre enge Kopplung der Semantik an Zustandsübergänge, ihre Teilung des Programmierens in eine Welt von Ausdrücken und eine Welt von Anweisungen, ihre Unfähigkeit, leistungsfähige Kombinationsformen effektiv zu verwenden, um neue Programme aus bestehenden zu erstellen, und ihr Mangel an nützlichen mathematischen Eigenschaften, um über Programme zu argumentieren. Ein alternativer funktionaler Programmierstil basiert auf der Verwendung von Kombinationsformen zum Erstellen von Programmen. Funktionale Programme behandeln strukturierte Daten, sind oft nicht repetitiv und nicht rekursiv, sind hierarchisch aufgebaut, nennen ihre Argumente nicht und benötigen nicht die komplexe Maschinerie von Prozedurdeklarationen, um allgemein anwendbar zu werden. Das Kombinieren von Formularen kann High-Level-Programme verwenden, um noch höhere Level in einem Stil zu erstellen, der in herkömmlichen Sprachen nicht möglich ist. Mit dem funktionalen Programmierstil ist eine Algebra von Programmen verbunden, deren Variablen sich über Programme erstrecken und deren Operationen Formen kombinieren. Diese Algebra kann verwendet werden, um Programme zu transformieren und Gleichungen zu lösen, deren \"Unbekannte\" Programme sind, auf ziemlich dieselbe Weise, wie man Gleichungen in der High-School-Algebra transformiert. Diese Transformationen sind durch algebraische Gesetze gegeben und werden in derselben Sprache ausgeführt, in der Programme geschrieben sind. Kombinierende Formen werden nicht nur wegen ihrer Programmierleistung ausgewählt, sondern auch wegen der Macht ihrer zugehörigen algebraischen Gesetze. Allgemeine Sätze der Algebra geben das detaillierte Verhalten und die Beendigungsbedingungen für große Klassen von Programmen an. Eine neue Klasse von Computersystemen verwendet den funktionalen Programmierstil sowohl in ihrer Programmiersprache als auch in ihren Zustandsübergangsregeln. Anders als von Neumann-Sprachen haben diese Systeme eine Semantik, die lose an Zustände gekoppelt ist – nur ein Zustandsübergang tritt pro Hauptberechnung auf."}
{"DOCID": "3078", "TEXT": "Analyse der Verfügbarkeit von Computersystemen mit Hilfe von Computer-Aided Algebra: In diesem Dokument werden analytische Ergebnisse in Bezug auf die Verfügbarkeit eines Computersystems präsentiert, das aus unzuverlässigen Prozessoren aufgebaut ist. Diese Ergebnisse werden durch Verwendung verschiedener computergestützter algebraischer Manipulationstechniken erhalten. Ein Hauptziel dieser Arbeit ist es zu zeigen, dass die Schwierigkeiten, analytische Lösungen für Markov-Prozesse zu erhalten, durch die Anwendung von Symbolmanipulationsprogrammen beträchtlich reduziert werden können. Da viele physikalische Systeme durch Markov- und Semi-Markov-Prozesse modelliert werden können, ist der potenzielle Anwendungsbereich dieser Techniken viel größer als das hier analysierte Verfügbarkeitsproblem."}
{"DOCID": "3079", "TEXT": "An Algorithm for Reasoning About Equality: Es wird eine einfache Technik zum Schließen von Gleichheiten vorgestellt, die schnell und vollständig für Grundformeln mit Funktionssymbolen und Gleichheit ist. Ein Korrektheitsnachweis wird ebenfalls erbracht."}
{"DOCID": "3080", "TEXT": "Beweisen der Korrektheit von heuristisch optimiertem Code: Ein System zum Beweisen, dass Programme, die in einer Hochsprache geschrieben sind, korrekt in eine Niedrigsprache übersetzt werden, wird beschrieben. Eine primäre Verwendung des Systems ist ein Schritt nach der Optimierung bei der Codegenerierung. Die Low-Level-Sprachprogramme müssen nicht von einem Compiler erzeugt werden und könnten tatsächlich von Hand codiert werden. Es werden Beispiele für die Nützlichkeit eines solchen Systems gegeben. Einige interessante Ergebnisse sind die Fähigkeit, Programme zu handhaben, die eine Rekursion implementieren, indem der Start des Programms umgangen wird, und die Erkennung und Lokalisierung einer breiten Klasse von Fehlern in den Low-Level-Sprachprogrammen. Die Beispiele demonstrieren, dass eine Optimierung des Genres dieses Papiers zu einem wesentlich schnelleren Betrieb und einer Einsparung von Speicher in Bezug auf Programm- und Stack-Größen führen kann."}
{"DOCID": "3081", "TEXT": "Flache Bindung in Lisp 1.5: Flache Bindung ist ein Schema, das den Zugriff auf den Wert einer Variablen in einem begrenzten Rechenaufwand ermöglicht. Ein elegantes Modell für flaches Binden in Lisp 1.5 wird vorgestellt, in dem der Kontextwechsel eine Umgebungsbaumtransformation namens Rerooting ist. Rerooting ist völlig allgemein und umkehrbar und in dem Sinne optional, dass ein Lisp 1.5-Interpreter korrekt arbeitet, unabhängig davon, ob Rerooting bei genau einer Kontextänderung aufgerufen wird oder nicht. Da Rerooting assoc [v, a] invariant lässt, kann der Programmierer für alle Variablen v und alle Umgebungen a auf ein Rerooting-Primitives, shallow[], zugreifen, das ihm dynamische Kontrolle darüber gibt, ob Zugriffe flach oder tief sind und welche Auswirkungen nur die Ausführungsgeschwindigkeit eines Programms, nicht seine Semantik. Außerdem können mehrere Prozesse in derselben Umgebungsstruktur aktiv sein, solange das Rerooten ein unteilbarer Vorgang ist. Schließlich wird gezeigt, dass das Konzept des Rerooting das Konzept der flachen Bindung in Lisp mit Dijkstras Anzeige für Algol kombiniert und daher ein allgemeines Modell für flache Bindung ist."}
{"DOCID": "3082", "TEXT": "Zeit, Uhren und die Reihenfolge von Ereignissen in einem verteilten System: Das Konzept, dass ein Ereignis vor einem anderen in einem verteilten System stattfindet, wird untersucht und es wird gezeigt, dass es eine teilweise Reihenfolge der Ereignisse definiert. Ein verteilter Algorithmus wird zum Synchronisieren eines Systems von logischen Uhren angegeben, die verwendet werden können, um die Ereignisse vollständig zu ordnen. Die Verwendung der Gesamtordnung wird anhand eines Verfahrens zum Lösen von Synchronisationsproblemen veranschaulicht. Der Algorithmus wird dann auf die Synchronisierung physischer Uhren spezialisiert, und es wird eine Grenze dafür abgeleitet, wie weit die Uhren von der Synchronität abweichen können."}
{"DOCID": "3083", "TEXT": "Pseudochaining in Hash Tables: Dieses Paper stellt Pseudochaining als eine neue Kollisionsauflösungsmethode vor. Pseudochaining liegt auf halbem Weg zwischen offener Adressierung und Verkettung. Seinen Namen verdankt es der Tatsache, dass in jeder Zelle der Hash-Tabelle Verknüpfungsfelder vorhanden sind, die ein „Verketten“ der ersten Überlaufelemente in der Tabelle ermöglichen. Die Effizienz der Methode wird abgeleitet und eine Tradeoff-Analyse gegeben."}
{"DOCID": "3084", "TEXT": "Interpolationssuche – Eine Protokoll-LogN-Suche: Die Interpolationssuche ist ein Verfahren zum Abrufen eines gewünschten Datensatzes nach Schlüssel in einer geordneten Datei unter Verwendung des Werts des Schlüssels und der statistischen Verteilung der Schlüssel. Es wird gezeigt, dass im Durchschnitt log log N Dateizugriffe erforderlich sind, um einen Schlüssel abzurufen, vorausgesetzt, dass die N Schlüssel gleichmäßig verteilt sind. Auch die Zahl der zusätzlichen Zugriffe wird als sehr gering eingeschätzt und ausgewiesen. Dasselbe gilt, wenn die kumulative Verteilungsfunktion der Schlüssel bekannt ist. Computerexperimente bestätigen diese Ergebnisse."}
{"DOCID": "3085", "TEXT": "Ein O(n)-Algorithmus zur Bestimmung einer nahezu optimalen Berechnungsreihenfolge von Matrix-Kettenprodukten: Dieses Papier diskutiert die Berechnung von Matrix-Kettenprodukten der Form M1 x M2 x ... x Mn, wobei Mi Matrizen sind. Die Reihenfolge, in der die Matrizen berechnet werden, wirkt sich auf die Anzahl der Operationen aus. Eine hinreichende Bedingung über die Zuordnung der Matrizen in der optimalen Reihenfolge wird präsentiert. Ein O(n)-Algorithmus zum Finden einer Berechnungsreihenfolge, die weniger als 25 Prozent länger dauert als die optimale Zeit Topt, wird ebenfalls vorgestellt. In den meisten Fällen ergibt der Algorithmus die optimale Bestellung oder eine Bestellung, die nur wenige Prozent länger dauert als Topt (im Durchschnitt weniger als 1 Prozent)."}
{"DOCID": "3086", "TEXT": "Zur Komplexität der Berechnung des Maßes von U[ai, bi]: Die Entscheidungsbaumkomplexität der Berechnung des Maßes der Vereinigung von n (möglicherweise überlappenden) Intervallen beträgt (n log n), auch wenn Vergleiche zwischen linearen Funktionen von die Intervallendpunkte sind erlaubt. Die Existenz einer (n log n)-Untergrenze, um zu bestimmen, ob irgendwelche zwei von n reellen Zahlen innerhalb voneinander liegen, wird ebenfalls demonstriert. Diese Probleme bieten eine hervorragende Gelegenheit, die Auswirkungen des Rechenmodells auf die Leichtigkeit der Analyse und auf die erzielten Ergebnisse zu diskutieren."}
{"DOCID": "3087", "TEXT": "Ein englischsprachiges Fragenbeantwortungssystem für eine große relationale Datenbank: Durch Eingabe von Anfragen in Englisch können gelegentliche Benutzer explizite Antworten aus einer großen relationalen Datenbank mit Flug- und Wartungsdaten von Flugzeugen erhalten, die ein System namens PLANES verwenden. Das Design und die Implementierung dieses Systems wird mit detaillierten Beispielen für den Betrieb von Systemkomponenten und Beispielen für den Gesamtsystembetrieb beschrieben und veranschaulicht. Der Sprachverarbeitungsteil des Systems verwendet eine Reihe erweiterter Übergangsnetzwerke, von denen jedes Phrasen mit einer bestimmten Bedeutung zusammen mit Kontextregistern (History Keepers) und Concept Case Frames abgleicht; Diese werden verwendet, um die Bedeutung von Fragen zu beurteilen, einen Dialog zur Klärung teilweise verstandener Fragen zu erzeugen und Probleme mit Auslassungspunkten und Pronomen zu lösen. Andere Systemkomponenten erstellen eine formale Abfrage für die relationale Datenbank und optimieren die Reihenfolge der Suchbeziehungen. Es werden Methoden zum Umgang mit vagen oder komplexen Fragen und zum Bereitstellen von Browsing-Möglichkeiten diskutiert. Ebenfalls enthalten sind Erörterungen wichtiger Themen bei der Programmierung natürlicher Sprachsysteme für begrenzte Bereiche und die Beziehung dieses Systems zu anderen."}
{"DOCID": "3088", "TEXT": "Allgemeine Gleichungen für idealisierte CPU-E/A-Überlappungskonfigurationen: Es werden allgemeine Gleichungen zum Schätzen der maximal möglichen Nutzung von Hauptspeicherpartitionen, CPU- und E/A-Geräten unter verschiedenen Bedingungen in einem idealisierten CPU-E/A-Überlappungsmodell von mehrfach programmierten Computersystemen abgeleitet . Die Gleichungen sind direkt auf jede Konfiguration anwendbar, die aus Sätzen identischer CPU-E/A-Prozessoren, Hauptspeicherpartitionen und Benutzertasks besteht. Es werden Beispiele bereitgestellt, um die Verwendung der Gleichungen zum Berechnen der effektiven Verarbeitungszeit pro Datensatz und der erwarteten Timesharing-Antwortzeit sowohl unter ausgeglichenen als auch unausgeglichenen Ressourcennutzungsbedingungen zu veranschaulichen."}
{"DOCID": "3089", "TEXT": "Leistung von Rollback-Recovery-Systemen bei intermittierenden Ausfällen: Ein mathematisches Modell eines transaktionsorientierten Systems bei intermittierenden Ausfällen wird vorgeschlagen. Es wird davon ausgegangen, dass das System mit einem Checkpointing- und Rollback-/Wiederherstellungsverfahren arbeitet, um eine zuverlässige Informationsverarbeitung sicherzustellen. Das Modell wird verwendet, um die wichtigsten Leistungskennzahlen abzuleiten, darunter Verfügbarkeit, Reaktionszeit und den Sättigungspunkt des Systems."}
{"DOCID": "3090", "TEXT": "Automated Welfare Client-Tracking and Service Integration: The Political Economy of Computing: Die Auswirkungen eines automatisierten Client-Tracking-Systems auf die Kunden, Sachbearbeiter, Administratoren und den Betrieb der Wohlfahrtsbehörden, die es verwenden, werden berichtet. Die Hauptwirkung dieses Systems bestand darin, die administrative Attraktivität der verwendenden Agenturen in den Augen der Geldgeber zu steigern, anstatt ihre interne Verwaltungseffizienz zu steigern. Diese Auswirkung ist ein gemeinsames Produkt sowohl der technischen Merkmale des computergestützten Systems als auch der organisatorischen Anforderungen, die an verschiedene Behörden, Administratoren und Sachbearbeiter gestellt werden. Es veranschaulicht, wie \"erfolgreiche\" automatisierte Informationssysteme zu den politischen Ökonomien der Gruppen passen, die sie verwenden."}
{"DOCID": "3091", "TEXT": "Einige grundlegende Determinanten der Produktivität der Computerprogrammierung: Das Ziel dieser Untersuchung war es, die Beziehung zwischen den Verarbeitungseigenschaften von Programmen und den Erfahrungseigenschaften von Programmierern und der Programmentwicklungszeit zu untersuchen. Das ultimative Ziel war die Entwicklung einer Technik zur Vorhersage der für die Erstellung eines Computerprogramms erforderlichen Zeit. Die fünfzehn Programmeigenschaften, von denen angenommen wird, dass sie mit einer Erhöhung der erforderlichen Programmierzeit verbunden sind, sind objektiv messbar aus Vorprogrammierungsspezifikationen. Die fünf Programmierereigenschaften sind erfahrungsbezogen und auch messbar, bevor eine Programmieraufgabe begonnen wird. Neun Programmeigenschaften haben sich als Haupteinflüsse auf die Programmentwicklungszeit erwiesen, die jeweils mit einer längeren Programmentwicklungszeit verbunden sind. Es wurde festgestellt, dass alle fünf Programmierermerkmale mit einer verkürzten Programmentwicklungszeit zusammenhängen. Eine multiple Regressionsgleichung, die eine Programmierercharakteristik und vier Programmcharakteristiken enthielt, zeigte eine gute Vorhersagekraft für die Vorhersage der Programmentwicklungszeit."}
{"DOCID": "3092", "TEXT": "Merkmale der Wartung von Anwendungssoftware: Wartung und Verbesserung von Anwendungssoftware machen einen großen Teil der gesamten Lebenszykluskosten eines Systems aus. Grobe Schätzungen des Gesamtverbrauchs an Systemen und Programmierressourcen reichen von 75 bis 80 Prozent in jeder Kategorie. In der Literatur wird dem Gebiet jedoch wenig Beachtung geschenkt. Um die Probleme in diesem Bereich zu analysieren, wurde ein Fragebogen entwickelt und vorgetestet. Anschließend wurde es 120 Organisationen vorgelegt. Die Zahl der Befragten betrug 69. Die Antworten wurden mit dem SPSS-Statistikpaket analysiert. Die Ergebnisse der Analyse zeigen, dass: (1) Wartung und Verbesserung einen Großteil der Gesamtressourcen von Systemen und Programmiergruppen verbrauchen; (2) Wartung und Verbesserung werden vom Management tendenziell als zumindest etwas wichtiger angesehen als die Entwicklung neuer Anwendungssoftware; (3) bei Instandhaltung und Weiterentwicklung sind Probleme einer Managementorientierung tendenziell bedeutsamer als die einer technischen Orientierung; und (4) Benutzerforderungen nach Verbesserungen und Erweiterungen bilden den wichtigsten Verwaltungsproblembereich."}
{"DOCID": "3093", "TEXT": "Automatische Fehlerwiederherstellung für LR-Parser: In diesem Dokument stellen wir ein Schema zum Erkennen und Beheben von Syntaxfehlern in Programmen vor. Das Schema, das auf LR-Parsing basiert, wird von Informationen angetrieben, die direkt und automatisch aus den bereits in einem LR-Parser vorhandenen Informationen erhältlich sind. Der Ansatz, der dem von Levy und Graham und Rhodes nachempfunden ist, scheint eine Fehlerbeseitigung bereitzustellen, die sowohl einfach als auch leistungsstark ist."}
{"DOCID": "3094", "TEXT": "Analysen deterministischer Parsing-Algorithmen: Dieses Papier beschreibt einen Ansatz zum Bestimmen der minimalen, maximalen und durchschnittlichen Zeiten zum Analysieren von Sätzen, die von einem deterministischen Parser akzeptiert werden. Diese Größen werden in Form von symbolischen Formeln, sogenannten Zeitformeln, dargestellt. Die Variablen in diesen Formeln stellen nicht nur die Länge der Eingabezeichenfolge dar, sondern auch die Zeit zum Ausführen elementarer Operationen wie Pushen, Popping, Subskription, Iteration usw. Durch Binden an die Variablen tatsächliche numerische Werte, die einer gegebenen Compiler-Maschinenkonfiguration entsprechen , kann man die Ausführungszeit für diese Konfiguration bestimmen. Zeitformeln werden abgeleitet, indem die Grammatikregeln und das Programm, das den zu analysierenden Algorithmus darstellt, untersucht werden. Der Ansatz wird anhand einer speziellen Grammatik beschrieben, die einfache arithmetische Ausdrücke definiert. Es werden zwei deterministische Parser analysiert: ein rekursiv absteigender LL(1)-Parser von oben nach unten und ein SLR(1)-Parser von unten nach oben. Das Papier liefert Schätzungen für die relative Effizienz der beiden Parser. Die Schätzungen, die für eine bestimmte Maschine, den PDP-10, gelten, werden präsentiert und begründete Kauf-Benchmarks. Abschließend veranschaulicht der Beitrag den vorgeschlagenen Ansatz, indem er ihn auf die Analyse von Parsern für eine einfache Programmiersprache anwendet."}
{"DOCID": "3095", "TEXT": "A Selective Traversal Algorithm for Binary Search Trees: Das Problem der Auswahl von Datenelementen aus einem binären Suchbaum gemäß einer Liste von Bereichsbedingungen wird betrachtet. Der Prozess des Besuchs einer minimalen Anzahl von Knoten zum Abrufen von Daten, die die Bereichsbedingungen erfüllen, wird als selektive Traversierung bezeichnet. In diesem Artikel wird ein Algorithmus zum selektiven Durchlaufen vorgestellt, der ein Tag-Feld für jeden Knoten im Baum verwendet. Der Algorithmus ist besonders nützlich und effizient, wenn die Untersuchung von Daten zeitaufwändiger ist als die Untersuchung eines Tag-Felds."}
{"DOCID": "3096", "TEXT": "Eine optimale Methode zum Löschen in einseitig höhenausgeglichenen Bäumen: Ein einseitig höhenausgeglichener Baum ist ein binärer Baum, bei dem der rechte Teilbaum jedes Knotens eine Höhe hat, die gleich oder genau um eins größer ist als die Höhe seines linken Teilbaums . Er hat gegenüber dem allgemeineren AVL-Baum den Vorteil, dass nur ein Bit an Ausgleichsinformationen erforderlich ist (zwei Bits sind für den ACL-Baum erforderlich). Es wird gezeigt, dass das Löschen eines beliebigen Knotens eines solchen Baums in O(logn)-Operationen durchgeführt werden kann, wobei n die Anzahl der Knoten in dem Baum ist. Darüber hinaus ist das Verfahren in dem Sinne optimal, dass seine Komplexität nicht um Größenordnungen reduziert werden kann. Dieses Ergebnis, gekoppelt mit früheren Ergebnissen von Hirschberg, zeigt, dass von den drei grundlegenden Problemen des Einfügens, Löschens und Abrufens nur das Einfügen durch diese Modifikation eines AVL-Baums nachteilig beeinflusst wird."}
{"DOCID": "3097", "TEXT": "Optimale Schiebestrategie für einen Blocktransfer-CCD-Speicher: Für die Zwecke dieses Dokuments besteht ein Blocktransfer-CCD-Speicher aus seriellen Schieberegistern, deren Schieberate variieren kann, die aber eine bestimmte minimale Schieberate (die Auffrischungsrate) haben eine bestimmte maximale Schichtrate. Die Bits in den Schieberegistern sind von 0 bis N - 1 nummeriert, und Blöcke von N Bits werden immer übertragen, immer beginnend bei Bit 0. Was ist die beste Schiebestrategie, damit eine zu einem zufälligen Zeitpunkt auftretende Blockübertragungsanforderung warten muss die minimale Zeit, bevor Bit 0 erreicht werden kann? Die Mindestverschiebungsratenanforderung erlaubt es einem nicht, einfach bei Bit 0 zu \"parken\" und auf eine Übertragungsanforderung zu warten. Die optimale Strategie besteht darin, so langsam wie möglich zu schalten, bis Bit 0 passiert ist, und dann so schnell wie möglich zu schalten, bis eine kritische Grenze erreicht ist, kurz bevor Bit 0 wieder kommt. Dies wird als \"Beeil dich und warte\"-Strategie bezeichnet und ist außerhalb des Computerbereichs gut bekannt. Der Blocktransfer-CCD-Speicher kann auch als Paging-Trommel mit variabler (begrenzter) Rotationsgeschwindigkeit angesehen werden."}
{"DOCID": "3098", "TEXT": "Computergenerierung von Gamma-Zufallsvariablen: Eine neue Methode zur Generierung von Zufallsvariablen aus der Gamma-Verteilung mit nicht ganzzahligem Formparameter a wird vorgeschlagen. Diese Methode ähnelt zwei anderen Methoden, die kürzlich von Wallace und Fishman vorgestellt wurden. Es wird mit den Methoden von Fishman und Ahrens und Dieter verglichen. Die Kernspeicheranforderungen und der Programmieraufwand für dieses Verfahren sind ähnlich denen des Fishman-Verfahrens. Das vorgeschlagene Verfahren ist dasselbe wie das Verfahren von Fishman für 1 < a < 2 und ist schneller als das Verfahren von Fishman für 3 < a < 19. Außerdem ist das vorgeschlagene Verfahren viel einfacher als das Verfahren von Ahrens und Dieter und ist schneller für a < 8."}
{"DOCID": "3099", "TEXT": "Neue hinreichende Optimalitätsbedingungen für die ganzzahlige Programmierung und ihre Anwendung: Der Zweck dieses Berichts ist es, eine neue Klasse hinreichender Optimalitätsbedingungen für Probleme der reinen und gemischten ganzzahligen Programmierung vorzustellen. Einige der vorgestellten Sätze von hinreichenden Bedingungen können als Verallgemeinerungen von Optimalitätsbedingungen betrachtet werden, die auf primal-dualer Komplementarität in der linearen Programmierung basieren. Diese hinreichenden Bedingungen sind besonders nützlich für die Konstruktion schwieriger ganzzahliger Programmierprobleme mit bekannten optimalen Lösungen. Diese Probleme können dann zum Testen und/oder \"Benchmarking\" ganzzahliger Programmiercodes verwendet werden."}
{"DOCID": "3100", "TEXT": "Eine Interferenzanpassungstechnik zum Induzieren von Abstraktionen: Es wird ein Verfahren zum Induzieren von Wissen durch Abstraktion von einer Folge von Trainingsbeispielen beschrieben. Das vorgeschlagene Verfahren, Interferenzanpassung, induziert Abstraktionen, indem relationale Eigenschaften gefunden werden, die zwei oder mehr Exemplaren gemeinsam sind. Es werden drei Aufgaben vorgestellt, die von einem Programm gelöst werden, das einen Interferenzanpassungsalgorithmus verwendet. Mehrere Probleme bezüglich der Beschreibung der Trainingsbeispiele und der Angemessenheit der Interferenzanpassung werden diskutiert, und es werden Richtungen für die zukünftige Forschung betrachtet."}
{"DOCID": "3101", "TEXT": "Der SL5-Prozedurmechanismus: Dieses Dokument beschreibt einen integrierten Prozedurmechanismus, der es erlaubt, Prozeduren als rekursive Funktionen oder als Coroutinen zu verwenden. Diese Integration wird erreicht, indem Prozeduren und ihre Aktivierungsdatensätze (sogenannte Umgebungen) als Datenobjekte behandelt werden und indem der Prozeduraufruf auf der Quellsprachenebene in drei separate Komponenten zerlegt wird. Darüber hinaus unterliegt die Argumentbindung der Kontrolle des Programmierers, wodurch die Definition verschiedener Methoden der Argumentübertragung in der Quellsprache selbst ermöglicht wird. Der resultierende Prozedurmechanismus, der Teil der SL5-Programmiersprache ist, eignet sich gut für zielorientierte Probleme und andere Probleme, die leichter unter Verwendung von Coroutinen programmiert werden können. Es werden mehrere Beispiele gegeben."}
{"DOCID": "3102", "TEXT": "Einbeziehung von Einheiten in Programmiersprachen: Es wird diskutiert, wie eine Programmiersprache dabei helfen kann, physikalische Einheiten (Fuß, Sek. usw.) im Auge zu behalten. Eine Methode zur Einführung von Beziehungen zwischen Einheiten (ein Watt ist Volt*Ampere, ein Yard sind drei Fuß) und die anschließende automatische Umrechnung auf der Grundlage dieser Beziehungen wird angegeben. Verschiedene Vorschläge zur Syntax werden berücksichtigt."}
{"DOCID": "3103", "TEXT": "Automatische Datenstrukturauswahl: Ein Beispiel und Überblick: Die Verwendung mehrerer Abstraktionsebenen hat sich als sehr hilfreich beim Erstellen und Pflegen von Programmen erwiesen. Wenn Programme mit abstrakten Datentypen wie Sätzen und Listen entworfen werden, kann Programmierzeit eingespart werden, indem der Prozess des Ausfüllens von Implementierungsdetails auf niedriger Ebene automatisiert wird. In der Vergangenheit haben Programmiersysteme nur eine einzige Universalimplementierung für einen abstrakten Typ bereitgestellt. Somit waren die mit abstrakten Typen erstellten Programme dann räumlich oder zeitlich ineffizient. In diesem Artikel wird ein System zum automatischen Auswählen effizienter Implementierungen für abstrakte Typen aus einer Bibliothek von Implementierungen diskutiert. Dieser Prozess wird detailliert für ein Beispielprogramm besprochen. Allgemeine Probleme bei der Datenstrukturauswahl werden ebenfalls überprüft."}
{"DOCID": "3104", "TEXT": "Testdaten als Hilfsmittel beim Nachweis der Programmkorrektheit: Der Nachweis der Programmkorrektheit ist in der Regel langwierig und mühsam, während das Testen, obwohl es zum Auffinden von Fehlern nützlich ist, die Korrektheit normalerweise nicht garantiert. Dieses Dokument stellt Techniken vor, mit denen Testdaten zum Nachweis der Korrektheit von Programmen verwendet werden können. Dieses Verfahren vereinfacht nicht nur den Prozess des Nachweises der Korrektheit, sondern auch den Prozess der Bereitstellung einer genauen Spezifikation für ein Programm. Die Anwendbarkeit dieser Technik auf Prozeduren und rekursive Programme wird demonstriert."}
{"DOCID": "3105", "TEXT": "Eine Spracherweiterung zum Ausdrücken von Einschränkungen beim Datenzugriff: Die kontrollierte gemeinsame Nutzung von Informationen ist für viele Anwendungen erforderlich und wünschenswert und wird in Betriebssystemen durch Zugriffskontrollmechanismen unterstützt. Dieses Whitepaper zeigt, wie Programmiersprachen erweitert werden können, um eine kontrollierte gemeinsame Nutzung bereitzustellen. Die Erweiterung ermöglicht den Ausdruck von Zugriffsbeschränkungen auf gemeinsam genutzte Daten. Zugriffsbeschränkungen können sowohl für einfache Objekte als auch für Objekte gelten, die Komponenten größerer Objekte sind, wie beispielsweise Bankkontodatensätze in einer Datenbank einer Bank. Die Einschränkungen werden deklarativ angegeben und können durch eine statische Prüfung ähnlich der Typprüfung erzwungen werden. Der Ansatz kann zum Erweitern jeder stark typisierten Sprache verwendet werden, eignet sich jedoch besonders zum Erweitern von Sprachen, die das Konzept abstrakter Datentypen unterstützen."}
{"DOCID": "3106", "TEXT": "Ein schneller Algorithmus zum Kopieren von Listenstrukturen: Es wird ein Algorithmus zum Kopieren einer willkürlich verknüpften Listenstruktur in einen Block zusammenhängender Speicherorte vorgestellt, ohne die ursprüngliche Liste zu zerstören. Abgesehen von einer festen Anzahl von Programmvariablen wird kein Hilfsspeicher wie zB ein Stack verwendet. Der Algorithmus benötigt keine Markierungsbits und arbeitet in linearer Zeit. Es hat sich gezeigt, dass er erheblich schneller ist als der Fisher-Algorithmus, der schnellste frühere lineare Zeitalgorithmus für dasselbe Problem. Seine Geschwindigkeit ergibt sich hauptsächlich aus seiner effizienten List-Traversal-Technik, die den Verarbeitungsstapel in die zu erstellende Struktur faltet, und aus seiner Klassifizierung von Listenzellen in neun Typen, wodurch Verarbeitungsvorgänge für jeden Typ optimiert werden können."}
{"DOCID": "3107", "TEXT": "Generieren von Beta-Variablen mit nicht ganzzahligen Formparametern: Eine neue Ablehnungsmethode zum Generieren von Beta-Variablen wird beschrieben. Das Verfahren wird sowohl theoretisch als auch durch Computertimings mit zuvor veröffentlichten Verfahren verglichen. Es wird vorgeschlagen, dass das Verfahren gegenüber früheren Verfahren Vorteile sowohl in der Geschwindigkeit als auch in der Programmiereinfachheit hat, insbesondere für \"schwierige\" Kombinationen von Parameterwerten."}
{"DOCID": "3108", "TEXT": "Ökonomische Codierung von Kommas zwischen Strings: Ein Verfahren zum Einfügen von Trennzeichen zwischen Strings ohne Verwendung neuer Symbole wird vorgestellt. Mit zunehmender Länge der Saiten wird der Mehraufwand in Form einer Verlängerung im Vergleich zu den Längen der Saiten verschwindend gering."}
{"DOCID": "3109", "TEXT": "Eine Datenstruktur zum Manipulieren von Prioritätswarteschlangen: Es wird eine Datenstruktur beschrieben, die zum Darstellen einer Sammlung von Prioritätswarteschlangen verwendet werden kann. Die primitiven Operationen sind Einfügen, Löschen, Vereinigen, Aktualisieren und Suchen nach einem Element mit der frühesten Priorität."}
{"DOCID": "3110", "TEXT": "Assemblieren von Code für Maschinen mit Span-abhängigen Anweisungen: Viele moderne Computer enthalten Anweisungen, deren Länge von der Entfernung von einer gegebenen Instanz einer solchen Anweisung zu dem Operanden dieser Anweisung abhängt. Dieses Papier betrachtet das Problem der Minimierung der Programmlängen für solche Maschinen. Eine effiziente Lösung wird für den Fall präsentiert, in dem der Operand jeder solchen \"spannenabhängigen\" Anweisung entweder ein Label oder ein Assemblerzeitausdruck einer bestimmten eingeschränkten Form ist. Wenn diese Einschränkung gelockert wird, indem zugelassen wird, dass diese Operanden allgemeiner sind Assemblerzeitausdrücke, dann wird gezeigt, dass das Problem NP-vollständig ist."}
{"DOCID": "3111", "TEXT": "Sichere Kommunikation über unsichere Kanäle: Nach traditionellen Konzepten der kryptografischen Sicherheit ist es notwendig, auf geheimem Wege einen Schlüssel zu übertragen, bevor verschlüsselte Nachrichten sicher gesendet werden können. Dieses Papier zeigt, dass es möglich ist, einen Schlüssel über offene Kommunikationskanäle so auszuwählen, dass die Kommunikationssicherheit aufrechterhalten werden kann. Es wird ein Verfahren beschrieben, das jeden Feind dazu zwingt, eine Arbeitsmenge aufzuwenden, die mit dem Quadrat der Arbeit zunimmt, die von den beiden Kommunikanten erforderlich ist, um den Schlüssel auszuwählen. Das Verfahren bietet eine logisch neue Art des Schutzes gegen den passiven Abhörer. Es deutet darauf hin, dass weitere Forschung zu diesem Thema sowohl in theoretischer als auch in praktischer Hinsicht sehr lohnend sein wird."}
{"DOCID": "3112", "TEXT": "Listenverarbeitung in Echtzeit auf einem seriellen Computer: Ein Echtzeit-Listenverarbeitungssystem ist eines, bei dem die von den elementaren Listenoperationen (z. B. CONS, CAR, CDR, RPLACA, REPLACD, EQ und ATOM in LISP) benötigte Zeit begrenzt ist durch eine (kleine) Konstante. Klassischen Implementierungen von Listenverarbeitungssystemen fehlt diese Eigenschaft, da das Zuordnen einer Listenzelle aus dem Heap eine Garbage-Collection verursachen kann, deren Abschluss eine Zeit benötigt, die proportional zur Heap-Größe ist. Es wird ein Echtzeit-Listenverarbeitungssystem vorgestellt, das Datenmüll kontinuierlich wiedergewinnt, einschließlich gerichteter Zyklen, während es die zugänglichen Zellen linearisiert und in zusammenhängende Orte komprimiert, um eine Fragmentierung des freien Speicherpools zu vermeiden. Das Programm ist klein und erfordert keine Timesharing-Interrupts, wodurch es für Microcode geeignet ist. Schließlich benötigt das System die gleiche durchschnittliche Zeit und nicht mehr als den doppelten Platz einer klassischen Implementierung, und dieser Platzbedarf kann durch eine kompakte Listendarstellung auf annähernd klassische Proportionen reduziert werden. Arrays unterschiedlicher Größe, ein Programmstack und Hash-Linking sind einfache Erweiterungen unseres Systems, und die Referenzzählung erweist sich für viele Anwendungen als unterlegen."}
{"DOCID": "3113", "TEXT": "Optimale Umwandlung von Entscheidungstabellen mit erweitertem Eintrag mit allgemeinen Kostenkriterien: Ein allgemeiner dynamischer Programmieralgorithmus zum Umwandeln von Entscheidungstabellen mit begrenztem, erweitertem oder gemischtem Eintrag in optimale Entscheidungsbäume wird vorgestellt, der Regelhäufigkeiten oder -wahrscheinlichkeiten, Mindestzeit und/oder berücksichtigen kann Speicherplatzkostenkriterien, gemeinsame Aktionssätze, komprimierte Regeln und ELSE-Regeln, Sequenzbeschränkungen bei Bedingungstests, ausschließbare Kombinationen von Bedingungen, bestimmte Mehrdeutigkeiten und unterbrochene Regelmaskierung."}
{"DOCID": "3114", "TEXT": "Eine Technik zum Isolieren von Unterschieden zwischen Dateien: Es wird ein einfacher Algorithmus zum Isolieren der Unterschiede zwischen zwei Dateien beschrieben. Eine Anwendung ist der Vergleich zweier Versionen eines Quellprogramms oder einer anderen Datei, um alle Unterschiede anzuzeigen. Der Algorithmus isoliert Unterschiede auf eine Weise, die unserer intuitiven Vorstellung von Unterschieden entspricht, einfach zu implementieren und rechnerisch effizient ist, wobei die Zeit linear in der Dateilänge ist. Für die meisten Anwendungen isoliert der Algorithmus Unterschiede, die denen ähneln, die durch die längste gemeinsame Teilsequenz isoliert werden. Eine andere Anwendung dieses Algorithmus führt Dateien, die unabhängig erzeugte Änderungen enthalten, zu einer einzigen Datei zusammen. Der Algorithmus kann auch verwendet werden, um effiziente Kodierungen einer Datei in Form der Unterschiede zwischen ihr selbst und einer gegebenen \"Datums\"-Datei zu erzeugen, wodurch eine Rekonstruktion der ursprünglichen Datei aus den Differenz- und Datumsdateien ermöglicht wird."}
{"DOCID": "3115", "TEXT": "Geordnete Aufzählung nicht singulärer binärer Matrizen, die auf die Textverschlüsselung angewendet werden: Nicht singuläre binäre Matrizen der Ordnung N, d. h. nicht singulär über dem Feld {0, 1}, und ein Anfangssegment der natürlichen Zahlen werden in eine Eins-zu-Eins-Korrespondenz gebracht. Jede natürliche Zahl entspricht zwei Zwischenvektoren. Diese Vektoren werden in eine nichtsinguläre binäre Matrix abgebildet. Beispiele für eine vollständige Aufzählung aller 2 x 2 und 3 x 3 nichtsingulären binären Matrizen wurden durch Abbildung der Zwischenvektoren auf die Matrizen erzeugt. Die Abbildung findet Anwendung auf das Vernam-Verschlüsselungsverfahren unter Verwendung von Pseudozufallszahlensequenzen. Eine aus Textbytes eines Datenverschlüsselungsschlüssels gebildete Bitfolge kann als Darstellung einer natürlichen Zahl verwendet werden. Diese natürliche Zahl wird in eine nichtsinguläre binäre Matrix transformiert. Die Schlüsselhebelwirkung wird erhalten, indem die Matrix als \"Keim\" in einem Pseudozufallszahlengenerator mit Schieberegistersequenz verwendet wird."}
{"DOCID": "3116", "TEXT": "Interferenzerkennung zwischen Festkörpern und Oberflächen: In vielen industriellen Umgebungen ist es notwendig festzustellen, ob es Interferenzen zwischen Komponenten gibt. Es gibt viele potenzielle Interferenzprobleme in Produkten, die aus Baugruppen von Komponenten bestehen, sowie bei der Produktherstellung und -prüfung. Typischerweise werden Zeichnungen verwendet, um zu versuchen, solche unerwünschten Interferenzen zu erkennen, aber das zweidimensionale, statische Zeichenmedium zeigt nicht immer Interferenzen zwischen dreidimensionalen, sich bewegenden Teilen. Dieses Papier stellt eine Computerdarstellung für Festkörper und Oberflächen und Algorithmen vor, die eine Interferenzprüfung zwischen so dargestellten Objekten durchführen. Objekte werden als Polyeder oder als stückweise ebene Flächen dargestellt. Es werden zwei Arten der Interferenzprüfung diskutiert: Erkennung von Schnittpunkten zwischen Objekten an festen Positionen und Erkennung von Kollisionen zwischen Objekten, die sich entlang spezifizierter Trajektorien bewegen."}
{"DOCID": "3117", "TEXT": "Der Einfluss und die Nutzung von Computertechnologie durch die Polizei: In den letzten zehn Jahren hat die Nutzung von Computertechnologie durch die US-Polizeidienststellen erheblich zugenommen. Dieses Wachstum war jedoch langsamer als in den frühen 1970er Jahren vorhergesagt. Wenn sich Computeranwendungen über „Routine“-Anwendungen hinaus auf „Nicht-Routine“-Bemühungen erstrecken, wie z der bisherigen Technologie sind gemischt. Dieses Papier berichtet über Fallstudien und Umfragen, die Aufschluss über die Implementierung und Wirkung von Polizeicomputertechnologie und die Beziehung dieser Technologie zu Strafverfolgung und Gesellschaft geben."}
{"DOCID": "3118", "TEXT": "Permutation von Datenblöcken in einem Blasenspeicher: Eine gemeinsame interne Organisation von Blasenspeichern besteht aus einer Reihe von (kleineren) Schleifen, die durch eine andere (große) Schleife verbunden sind. Das Problem, eine gegebene n-Permutation des Inhalts der Nebenschleife in minimaler Zeit zu erhalten, wird in diesem Artikel untersucht. Eine Untergrenze für die Anzahl der Schritte, die für einen Permutationsalgorithmus erforderlich sind, wird abgeleitet, und die Klasse optimaler Algorithmen wird identifiziert."}
{"DOCID": "3119", "TEXT": "Der Einfluss von Verteilungen und Disziplinen auf Mehrprozessorsysteme: Einfache Warteschlangenmodelle werden verwendet, um die Leistungskompromisse von Mehrprozessorsystemen zu untersuchen. Zu den berücksichtigten Problemen gehören die Auswirkungen von CPU-Dienstdisziplinen und -Verteilungen, das Niveau von Multiprogramming, Multitasking und Jobprioritäten."}
{"DOCID": "3120", "TEXT": "Eine ereignisgesteuerte Kompilierungstechnik: Aufgrund der linearen Struktur des Quelltextes können Schwierigkeiten bei einem One-Pass-Kompilierungsprozess auftreten. Diese Schwierigkeiten treten auf, wenn eine Entität aufgrund eines Vorwärtsbezugs auf Informationen, die nur von nachfolgenden Entitäten erhältlich sind, nicht verarbeitet werden kann. Klassische Lösungen verlangen für jeden Fall passende Datenstrukturen. Hier wird eine Technik vorgestellt, die stattdessen Kontrollstrukturen verwendet, nämlich Ereignisse und Prozesse. Die Arbeit des Compiler-Schreibers wird sowohl konzeptionell als auch praktisch einfacher, weil er diese Probleme von vornherein vergessen kann und er eine spezielle Bearbeitung für jedes Problem vermeidet. Diese Technik wurde auf die Konstruktion eines Algol 68-Compilers angewendet. Drei Beispiele aus dieser Implementierung werden hier beschrieben und diskutiert."}
{"DOCID": "3121", "TEXT": "Syntaktische Source-to-Source-Transformationen und Programmmanipulation: Syntaktische Transformationen sind die Source-to-Source-Programmtransformationen, die die Berechnungshistorie bewahren und somit die Ausführungszeit nicht modifizieren. In Kombination mit einer kleinen Anzahl primitiver semantischer Transformationen stellen sie ein leistungsfähiges Werkzeug zur Programmmanipulation bereit. Ein Katalog syntaktischer Transformationen und ihre Verwendung zur Lösung eines Systems von Programmgleichungen wird angegeben. Beispiele für die Ableitung komplexerer Quelle-zu-Quelle-Transformationen werden ebenfalls präsentiert. Zwei Fallstudien veranschaulichen, wie syntaktische und semantische Source-to-Source-Transformationen für die Entwicklung klarer, einfacher und einigermaßen effizienter Programme verwendet werden können."}
{"DOCID": "3122", "TEXT": "Produktion und Beschäftigung von Doktoranden in Informatik - 1977 und 1978"}
{"DOCID": "3123", "TEXT": "Beschäftigungsmerkmale promovierter Informatiker"}
{"DOCID": "3124", "TEXT": "Rekursive Datenstrukturen in APL: Eine mathematische Untersuchung von drei Ansätzen zum Definieren verschachtelter Arrays in APL wird vorgestellt. Sätze, die die Beziehungen zwischen den Definitionssystemen zeigen, werden angegeben und durch graphische Darstellungen veranschaulicht. Einer der Ansätze wird verwendet, um ein APL-Array als eine rekursive Datenstruktur zu definieren, die einer Baumstruktur entspricht, in der alle Daten in den Blättern als homogene Arrays von Zahlen und Zeichen gespeichert werden. Eine Erweiterung von APL wird vorgeschlagen, die neue primitive Funktionen zum Manipulieren der Verschachtelungsebene von Arrays und neue Operatoren enthält, um bei der Konstruktion von datengesteuerten Algorithmen zu helfen."}
{"DOCID": "3125", "TEXT": "Globale Optimierung durch Unterdrückung partieller Redundanzen: Die Eliminierung redundanter Berechnungen und das Verschieben invarianter Berechnungen aus Schleifen werden oft separat durchgeführt, wobei Invarianten Schleife für Schleife nach außen verschoben werden. Wir schlagen vor, beides gleichzeitig zu tun und jeden Ausdruck direkt an den Eingang der äußersten Schleife zu verschieben, in der er unveränderlich ist. Dies erfolgt durch Lösung eines allgemeineren Problems, d. h. der Eliminierung von Berechnungen, die zweimal auf einem gegebenen Ausführungspfad durchgeführt werden. Solche Berechnungen werden als teilweise redundant bezeichnet. Darüber hinaus erfordert der Algorithmus keine grafischen Informationen oder Einschränkungen hinsichtlich der Form des Programmgraphen. Das Testen dieses Algorithmus hat gezeigt, dass seine Ausführungskosten nahezu linear mit der Größe des Programms sind und dass er zu einem kleineren Optimierer führt, der weniger Ausführungszeit benötigt."}
{"DOCID": "3126", "TEXT": "Kommentare zu Perfect Hashing Functions: A Single Probe Retrieving Method for Static Sets"}
{"DOCID": "3127", "TEXT": "Thoth, ein tragbares Echtzeit-Betriebssystem: Thoth ist ein Echtzeit-Betriebssystem, das so konzipiert ist, dass es auf eine große Anzahl von Maschinen portierbar ist. Es läuft derzeit auf zwei Minicomputern mit ganz unterschiedlichen Architekturen. Sowohl das System als auch die Anwendungsprogramme, die es verwenden, sind in einer Hochsprache geschrieben. Da das System durch dieselbe Software auf unterschiedlicher Hardware implementiert wird, hat es dieselbe Schnittstelle zu Benutzerprogrammen. Daher sind Anwendungsprogramme, die Thoth verwenden, sehr portabel. Thoth fördert die Strukturierung von Programmen als Netzwerke von kommunizierenden Prozessen, indem er effiziente Grundelemente für die Kommunikation zwischen Prozessen bereitstellt."}
{"DOCID": "3128", "TEXT": "Synchronisierung mit Eventcounts und Sequencern: Die Synchronisierung gleichzeitiger Prozesse erfordert die Steuerung der relativen Reihenfolge von Ereignissen in den Prozessen. Es wird ein neuer Synchronisierungsmechanismus vorgeschlagen, der abstrakte Objekte namens Eventcounts und Sequencer verwendet, die es Prozessen ermöglichen, die Reihenfolge von Ereignissen direkt zu steuern, anstatt gegenseitigen Ausschluss zu verwenden, um Manipulationen gemeinsam genutzter Variablen zu schützen, die die Reihenfolge von Ereignissen steuern. Die direkte Steuerung der Reihenfolge scheint Korrektheitsargumente zu vereinfachen und vereinfacht auch die Implementierung in verteilten Systemen. Der Mechanismus wird formal definiert, und dann werden mehrere Beispiele für seine Verwendung gegeben. Die Beziehung des Mechanismus zu Schutzmechanismen im System wird erläutert; insbesondere hat sich gezeigt, dass Ereigniszählungen auf Situationen anwendbar sind, in denen es auf die Beschränkung von Informationen ankommt. Eine Implementierung von Ereigniszählern und Sequenzern in einem System mit gemeinsam genutztem Speicher wird beschrieben."}
{"DOCID": "3129", "TEXT": "Optimale Speicherzuweisung für serielle Dateien: Ein Computersystem verwendet mehrere serielle Dateien. Die Dateien befinden sich auf einem Speichergerät mit direktem Zugriff, auf dem der Speicherplatz begrenzt ist. Datensätze werden den Dateien entweder durch Jobs im Stapelverarbeitungsmodus oder durch Online-Transaktionen hinzugefügt. Jede Transaktion (oder jeder Job) erzeugt einen Bedarfsvektor, der den Platz angibt, der in jeder Datei zum Hinzufügen von Datensätzen erforderlich ist. Wenn einer Datei der Speicherplatz ausgeht, muss das System neu organisiert werden. In diesem Dokument werden mehrere Kriterien für die optimale Zuweisung von Speicherplatz zu den Dateien betrachtet."}
{"DOCID": "3130", "TEXT": "CURRICULUM '78 - Empfehlungen für den Bachelor-Studiengang Informatik: In diesem Bericht sind die Empfehlungen des Curriculum Committee on Computer Science (C3S) der Association for Computing Machinery (ACM) für den Bachelor-Studiengang Informatik enthalten. Das Kerncurriculum, das allen Bachelor-Studiengängen der Informatik gemeinsam ist, wird in Form von Themen und Kursen auf Grundniveau und Kursen auf mittlerem Niveau präsentiert. Wahlfächer, die zur Abrundung eines Bachelor-Studiums dienen, werden dann besprochen und das gesamte Programm einschließlich des Informatik-Anteils und anderer Materialien vorgestellt. Behandelt werden Themen der Informatikausbildung im Grundstudium wie Servicekurse, unterstützende Bereiche, Weiterbildung, Ausstattung, Personal und Artikulation."}
{"DOCID": "3131", "TEXT": "FOCUS-Mikrocomputer-Zahlensystem: FOCUS ist ein Zahlensystem und unterstützt Rechenalgorithmen, die besonders nützlich für die Mikrocomputersteuerung und andere Signalverarbeitungsanwendungen sind. FOCUS hat den weitreichenden Charakter von Gleitkommazahlen mit einer Einheitlichkeit der Zustandsverteilungen, die FOCUS einen mehr als zweifachen Genauigkeitsvorteil gegenüber einem Gleitkommasystem gleicher Wortlänge verleihen. FOCUS-Berechnungen sind in der Regel fünfmal schneller als Festkomma- oder Integer-Arithmetik mit einfacher Genauigkeit für eine Mischung von Operationen, vergleichbar in der Geschwindigkeit mit Hardware-Arithmetik für viele Anwendungen. Algorithmen für 8-Bit- und 16-Bit-Implementierungen von FOCUS sind enthalten."}
{"DOCID": "3132", "TEXT": "Experimente mit einigen Algorithmen, die zentrale Lösungen für die Musterklassifizierung finden: Bei der Zwei-Klassen-Mustererkennung ist es eine Standardtechnik, einen Algorithmus zu haben, der Hyperebenen findet, der die zwei Klassen in einem linear trennbaren Trainingssatz trennt. Die traditionellen Methoden finden eine Hyperebene, die alle Punkte in der anderen trennt, aber eine solche Hyperebene ist nicht notwendigerweise in dem leeren Raum zwischen den beiden Klassen zentriert. Da eine zentrale Hyperebene weder die eine noch die andere Klasse bevorzugt, sollte sie eine geringere Fehlerrate bei der Klassifizierung neuer Punkte haben und ist daher besser als eine nicht zentrale Hyperebene. Sechs Algorithmen zum Auffinden zentraler Hyperebenen werden an drei Datensätzen getestet. Obwohl häufig in der Praxis verwendet, ist der modifizierte Relaxationsalgorithmus sehr schlecht. Drei Algorithmen, die in der Arbeit definiert sind, werden als ziemlich gut befunden."}
{"DOCID": "3133", "TEXT": "Logik und semantische Netze: Es wird eine erweiterte Form semantischer Netze definiert, die als syntaktische Variante der Klauselform der Logik angesehen werden kann. Das erweiterte semantische Netz ist aufgrund seiner Beziehung zur Logik mit einer präzisen Semantik, Schlußregeln und einer prozeduralen Interpretation ausgestattet. Andererseits stellen wir, indem wir semantische Netze als abstrakte Datenstruktur für die Repräsentation von Klauseln betrachten, einen Theorem-Beweis mit einem potenziell nützlichen Indexierungsschema und einer Pfadverfolgungsstrategie zur Verfügung, um die Suche nach einem Beweis zu leiten."}
{"DOCID": "3134", "TEXT": "Die Verwendung von normalen Einmaleins für Informationsspeicherung und -wiedergewinnung: Dieses Papier beschreibt ein Verfahren für die Organisation und Wiedergewinnung von attributbasierten Informationssystemen, wobei das normale Einmaleins als Verzeichnis für das Informationssystem verwendet wird. Algorithmen für die Organisation und den Abruf von Informationen werden beschrieben. Dieses Verfahren eignet sich besonders für Abfragen, die eine Gruppe von Informationselementen anfordern, die alle einen bestimmten Satz von Attributen (und möglicherweise auch einige andere Attribute) besitzen. Es werden mehrere Beispiele gegeben; die Ergebnisse hinsichtlich der Anzahl der Plattenzugriffe und des Plattenplatzes werden mit anderen gängigen Ansätzen verglichen. Es werden Algorithmen beschrieben, die die Angemessenheit des obigen Ansatzes für ein gegebenes Informationssystem bewerten. Für eine bestimmte Klasse von Informationssystemen ergibt das normale Einmaleins-Verfahren eine viel schnellere Wiedergewinnung mit einem sparsameren Raumbedarf als herkömmliche Systeme. Darüber hinaus enthält dieses Verfahren eine verbesserte Modifikation der invertierten Dateitechnik."}
{"DOCID": "3135", "TEXT": "Erkennung von dreidimensionalen Mustern von Atomen in chemischen Strukturen: Ein Algorithmus zur Erkennung von Vorkommen eines dreidimensionalen Musters von Objekten innerhalb einer größeren Struktur wird vorgestellt. Die vorgestellte Suchtechnik verwendet die geometrische Struktur des Musters, um Eigenschaften zu definieren, die von Kandidaten für den Abgleich verlangt werden. Dies ist in Fällen nützlich, in denen die Eigenschaften jedes Atoms einzeln betrachtet die Anzahl der Sätze möglicher Übereinstimmungen nicht angemessen begrenzen. Mehrere Anwendungen dieser Technik auf dem Gebiet der Chemie sind: (1) in der Pharmakologie: Suche nach einer gemeinsamen Konstellation von Atomen in Molekülen, die ähnliche biologische Aktivitäten besitzen; (2) in der Röntgenkristallographie: Anpassen einer Struktur oder eines Strukturfragments an einen Satz von Spitzen in der Elektronendichteverteilung einer Fourier-Karte; (3) in der chemischen Dokumentation; Abrufen der Strukturen, die spezifizierte Unterstrukturen enthalten, aus einer Datei."}
{"DOCID": "3136", "TEXT": "Preis-/Leistungsmuster von US-Computersystemen: Ökonometrische Modelle des US-Computermarktes wurden entwickelt, um die Beziehungen zwischen Systempreis und Hardwareleistung zu untersuchen. Einzelne Preis-/Leistungsmaße wie das „Grosch'sche Gesetz“ erweisen sich als so stark vereinfacht, dass sie nichtssagend sind. Multiple Regressionsmodelle, die Systemkosten als Funktion mehrerer Hardwareeigenschaften vorhersagen, zeigen jedoch eine Marktdichotomie. Auf der einen Seite gibt es einen stabilen, preislich vorhersehbaren Markt für größere Allzweck-Computersysteme. Der andere Markt ist der sich entwickelnde Markt für Computersysteme für kleine Unternehmen, ein relativ instabiler Markt mit geringer Preisvorhersagbarkeit."}
{"DOCID": "3137", "TEXT": "Eine Methodologie für den Entwurf verteilter Informationssysteme: Ein Makromodell eines verteilten Informationssystems wird vorgestellt. Das Modell beschreibt die wesentlichen Kosten der Nutzung eines Informationssystems aus Sicht des Endnutzers. Das Aufzeigen der Auswirkung verschiedener Design- und Betriebsparameter auf die Gesamtkosten pro Transaktion. Die Technik wird durch Anwendung auf den Entwurf eines interaktiven Transaktionsverarbeitungssystems veranschaulicht."}
{"DOCID": "3138", "TEXT": "Ein Aktualisierungsverfahren für mathematische Programmierung, das modifizierte gegebene Transformationen verwendet und auf LP-Probleme angewendet wird: Es wird ein effizientes und numerisch stabiles Verfahren für das Problem der Aktualisierung einer orthogonalen Zerlegung einer Matrix von Spalten- (oder Zeilen-) Vektoren präsentiert. Die Grundidee besteht darin, eine Spalte (oder Zeile) analog zum Hinzufügen einer zusätzlichen Datenzeile in einem linearen Problem der kleinsten Quadrate hinzuzufügen. Eine Spalte (oder Zeile) wird durch eine formale Skalierung mit der imaginären Einheit, -1, gefolgt von einer Addition der Spalte (oder Zeile) nach der Methode der kleinsten Quadrate entfernt. Der Eliminationsprozess für das Verfahren ist die sukzessive Anwendung der Givens-Transformation in modifizierter (effizienterer) Form. Diese Ideen werden mit einer Implementierung des überarbeiteten Simplex-Verfahrens veranschaulicht. Der Algorithmus ist ein Allzweckalgorithmus, der keine bestimmte Struktur oder Spärlichkeit in den Gleichungen berücksichtigt. Einige vorgeschlagene Berechnungstests zum Bestimmen von Vorzeichen verschiedener Steuerparameter in dem überarbeiteten Simplex-Algorithmus werden erwähnt. Eine einfache Methode zum Erstellen von Testfällen und einige Beispielrechenzeiten werden vorgestellt."}
{"DOCID": "3139", "TEXT": "Neue Verfahren zum Einfärben der Scheitelpunkte eines Graphen: Dieses Dokument beschreibt effiziente neue heuristische Verfahren zum Einfärben der Scheitelpunkte eines Graphen, die auf dem Vergleich der Grade und der Struktur eines Graphen beruhen. Es wird ein Verfahren entwickelt, das für bipartite Graphen exakt ist und ein wichtiger Bestandteil heuristischer Verfahren ist, um maximale Cliquen in allgemeinen Graphen zu finden. Schließlich wird ein exaktes Verfahren angegeben, das besser als der Randall-Brown-Algorithmus funktioniert und größere Graphen färben kann, und die neuen heuristischen Verfahren, die klassischen Verfahren und das exakte Verfahren werden verglichen."}
{"DOCID": "3140", "TEXT": "Soziale Prozesse und Beweise von Theoremen und Programmen: Es wird argumentiert, dass formale Verifikationen von Programmen, egal wie erhalten, in der Entwicklung der Informatik und Softwaretechnik nicht die gleiche Schlüsselrolle spielen werden wie Beweise in der Mathematik. Darüber hinaus erschweren das Fehlen von Kontinuität, die Unvermeidbarkeit von Änderungen und die Komplexität der Spezifikation erheblich vieler realer Programme die Rechtfertigung und Verwaltung des formalen Verifizierungsprozesses. Es wird davon ausgegangen, dass die Einfachheit der formalen Verifikation das Design der Programmiersprache nicht dominieren sollte."}
{"DOCID": "3141", "TEXT": "An Improved Algorithm for Decentralized Extrema-Finding in Circular Configurations of Processes: Dieser Hinweis stellt eine Verbesserung des LeLann-Algorithmus zum Finden des größten (oder kleinsten) einer Menge von eindeutig nummerierten Prozessen dar, die in einem Kreis angeordnet sind, in dem kein zentraler Controller existiert und der Die Anzahl der Prozesse ist a priori nicht bekannt. Dieser dezentralisierte Algorithmus verwendet eine Technik der selektiven Nachrichtenauslöschung, um eine durchschnittliche Anzahl von Nachrichtendurchläufen der Ordnung (n log n) anstelle von O(n2) zu erreichen."}
{"DOCID": "3142", "TEXT": "Verbraucherschwierigkeiten bei computergestützten Transaktionen: Eine empirische Untersuchung: Die Prävalenz, mit der Fehler bei den Endzielen eines computergestützten Prozesses auftreten können, wird bewertet. Wie viele und welche Fehler treten auf? Wie leicht lassen sie sich korrigieren? Wie reagieren die Verbraucher auf Fehler – auf das Versäumnis, sie zu korrigieren? Was können Entwickler großer Verwaltungspakete aus solchen Daten lernen? Die Ergebnisse zeigen, dass beim gegenwärtigen Stand der Technik ungefähr 40 Prozent der Personen (oder Haushalte), die durchschnittliche Kontakte mit unterschiedlichen Arten von Konten haben, einen oder mehrere Fehler pro Jahr erfahren. Achtzig Prozent beziehen sich auf die Abrechnung. Versuche, Fehler zu korrigieren, gestalteten sich oft schwierig und nicht immer erfolgreich. Es scheint einen Konflikt zwischen computerbenutzenden Organisationen und ihrer Öffentlichkeit zu geben. Auch die Rolle schlechter Managementpakete einschließlich schlechter Software wird aufgezeigt. Während die meisten Managementsysteme angemessen sein mögen, werfen die Ergebnisse der Umfrage Bedenken hinsichtlich der Aktualität und der Anzahl der Entwürfe sehr großer verknüpfter Programmpakete (wie beispielsweise EFT) auf."}
{"DOCID": "3143", "TEXT": "Argumentieren über Arrays: Es wird eine Vielzahl von Konzepten, Gesetzen und Notationen vorgestellt, die das logische Denken über Arrays erleichtern. Zu den grundlegenden Konzepten gehören Intervalle und ihre Partitionen, funktionale Beschränkung, Bilder, punktweise Erweiterung von Beziehungen, Ordnung, Einzelpunktvariation von Funktionen, verschiedene Äquivalenzbeziehungen für Array-Werte und Verkettung. Die Wirksamkeit dieser Ideen wird durch informelle Beschreibungen von Algorithmen für die binäre Suche und Zusammenführung und durch einen kurzen formalen Beweis veranschaulicht."}
{"DOCID": "3144", "TEXT": "Ein Modell für und Diskussion von Multi-Interpreter-Systemen: Ein Multi-Interpreter-System ist ein System, in dem Programme ausgeführt werden, indem sie von anderen Programmen interpretiert werden, die selbst entweder interpretiert werden können (d. h. verschachtelte Interpreter) oder direkt auf der Host-Maschine laufen . Das Modell zeigt die Anatomie von Interpretern und wie sich diese von Prozeduren unterscheiden, und zeigt Verbindungen zu Schutzdomänen und Mehrprozessorarchitekturen auf."}
{"DOCID": "3145", "TEXT": "Eine Implementierung von strukturierten Walk-Throughs beim Unterrichten der Cobol-Programmierung: Die Effektivität von strukturierten Walk-Throughs beim Unterrichten von einführenden Cobol-Programmierungen wurde empirisch mit einer Stichprobe von 215 Bachelor-Studiengängen der Betriebswirtschaftslehre bewertet. Die Cobol-Kenntnisse wurden durch eine Abschlussprüfung gemessen, bei der (a) die Kenntnis der Sprachregeln, (b) die Fähigkeit, ein Programm zu lesen und zu debuggen, und (c) die Fähigkeit, ein Programm zu schreiben, getestet wurde. Die Analyse der multiplen Kovarianz wurde verwendet, um die Testergebnisse für das Alter und die Ergebnisse für bedingtes Denken statistisch anzupassen. Die Ergebnisse bieten empirische Unterstützung für die Integration strukturierter Walk-Throughs in den Programmierlernprozess, um die Fähigkeiten der Schüler beim Schreiben von Cobol-Programmen effektiver zu entwickeln."}
{"DOCID": "3146", "TEXT": "Ein akademisches Programm, das eine realistische Ausbildung in Softwareentwicklung bietet: Ein akademisches Programm am Harvey Mudd College, das so genannte Klinikprogramm, bringt Projekte aus der Industrie auf den Campus, die von Studententeams untersucht und gelöst werden. Das Ziel der Klinik ist es, Studenten, die in kleinen Teams unter sorgfältiger Aufsicht der Fakultät arbeiten, die Möglichkeit zu geben, an realen Problemen von ausreichendem Ausmaß und Komplexität zu arbeiten. Im Rahmen dieses Programms können die Studierenden wesentliche Fähigkeiten des Software-Engineering wie Teamarbeit, Software-Projektmanagement, Software-Design-Methodik und Kommunikationsfähigkeiten in einer realistischen Umgebung erwerben. Beispielhafte Softwareprojekte der Klinik werden beschrieben. Die bisherigen Erfahrungen haben gezeigt, dass das Programm einen gangbaren Übergang von der akademischen in die industrielle Welt darstellt."}
{"DOCID": "3147", "TEXT": "Ein Modell zur Automatisierung des Datei- und Programmdesigns in Geschäftsanwendungssystemen: In diesem Beitrag wird ein Modell zum Finden einer effizienten Implementierung eines Geschäftsanwendungssystems diskutiert, dessen logische Spezifikationen im Voraus festgelegt wurden. Das Modell betrachtet das Datei- und Programmdesign als Problem der systematischen Koordinierung der Konfigurationen von Datensätzen und Berechnungen. Es verwendet eine direkte Suchtechnik, um Aggregationen von Berechnungen, Aggregationen von Datensätzen, Gerät, Organisation und Schlüsselreihenfolge für jeden Datensatz, Schlüsselreihenfolge für jede Berechnung und Zugriffsmethode für jedes Datensatz-Berechnungs-Paar zu bestimmen. Obwohl Berechnungsergebnisse für ein Beispielproblem mit 54 Berechnungen und 49 Datensätzen präsentiert werden, ist der Hauptpunkt des Papiers, dass das zugrunde liegende Modell rechnerisch funktioniert und einfach genug ist, um an viele Dateientwurfssituationen angepasst zu werden."}
{"DOCID": "3148", "TEXT": "High-Level-Programmierung für verteiltes Rechnen: Die Programmierung für verteilte und andere lose gekoppelte Systeme ist ein Problem von wachsendem Interesse. Dieses Papier beschreibt einen Ansatz für verteiltes Rechnen auf der Ebene von Programmiersprachen für allgemeine Zwecke. Basierend auf primitiven Begriffen von Modul, Nachricht und Transaktionsschlüssel wird gezeigt, dass die Methodik unabhängig von bestimmten Sprachen und Maschinen ist. Es scheint nützlich zu sein, um eine Vielzahl von Aufgaben zu programmieren. Dies ist Teil eines ehrgeizigen Entwicklungsprogramms für fortgeschrittene Programmiersprachen, und es werden auch Beziehungen zu anderen Aspekten des Projekts erörtert."}
{"DOCID": "3149", "TEXT": "Die zyklische Ordnungseigenschaft von Scheitelpunkten als Hilfsmittel bei der Szenenanalyse: Eine zyklische Ordnungseigenschaft wird für Körper definiert, die durch glatt gekrümmte Flächen begrenzt sind. Es hat sich gezeigt, dass die Eigenschaft zum Analysieren von Bildern solcher Körper nützlich ist, insbesondere wenn die aus den Bildern extrahierten Liniendaten unvollkommen sind. Diese Eigenschaft erweitert zuvor bekannte grammatikalische Regeln, die die Existenz von dreidimensionalen Körpern bestimmen, die gegebenen zweidimensionalen Linienstrukturdaten entsprechen."}
{"DOCID": "3150", "TEXT": "Jenseits von Programmiersprachen: Mit zunehmender Reife der Computertechnologie führt unsere wachsende Fähigkeit, große Systeme zu erstellen, zu grundlegenden Veränderungen in der Art der Programmierung. Gegenwärtige Programmiersprachenkonzepte werden nicht angemessen sein, um Systeme mit der Komplexität zu erstellen und zu warten, die für die Aufgaben erforderlich ist, die wir versuchen. Genauso wie Hochsprachen es dem Programmierer ermöglichten, den Feinheiten des Auftragscodes einer Maschine zu entkommen, können höhere Programmiersysteme die Mittel bereitstellen, um komplexe Systeme und Komponenten zu verstehen und zu manipulieren. Um solche Systeme zu entwickeln, müssen wir unsere Aufmerksamkeit von der detaillierten Spezifikation von Algorithmen auf die Beschreibung der Eigenschaften der Pakete und Objekte lenken, mit denen wir bauen. Dieses Papier analysiert einige der Mängel von Programmiersprachen, wie sie jetzt existieren, und legt einige mögliche Richtungen für zukünftige Forschung dar."}
{"DOCID": "3151", "TEXT": "Ein optimaler Echtzeitalgorithmus für planare konvexe Hüllen: Es wird ein Algorithmus für die Konstruktion der konvexen Hülle einer Menge von n Punkten in der Ebene in Echtzeit beschrieben. Unter Verwendung einer geeigneten Datenstruktur konstruiert der Algorithmus die konvexe Hülle durch aufeinanderfolgende Aktualisierungen, die jeweils Zeit O(log n) benötigen, wodurch eine Gesamtverarbeitungszeit O(n log n) erreicht wird."}
{"DOCID": "3152", "TEXT": "Speicherreorganisationstechniken für Matrixberechnungen in einer Paging-Umgebung: Um Matrizen zu multiplizieren und gleichzeitig die Anzahl der erforderlichen Seitenabrufe zu minimieren, ist es oft effizienter, die Daten in Submatrixform zu reorganisieren und Blockmultiplikation zu verwenden, anstatt die besten bekannten Algorithmen zu verwenden die die Matrizen in zeilen- (oder spalten-)orientierter Form gespeichert lassen. Es wird ein effizientes Verfahren zur Durchführung dieser Reorganisation angegeben. Dies ermöglicht auch die Ableitung einer asymptotisch besseren Schranke für die Multiplikation von in zeilenorientierter Form gegebenen Matrizen durch Anpassung der Technik von Strassen an die reorganisierten Daten. Das Reorganisations-/Blockmultiplikationsschema erweist sich als vorteilhaft für Matrizen und Seiten realistischer Größe; die Strassen-Adaption ist es nicht. Das erstere Schema erweist sich auch dann als vorteilhaft, wenn die Transponierung einer der Matrizen ohne zusätzliche Kosten verfügbar ist."}
{"DOCID": "3153", "TEXT": "Die Steuerung von Antwortzeiten in Mehrklassensystemen durch Speicherzuweisungen: Die Möglichkeit, Jobs unterschiedlicher Klassen durch Regulieren ihrer Speicherzuweisung unterschiedliche Dienstqualität zu geben, wird im Zusammenhang mit einem ausgelagerten Computersystem untersucht. Es werden zwei parametrisierte Algorithmen betrachtet, die den Hauptspeicher auf zwei Klassen von Jobs aufteilen. Zunächst wird ein geschlossenes System, bestehend aus einem Prozess oder und Paging- und Dateigeräten, mit einer festen Anzahl von Jobs untersucht, um optimale Grade der Mehrfachprogrammierung und den Anteil der jeder Klasse gewidmeten Prozessorzeit zu bestimmen. Unter Anwendung eines Dekompositionsansatzes und Behandlung des geschlossenen Systems als einzelner Server werden die Antwortzeiten in einem offenen System mit externen Ankünften untersucht. Das Ziel besteht darin, den Effekt der Speicherbelegungsparameter auf die erwarteten Antwortzeiten unter den beiden Algorithmen zu untersuchen. Numerische Lösungen und wirtschaftliche Untergrenzen für die erwarteten Reaktionszeiten als Funktionen der Steuerparameter werden erhalten. Eine Möglichkeit, die Ergebnisse auf Systeme mit mehr als zwei Jobklassen anzuwenden, wird aufgezeigt."}
{"DOCID": "3154", "TEXT": "Algorithmus = Logik + Kontrolle: Ein Algorithmus besteht aus einer logischen Komponente, die das zur Lösung von Problemen zu verwendende Wissen vorgibt, und einer Kontrollkomponente, die die Problemlösungsstrategien bestimmt, mit denen dieses Wissen verwendet wird. Die Logikkomponente bestimmt die Bedeutung des Algorithmus, während die Steuerkomponente nur seine Effizienz beeinflusst. Die Effizienz eines Algorithmus kann oft durch Verbesserung der Steuerkomponente erhöht werden, ohne die Logik des Algorithmus zu ändern. Wir argumentieren, dass Computerprogramme häufiger korrekt und leichter zu verbessern und zu modifizieren wären, wenn ihre Logik- und Steuerungsaspekte im Programmtext identifiziert und getrennt würden."}
{"DOCID": "3155", "TEXT": "Die Paradigmen der Programmierung"}
{"DOCID": "3156", "TEXT": "Berechnung von Zusammenhangskomponenten auf parallelen Computern: Wir stellen einen parallelen Algorithmus vor, der n2 Prozessoren verwendet, um die Zusammenhangskomponenten eines ungerichteten Graphen mit n Ecken in der Zeit O(log2n) zu finden. Eine Zeitgrenze von O(log2n) kann auch erreicht werden, wenn nur n$n/$log2n)) Prozessoren verwendet werden. Der Algorithmus kann verwendet werden, um den transitiven Abschluss einer symmetrischen Booleschen Matrix zu finden. Wir gehen davon aus, dass die Prozessoren Zugriff auf einen gemeinsamen Speicher haben. Ein gleichzeitiger Zugriff auf dieselbe Stelle ist für Abrufbefehle erlaubt, aber nicht für Speicherbefehle."}
{"DOCID": "3157", "TEXT": "Terminierung mit Multiset-Ordnungen beweisen: Ein gängiges Werkzeug zum Beweis der Terminierung von Programmen ist die Fundierte Menge, eine Menge, die so geordnet ist, dass sie keine unendlichen absteigenden Folgen zulässt. Der grundlegende Ansatz besteht darin, eine Terminierungsfunktion zu finden, die die Werte der Programmvariablen in einen wohlbegründeten Satz abbildet, so dass der Wert der Terminierungsfunktion während der gesamten Berechnung wiederholt reduziert wird. Allzu oft sind die erforderlichen Terminierungsfunktionen schwer zu finden und stehen in keinem Verhältnis zum betrachteten Programm. Multisets (Taschen) über einer gegebenen wohlbegründeten Menge S sind Mengen, die ein mehrfaches Vorkommen von Elementen aus S zulassen. Die gegebene Ordnung auf S induziert eine Ordnung auf den endlichen Multisets über S. Diese Multiset-Ordnung erweist sich als wohlbegründet. Die Multiset-Ordnung ermöglicht die Verwendung relativ einfacher und intuitiver Terminierungsfunktionen in ansonsten schwierigen Terminierungsbeweisen. Insbesondere wird die Multiset-Ordnung verwendet, um die Terminierung von Produktionssystemen, Programmen, die in Form von Sätzen von Umschreibregeln definiert sind, nachzuweisen."}
{"DOCID": "3158", "TEXT": "Sicheres Personal Computing in einem unsicheren Netzwerk: Es wird ein Verfahren zum Implementieren von sicherem Personal Computing in einem Netzwerk mit einer oder mehreren zentralen Einrichtungen vorgeschlagen. Das Verfahren verwendet eine Verschlüsselungsvorrichtung mit öffentlichem Schlüssel und Hardwareschlüssel. Jeder Benutzer ist für seine eigene Sicherheit verantwortlich und muss sich nicht auf die Sicherheit der zentralen Einrichtung oder der Kommunikationsverbindungen verlassen. Ein Benutzer kann vertrauliche Dateien sicher in der zentralen Einrichtung speichern oder vertrauliche Daten an andere Benutzer im Netzwerk übertragen."}
{"DOCID": "3159", "TEXT": "Weitere Bemerkung zur stabilen Aktualisierung von Mittelwert- und Standardabweichungsschätzungen"}
{"DOCID": "3160", "TEXT": "Rejuvenating Experimental Computer Science: Dieser Bericht basiert auf den Ergebnissen eines von der NSF gesponserten Workshops, der am 2. November 1978 in Wasington, D.C. stattfand. Die Co-Autoren des Berichts sind: Gordon Bell, Digital Equipment Corporation; Bernard A. Galler, Universität von Michigan; Patricia Goldberg, IBM Corporation; John Hamblen, Universität von Missouri in Rolla; Elliot Pinson, Bell Telephone Laboratories; und Ivan Sutherland, California Institute of Technology. An dem Workshop nahmen auch Vertreter der NSF und anderer Regierungsbehörden teil. Neben den Autoren haben eine Reihe weiterer Personen zum Inhalt dieses Berichts beigetragen. Zur Vorbereitung des ursprünglichen Workshops wurden alle promovierenden Informatik-Fakultäten des Landes um Kommentare und Anregungen zu den Problemen der experimentellen Informatik gebeten. Eine Version des aktuellen Berichts vom 15. Januar wurde an diese Abteilungen und an eine Reihe von Industrie- und Regierungsgruppen zur Kritik verteilt. Die Herausgeber und Autoren dieser endgültigen Fassung erkennen den Beitrag einer großen Anzahl anderer Personen in allen Phasen der Erstellung des Berichts dankbar an. $Anmerkung: Im Anschluss an diese Präsentation des Berichts gibt es ein vom ACM-Exekutivkomitee verfasstes Positionspapier zur Krise in der experimentellen Informatik.)"}
{"DOCID": "3161", "TEXT": "Eine Position des ACM-Exekutivkomitees zur Krise in der experimentellen Informatik"}
{"DOCID": "3162", "TEXT": "Zur Verbesserung der Worst-Case-Laufzeit des Boyer-Moore-String-Matching-Algorithmus: Es wird gezeigt, wie der Boyer-Moore-String-Matching-Algorithmus modifiziert werden kann, sodass seine Worst-Case-Laufzeit linear ist, selbst wenn mehrere Vorkommen des Musters im Text vorhanden sind ."}
{"DOCID": "3163", "TEXT": "Ein optimaler Einfügungsalgorithmus für einseitige höhenausgeglichene binäre Suchbäume: Ein Algorithmus zum Einfügen eines Elements in einen einseitigen höhenausgeglichenen (OSHB) binären Suchbaum wird vorgestellt. Der Algorithmus arbeitet in der Zeit O(log n), wobei n die Anzahl der Knoten im Baum ist. Dies stellt eine Verbesserung gegenüber den besten bisher bekannten Einfügungsalgorithmen von Hirschberg und Kosaraju dar, die Zeit O(log 2n) benötigen. Außerdem ist die O(log n)-Komplexität optimal. Frühere Ergebnisse haben gezeigt, dass das Löschen in einer solchen Struktur auch in O(log n)-Zeit durchgeführt werden kann. Somit gibt das Ergebnis dieser Arbeit eine negative Antwort auf die Frage, ob solche Bäume die ersten Beispiele ihrer Art sein sollten, bei denen das Löschen eine geringere Zeitkomplexität hat als das Einfügen. Darüber hinaus kann nun geschlussfolgert werden, dass das Einfügen, Löschen und Abrufen in OSHB-Bäumen innerhalb eines konstanten Faktors zur gleichen Zeit wie die entsprechenden Operationen für die allgemeineren AVL-Bäume durchgeführt werden können. Die Einfügungs- und Löschalgorithmen für OSHB-Bäume erscheinen jedoch viel komplizierter als die entsprechenden Algorithmen für AVL-Bäume."}
{"DOCID": "3164", "TEXT": "Progressive azyklische Digraphen – ein Werkzeug für Datenbankintegrität: Ein progressiver azyklischer Digraph (PAD)-Algorithmus akzeptiert Anfragen und hält einen Graphen in einem azyklischen Zustand. Wenn eine Anfrage einen Zyklus erzeugt, werden Knoten \"abgetrennt\", bis die neuen Knoten azyklisch eingegeben werden können. Dieser Vorgang ist in bestimmten Bereichen der Datenbankimplementierung wichtig, in denen Beschränkungen hinsichtlich der zulässigen Aktionssequenzen bestehen. Zwei PAD-Algorithmen werden vorgestellt; die eine verwendet eine einfache Pfadmatrixdarstellung und die andere eine Liste mit einem \"künstlichen Gradienten\". Experimente legen nahe, dass für große N die zweite erheblich schneller ist, obwohl beide asymptotisch O(NR) sind, wobei N die Anzahl der Knoten und R die erwartete Anzahl von Knoten ist, die entlang Pfaden von jedem gegebenen Knoten erreichbar sind."}
{"DOCID": "3165", "TEXT": "Approximation polygonaler Karten durch zellulare Karten: Die Approximation polygonaler thematischer Karten durch zellulare Karten, eine wichtige Operation in der geographischen Datenverarbeitung, wird analysiert. Die Datenorganisation, die zum Darstellen der polygonalen Karten verwendet wird, ist eine weit verbreitete segmentbasierte Datenstruktur, in der Klassenetiketten die Regionen identifizieren, die jedes Segment auf beiden Seiten begrenzen. Der vorgestellte Approximationsalgorithmus arbeitet mit einer solchen Organisation, wodurch die Notwendigkeit der Erkennung von Bereichsgrenzen entfällt. Jedes Segment wird nur einmal untersucht. Die Vielseitigkeit der neuen Organisation wird weiter durch den Überblick über Algorithmen zur Flächenberechnung und Punktaufnahme veranschaulicht. Der Algorithmus wird auf einen Satz von Bodenkarten angewendet, die mittels eines Koordinatendigitalisierers in eine computerlesbare Form umgewandelt wurden."}
{"DOCID": "3166", "TEXT": "Berechnung von Standardabweichungen: Genauigkeit: Vier Algorithmen zur numerischen Berechnung der Standardabweichung von (ungewichteten) Stichprobendaten werden analysiert. Zwei der Algorithmen sind in der Statistik- und Computerliteratur gut bekannt; die anderen beiden sind neue Algorithmen, die speziell für die automatische Berechnung gedacht sind. Unsere Diskussion ist erläuternd, wobei der Schwerpunkt darauf liegt, eine geeignete Definition von \"Genauigkeit\" zu erreichen. Jeder der vier Algorithmen wird auf die Bedingungen hin analysiert, unter denen er genau ist. Wir schließen daraus, dass alle vier Algorithmen genaue Antworten auf viele Probleme liefern werden, aber zwei der Algorithmen, einer neu und einer alt, sind bei schwierigen Problemen wesentlich genauer als die anderen beiden."}
{"DOCID": "3167", "TEXT": "Aktualisieren von Mittelwert- und Varianzschätzungen: Ein verbessertes Verfahren: Es wird ein Verfahren mit verbesserter Effizienz zum Aktualisieren des Mittelwerts und der Varianz von gewichteten Stichprobendaten angegeben, wenn ein zusätzlicher Datenwert in dem Satz enthalten ist. Es wird nachgewiesen, dass die Methode stabil und mindestens so genau ist wie die beste vorhandene Aktualisierungsmethode."}
{"DOCID": "3168", "TEXT": "Kommentar zu \"Eine optimale Auswertung boolescher Ausdrücke in einem Online-Abfragesystem.\""}
{"DOCID": "3169", "TEXT": "Hinweis zu \"Eine optimale Auswertung boolescher Ausdrücke in einem Online-Abfragesystem\"."}
{"DOCID": "3170", "TEXT": "Zum Korrektheitsbeweis eines Kalenderprogramms: Für ein einfaches Kalenderprogramm wird eine formale Spezifikation gegeben und die Herleitung und der Korrektheitsbeweis des Programms skizziert. Die Spezifikation ist leicht verständlich und ihre Korrektheit ist für den Menschen offensichtlich."}
{"DOCID": "3171", "TEXT": "Billig gemachte Zeilennummern: Es wird eine Technik für die Verwaltung von Zeilennummern während der Laufzeit beschrieben, die für Implementierungen von Hochsprachen verwendet werden soll. Unter geeigneten Umständen erfordert dieses Verfahren während der Ausführung des Programms absolut keinen Zeit- oder Raumaufwand."}
{"DOCID": "3172", "TEXT": "Ein Algorithmus zum Planen kollisionsfreier Wege zwischen polyedrischen Hindernissen: Dieses Dokument beschreibt einen Kollisionsvermeidungsalgorithmus zum Planen eines sicheren Weges für ein polyedrisches Objekt, das sich zwischen bekannten polyedrischen Objekten bewegt. Der Algorithmus transformiert die Hindernisse so, dass sie den Ort verbotener Positionen für einen beliebigen Referenzpunkt auf dem sich bewegenden Objekt darstellen. Eine Trajektorie dieses Referenzpunktes, die alle verbotenen Bereiche vermeidet, ist kollisionsfrei. Trajektorien werden gefunden, indem ein Netzwerk durchsucht wird, das für jeden Scheitelpunkt in den transformierten Hindernissen anzeigt, welche anderen Scheitelpunkte sicher erreicht werden können."}
{"DOCID": "3173", "TEXT": "Eine Psychologie des BASIC-Lernens: Dieses Papier befasst sich mit der Frage: Was weiß eine Person nach dem Erlernen der BASIC-Programmierung? Mehrere zugrunde liegende konzeptionelle Strukturen werden identifiziert: (1) eine Transaktion ist ein Ereignis, das im Computer auftritt und eine Operation an einem Objekt an einer Stelle beinhaltet, (2) eine Voranweisung ist eine Menge von Transaktionen, die einer Codezeile entsprechen, (3 ) Chunks sind häufig vorkommende Konfigurationen von Prästatements, die mehreren Codezeilen entsprechen."}
{"DOCID": "3174", "TEXT": "Passwortsicherheit: Eine Fallgeschichte: Dieses Dokument beschreibt die Geschichte des Entwurfs des Passwortsicherheitssystems auf einem Time-Sharing-System mit Fernzugriff. Das vorliegende Design war das Ergebnis der Abwehr beobachteter Versuche, in das System einzudringen. Das Ergebnis ist ein Kompromiss zwischen extremer Sicherheit und Benutzerfreundlichkeit."}
{"DOCID": "3175", "TEXT": "Brechen von Substitutions-Chiffren mit einem Relaxationsalgorithmus: Substitutions-Chiffren sind Codes, bei denen jeder Buchstabe des Alphabets einen festen Ersatz hat und sich die Wortteilungen nicht ändern. In diesem Beitrag wird das Problem des Brechens von Substitutions-Chiffren als probabilistisches Kennzeichnungsproblem dargestellt. Jedem Kennbuchstaben sind Wahrscheinlichkeiten für die Darstellung von Klartextbuchstaben zugeordnet. Diese Wahrscheinlichkeiten werden parallel für alle Codebuchstaben aktualisiert, wobei gemeinsame Buchstabenwahrscheinlichkeiten verwendet werden. Das Iterieren des Aktualisierungsschemas führt zu verbesserten Schätzungen, die schließlich zum Brechen der Chiffre führen. Das Verfahren wird erfolgreich auf zwei Beispiele angewendet."}
{"DOCID": "3176", "TEXT": "Speichern einer Sparse-Tabelle: Das Problem des Speicherns und Durchsuchens großer Sparse-Tabellen ist in der Informatik allgegenwärtig. Die Standardtechnik zum Speichern solcher Tabellen ist Hashing, aber Hashing hat im schlimmsten Fall eine schlechte Leistung. Wir schlagen ein gutes Worst-Case-Verfahren zum Speichern einer statischen Tabelle mit n Einträgen vor, von denen jeder eine ganze Zahl zwischen 0 und N - 1 ist. Das Verfahren erfordert 0(n) w Speicherworte und ermöglicht O(logn N) Zugriffszeit. Obwohl unsere Methode in der Praxis etwas kompliziert zu verwenden ist, zeigt unsere Analyse, warum ein einfacherer Algorithmus, der zum Komprimieren von LR-Parsing-Tabellen verwendet wird, so gut funktioniert."}
{"DOCID": "3177", "TEXT": "How to Share a Secret: In diesem Aufsatz zeigen wir, wie man Daten D so in n Teile aufteilt, dass D aus beliebigen k Teilen leicht rekonstruierbar ist, aber selbst vollständige Kenntnis von k - 1 Teilen keinerlei Informationen über D preisgibt. Dies Die Technik ermöglicht den Aufbau robuster Schlüsselverwaltungsschemata für kryptografische Systeme, die sicher und zuverlässig funktionieren können, selbst wenn Unglücksfälle die Hälfte der Teile zerstören und Sicherheitsverletzungen alle bis auf einen der verbleibenden Teile aufdecken."}
{"DOCID": "3178", "TEXT": "Einführung in das EFT-Symposium"}
{"DOCID": "3179", "TEXT": "Überblick über das EFT-Symposium: Es wird zunehmend anerkannt, dass groß angelegte Technologien wie EFT das Potenzial haben, bei der Lösung aktueller gesellschaftlicher Probleme zu helfen. Diese Technologien erzeugen jedoch auch Probleme. Dieses Symposium präsentiert ausgewählte Beiträge einer Konferenz, die herausfinden wollte, was derzeit über die Auswirkungen von EFT auf die Gesellschaft bekannt ist und welche Forschungsarbeiten in der Zukunft erforderlich sind."}
{"DOCID": "3180", "TEXT": "Kosten des derzeitigen US-Zahlungssystems: Weder die Bankenbranche noch öffentliche Entscheidungsträger verfügen über gute Informationen zu den Vergleichskosten alternativer Zahlungssysteme wie Bargeld, Schecks, Kreditkarten und EFT-Transaktionen. Infolgedessen werden EFT-Systeme und -Dienste wahrscheinlich ohne eine gültige Bewertung implementiert, ob sie kostengerecht sind, nicht zuletzt aufgrund anderer Kriterien gerechtfertigt."}
{"DOCID": "3181", "TEXT": "Öffentlicher Schutz und Aufklärung mit EFT: Die Forschung hat die Existenz weit verbreiteter Fehlinformationen und mangelnden Wissens über EFT unter Unternehmen und Regierungen sowie Verbrauchern aufgedeckt. Folglich erfordert jede Anstrengung, eine sinnvolle Beteiligung der Öffentlichkeit an Entscheidungen über die Einführung von EFT-Systemen zu fördern, eine koordinierte Bildungsanstrengung von beträchtlichem Ausmaß. Darüber hinaus hat die Forschung Mängel im derzeitigen System zur Definition von Verantwortlichkeiten, Haftungen und Regressmöglichkeiten aufgedeckt. Dieser Artikel stellt mehrere mögliche Alternativen zur Verbesserung des derzeitigen Systems vor, aber es bedarf auch laufender Forschung, um sicherzustellen, dass die ergriffenen Maßnahmen auf die sich ändernde Umwelt und die Bedürfnisse der Verbraucher eingehen."}
{"DOCID": "3182", "TEXT": "Schwachstellen von EFTs gegenüber absichtlich verursachten Verlusten: Die Hypothese, dass Verbrauchern mit elektronischen Geldtransfersystemen (EFTs) eine größere Genauigkeit und Freiheit von Fehlern und Betrug geboten wird, wird im Lichte der technischen Möglichkeiten und des Potenzials des Computers zum Schutz vor versehentlichem und vorsätzlichem Handeln diskutiert Verluste verursacht. Obwohl die Nomenklatur für Wirtschaftsdelikte die gleiche bleibt wie für manuelle Hinterlegungs- und andere Finanzdienstleistungssysteme – zum Beispiel Betrug, Diebstahl, Unterschlagung – sind die Merkmale der Delikte neu. Die Veränderungen, die sich aus der beschleunigten Verwendung von EFTs und ihren kontinuierlichen technologischen Fortschritten ergeben, erweitern den Umfang der zu untersuchenden Sicherheitsfragen. Faktoren wie Backup-Anforderungen, behördliche und gesetzliche Maßnahmen sowie die Wirtschaftlichkeit machen es dringend erforderlich, sofort nach Lösungen für neu auftretende Schwachstellen im Zusammenhang mit EFTs zu suchen."}
{"DOCID": "3183", "TEXT": "Politik, Werte und EFT-Forschung: Anatomie einer Forschungsagenda: Es zeichnet sich ab, dass EFT-Systeme das Potenzial haben, das Zahlungs- und Geldtransfersystem in der amerikanischen Gesellschaft erheblich zu verändern. An dieser Entwicklung sind eine Reihe von Kräften und Akteuren beteiligt, und die Werte variieren je nach individueller und institutioneller Perspektive erheblich. Diese Wertekonflikte werden in einer sechsteiligen Forschungsagenda hervorgehoben: technologische Probleme bei EFT, Auswirkungen von EFT auf Menschen, wirtschaftliche Auswirkungen von EFT, Regulierung und Kontrolle von EFT sowie Bewertung und Überwachung von EFT-Systemen."}
{"DOCID": "3184", "TEXT": "Überarbeiteter Bericht über die algorithmische Sprache ALGOL 60: Der Bericht enthält eine vollständige, definierende Beschreibung der internationalen algorithmischen Sprache ALGOL 60. Dies ist eine Sprache, die geeignet ist, eine große Klasse numerischer Prozesse in einer Form auszudrücken, die ausreichend prägnant für eine direkte automatische Übersetzung in die Sprache von ist programmierte automatische Computer."}
{"DOCID": "3185", "TEXT": "Der bescheidene Programmierer: Wir werden eine viel bessere Programmierarbeit leisten, vorausgesetzt, wir gehen die Aufgabe mit voller Anerkennung ihrer enormen Schwierigkeit an, vorausgesetzt, wir bleiben bei bescheidenen und eleganten Programmiersprachen, vorausgesetzt, wir respektieren die dem menschlichen Verstand innewohnenden Grenzen und gehen Sie die Aufgabe als sehr bescheidene Programmierer an."}
{"DOCID": "3186", "TEXT": "GEHEN SIE ZU Erklärung Wird als schädlich angesehen"}
{"DOCID": "3187", "TEXT": "Zertifizierung des Algorithmus 271 (QUICKERSORT): QUICKERSORT kompiliert und ohne Korrektur durch den ALDEP-Übersetzer für den CDC 1604A laufen gelassen. Der Vergleich von durchschnittlichen Sortierelementen mit anderen kürzlich veröffentlichten Algorithmen demonstriert die überlegene Leistung von QUICKERSORT."}
{"DOCID": "3188", "TEXT": "Semiotik und Programmiersprachen: Ich habe meine Arbeit auf Semiotik und ihre Dreidimensionalität gestützt. Ich sollte an dieser Stelle hinzufügen, dass Sprache viele Aspekte hat und dass Pragmatik, Semantik und Syntaktik nicht notwendigerweise alle abdecken. Man kann jedoch die meisten Aspekte in die drei semiotische Dimension projizieren, und es scheint heute eine starke Tendenz dazu zu geben."}
{"DOCID": "3189", "TEXT": "Ein algebraischer Compiler für das FORTRAN-Assembler-Programm: Ein algebraischer Compiler wurde geschrieben, der dem FORTRAN-Assembler-Programm hinzugefügt werden kann. Dieser Compiler erweitert alle algebraischen Anweisungen um die folgenden Operationen: Addition, Subtraktion, Multiplikation und Division. Es kompiliert mehrstufige Ausdrücke in Fließkomma-Arithmetik (diese kann leicht in Festkomma umgewandelt werden)."}
{"DOCID": "3190", "TEXT": "Korrektur zu Economies of Scale und dem IBM System/360: Auf Seite 439 wird eine „typische“ Anweisungsmix-ID besprochen und das Timing wird wie auf dieser Seite beschrieben berechnet. Durch einen unerkannten Programmierfehler sind die Zeiten und die resultierende Regressionsgleichung leicht fehlerhaft."}
{"DOCID": "3191", "TEXT": "Generieren von Permutationen durch Nested Cycling: Der Zweck dieses Schreibens ist zweifach: Erstens, dem Tompkins-Paige-Algorithmus gebührende Anerkennung zu zollen, und zweitens, um einen Kommentar von Hill, CR Review 13891, zu \"Programs for Permutations\" klarzustellen."}
{"DOCID": "3192", "TEXT": "Die Lincoln-Tastatur – eine Schreibmaschinentastatur, die für Computereingabeflexibilität entwickelt wurde: Eine neue Schreibmaschinentastatur für direkte und Lochstreifen-Computereingaben wird die übliche kommerzielle Tastatur mit 88 Zeichen ersetzen, die für die Bequemlichkeit von Programmierern ausgewählt wurde. Von der Lincoln-Tastatur wird erwartet, dass sie die Programmierung von algorithmischen Prozessen erleichtert und eine beträchtliche Flexibilität bei Assembler- und Dienstprogrammroutinen ermöglicht."}
{"DOCID": "3193", "TEXT": ": Es wird an einer Formelcodiertechnik gearbeitet, die die direkte Eingabe von Formeln, die auf einem Flexo-Writer mit 84 Zeichen getippt wurden, in den Computer ermöglicht. Dieser Flexo-Writer wird für den automatischen Halbzeilenvorschub und -rückzug ohne Wagenrücklauf modifiziert, um ein vollständig allgemeines Unter- und Hochstellen zu ermöglichen."}
{"DOCID": "3194", "TEXT": "Ein nicht-heuristisches Programm zum Beweis elementarer logischer Theoreme: Der Aufsatz diskutiert Probleme beim Entwerfen eines Geräts, das in der Lage ist, zwischen Sprachereignissen zu unterscheiden, die normalerweise von Muttersprachlern einer bestimmten Sprache als unterschiedlich erkannt werden. Parallelen zwischen diesen Problemen und denen der chemischen Analytik werden aufgezeigt."}
{"DOCID": "3195", "TEXT": "Wiederholung der ACM-Richtlinien zur Standardisierung: Der regelmäßige Wechsel der Vorstandsmitglieder, Vorsitzenden und Redakteure, der normalerweise auf Wahlen folgt, führt gelegentlich zu einer Änderung der Richtlinien. Im Fall dieser Abteilung gibt es keine radikale Änderung, aber dies ist dennoch der richtige Zeitpunkt, um die Politik von ACM in Bezug auf die Standardisierung im Computerbereich zu wiederholen und zu unterstreichen."}
{"DOCID": "3196", "TEXT": "The Reactive Typewriter Program: 84-Zeichen-Tastatur mit alphabetischer Groß- und Kleinschreibung für gute Lesbarkeit. Wenn die Maschine nur auf einen einzigen Fall beschränkt ist, wird der Kleinbuchstabe bevorzugt. Die reaktive Schreibmaschine sollte tragbar sein. Die reaktive Schreibmaschine sollte austauschbar über jede kommerziell genutzte Telefon- (Sprach-) oder Telegrafen- (Telex-) Leitung oder über gemietete (nicht gewählte) Telegrafenleitungen betrieben werden."}
{"DOCID": "3197", "TEXT": "Strukturen von Normen verarbeitenden Organisationen im Computerbereich: In Übereinstimmung mit der Grundsatzerklärung der ACM [Comm. ACM 5 (Nov. 1962), 547-549] wurden die folgenden organisatorischen Beschreibungen bereitgestellt, um Standardisierungsaktivitäten zu beschreiben, die für Computer und Informationsverarbeitung relevant sind."}
{"DOCID": "3198", "TEXT": "Mikroprogrammierung, Emulatoren und Programmiersprachen: Das Problem, mit dem wir uns beschäftigt haben, ist das der Umwandlung von Sprache in Handlung – oder intellektueller Energie in mechanische Energie. Das Medium, das wir dafür verwenden, ist die Sprache und daher beschäftigen wir uns intensiv mit dem Thema Sprache. In den Bereichen der Sprachforschung haben wir uns zunächst auf die Formalisierung der Syntax und dann auf die Semantik konzentriert."}
{"DOCID": "3199", "TEXT": "ALGEM - Ein algebraischer Manipulator: ALGEM ist ein Paket von Unterprogrammen, die in Slip, FORTRAN IV und MAP 7094 II geschrieben wurden, um algebraische Ausdrücke zu manipulieren. Die grundlegenden algebraischen Operationen von Algem sind Additionen, Subtraktionen, Multiplikationen, Divisionen und Potenzierungen. Es ist in der Lage, eine beliebige Anzahl von Einzelbuchstabenvariablen und Variablenexponenten zu verarbeiten und den größten gemeinsamen Teiler zweier Polynome zu finden. Ebenfalls enthalten sind solche Funktionen wie Substitution, Differentiation, Bestimmung von Koeffizienten spezifizierter Variablen, Lösung einer linearen Gleichung, grundlegende E/A-Routinen sowie andere spezielle und arithmetische Routinen. Die Hauptinnovation von Algem gegenüber anderen Manipulatoren ist die Zuordnung von Typen zu allen Ausdrücken und die Verwendung eines Standard-Ordnungsverfahrens."}
{"DOCID": "3200", "TEXT": "Ein FORMAC-Programm zur Lösung von linearen Rand- und Anfangswertproblemen: Es wird ein Computerprogramm beschrieben, das entwickelt wurde, um Näherungslösungen für lineare Anfangs- und Randwertprobleme zu erhalten, die Differentialgleichungen beinhalten. Für jedes Problem umfasst die Eingabe in das Programm: 1. Die zu erfüllenden Gleichungen (in symbolischer Form) – die Differentialgleichungen, Gleichungen, die Hilfsbedingungen wie Randbedingungen usw. beschreiben. 2. Eine numerische Beschreibung der Bereiche, in denen jeder von Die Gleichungen sind zu erfüllen. 3. Sätze von Funktionen (in symbolischer Form), die in Linearkombinationen verwendet werden, um die Lösungsfunktionen zu approximieren. Wenn Sie die obigen Eingaben machen, erzeugt das Programm eine Annäherung an die Lösungen des spezifizierten Problems bezüglich der spezifizierten Funktionen, die im Sinne der kleinsten Quadrate optimal ist."}
{"DOCID": "3201", "TEXT": "Symbolische Manipulation von Poisson-Reihen: Poisson-Reihen von drei Variablen sind symbolisch durch einen Satz von formalen Subroutinen verwaltbar, die teilweise in der Maschinensprache IBM 7094 geschrieben sind, aber zur Verwendung in Fortran-Programmen in der FORTRAN-Sprache aufgerufen werden. Es wurden Anstrengungen unternommen, um diejenigen Operationen bereitzustellen, die von der Himmelsmechanik am meisten benötigt werden. Die Routinen sind vollständig in sich geschlossene Unterroutinen und erfordern nur Standard-Fortran-Eingabe/Ausgabe-Einheiten 5 und 6; Sie sind so konzipiert, dass Verschwendung und Überlaufen des Kernspeicherplatzes vermieden werden."}
{"DOCID": "3202", "TEXT": "MANIP: A Computer System for Algebra and Analytic Differentiation: Ein zu bearbeitender mathematischer Ausdruck wird in FORTRAN-ähnlicher Notation geschrieben und im Computer als eine Folge von BCD-Zeichen gespeichert, wobei alle Leerzeichen entfernt werden. Er kann beliebig kompliziert sein (Klammer ohne Einschränkung verschachtelt usw.), solange der gesamte Ausdruck (oder jede Folgeform) 5000 Zeichen nicht überschreitet. Das Problem, algebraische Operationen durchzuführen und analytische Ableitungen zu erhalten, wurde in das der Identifizierung und Manipulation von Zeichenfolgen übersetzt. Die dabei entstandenen Programme wurden in FORTRAN IV für einen CDC 3600 geschrieben und werden ausführlich besprochen."}
{"DOCID": "3203", "TEXT": "GRAD-Assistent – ​​Ein Programm zur symbolischen algebraischen Manipulation und Differentiation: Der derzeit in der Entwicklung befindliche General Recursive Algebra and Differentiation Assistant (GRAD-Assistent) ist ein Satz von LISP-Funktionen, die algebraische Ausdrücke symbolisch manipulieren und differenzieren. Es ist für die Verwendung bei Problemen ausgelegt, bei denen eine große Menge routinemäßiger Manipulationen von einem Programm ohne menschliches Eingreifen durchgeführt werden müssen. Daher muss GRAD notwendige Vereinfachungen ohne externe Anleitung erkennen. Während einige komplizierte Ausdrücke (insbesondere solche mit verschachtelten Radikalen und trigonometrischen Funktionen) der vorliegenden Version nicht vollständig weichen, hat sie sich in der Tat als sehr nützlich erwiesen."}
{"DOCID": "3204", "TEXT": "Ein Online-Programm für nicht-numerische Algebra: Das Ziel dieses Programms ist es, einen Schritt in Richtung des Entwurfs eines automatisierten mathematischen Assistenten zu machen. Einige Anforderungen an ein solches Programm sind: Es muss leicht zugänglich sein und das Ergebnis muss in angemessen kurzer Zeit erzielt werden. Dementsprechend ist das Programm für einen Time-Sharing-Computer geschrieben. Der Q-32-Computer der System Development Corporation, Santa Monica, Kalifornien, wurde ausgewählt, weil er auch über einen LISP 1.5-Compiler verfügte. Programmierung und Debugging wurden von einer entfernten Teletype-Konsole an der Stanford University durchgeführt."}